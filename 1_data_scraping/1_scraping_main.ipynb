{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import statements\n",
    "import urllib\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "from dateutil.parser import parse\n",
    "from dateutil import parser\n",
    "from collections import defaultdict,Counter\n",
    "import re\n",
    "import pickle\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import datetime\n",
    "import json\n",
    "\n",
    "os.chdir('/Users/yiweiluo/scientific-debates')\n",
    "from utils import get_fname,fulltext_exists#,soupify\n",
    "os.chdir('./1_data_scraping')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_google_res_stance(x):\n",
    "    if 'foxnews.com' in x:\n",
    "        return 'anti'\n",
    "    elif 'breitbart.com' in x:\n",
    "        return 'anti'\n",
    "    elif 'blaze.com' in x:\n",
    "        return 'anti'\n",
    "    elif 'pjmedia.com' in x:\n",
    "        return 'anti'\n",
    "    elif 'nationalreview.com' in x:\n",
    "        return 'anti'\n",
    "    elif 'dailycaller.com' in x:\n",
    "        return 'anti'\n",
    "    elif 'reason.com' in x:\n",
    "        return 'anti'\n",
    "    elif 'americanthinker.com' in x:\n",
    "        return 'anti'\n",
    "    elif 'redstate.com' in x:\n",
    "        return 'anti'\n",
    "    elif 'infowars.com' in x:\n",
    "        return 'anti'\n",
    "    else:\n",
    "        return 'pro'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "NYT_SECTIONS_TO_REMOVE = set(['/automobiles/','/autoreviews/','/autoshow/','/business/','/campaign-stops/',\n",
    "                          '/crosswords/',\n",
    "               '/booming/','/giving/','/gmcvb/','/jobs/','/lens/','/letters/','/newyorktoday/',\n",
    "               '/nutrition/','/sept-11-reckoning/','/smallbusiness/',\n",
    "               '/sunday-review/','/garden/','/arts/','/theater/','/sports/','/dining/','/books/','/weekinreview/','/your-money/',\n",
    "                         '/movies/','/fashion/','/technology/','/pageoneplus/','/travel/','/nytnow/',\n",
    "                         '/public-editor/','/education/','/learning/','/podcasts/','/style/','/t-magazine/',\n",
    "                         '/reader-center/','/awardsseason/','/briefing/','/dealbook/','/es/',\n",
    "                          '/greathomesanddestinations/','/interactive/','/media/',\n",
    "                         '/mutfund/','/obituaries/','/personaltech/','/realestate/',\n",
    "                          '/smarter-living/','/todayspaper/','/your-money/','/yourtaxes/',\n",
    "                             '/slideshow/','/interactive/'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "BLACKLIST_URL_STRS = set(['/tag/','/author/','/clips/','/podcasts/','/subject/','/authors/',\n",
    "                         '/category/','/person/','/category/','/shows/','/video/','/topic/',\n",
    "                         '/es/','/topics/','/de/','/tags/','/slideshow/',\n",
    "                         '/interactive/','/transcripts/','/headlines/'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "BLACKLIST_URL_INIT_STRS = set(['rss.','feeds.','rssfeeds.'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_rss(url):\n",
    "    for xx in BLACKLIST_URL_INIT_STRS:\n",
    "        if url[:len(xx)] == xx:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def is_blacklist(url):\n",
    "    for xx in BLACKLIST_URL_STRS:\n",
    "        if xx in url:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "def get_hostname(url, uri_type='both'):\n",
    "    \"\"\"Get the host name from the url\"\"\"\n",
    "    parsed_uri = urlparse(url)\n",
    "    if uri_type == 'both':\n",
    "        return '{uri.scheme}://{uri.netloc}/'.format(uri=parsed_uri)\n",
    "    elif uri_type == 'netloc_only':\n",
    "        return '{uri.netloc}'.format(uri=parsed_uri)\n",
    "\n",
    "def strip_url(url):\n",
    "    if url.startswith('http'):\n",
    "        url = re.sub(r'https?://', '', url)\n",
    "        #print(url)\n",
    "    if url.startswith('www.'):\n",
    "        url = re.sub(r'www.', '', url)\n",
    "    return url\n",
    "\n",
    "from urllib.error import URLError\n",
    "\n",
    "def soupify(url):\n",
    "        \n",
    "    try:\n",
    "        req = urllib.request.Request(url, headers={'User-Agent' : \"Magic Browser\"}) \n",
    "        con = urllib.request.urlopen( req )\n",
    "        html = con.read()\n",
    "        soup = BeautifulSoup(html,'html.parser')\n",
    "        return soup\n",
    "    except (URLError,TimeoutError) as e:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "google_cc_urls = pickle.load(open('google_search_res_climate_change.pkl','rb')) # domain, keyword, title, url, date\n",
    "new_anti_google_cc_urls = pickle.load(open('new_anti_google_search_res_climate_change.pkl','rb'))\n",
    "R_google_cc_urls = pickle.load(open('R_google_search_res_climate_change.pkl','rb'))\n",
    "mediacloud_cc_urls = pd.read_pickle('mediacloud_df.pkl') # ap_syndicated, domain, title, url, date\n",
    "reid_cc_urls = pd.read_pickle('reid_urls.pkl') # url only\n",
    "prev_urls = pd.read_pickle('filtered_all_url_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_urls = []\n",
    "filtered_titles = []\n",
    "filtered_dates = []\n",
    "filtered_domains = []\n",
    "filtered_stances = []\n",
    "filtered_topics = []\n",
    "filtered_is_AP = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in google_cc_urls:\n",
    "    for keyword in google_cc_urls[key]:\n",
    "        for item in google_cc_urls[key][keyword]:\n",
    "            url = strip_url(item[1])\n",
    "            if not is_rss(url) and not is_blacklist(url):\n",
    "                title = item[0]\n",
    "                date = item[2] if len(item) > 2 else None\n",
    "                stance = get_google_res_stance(url)\n",
    "                topic = 'cc'\n",
    "                is_AP = None\n",
    "\n",
    "                if ' | ' not in title:\n",
    "                    filtered_urls.append(url)\n",
    "                    filtered_titles.append(title)\n",
    "                    filtered_dates.append(date)\n",
    "                    filtered_domains.append(key)\n",
    "                    filtered_stances.append(stance)\n",
    "                    filtered_topics.append(topic)\n",
    "                    filtered_is_AP.append(is_AP)\n",
    "                    \n",
    "for key in new_anti_google_cc_urls:\n",
    "    for keyword in new_anti_google_cc_urls[key]:\n",
    "        for item in new_anti_google_cc_urls[key][keyword]:\n",
    "            url = strip_url(item[1])\n",
    "            if not is_rss(url) and not is_blacklist(url):\n",
    "                title = item[0]\n",
    "                date = item[2] if len(item) > 2 else None\n",
    "                stance = get_google_res_stance(url)\n",
    "                topic = 'cc'\n",
    "                is_AP = None\n",
    "\n",
    "                if ' | ' not in title:\n",
    "                    filtered_urls.append(url)\n",
    "                    filtered_titles.append(title)\n",
    "                    filtered_dates.append(date)\n",
    "                    filtered_domains.append(key)\n",
    "                    filtered_stances.append(stance)\n",
    "                    filtered_topics.append(topic)\n",
    "                    filtered_is_AP.append(is_AP)\n",
    "                    \n",
    "for key in R_google_cc_urls:\n",
    "    for keyword in R_google_cc_urls[key]:\n",
    "        for item in R_google_cc_urls[key][keyword]:\n",
    "            url = strip_url(item[1])\n",
    "            if not is_rss(url) and not is_blacklist(url):\n",
    "                title = item[0]\n",
    "                date = item[2] if len(item) > 2 else None\n",
    "                stance = 'anti'#get_google_res_stance(url)\n",
    "                topic = 'cc'\n",
    "                is_AP = None\n",
    "\n",
    "                if ' | ' not in title:\n",
    "                    filtered_urls.append(url)\n",
    "                    filtered_titles.append(title)\n",
    "                    filtered_dates.append(date)\n",
    "                    filtered_domains.append(key)\n",
    "                    filtered_stances.append(stance)\n",
    "                    filtered_topics.append(topic)\n",
    "                    filtered_is_AP.append(is_AP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ix in mediacloud_cc_urls.index:\n",
    "    row = mediacloud_cc_urls.loc[ix]\n",
    "    url = strip_url(row['url']) if 'http' in row['url'] else strip_url(row['guid'])\n",
    "    if not is_rss(url) and not is_blacklist(url):\n",
    "        title = row['clean_title']\n",
    "        date = row['publish_date']\n",
    "        domain = row['media_name']\n",
    "        stance = row['stance']\n",
    "        topic = row['topic']\n",
    "        is_AP = row['ap_syndicated']\n",
    "\n",
    "        if ' | ' not in title:\n",
    "            filtered_urls.append(url)\n",
    "            filtered_titles.append(title)\n",
    "            filtered_dates.append(date)\n",
    "            filtered_domains.append(domain)\n",
    "            filtered_stances.append(stance)\n",
    "            filtered_topics.append(topic)\n",
    "            filtered_is_AP.append(is_AP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in reid_cc_urls:\n",
    "    for url in reid_cc_urls[key][0].values:\n",
    "        url = strip_url(url)\n",
    "        if not is_rss(url) and not is_blacklist(url):\n",
    "            filtered_urls.append(url)\n",
    "            filtered_titles.append(None)\n",
    "            filtered_dates.append(None)\n",
    "            filtered_domains.append(key)\n",
    "            filtered_stances.append('pro')\n",
    "            filtered_topics.append('cc')\n",
    "            filtered_is_AP.append(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(17475, 9)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prev_cc_urls = prev_urls.loc[prev_urls['topic'] == 'cc']\n",
    "prev_cc_urls['is_AP'] = [None]*len(prev_cc_urls)\n",
    "prev_cc_urls.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.DataFrame({'url':filtered_urls,\n",
    "                              'title':filtered_titles,\n",
    "                              'date':filtered_dates,\n",
    "                              'domain':filtered_domains,\n",
    "                              'stance':filtered_stances,\n",
    "                              'topic':filtered_topics,\n",
    "                              'is_AP':filtered_is_AP})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(98892, 7)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df = combined_df.append(prev_cc_urls[combined_df.columns],\n",
    "                                 ignore_index=True)\n",
    "combined_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check consistency of coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_domain(x):\n",
    "    if x == 'Guardian US':\n",
    "        return 'guardian_us'\n",
    "    elif x == 'the_boston_globe':\n",
    "        return 'boston_globe'\n",
    "    elif 'washingtonpost.com' in x:\n",
    "        return 'wapo'\n",
    "    elif 'vox.com' in x:\n",
    "        return 'vox'\n",
    "    elif 'breitbart.com' in x:\n",
    "        return 'breitbart'\n",
    "    elif 'nytimes.com' in x:\n",
    "        return 'nyt'\n",
    "    elif 'motherjones.com' in x:\n",
    "        return 'mj'\n",
    "    elif x == 'democracy_now':\n",
    "        return 'dem_now'\n",
    "    elif 'foxnews.com' in x:\n",
    "        return 'fox'\n",
    "    elif 'buzzfeednews.com' in x or 'www.buzzfeed' in x:\n",
    "        return 'buzzfeed'\n",
    "    elif 'https://childrenshealthdefense.org/' in x:\n",
    "        return 'chd'\n",
    "    elif x == 'Daily Caller' or 'www.dailycaller' in x:\n",
    "        return 'daily_caller'\n",
    "    elif 'www.dailysignal' in x:\n",
    "        return 'daily_signal'\n",
    "    elif x == 'Washington Post':\n",
    "        return 'wapo'\n",
    "    elif 'theblaze.com' in x or x == 'the_blaze':\n",
    "        return 'blaze'\n",
    "    elif 'democracynow.org' in x:\n",
    "        return 'dem_now'\n",
    "    elif x == 'Grist':\n",
    "        return 'grist'\n",
    "    elif x == 'New York Times':\n",
    "        return 'nyt'\n",
    "    elif 'nationalreview.com' in x:\n",
    "        return 'nat_review'\n",
    "    elif 'thenation.com' in x:\n",
    "        return 'nation'\n",
    "    elif x == 'Breitbart':\n",
    "        return 'breitbart'\n",
    "    elif x == 'Christian Science Monitor':\n",
    "        return 'cs_monitor'\n",
    "    elif 'https://www.csmonitor/' in x:\n",
    "        return 'cs_monitor'\n",
    "    elif x == 'buzzfeed_news':\n",
    "        return 'buzzfeed'\n",
    "    elif x == 'washington_post':\n",
    "        return 'wapo'\n",
    "    elif x == 'FOX News':\n",
    "        return 'fox'\n",
    "    elif x == 'USA Today':\n",
    "        return 'usa_today'\n",
    "    elif x == 'Mother Jones':\n",
    "        return 'mj'\n",
    "    elif x == 'NBC News' or 'nbcnews.com' in x:\n",
    "        return 'nbc'\n",
    "    elif x == 'Democracy Now!':\n",
    "        return 'dem_now'\n",
    "    elif x == 'National Review':\n",
    "        return 'nat_review'\n",
    "    elif x == 'CNS News':\n",
    "        return 'cns'\n",
    "    elif x == 'Buzzfeed':\n",
    "        return 'buzzfeed'\n",
    "    elif x == 'The Nation':\n",
    "        return 'nation'\n",
    "    elif 'pjmedia' in x:\n",
    "        return 'pj'\n",
    "    elif 'pajamas_media' in x:\n",
    "        return 'pj'\n",
    "    elif x == 'pj' or x == 'pjmedia':\n",
    "        return 'pj'\n",
    "    elif 'www.americanthinker' in x:\n",
    "        return 'american_thinker'\n",
    "    elif 'www.redstate' in x:\n",
    "        return 'redstate'\n",
    "    elif 'www.infowars' in x:\n",
    "        return 'infowars'\n",
    "    elif 'www.wnd' in x:\n",
    "        return 'wnd'\n",
    "    elif 'www.nysun' in x:\n",
    "        return 'new_york_sun'\n",
    "    elif 'www.cnsnews' in x:\n",
    "        return 'cns'\n",
    "    elif 'www.realclearpolitics' in x:\n",
    "        return 'real_clear_politics'\n",
    "    elif 'www.newsmax' in x:\n",
    "        return 'newsmax'\n",
    "    elif 'www.newsbusters.org' in x:\n",
    "        return 'newsbusters'\n",
    "    elif 'www.unionleader' in x:\n",
    "        return 'unionleader'\n",
    "    elif 'www.townhall' in x:\n",
    "        return 'townhall'\n",
    "    elif 'www.hotair' in x:\n",
    "        return 'hot_air'\n",
    "    else:\n",
    "        return x.lower().strip().replace(' ','_').replace('.com','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df['domain'] = combined_df.domain.apply(standardize_domain)\n",
    "combined_df['domain'] = combined_df.domain.apply(standardize_domain) # do twice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.title = combined_df.title.apply(lambda x: x.strip().lower() if x \n",
    "                                           is not None else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(85112, 8)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df = combined_df.loc[~pd.isnull(combined_df.stance)]\n",
    "combined_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pro        57971\n",
       "anti       37918\n",
       "between     2411\n",
       "Name: stance, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stance_reg_dict = {'l':'pro','r':'anti','c':'between','pro':'pro','anti':'anti','between':'between'}\n",
    "combined_df['stance'] = combined_df.stance.apply(lambda x: stance_reg_dict[x])\n",
    "combined_df.stance.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_date(x):\n",
    "    if x is not None:\n",
    "        if type(x) == str:\n",
    "            x = x.replace('·','').strip()\n",
    "            try:\n",
    "                return parser.parse(x)\n",
    "            except ValueError:\n",
    "                #print(x)\n",
    "                return None\n",
    "        elif type(x) == datetime.datetime:\n",
    "            return x\n",
    "        else:\n",
    "            return x.to_pydatetime()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({datetime.datetime: 83658, NoneType: 14642})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df['date'] = combined_df['date'].apply(standardize_date)\n",
    "Counter([type(x) for x in combined_df.date])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98300"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "14642+83658"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dedup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(98300, 7)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df = combined_df.sort_values(['title'],axis=0)#,ignore_index=True)\n",
    "combined_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(85112, 7)\n"
     ]
    }
   ],
   "source": [
    "combined_df = combined_df.drop_duplicates(subset='url',keep='first')#,ignore_index=True)\n",
    "print(combined_df.shape)\n",
    "combined_df.to_pickle('temp_combined_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.to_pickle('temp_combined_df.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape full text, title, date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from newspaper import Article\n",
    "from newspaper import ArticleException\n",
    "from urllib.error import HTTPError\n",
    "from date_guesser import guess_date, Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "def get_guess_date(url):\n",
    "    req = urllib.request.Request(url, headers={'User-Agent' : \"Magic Browser\"}) \n",
    "    try:\n",
    "        con = urllib.request.urlopen( req )\n",
    "        html = con.read()\n",
    "        guess = guess_date(url=url,\n",
    "                           html=html)\n",
    "        return guess.date\n",
    "    except (HTTPError,TimeoutError,URLError) as e:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def newspaper_parse(url):\n",
    "    try:\n",
    "        article = Article(url)\n",
    "        article.download()\n",
    "        article.parse()\n",
    "        return (article.title,article.publish_date,\n",
    "                article.text.replace('\\n',' '))\n",
    "    except ArticleException:\n",
    "        return (None,None,None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "code_folding": [
     2
    ]
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "def get_fulltext(url,domain):\n",
    "    scraping_url = 'http://'+url\n",
    "    \n",
    "    stop_ix,title,text = None,None,None\n",
    "    if domain == 'alternet':\n",
    "        title,text = newspaper_parse(scraping_url)\n",
    "    elif domain == 'american_conservative':\n",
    "        title,text = newspaper_parse(scraping_url)\n",
    "        stop_ix = -1\n",
    "    elif domain == 'activistpost':\n",
    "        title,text = newspaper_parse(scraping_url)\n",
    "        stop_ix = -4\n",
    "    elif domain == 'american_thinker':\n",
    "        title,text = newspaper_parse(scraping_url)\n",
    "        stop_ix = -1\n",
    "    elif domain == 'the_atlanta_journal_constitution':\n",
    "        soup = soupify(scraping_url)\n",
    "        if soup is not None:\n",
    "            ps = soup.find('div',attrs={'class':'story-text clearfix'}).find_all('p')\n",
    "            text = ' '.join([p.text.replace('\\n',' ') for p in ps])\n",
    "            title = soup.find('div',attrs={'class':'tease__text'}).find('h1').text.strip()\n",
    "            stop_ix = -5\n",
    "    elif domain == 'bipartisanreport':\n",
    "        title,text = newspaper_parse(scraping_url)\n",
    "    elif domain == 'blaze':\n",
    "        title,text = newspaper_parse(scraping_url)\n",
    "        stop_ix = -2\n",
    "    elif domain == 'boston_globe':\n",
    "        title,text = newspaper_parse(scraping_url)\n",
    "        stop_ix = -2\n",
    "    elif domain == 'breitbart':\n",
    "        title,text = newspaper_parse(scraping_url)\n",
    "        stop_ix = -2\n",
    "    elif domain == 'buzzfeed':\n",
    "        title,text = newspaper_parse(scraping_url)\n",
    "        stop_ix = -1\n",
    "    elif domain == 'cbn':\n",
    "        title,text = newspaper_parse(scraping_url)\n",
    "    elif domain == 'cbs_news':\n",
    "        soup = soupify(scraping_url)\n",
    "        ps = soup.find('section',attrs={'class':'content__body'}).find_all('p')\n",
    "        text = ' '.join([p.text.replace('\\n',' ') for p in ps])\n",
    "        title = soup.find('header',attrs={'class':'content__header'}).find('h1').text.strip()\n",
    "    elif domain == 'charismanews':\n",
    "        title,text = newspaper_parse(scraping_url)\n",
    "        stop_ix = -14\n",
    "    elif domain == 'chd':\n",
    "        title,text = newspaper_parse(scraping_url)\n",
    "    elif domain == 'https://www.citizens.org/':\n",
    "        title,text = newspaper_parse(scraping_url)\n",
    "    elif domain == 'cns':\n",
    "        title,text = newspaper_parse(scraping_url)\n",
    "    elif domain == 'commdiginews':\n",
    "        title,text = newspaper_parse(scraping_url)\n",
    "    elif domain == 'conservative_review':\n",
    "        title,text = newspaper_parse(scraping_url)\n",
    "        stop_ix = -2\n",
    "    elif domain == 'conservative_treehouse':\n",
    "        title,text = newspaper_parse(scraping_url)\n",
    "        stop_ix = -2\n",
    "    elif domain == 'conservativedailynews':\n",
    "        title,text = newspaper_parse(scraping_url)\n",
    "        stop_ix = -4\n",
    "    elif domain == 'conservativefiringline':\n",
    "        title,text = newspaper_parse(scraping_url)\n",
    "        stop_ix = -10\n",
    "    elif domain == 'cs_monitor':\n",
    "        title,text = newspaper_parse(scraping_url)\n",
    "        stop_ix = -1\n",
    "    elif domain == 'daily_caller':\n",
    "        title,text = newspaper_parse(scraping_url)\n",
    "        stop_ix = -3\n",
    "    elif domain == 'daily_dot':\n",
    "        title,text = newspaper_parse(scraping_url)\n",
    "        stop_ix = -2\n",
    "    elif domain == 'www.dailysignal':\n",
    "        soup = soupify(scraping_url)\n",
    "        if soup is not None:\n",
    "            title = soup.find('h1').text.strip()\n",
    "            try:\n",
    "                ps = soup.find('div',attrs={'class':'tds-content'}).find_all('p')\n",
    "            except AttributeError:\n",
    "                ps = soup.find('div',attrs={'class':'amp-wp-article-content'}).find_all('p')\n",
    "            text = ' '.join([p.text.replace('\\n',' ') for p in ps])\n",
    "    elif domain == 'dallas_morning_news':\n",
    "        soup = soupify(scraping_url)\n",
    "        if soup is not None:\n",
    "            title = soup.find('h1').text.strip()\n",
    "            ps = soup.find('div',attrs={'itemprop':'articleBody'})\n",
    "            text = ' '.join([p.text.replace('\\n',' ') for p in ps])\n",
    "    elif domain == 'dem_now':\n",
    "        soup = soupify(scraping_url)\n",
    "        try:\n",
    "            ps = soup.find('div',attrs={'itemprop':'articleBody'}).find_all('p')\n",
    "        except AttributeError:\n",
    "            ps = soup.find('div',attrs={'class':'story_summary'}).find_all('p')\n",
    "        text = ' '.join([p.text.replace('\\n', ' ') for p in ps])\n",
    "    elif domain == 'drudgereport':\n",
    "        title,text = newspaper_parse(scraping_url)\n",
    "    elif domain == 'forbes':\n",
    "        soup = soupify(scraping_url)\n",
    "        if soup is not None:\n",
    "            try:\n",
    "                ps = soup.find('div',attrs={'class':'article-body fs-article fs-responsive-text current-article'}).find_all('p')\n",
    "                text = ' '.join([p.text.replace('\\n', ' ') for p in ps])\n",
    "                title = soup.find('h1').text.strip()\n",
    "            except AttributeError:\n",
    "                pass\n",
    "    elif domain == 'fox':\n",
    "        title,text = newspaper_parse(scraping_url)\n",
    "        stop_ix = -2\n",
    "    elif domain == 'gateway_pundit':\n",
    "        title,text = newspaper_parse(scraping_url)\n",
    "        stop_ix = -2\n",
    "    elif domain == 'gawker':\n",
    "        title,text = newspaper_parse(scraping_url)\n",
    "        stop_ix = -1\n",
    "    elif domain == 'grabien':\n",
    "        title,text = newspaper_parse(scraping_url)\n",
    "        stop_ix = -2\n",
    "    elif domain == 'grist':\n",
    "        title,text = newspaper_parse(scraping_url)\n",
    "    elif domain == 'guardian_us':\n",
    "        title,text = newspaper_parse(scraping_url)\n",
    "        stop_ix = -2\n",
    "    elif domain == 'hot_air':\n",
    "        title,text = newspaper_parse(scraping_url)\n",
    "        stop_ix = -2\n",
    "    elif domain == 'https://adultvaccinesnow.org/blog/':\n",
    "        title,text = newspaper_parse(scraping_url)\n",
    "    elif domain == 'https://immunizationevidence.org/featured_issues/':\n",
    "        title,text = newspaper_parse(scraping_url)\n",
    "        stop_ix = -2\n",
    "    elif domain == 'https://shotofprevention/':\n",
    "        title,text = newspaper_parse(scraping_url)\n",
    "        stop_ix = -1\n",
    "    elif domain == 'https://www.voicesforvaccines.org/blog/':\n",
    "        title,text = newspaper_parse(scraping_url)\n",
    "        stop_ix = -2\n",
    "    elif domain == 'https://icandecide.org/':\n",
    "        pass\n",
    "    elif domain == 'independentsentinel':\n",
    "        title,text = newspaper_parse(scraping_url)\n",
    "        stop_ix = -2\n",
    "    elif domain == 'infowars':\n",
    "        title,text = newspaper_parse(scraping_url)\n",
    "        stop_ix = -2\n",
    "    elif domain == 'inthesetimes':\n",
    "        title,text = newspaper_parse(scraping_url)\n",
    "    elif domain == 'libertyunyielding':\n",
    "        title,text = newspaper_parse(scraping_url)\n",
    "        stop_ix = -1\n",
    "    elif domain == 'mj':\n",
    "        title,text = newspaper_parse(scraping_url)\n",
    "        stop_ix = -2\n",
    "    elif domain == 'nat_review':\n",
    "        title,text = newspaper_parse(scraping_url)\n",
    "    elif domain == 'nation':\n",
    "        title,text = newspaper_parse(scraping_url)\n",
    "    elif domain == 'nbc':\n",
    "        soup = soupify(scraping_url)\n",
    "        ps = soup.find('div',attrs={'class':'article-body__content'}).\\\n",
    "        find_all('p',attrs={'class':'endmarkEnabled'})\n",
    "        text = ' '.join([p.text.replace('\\n',' ') for p in ps])\n",
    "        title = soup.find('h1').text.strip()\n",
    "    elif domain == 'msnbc':\n",
    "        soup = soupify(scraping_url)\n",
    "        ps = soup.find('div',attrs={'itemprop':'articleBody'}).find_all('p')\n",
    "        text = ' '.join([p.text.replace('\\n',' ') for p in ps])\n",
    "        title = soup.find('h1').text.strip()\n",
    "    elif domain == 'new_york_magazine':\n",
    "        title,text = newspaper_parse(scraping_url)\n",
    "        stop_ix = -2\n",
    "    elif domain == 'new_york_sun':\n",
    "        soup = soupify(scraping_url)\n",
    "        if soup is not None:\n",
    "            ps = soup.find('div',attrs={'itemprop':'articleBody'}).find_all('p')\n",
    "            text = ' '.join([p.text.replace('\\n',' ') for p in ps])\n",
    "            title = soup.find('h1').text.strip()\n",
    "    elif domain == 'newsbusters':\n",
    "        soup = soupify(scraping_url)\n",
    "        if soup is not None:\n",
    "            ps = soup.find('div',attrs={'class':'field-item'}).find_all('p')\n",
    "            text = ' '.join([p.text.replace('\\n',' ') for p in ps])\n",
    "            title = soup.find('h2').text.strip()\n",
    "    elif domain == 'www.newsbusters.org':\n",
    "        title,text = newspaper_parse(scraping_url)\n",
    "    elif domain == 'newsday':\n",
    "        soup = soupify(scraping_url)\n",
    "        if soup is not None:\n",
    "            title = soup.find('div',attrs={'class':'sticky'}).find('header').find('h1').text.strip()\n",
    "            ps = soup.find('div',attrs={'id':'contentAccess'}).find_all('p')\n",
    "            text = ' '.join([p.text.replace('\\n',' ') for p in ps])\n",
    "    elif domain == 'newsmax':\n",
    "        soup = soupify(scraping_url)\n",
    "        if soup is not None:\n",
    "            title = soup.find('h1',attrs={'itemprop':'headline'}).text.strip()\n",
    "            text = soup.find('div',attrs={'id':'mainArticleDiv'}).text.replace('\\n',' ')\n",
    "            #text = ' '.join([p.text.replace('\\n',' ') for p in ps])\n",
    "    elif domain == 'www.newsmax':\n",
    "        title,text = newspaper_parse(scraping_url)\n",
    "    elif domain == 'newsweek':\n",
    "        soup = soupify(scraping_url)\n",
    "        ps = soup.find('div',attrs={'class':'article-content'}).find_all('p')\n",
    "        text = ' '.join([p.text.replace('\\n', ' ') for p in ps])\n",
    "    elif domain == 'newswithviews':\n",
    "        title,text = newspaper_parse(scraping_url)\n",
    "        stop_ix = -10\n",
    "    elif domain == 'ny_post':\n",
    "        title,text = newspaper_parse(scraping_url)\n",
    "    elif domain == 'nyt':\n",
    "        try:\n",
    "            soup = soupify(scraping_url)\n",
    "            if soup is not None:\n",
    "                ps = soup.find('section',attrs={'itemprop':'articleBody'}).find_all('p')#,recursive=False)\n",
    "                text = ' '.join([p.text.replace('\\n', ' ') for p in ps])\n",
    "                stop_ix = -5\n",
    "        except HTTPError:\n",
    "            pass\n",
    "    elif domain == 'pajamas_media':\n",
    "        title,text = newspaper_parse(scraping_url)\n",
    "        stop_ix = -2\n",
    "    elif domain == 'patriotpost.us':\n",
    "        title,text = newspaper_parse(scraping_url)\n",
    "    elif domain == 'pj':\n",
    "        title,text = newspaper_parse(scraping_url)\n",
    "        stop_ix = -2\n",
    "    elif domain == 'https://physiciansforinformedconsent.org/':\n",
    "        soup = soupify(scraping_url)\n",
    "        ps = soup.find('div',attrs={'class':'entry-content'}).find_all('p',attrs={'class':'responsiveNews'})\n",
    "        text = ' '.join([p.text.replace('\\n', ' ') for p in ps])\n",
    "    elif domain == 'progressivestoday':\n",
    "        title,text = newspaper_parse(scraping_url)\n",
    "        stop_ix = -1\n",
    "    elif domain == 'quartz':\n",
    "        title,text = newspaper_parse(scraping_url)\n",
    "        stop_ix = -2\n",
    "    elif domain == 'rare.us':\n",
    "        title,text = newspaper_parse(scraping_url)\n",
    "        stop_ix = -2\n",
    "    elif domain == 'www.realclearpolitics':\n",
    "        soup = soupify(scraping_url)\n",
    "        #print('soup:',soup)\n",
    "        try:\n",
    "            ps = soup.find('div',attrs={'class':'article_body'}).find_all('p',recursive=False)\n",
    "            print('ps:',ps)\n",
    "            text = ' '.join([p.text.replace('\\n',' ') for p in ps])\n",
    "        except AttributeError:\n",
    "            try:\n",
    "                ps = soup.find('div',attrs={'id':'alpha'}).find_all('p')\n",
    "                text = ' '.join([p.text.replace('\\n',' ') for p in ps])\n",
    "            except AttributeError:\n",
    "                pass\n",
    "        \n",
    "        try:\n",
    "            title = soup.find('h2').text.strip()\n",
    "        except AttributeError:\n",
    "            pass\n",
    "    elif domain == 'real_clear_politics':\n",
    "        soup = soupify(scraping_url)\n",
    "        if soup is not None:\n",
    "            ps = soup.find('div',attrs={'class':'article-body-text'}).find_all('p')\n",
    "            text = ' '.join([p.text.replace('\\n',' ') for p in ps])\n",
    "            title = soup.find('h1').text.strip()\n",
    "\n",
    "    elif domain == 'reason':\n",
    "        title,text = newspaper_parse(scraping_url)\n",
    "        stop_ix = -3\n",
    "    elif domain == 'redstate':\n",
    "        title,text = newspaper_parse(scraping_url)\n",
    "        stop_ix = -1\n",
    "    elif domain == 'sgtreport':\n",
    "        title,text = newspaper_parse(scraping_url)\n",
    "        stop_ix = -1\n",
    "    elif domain == 'shoebat':\n",
    "        title,text = newspaper_parse(scraping_url)\n",
    "        stop_ix = -1\n",
    "    elif domain == 'sonsoflibertymedia':\n",
    "        title,text = newspaper_parse(scraping_url)\n",
    "        stop_ix = -1\n",
    "    elif domain == 'the_american_conservative':\n",
    "        title,text = newspaper_parse(scraping_url)\n",
    "        stop_ix = -2\n",
    "    elif domain == 'the_american_spectator':\n",
    "        title,text = newspaper_parse(scraping_url)\n",
    "    elif domain == 'the_columbus_dispatch':\n",
    "        title,text = newspaper_parse(scraping_url)\n",
    "    elif domain == 'the_nation':\n",
    "        title,text = newspaper_parse(scraping_url)\n",
    "        stop_ix = -2\n",
    "    elif domain == 'the_progressive':\n",
    "        title,text = newspaper_parse(scraping_url)\n",
    "    elif domain == 'therealnews':\n",
    "        soup = soupify(scraping_url)\n",
    "        if soup is not None:\n",
    "            title = soup.find('h1').text.strip()\n",
    "            try:\n",
    "                ps = soup.find('div',attrs={'id':'column-content'}).find_all('p')\n",
    "            except AttributeError:\n",
    "                ps = soup.find('div',attrs={'class':'fl-rich-text'}).find_all('p')\n",
    "            text = ' '.join([p.text.replace('\\n',' ') for p in ps])\n",
    "    elif domain == 'the_verge':\n",
    "        title,text = newspaper_parse(scraping_url)\n",
    "    elif domain == 'the_week':\n",
    "        title,text = newspaper_parse(scraping_url)\n",
    "        stop_ix = -2\n",
    "    elif domain == 'think_progress':\n",
    "        soup = soupify(scraping_url)\n",
    "        if soup is not None:\n",
    "            title = soup.find('h1').text.strip()\n",
    "            ps = soup.find('div',attrs={'class':'post__content'}).find_all('p')\n",
    "            text = ' '.join([p.text.replace('\\n',' ') for p in ps])\n",
    "    elif domain == 'townhall':\n",
    "        soup = soupify(scraping_url)\n",
    "        if soup is not None:\n",
    "            title = soup.find('h1').text.strip()\n",
    "            ps = soup.find('section',attrs={'id':'article-body'}).find_all('p',recursive=False)\n",
    "            text = ' '.join([p.text.replace('\\n',' ') for p in ps])\n",
    "    elif domain == 'unionleader':\n",
    "        pass\n",
    "    elif domain == 'usa_today':\n",
    "        title,text = newspaper_parse(scraping_url)\n",
    "        stop_ix = -2\n",
    "    elif domain == 'vax_safety_commission':\n",
    "        root_url = 'https://vaccinesafetycommission.org/studies.html'\n",
    "        soup = soupify(root_url)\n",
    "        panel_bodies = soup.find_all('div',attrs={'class':'panel-body'})\n",
    "        #print(len(panel_bodies))\n",
    "        text = \"\"\n",
    "        for pb in panel_bodies:\n",
    "            text += pb.text.strip()\n",
    "    elif domain == 'vice':\n",
    "        title,text = newspaper_parse(scraping_url)\n",
    "        stop_ix = -2\n",
    "    elif domain == 'https://www.voicesforvaccines.org/blog/':\n",
    "        title,text = newspaper_parse(scraping_url)\n",
    "    elif domain == 'vox':\n",
    "        title,text = newspaper_parse(scraping_url)\n",
    "        stop_ix = -2\n",
    "    elif domain == 'washington_times':\n",
    "        title,text = newspaper_parse(scraping_url)\n",
    "    elif domain == 'wapo':\n",
    "        title,text = newspaper_parse(scraping_url)\n",
    "        stop_ix = -2\n",
    "    elif domain == 'wnd':\n",
    "        soup = soupify(scraping_url)\n",
    "        if soup is not None:\n",
    "            title = soup.find('h1').text.strip()\n",
    "            ps = soup.find('div',attrs={'class':'entry-content'}).find_all('p')\n",
    "            text = ' '.join([p.text.replace('\\n',' ') for p in ps])\n",
    "    else:\n",
    "        print('Unknown domain:',domain)\n",
    "        with open('unknown_domains.txt','w') as f:\n",
    "            f.write(domain+'\\n')\n",
    "\n",
    "    if text is not None and len(text) > 0:\n",
    "        text = text.strip()\n",
    "        sent_tokens = sent_tokenize(text)\n",
    "\n",
    "        # Remove final few sentences (usually about social media)\n",
    "        sent_tokens = sent_tokens[:stop_ix]\n",
    "        text = ' '.join(sent_tokens)\n",
    "\n",
    "    return (title,text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def guess_title(url):\n",
    "    try:\n",
    "        soup = soupify(url)\n",
    "    except TimeoutError:\n",
    "        soup = None\n",
    "    if soup is not None:\n",
    "        titles = []\n",
    "        h1 = soup.find('h1')\n",
    "        h2 = soup.find('h2')\n",
    "        if h1 is not None:\n",
    "            titles.append(h1.text.strip())\n",
    "        if h2 is not None:\n",
    "            titles.append(h2.text.strip())\n",
    "        if len(titles) > 0:\n",
    "            return titles\n",
    "        else:\n",
    "            return None\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nyt             9363\n",
       "mj              3894\n",
       "breitbart       3161\n",
       "wapo            2920\n",
       "fox             2845\n",
       "                ... \n",
       "azcentral          8\n",
       "cbn                6\n",
       "cincinnati         5\n",
       "charismanews       3\n",
       "bgr                1\n",
       "Name: domain, Length: 132, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.domain.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(85112, 7)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=85112, step=1)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.reset_index(drop=True,inplace=True)\n",
    "combined_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "combined_df['guid'] = ['url_no_{}'.format(i) for i in range(len(combined_df))]\n",
    "#combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24174\n",
      "7025\n"
     ]
    }
   ],
   "source": [
    "existing_guids_set = set(glob.glob('url_meta/*.json'))\n",
    "missing_guids = [x for x in combined_df.guid.values[:last_ix] \n",
    "                 if 'url_meta/{}.json'.format(x) not in existing_guids_set]\n",
    "print(len(existing_guids_set),len(missing_guids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Int64Index([   80,   152,   266,   289,   294,   302,   315,   317,   321,\n",
       "               327,\n",
       "             ...\n",
       "             31154, 31155, 31163, 31167, 31169, 31170, 31171, 31176, 31177,\n",
       "             31192],\n",
       "            dtype='int64', length=7025), (7025, 8))"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_guids_df = combined_df.loc[combined_df.guid.isin(missing_guids)]\n",
    "missing_guids_df.index,missing_guids_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1900\n",
      "dailykos.com/story/2014/03/09/1283109/-Book-review-Capitalism-and-climate-change\n",
      "Length existing: 24985\n",
      "Length missing: 6214\n",
      "2000\n",
      "apnews.myway.com/article/20150116/us-sci--hottest_year-b64ea00652.html\n",
      "Length existing: 25011\n",
      "Length missing: 6188\n",
      "2100\n",
      "startribune.com/nation/331193571.html\n",
      "Length existing: 25033\n",
      "Length missing: 6166\n",
      "2200\n",
      "sacbee.com/news/local/transportation/article236925038.html#storylink=rss\n",
      "Length existing: 25039\n",
      "Length missing: 6160\n",
      "2300\n",
      "kansascity.com/2011/02/15/2656343/canada-pipeline-deal-too-costly.html#storylink=rss\n",
      "Length existing: 25076\n",
      "Length missing: 6123\n",
      "2400\n",
      "chicago.suntimes.com/environment/william-nordhaus-donald-trump-carbon-tax-renewed-attention-climate-change/\n",
      "Length existing: 25092\n",
      "Length missing: 6107\n",
      "2500\n",
      "sacbee.com/2013/04/08/5324980/chiles-codelco-begins-exports.html#mi_rss=Wire%20World%20News\n",
      "Length existing: 25128\n",
      "Length missing: 6071\n",
      "2600\n",
      "forbes.com/sites/stratfor/2014/08/19/chinas-shale-production-falls-short-but-goals-remain-in-place/\n",
      "Length existing: 25156\n",
      "Length missing: 6043\n",
      "2700\n",
      "thinkprogress.org.feedsportal.com/c/34726/f/638927/s/26b16afa/l/0Lthinkprogress0Borg0Cclimate0C20A120C120C170C13432310Ccleaning0Eup0Ecarbon0Epollution0E10A10C/story01.htm\n",
      "Length existing: 25180\n",
      "Length missing: 6019\n",
      "2800\n",
      "realclearpolitics.com/articles/2019/08/23/climate_change_divides_dems_as_dnc_plots_2020_strategy_141086.html\n",
      "Length existing: 25214\n",
      "Length missing: 5985\n",
      "2900\n",
      "forbes.com/sites/robertbradley/2016/09/23/climate-exaggeration-is-backfiring/\n",
      "Length existing: 25258\n",
      "Length missing: 5941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000\n",
      "thinkprogress.org.feedsportal.com/c/34726/f/638927/s/2765d615/l/0Lthinkprogress0Borg0Cclimate0C20A130C0A10C10A0C14210A310Cclimate0Einformed0Edevelopment0Ehow0Eto0Erebuild0Ein0Ea0Ewarming0Eworld0C/story01.htm\n",
      "Length existing: 25290\n",
      "Length missing: 5909\n",
      "3100\n",
      "forbes.com/sites/kensilverstein/2013/10/05/political-discord-heightens-as-coal-sector-revels-in-latest-conquest/\n",
      "Length existing: 25301\n",
      "Length missing: 5898\n",
      "3200\n",
      "neighbors.denverpost.com/viewtopic.php?p=2973013#p2973013\n",
      "Length existing: 25311\n",
      "Length missing: 5888\n",
      "3300\n",
      "neighbors.denverpost.com/viewtopic.php?p=2780872#p2780872\n",
      "Length existing: 25311\n",
      "Length missing: 5888\n",
      "3400\n",
      "startribune.com/bios/441394853.html\n",
      "Length existing: 25323\n",
      "Length missing: 5876\n",
      "3500\n",
      "sun-sentinel.com/fl-pollution-crackdown-palm-20151030-story.html\n",
      "Length existing: 25366\n",
      "Length missing: 5833\n",
      "3600\n",
      "chicagotribune.com/ct-dakota-access-protest-service-preparation-20170328-story.html\n",
      "Length existing: 25386\n",
      "Length missing: 5813\n",
      "3700\n",
      "therealnews.com/idirect.php?i=21465\n",
      "Length existing: 25404\n",
      "Length missing: 5795\n",
      "3800\n",
      "sacbee.com/news/politics-government/article120322798.html#storylink=rss\n",
      "Length existing: 25442\n",
      "Length missing: 5757\n",
      "3900\n",
      "startribune.com/politics/national/402878886.html\n",
      "Length existing: 25469\n",
      "Length missing: 5730\n",
      "4000\n",
      "tampabay.com/opinion/columns/article1210993.ece\n",
      "Length existing: 25500\n",
      "Length missing: 5699\n",
      "4100\n",
      "feedproxy.google.com/~r/staradvertiser_rss/~3/u5Ic-KdSppQ/20130811__Earth_will_long_suffer_from_humans_impact.html\n",
      "Length existing: 25530\n",
      "Length missing: 5669\n",
      "4200\n",
      "forbes.com/sites/alanohnsman/2017/01/04/electric-bus-maker-proterra-raises-further-140-million-to-boost-production/\n",
      "Length existing: 25550\n",
      "Length missing: 5649\n",
      "4300\n",
      "commondreams.org/headline/2013/01/31-7\n",
      "Length existing: 25588\n",
      "Length missing: 5611\n",
      "4400\n",
      "chron.com/news/science/article/Environmental-issues-top-major-legislative-6120501.php\n",
      "Length existing: 25633\n",
      "Length missing: 5566\n",
      "4500\n",
      "startribune.com/politics/national/501639361.html\n",
      "Length existing: 25656\n",
      "Length missing: 5543\n",
      "4600\n",
      "sacbee.com/2013/09/11/5726614/eu-lawmakers-reduce-use-of-food.html#mi_rss=Wire%20World%20News\n",
      "Length existing: 25671\n",
      "Length missing: 5528\n",
      "4700\n",
      "forbes.com/forbes/2010/0118/americas-best-company-10-exelon-utility-tax-carbon-windfall.html#533dff1a7a22\n",
      "Length existing: 25707\n",
      "Length missing: 5492\n",
      "4800\n",
      "mysanantonio.com/news/texas/article/Exxon-profit-slips-in-the-fourth-quarter-15019323.php\n",
      "Length existing: 25725\n",
      "Length missing: 5474\n",
      "4900\n",
      "forbes.com/sites/jamesconca/2017/01/22/white-house-begins-purging-climate-change-science/#249339251d5b\n",
      "Length existing: 25742\n",
      "Length missing: 5457\n",
      "5000\n",
      "nydailynews.com/autos/latest-reviews/first-drive-2019-ram-1500-limited-v8-review-article-1.3876423\n",
      "Length existing: 25762\n",
      "Length missing: 5437\n",
      "5100\n",
      "startribune.com/local/stpaul/39243237.html\n",
      "Length existing: 25793\n",
      "Length missing: 5406\n",
      "5200\n",
      "forbes.com/sites/tomkonrad/2013/10/25/four-green-dividend-stocks-that-ipod-in-2013/\n",
      "Length existing: 25824\n",
      "Length missing: 5375\n",
      "5300\n",
      "thinkprogress.org/2009/05/15/armey-soda/\n",
      "Length existing: 25846\n",
      "Length missing: 5353\n",
      "5400\n",
      "forbes.com/sites/uhenergy/2016/02/16/galactic-travel-or-a-trip-to-the-mall-its-all-about-energy/\n",
      "Length existing: 25882\n",
      "Length missing: 5317\n",
      "5500\n",
      "sfgate.com/news/world/article/Germany-Climate-will-last-longer-than-Trump-11209321.php\n",
      "Length existing: 25909\n",
      "Length missing: 5290\n",
      "5600\n",
      "kansascity.com/2011/02/09/2642656/global-warming-fix-heats-up-hearing.html#storylink=rss\n",
      "Length existing: 25947\n",
      "Length missing: 5252\n",
      "5700\n",
      "startribune.com/politics/national/421707863.html\n",
      "Length existing: 25977\n",
      "Length missing: 5222\n"
     ]
    }
   ],
   "source": [
    "for ix in range(1872,len(missing_guids_df)):\n",
    "    row = missing_guids_df.iloc[ix]\n",
    "    url = row['url']\n",
    "    scrape_url = 'https://'+url\n",
    "    res = newspaper_parse(scrape_url)\n",
    "    #if res[0] is not None:\n",
    "    title = res[0]\n",
    "    date = res[1]\n",
    "    if title is None:\n",
    "        title = guess_title(scrape_url)\n",
    "    if date is None:\n",
    "        date = get_guess_date(scrape_url)\n",
    "    if title is None and date is None:\n",
    "        pass\n",
    "    else:\n",
    "        json_name = row['guid']\n",
    "        with open(os.path.join('url_meta',json_name+'.json'),'w') as f:\n",
    "            json_object = json.dumps({\n",
    "                    \"title\":title,\n",
    "                    \"date\":date.isoformat() if date is not None else None,\n",
    "                    \"text\":res[2]\n",
    "            }, indent = 4) \n",
    "            f.write(json_object)\n",
    "    if ix % 100 == 0:\n",
    "        print(ix)\n",
    "        print(url)\n",
    "        existing_guids_set = set(glob.glob('url_meta/*.json'))\n",
    "        print('Length existing:',len(existing_guids_set))\n",
    "        missing_guids = [x for x in combined_df.guid.values[:last_ix] \n",
    "                         if 'url_meta/{}.json'.format(x) not in existing_guids_set]\n",
    "        print('Length missing:',len(missing_guids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1871,\n",
       " 'https://midwestdemocracy.com/articles/blog-watch-friday-may-11/#storylink=rss')"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ix,scrape_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "get_guess_date(scrape_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "article = Article(scrape_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "article.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TimeoutError",
     "evalue": "[Errno 60] Operation timed out",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTimeoutError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-138-95e0fabd43de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msoup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoupify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscrape_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-98-b3675e16f7c7>\u001b[0m in \u001b[0;36msoupify\u001b[0;34m(url)\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mreq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'User-Agent'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m\"Magic Browser\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mcon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mreq\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0mhtml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0msoup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhtml\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'html.parser'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    529\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mprocessor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mmeth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36mhttp_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m             response = self.parent.error(\n\u001b[0;32m--> 641\u001b[0;31m                 'http', request, response, code, msg, hdrs)\n\u001b[0m\u001b[1;32m    642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36merror\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    561\u001b[0m             \u001b[0mhttp_err\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 563\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_chain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    564\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    501\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 503\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    504\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36mhttp_error_302\u001b[0;34m(self, req, fp, code, msg, headers)\u001b[0m\n\u001b[1;32m    753\u001b[0m         \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    754\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 755\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    756\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m     \u001b[0mhttp_error_301\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhttp_error_303\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhttp_error_307\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhttp_error_302\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0mreq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 525\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    526\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         \u001b[0;31m# post-process response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(self, req, data)\u001b[0m\n\u001b[1;32m    541\u001b[0m         \u001b[0mprotocol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m         result = self._call_chain(self.handle_open, protocol, protocol +\n\u001b[0;32m--> 543\u001b[0;31m                                   '_open', req)\n\u001b[0m\u001b[1;32m    544\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    501\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 503\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    504\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36mhttps_open\u001b[0;34m(self, req)\u001b[0m\n\u001b[1;32m   1358\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mhttps_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1359\u001b[0m             return self.do_open(http.client.HTTPSConnection, req,\n\u001b[0;32m-> 1360\u001b[0;31m                 context=self._context, check_hostname=self._check_hostname)\n\u001b[0m\u001b[1;32m   1361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1362\u001b[0m         \u001b[0mhttps_request\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAbstractHTTPHandler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_request_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36mdo_open\u001b[0;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[1;32m   1318\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# timeout error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mURLError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1320\u001b[0;31m             \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1321\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m             \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1319\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1321\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1322\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;31m# read until we get a non-100 response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iso-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"status line\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1050\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1052\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1053\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1054\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m    909\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 911\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    912\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTimeoutError\u001b[0m: [Errno 60] Operation timed out"
     ]
    }
   ],
   "source": [
    "soup = soupify(scrape_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "ename": "TimeoutError",
     "evalue": "[Errno 60] Operation timed out",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTimeoutError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-140-d823133cb1d2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mreq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscrape_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'User-Agent'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m\"Magic Browser\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mreq\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mhtml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    529\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mprocessor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mmeth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36mhttp_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m             response = self.parent.error(\n\u001b[0;32m--> 641\u001b[0;31m                 'http', request, response, code, msg, hdrs)\n\u001b[0m\u001b[1;32m    642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36merror\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    561\u001b[0m             \u001b[0mhttp_err\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 563\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_chain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    564\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    501\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 503\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    504\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36mhttp_error_302\u001b[0;34m(self, req, fp, code, msg, headers)\u001b[0m\n\u001b[1;32m    753\u001b[0m         \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    754\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 755\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    756\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m     \u001b[0mhttp_error_301\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhttp_error_303\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhttp_error_307\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhttp_error_302\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0mreq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 525\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    526\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         \u001b[0;31m# post-process response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(self, req, data)\u001b[0m\n\u001b[1;32m    541\u001b[0m         \u001b[0mprotocol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m         result = self._call_chain(self.handle_open, protocol, protocol +\n\u001b[0;32m--> 543\u001b[0;31m                                   '_open', req)\n\u001b[0m\u001b[1;32m    544\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    501\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 503\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    504\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36mhttps_open\u001b[0;34m(self, req)\u001b[0m\n\u001b[1;32m   1358\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mhttps_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1359\u001b[0m             return self.do_open(http.client.HTTPSConnection, req,\n\u001b[0;32m-> 1360\u001b[0;31m                 context=self._context, check_hostname=self._check_hostname)\n\u001b[0m\u001b[1;32m   1361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1362\u001b[0m         \u001b[0mhttps_request\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAbstractHTTPHandler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_request_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36mdo_open\u001b[0;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[1;32m   1318\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# timeout error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mURLError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1320\u001b[0;31m             \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1321\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m             \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1319\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1321\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1322\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;31m# read until we get a non-100 response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iso-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"status line\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1050\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1052\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1053\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1054\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m    909\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 911\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    912\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTimeoutError\u001b[0m: [Errno 60] Operation timed out"
     ]
    }
   ],
   "source": [
    "req = urllib.request.Request(scrape_url, headers={'User-Agent' : \"Magic Browser\"}) \n",
    "con = urllib.request.urlopen( req )\n",
    "html = con.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "newsmax.com/Health/Health-News/death-wish-coffee/2017/09/21/id/814971/\n",
      "200\n",
      "newsmax.com/LarryBell/Climate-Change-Global-Warming-U-SState-Facts/2015/11/23/id/703229/\n",
      "300\n",
      "newsmax.com/newsfront/france-gas-protests-killed/2018/11/17/id/891059/\n",
      "400\n",
      "gizmodo.com/100-websites-that-shaped-the-internet-as-we-know-it-1829634771\n",
      "500\n",
      "buzzfeednews.com/article/tomvellner/plants-that-purify-air\n",
      "600\n",
      "twincities.com/localnews/ci_27119078/2-environmental-groups-sue-wisconsin-dnr-over-air?source=rss\n",
      "700\n",
      "politico.com/tipsheets/politico-influence/2015/12/2015-finale-211922\n",
      "800\n",
      "commondreams.org/views/2020/01/30/2020-election-must-focus-voter-needs-and-future?cd-origin=rss\n",
      "900\n",
      "feedproxy.google.com/~r/time/politics/~3/FHaXdA9vDW8/0,8599,2057085,00.html\n",
      "1000\n",
      "commondreams.org/newswire/2016/01/07/350org-responds-transcanadas-nafta-lawsuit-over-keystone-xl\n",
      "1100\n",
      "hosted.ap.org/dynamic/stories/C/CA_CALIFORNIA_INITIATIVE_SPENDING_CAOL-?SITE=CAANR&SECTION=HOME&TEMPLATE=DEFAULT\n",
      "1200\n",
      "dailykos.com/stories/2019/8/26/1881259/-5-Things-Warming-Believers-Alaska-Burning-Wind-Mills-the-Horror-Coral-Romance-TESCO\n",
      "1300\n",
      "politico.eu/article/6-ways-coronavirus-is-changing-the-environment/\n",
      "1400\n",
      "thenation.com/article/archive/80-percent-worlds-fossil-fuels-must-stay-ground-avert-catastrophe/\n",
      "1500\n",
      "thinkprogress.org/new-jersey-just-passed-the-nations-strongest-ban-on-offshore-drilling-682220734c79/\n",
      "1600\n",
      "forbes.com/sites/jeffmcmahon/2016/07/13/93-percent-of-public-companies-face-climate-risk-only-12-percent-disclose-it/\n",
      "1700\n",
      "dailykos.com/stories/2017/03/09/1641867/-A-Call-for-Climate-Action\n",
      "1800\n",
      "unionleader.com/a-combination-picture-shows-st-marks-square-before-and-after-floods-in-venice/image_be1deca3-d80b-5cd5-98cc-aa472c7af51b.html\n",
      "1900\n",
      "forbes.com/sites/uciliawang/2015/02/09/a-first-for-duke-energy-investing-in-a-solar-installer/\n",
      "2000\n",
      "vox.com/2016/1/13/10759062/state-of-the-union-2016-policy\n",
      "2100\n",
      "mercurynews.com/2017/12/20/a-look-at-some-winners-and-losers-under-the-gop-tax-plan-2/\n",
      "2200\n",
      "truth-out.org/opinion/item/14445-a-new-manhattan-project\n",
      "2300\n",
      "americanthinker.com/blog/2018/11/a_quick_refresher_course_to_remind_us_of_previous_global_warmingcooling_scares.html\n",
      "2400\n",
      "washingtonpost.com/national/health-science/a-smart-look-at-the-climate-change-debate/2014/09/15/1aacd5c0-3906-11e4-8601-97ba88884ffd_story.html\n",
      "2500\n",
      "redstate.com/alexparker/2019/04/30/mark-stevens-domingo-terrorist-california-long-beach-rally-ied-arrested-islam/\n",
      "2600\n",
      "foxnews.com/entertainment/abby-huntsman-jane-fonda-green-new-deal\n",
      "2700\n",
      "truthout.org/articles/activist-faces-jail-for-resisting-massachusetts-sheriffs-collaboration-with-ice/\n",
      "2800\n",
      "washingtonpost.com/opinions/the-united-states-already-has-a-carbon-tax/2019/01/23/9f02c3a8-1f56-11e9-8e21-59a09ff1e2a1_story.html\n",
      "2900\n",
      "infowars.com/africa-open-for-plunder-now-that-libya-has-fallen/\n",
      "3000\n",
      "washingtonpost.com/politics/after-sanders-can-the-democrats-unify-their-party/2016/06/06/41dae966-2806-11e6-ae4a-3cdd5fe74204_story.html\n",
      "3100\n",
      "salon.com/2019/03/15/ahead-of-global-climatestrike-16-year-old-greta-thunberg-nominated-for-nobel-peace-prize/\n",
      "3200\n",
      "infowars.com/al-gore-backlash-why-environmentalists-are-celebrating-rising-co2-levels/\n",
      "3300\n",
      "americanthinker.com/blog/2013/11/al_gore_still_stranded.html\n",
      "3400\n",
      "infowars.com/al-sharpton-demonstrates-hes-clueless-about-global-warming/\n",
      "3500\n",
      "dailykos.com/stories/2017/5/25/1665966/-ALEC-Restrictive-Wind-Farm-Rules-hold-up-2B-wind-investment-in-Ohio\n",
      "3600\n",
      "businessinsider.com/alexandria-ocasio-cortezs-tax-plan-would-supply-tens-of-billions-of-dollars-2019-1?r=US&IR=T?utm_source=yahoo.com&utm_medium=referral\n",
      "3700\n",
      "redstate.com/vladimir/2013/03/10/alternate-new-york-times-headline-global-warming-saves-civilization/\n",
      "3800\n",
      "stltoday.com/business/amazon-feels-heat-from-employees-on-climate-change-and-disclosing/article_4bdfc4e0-1ae8-5964-96c8-1d2c0862dc00.html\n",
      "3900\n",
      "americanthinker.com/articles/2016/02/americas_energy_outlook_is_bright_and_obama_hates_it.html\n",
      "4000\n",
      "feedproxy.google.com/~r/sun-sentinel/news/opinion/~3/rZPmNzsFly4/fl-op-viewpoint-sea-level-rise-pearl-harbor-20180823-story.html\n",
      "4100\n",
      "feedproxy.google.com/~r/baltimoresun/news/nation/rss2/~3/L83wXeGdf3E/ct-clinton-sanders-political-games-20160402-story.html\n",
      "4200\n",
      "newsmax.com/gidonbenzvi/writing-creativity-jerusalem-parenthood/2019/07/25/id/925899/\n",
      "4300\n",
      "huffpost.com/entry/nyc-climate-change-queens-borough-president_n_5e46c911c5b64433c61599d9\n",
      "4400\n",
      "redstate.com/streiff/2018/05/20/andrew-sullivan-obamas-legacy-dead-trump-killed/\n",
      "4500\n",
      "therealnews.com/stories/another-county-just-banned-new-fossil-fuel-infrastructure\n",
      "4600\n",
      "huffingtonpost.com/nikolas-kozloff/anthony-bourdain-coolness_b_322709.html\n",
      "4700\n",
      "dailycaller.com/2017/07/04/anyone-for-a-serious-discussion-about-climate/\n",
      "4800\n",
      "hosted.ap.org/dynamic/stories/U/US_WIND_POWER_PUBLIC_LANDS?SITE=CAANR&SECTION=HOME&TEMPLATE=DEFAULT\n",
      "4900\n",
      "breitbart.com/news/ap-interview-gore-says-backing-biden-isnt-rocket-science/\n",
      "5000\n",
      "talkingpointsmemo.com/news/natural-disasters-influence-climate-change-thinking-poll\n",
      "5100\n",
      "denverpost.com/breakingnews/ci_28658265/approval-arctic-drilling-comes-just-before-obamas-visit?source=rss\n",
      "5200\n",
      "americanthinker.com/blog/2008/05/are_32000_scientists_enough_to.html\n",
      "5300\n",
      "forbes.com/sites/timworstall/2016/12/07/arent-competition-and-technological-advance-just-absolutely-marvellous/\n",
      "5400\n",
      "realclearpolitics.com/articles/2007/04/thinking_globally_but_not_clea.html\n",
      "5500\n",
      "americanthinker.com/articles/2016/03/the_dirty_little_secret_about_allelectric_vehicles.html\n",
      "5600\n",
      "mysanantonio.com/news/article/As-Earth-Day-turns-50-green-movement-faces-fresh-15215670.php\n",
      "5700\n",
      "chron.com/news/politics/us/article/As-rabbi-prays-at-inauguration-Rick-Perry-amuses-10874095.php\n",
      "5800\n",
      "stltoday.com/lifestyles/health-med-fit/medical/article_4227ee1b-d06b-5046-a551-ada6d3124220.html\n",
      "5900\n",
      "nytimes.com/1996/08/06/science/at-hot-center-of-debate-on-global-warming.html\n",
      "6000\n",
      "cnet.com/news/solar-plane-gearing-up-to-attempt-first-round-the-world-trip/#ftag=CADf028e5a\n",
      "6100\n",
      "sfgate.com/news/article/Australian-Parliament-remembers-victims-and-15027936.php\n",
      "6200\n",
      "theblaze.com/news/international-actress-and-climate-change-activist-hysterically-warns-of-climate-emergency-says-people-should-prepare-to-eat-their-pets\n",
      "6300\n",
      "dailycaller.com/2018/08/13/baltimore-records-request-climate-lawsuit/\n",
      "6400\n",
      "mlive.com/business/mid-michigan/index.ssf/2015/03/xalt_energy_enters_1_billion_l.html\n",
      "6500\n",
      "feedproxy.google.com/~r/time/topstories/~3/voyoksfu6b4/\n",
      "6600\n",
      "opednews.com/articles/Bernie-is-Right--It-is-N-by-Daniel-Geery-Illuminati_Illumination-160409-713.html\n",
      "6700\n",
      "rare.us/story/bernie-sanders-green-energy-plans-will-actually-raise-greenhouse-gas-levels/\n",
      "6800\n",
      "commondreams.org/views/2020/01/21/bernie-sanders-people-powered-campaign-fire?cd-origin=rss\n",
      "6900\n",
      "rawstory.com/2015/12/bernie-sanders-unveils-climate-plan-to-end-us-oil-coal-and-nuclear-dependence/\n",
      "7000\n",
      "washingtonpost.com/news/energy-environment/wp/2017/01/26/besieged-by-climate-controversy-exxonmobil-puts-a-climate-scientist-on-its-board/\n",
      "7100\n",
      "nytimes.com/2018/12/02/climate/betting-on-a-new-way-to-make-concrete-that-doesnt-pollute.html\n",
      "7200\n",
      "grabien.com/file.php?id=667487\n",
      "7300\n",
      "thenation.com/article/archive/big-coal-mess/\n",
      "7400\n",
      "motherjones.com/environment/2014/05/big-energy-developing-country-oil-exxon-coal/\n",
      "7500\n",
      "salon.com.feedsportal.com/c/35105/f/648624/s/4b518f96/sc/7/l/0L0Ssalon0N0C20A150C110C0A70Cbill0Igates0Igives0Iexxon0Icover0Ithe0Igates0Ifoundation0Iis0Ideadly0Iwrong0Ion0Iclimate0Ichange0Ifossil0Ifuels0C/story01.htm\n",
      "7600\n",
      "washingtonpost.com/news/wonk/wp/2013/12/26/bill-mckibbens-graph-of-the-year/\n",
      "7700\n",
      "huffingtonpost.com/bill-shireman/ryans-two-gifts-progressives_b_1808744.html\n",
      "7800\n",
      "dispatch.com/news/20171015/biology-greenhouse-gas-steroids-fuel-damaging-storms?rssfeed=true\n",
      "7900\n",
      "wnd.com/2012/10/blame-everything-on-global-warming/\n",
      "8000\n",
      "newsmax.com/newsfront/US-Election-2020-Bloomberg-Climate/2019/12/13/id/945856/\n",
      "8100\n",
      "stltoday.com/business/local/boeing-conducts-first-flight-using-green-diesel/article_e4aaf941-65c8-5143-8a5f-7df8639ff435.html\n",
      "8200\n",
      "infowars.com/botanist-bellamy-shunned-by-bbc-for-questioning-climate-change/\n",
      "8300\n",
      "huffingtonpost.com/brad-friedman-and-desi-doyen/green-news-report---augus_b_5680152.html\n",
      "8400\n",
      "twincities.com/national/ci_25059038/branson-hosts-renewable-energy-summit-caribbean?source=rss\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8500\n",
      "infowars.com/breakthrough-late-night-deal-breaks-two-year-deadlock-over-natural-gas-exports/\n",
      "8600\n",
      "blogs.forbes.com/energysource/2011/05/23/british-government-faces-up-to-peak-oil/\n",
      "8700\n",
      "nytimes.com/2015/11/20/business/dealbook/buffetts-grandson-seeks-own-investment-route-social-change.html?partner=rss&emc=rss\n",
      "8800\n",
      "post-gazette.com/pg/11106/1139688-432-0.stm?cmpid=news.xml\n",
      "8900\n",
      "washingtonpost.com/blogs/innovations/wp/2014/04/15/by-2050-every-company-needs-to-be-a-zero-energy-company-or-else/\n",
      "9000\n",
      "truthdig.com/articles/california-air-boss-open-to-compromise-in-mileage-standoff/\n",
      "9100\n",
      "truthdig.com/articles/california-sets-goal-of-100-percent-clean-energy-by-2045/\n",
      "9200\n",
      "sfgate.com/news/article/California-legal-water-cremation-alkaline-burial-12285298.php\n",
      "9300\n",
      "seattletimes.com/nation-world/california-says-oceans-expected-to-rise-higher-than-thought/?utm_source=RSS&utm_medium=Referral&utm_campaign=RSS_all\n",
      "9400\n",
      "dailycaller.com/2017/04/11/californias-new-fuel-tax-burdens-gas-powered-vehicles-more-than-tesla-models/\n",
      "9500\n",
      "nationalreview.com/planet-gore/camille-paglia-answers-reader-mail-global-warming-greg-pollowitz/\n",
      "9600\n",
      "motherjones.com/environment/2010/04/climate-desk-health-insurance-climate-change\n",
      "9700\n",
      "dailykos.com/stories/2019/3/13/1841792/-Can-Trump-s-Fox-News-Fixation-Get-Any-Moore-Stupid-and-Shameful\n",
      "9800\n",
      "chicagotribune.com/sns-wp-canada-energy-6bb4256a-fadf-11e7-a46b-a3614530bd87-20180116-story.html\n",
      "9900\n",
      "motherjones.com/politics/2011/05/chris-christie-president-cap-trade-carbon/\n",
      "10000\n",
      "houstonchronicle.com/business/energy/article/Carbon-capture-subsidies-don-t-go-far-enough-14901662.php\n",
      "10100\n",
      "foxnews.com/printer_friendly_story/0,3566,579071,00.html\n",
      "10200\n",
      "newsday.com/opinion/commentary/carbon-taxes-global-warming-climate-change-1.36828017\n",
      "10300\n",
      "newsmax.com/fastfeatures/cars-global-warming-electric-cars/2015/03/23/id/631733/\n",
      "10400\n",
      "newsbusters.org/blogs/nb/nicholas-fondacaro/2017/11/13/cbs-climate-change-saving-world-has-been-harder-trump\n",
      "10500\n",
      "americanthinker.com/blog/2019/04/changing_hearts_and_minds_on_nuclear_power.html\n",
      "10600\n",
      "washingtonpost.com/business/economy/cheap-natural-gas-jumbles-energy-markets-stirs-fears-it-could-inhibit-renewables/2012/01/08/gIQApLr5hQ_story.html\n",
      "10700\n",
      "sonsoflibertymedia.com/2015/09/chicken-little-al-gore-renews-climate-change-lie/\n",
      "10800\n",
      "feedproxy.google.com/~r/timeblogs/middle_east/~3/xMit--IY_J4/\n",
      "10900\n",
      "motherjones.com/environment/2015/09/china-cap-and-trade-carbon-xi-obama-agreement/\n",
      "11000\n",
      "truthdig.com/articles/chinas-trade-plan-may-cause-lasting-harm/\n",
      "11100\n",
      "buzz.blog.ajc.com/2017/09/22/chris-evans-and-mark-ruffalo-salute-atlanta-eco-super-heroes/\n",
      "11200\n",
      "dailysignal.com/2017/08/25/cia-veteran-sees-russian-connection-to-2-groups-opposing-fracking-pipelines/\n",
      "11300\n",
      "startribune.com/variety/celebrities/331877991.html\n",
      "11400\n",
      "news.cnet.com/8301-11128_3-20028823-54.html?part=rss&subj=news&tag=2547-1_3-0-20\n",
      "11500\n",
      "foxnews.com/media/greta-thunberg-tv-series-bbc\n",
      "11600\n",
      "sgtreport.com/2018/12/climate-alarmism-is-in-retreat-across-the-world/\n",
      "11700\n",
      "nationalreview.com/2019/09/scientist-suggests-climate-change-could-pave-the-way-for-cannibalism/\n",
      "11800\n",
      "dailysignal.com/2018/12/08/climate-change-alarmism-is-the-worlds-leading-cause-of-hot-gas/\n",
      "11900\n",
      "newsmax.com/finance/peter-morici/climate-change-ideas-carbon/2019/03/05/id/905517/\n",
      "12000\n",
      "sacbee.com/2012/10/24/4933569/pefpof-posf-psoef-jposf-jpsoef.html#mi_rss=Presidential%20Campaign\n",
      "12100\n",
      "buzzfeednews.com/article/zahrahirji/climate-science-us-report\n",
      "12200\n",
      "washingtonpost.com/opinions/local-opinions/climate-change-is-the-next-world-war-give-it-the-coverage-it-deserves/2019/08/23/5ec66fe8-c383-11e9-b5e4-54aa56d5b7ce_story.html\n",
      "12300\n",
      "vox.com/2019/11/25/20981768/climate-change-pew-opinion-poll-republicans-ok-boomer\n",
      "12400\n",
      "ireport.cnn.com/docs/DOC-803552\n",
      "12500\n",
      "thenation.com/article/archive/climate-change-alien-invasions-and-other-conspiracy-theories-cooked-up-by-scientists/\n",
      "12600\n",
      "americanthinker.com/articles/2019/09/climate_changing_for_the_better.html\n",
      "12700\n",
      "msn.com/en-us/news/opinion/climate-deniers-are-cooking-themselves-and-everyone-else/ar-BBYA0sv?ocid=msn360\n",
      "12800\n",
      "wnd.com/2015/08/climate-is-dooming-the-profiteers-of-doom/\n",
      "12900\n",
      "townhall.com/columnists/pauldriessen/2011/08/23/climate-prostitutes,-charlatans-and-comedians-n1027256\n",
      "13000\n",
      "foxnews.com/science/climate-scientist-heated-up-over-satirical-video-threatens-lawsuit\n",
      "13100\n",
      "dispatch.com/ZZ/news/20191213/climate-talks-head-into-overtime-with-key-issues-unresolved?rssfeed=true\n",
      "13200\n",
      "infowars.com/climategate-spells-end-to-the-false-science-of-climate-change/\n",
      "13300\n",
      "cbsnews.com/news/clinton-sets-goals-for-solar-panels-clean-energy/\n",
      "13400\n",
      "cnnpressroom.blogs.cnn.com/2013/10/29/cnn-films-to-air-pandoras-promise-thursday-nov-7/\n",
      "13500\n",
      "transcripts.cnn.com/TRANSCRIPTS/1903/10/se.02.html\n",
      "13600\n",
      "Newsmax.com/Finance/StreetTalk/coal-climate-Donald-Trump-energy/2017/07/28/id/804422\n",
      "13700\n",
      "thinkprogress.org/green/2011/08/02/286042/coal-river-mountain-protest-continues-after-one-sitter-arrested/\n",
      "13800\n",
      "rawstory.com/2020/04/collapsology-is-this-the-end-of-civilization-as-we-know-it/\n",
      "13900\n",
      "denverpost.com/2018/01/09/colorado-oil-gas-pipeline-rule-delay/\n",
      "14000\n",
      "commondreams.org/view/2009/02/26-2\n",
      "14100\n",
      "neighbors.denverpost.com/viewtopic.php?p=3356401#p3356401\n",
      "14200\n",
      "dailysignal.com/2008/03/12/common-sense-questions-on-the-clean-air-act/\n",
      "14300\n",
      "feedproxy.google.com/~r/reason/HitandRun/~3/O5L4WFv-mJI/\n",
      "14400\n",
      "huffingtonpost.com/2015/11/05/congressional-energy-chairs_n_8479016.html?utm_hp_ref=politics&ir=Politics\n",
      "14500\n",
      "infowars.com/conservatives-slam-iowa-dem-incompetence-cant-run-a-caucus-but-they-want-to-take-over-healthcare/\n",
      "14600\n",
      "washingtontimes.com/news/2015/dec/6/cop-21-climate-deal-drafted-obama-goals-sticking-p/?utm_source=RSS_Feed&utm_medium=RSS\n",
      "14700\n",
      "dailymail.co.uk/news/article-8183607/Coronavirus-trigger-biggest-fall-carbon-emissions-World-War-Two.html?ns_mchannel=rss&ns_campaign=1490&ito=1490\n",
      "14800\n",
      "nytimes.com/2014/07/22/science/corralling-carbon-before-it-belches-from-stack.html\n",
      "14900\n",
      "motherjones.com/politics/2010/10/clean-cookstoves-jacob-moss/\n",
      "15000\n",
      "tampabay.com/opinion/letters/article1154553.ece\n",
      "15100\n",
      "mysanantonio.com/news/environment/article/CPS-proud-of-its-greenhouse-gas-emissions-4621902.php\n",
      "15200\n",
      "townhall.com/news/politics-elections/2018/08/21/crowded-wyoming-republican-governors-race-heads-to-vote-n2511580\n",
      "15300\n",
      "commondreams.org/news/2019/02/21/curious-about-who-refuses-back-green-new-deal-follow-fossil-fuel-money?cd-origin=rss\n",
      "15400\n",
      "dailykos.com/story/2013/06/29/1219947/-Don-t-Believe-the-Anti-Electric-Vehicle-Hype\n",
      "15500\n",
      "sacbee.com/2012/01/12/4181493/valeros-revenge-foils-ab-32-implementation.html#mi_rss=Opinion\n",
      "15600\n",
      "kansascity.com/news/local/news-columns-blogs/local-columnists/article44071743.html#storylink=rss\n",
      "15700\n",
      "rare.us/rare-news/days-after-meeting-with-al-gore-about-climate-change-trump-picks-a-fossil-fuel-ally-to-head-the-epa/\n",
      "15800\n",
      "infowars.com/dear-gary-johnson-there-is-no-free-market-carbon-tax/\n",
      "15900\n",
      "truth-out.org/news/item/41971-decolonization-in-action-maori-town-revives-lost-language\n",
      "16000\n",
      "feedproxy.google.com/~r/breitbart/~3/FuMkOQv4B6s/\n",
      "16100\n",
      "breitbart.com/politics/2017/03/23/delingpole-climate-change-is-real-because-bad-weather-explains-wmo/\n",
      "16200\n",
      "independentsentinel.com/dem-debate-with-two-crazy-old-men-videos/\n",
      "16300\n",
      "sacbee.com/news/business/article234719647.html#storylink=rss\n",
      "16400\n",
      "politico.com/newsletters/morning-energy/2019/06/28/democrats-climate-plan-beat-trump-452170\n",
      "16500\n",
      "thenation.com/article/democrats-should-have-called-mcconnells-bluff-and-voted-yes-on-the-green-new-deal/\n",
      "16600\n",
      "dailycaller.com/2017/01/16/dems-still-convinced-green-energy-best-way-to-reach-rural-trump-voters/\n",
      "16700\n",
      "newsmax.com/rahn/global-warming-temperature-data/2013/04/02/id/497516/\n",
      "16800\n",
      "nypost.com/2019/09/25/devine-irresponsible-adults-have-caused-the-climate-fear-plaguing-greta-thunberg/\n",
      "16900\n",
      "redstate.com/page/795/?post_type=diary\n",
      "17000\n",
      "forbes.com/sites/steveandriole/2017/06/20/digital-generals-are-as-important-as-military-generals-because-the-us-is-losing-the-digital-war/\n",
      "17100\n",
      "forbes.com/sites/christopherskroupa/2015/07/16/disrupting-unsustainable-business-models-through-low-carbon-investment/\n",
      "17200\n",
      "newsmax.com/larrybell/al-gore/2016/11/07/id/757409/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17300\n",
      "online.wsj.com/article/SB10001424052748703779704576074333552233782.html?mod=fox_australian\n",
      "17400\n",
      "dallasnews.com/life/pets/2017/05/26/dog-town-saluting-veterans-four-leggers-things\n",
      "17500\n",
      "dailykos.com/stories/2019/7/19/1872968/-Donald-Trump-and-the-GOP-hate-America?utm_campaign=spotlight\n",
      "17600\n",
      "motherjones.com/politics/2019/02/donald-trump-still-doesnt-understand-climate-change-science/\n",
      "17700\n",
      "theverge.com/2020/3/23/21187076/cruise-line-industry-bailout-trump-coronavirus-us-companies-tax\n",
      "17800\n",
      "dotearth.blogs.nytimes.com/2016/11/15/probing-worst-case-environmental-outcomes-under-trump-and-the-g-o-p/?partner=rss&emc=rss\n",
      "17900\n",
      "dailykos.com/stories/2018/6/8/1770452/-DrawDown-8-BioPlastic-v-PetroPlastic\n",
      "18000\n",
      "huffingtonpost.com/david-h-bailey/dubious-digits-is-this-da_b_6129864.html?utm_hp_ref=science&ir=Science\n",
      "18100\n",
      "opednews.com/articles/Earth-Day-Conflict-Over-t-by-Margaret-Flowers-Activism-Environmental_Earth-Day_Energy_Planet-Destruction-180423-347.html\n",
      "18200\n",
      "dailykos.com/stories/2018/8/13/1787856/-Earthquake-shakes-Alaska-s-North-Slope-the-very-fragile-eco-system-Trump-just-sacrificed-to-Big-Oil\n",
      "18300\n",
      "commondreams.org/newswire/2012/04/27-1\n",
      "18400\n",
      "feedproxy.google.com/~r/Editorial-TheWashingtonTimesAmericasNewspaper/~3/CgQGKd7B8q0/story01.htm\n",
      "18500\n",
      "feedproxy.google.com/~r/Editorial-TheWashingtonTimesAmericasNewspaper/~3/RnmzUzstEwQ/story01.htm\n",
      "18600\n",
      "newsday.com/editorials-from-around-new-york-1.12689433\n",
      "18700\n",
      "forbes.com/sites/alanohnsman/2017/01/04/electric-bus-maker-proterra-raises-further-140-million-to-boost-production/\n",
      "18800\n",
      "dallasnews.com/news/politics/2019/09/10/elizabeth-warren-assails-corruption-promises-change-as-democrats-swarm-to-texas/\n",
      "18900\n",
      "feedproxy.google.com/~r/businessinsider/~3/MWXquwe2n2A/humans-driving-and-self-driving-cars-2015-10\n",
      "19000\n",
      "washingtontimes.com/news/2018/may/26/emails-show-cooperation-among-epa-climate-change-d/?utm_source=RSS_Feed&utm_medium=RSS\n",
      "19100\n",
      "feedproxy.google.com/~r/thedailybeast/articles/~3/X0O82cKfFFE/the-energy-war-how-fossil-fuel-democrats-became-an-endangered-species.html\n",
      "19200\n",
      "cbsnews.com/news/energy-dept-rejects-trump-transition-request-for-climate-staff-names/\n",
      "19300\n",
      "redstate.com/diary/Nikitas3/2008/10/13/energy-price-drop-foreseen/\n",
      "19400\n",
      "startribune.com/blogs/381925721.html\n",
      "19500\n",
      "cnsnews.com/news/article/penny-starr/environmental-expert-dem-greenhouse-gases-dont-cause-respiratory-illnesses\n",
      "19600\n",
      "americanthinker.com/articles/2015/06/environmentalist_shipwreck.html\n",
      "19700\n",
      "dailycaller.com/2017/05/17/enviros-claim-chinas-coal-plants-are-greener-than-the-us\n",
      "19800\n",
      "seattletimes.com/nation-world/nation-politics/epa-chief-doubts-scientific-consensus-that-carbon-dioxide-is-behind-global-warming/?utm_source=RSS&utm_medium=Referral&utm_campaign=RSS_all\n",
      "19900\n",
      "foxnews.com/politics/epa-chief-trump-to-undo-obama-plan-to-curb-global-warming\n",
      "20000\n",
      "feedproxy.google.com/~r/baltimoresun/news/nation/rss2/~3/b7PJyHFwV8E/ct-epa-scientists-20171110-story.html\n",
      "20100\n",
      "cnsnews.com/commentary/nicolas-loris/epa-revision-obama-era-fuel-standards-could-save-car-buyers-thousands\n",
      "20200\n",
      "latimes.com/nation/la-na-obama-climate-plan-20140602-story.html\n",
      "20300\n",
      "vox.com/2019/6/26/18715400/eric-swalwell-2020-presidential-campaign-policies\n",
      "20400\n",
      "sacbee.com/2012/10/17/4918763/eu-mulls-ways-to-reduce-use-of.html#mi_rss=Wire%20Business%20News\n",
      "20500\n",
      "thenation.com/article/archive/europe-climate-kids-elections-far-right/\n",
      "20600\n",
      "cbsnews.com/news/majority-of-americans-in-coal-reliant-states-prefer-renewables/\n",
      "20700\n",
      "theblaze.com/news/2014/03/18/exaggerated-correct-or-underestimated-poll-finds-what-most-americans-think-of-global-warming\n",
      "20800\n",
      "mysanantonio.com/news/texas/article/Existing-climate-efforts-expected-to-keep-US-11200669.php\n",
      "20900\n",
      "huffingtonpost.com/julie-fox-gorte/explainer-the-carbon-transition_b_12011240.html\n",
      "21000\n",
      "Newsmax.com/US/US-Profile-in-Courage-Award/2015/05/03/id/642286\n",
      "21100\n",
      "nytimes.com/2017/06/09/business/energy-environment/exxon-mobil-schneiderman.html?partner=rss&emc=rss\n",
      "21200\n",
      "thenation.com/article/exxon-lawsuit-climate-change/\n",
      "21300\n",
      "sfgate.com/news/article/Facebook-to-cut-ties-with-conservative-policy-5776055.php\n",
      "21400\n",
      "washingtonpost.com/national/religion/faith-communities-are-dumping-their-fossil-fuel-investments/2014/07/16/5d195304-0d30-11e4-bd4e-462c357f0998_story.html\n",
      "21500\n",
      "dailymail.co.uk/news/article-7592485/Father-eight-invents-electric-car-battery-drivers-1-500-miles-without-charging-it.html?ns_mchannel=rss&ns_campaign=1490&ito=1490\n",
      "21600\n",
      "theblaze.com/news/judge-dismisses-climate-suit-against-trump-administration\n",
      "21700\n",
      "townhall.com/columnists/calthomas/2017/01/26/feeling-good-so-far-n2276794?utm_source=thdaily&utm_medium=email&utm_campaign=nl&newsletterad=\n",
      "21800\n",
      "commondreams.org/view/2010/11/23-1\n",
      "21900\n",
      "sfgate.com/news/science/article/Fire-sale-on-stuff-that-burns-Oil-natural-gas-6422995.php\n",
      "22000\n",
      "truth-out.org/news/item/34081-five-new-studies-that-change-our-understanding-of-permafrost\n",
      "22100\n",
      "startribune.com/floods-expose-threat-to-military-posed-by-climate-change/507501752/\n",
      "22200\n",
      "startribune.com/world/111725164.html\n",
      "22300\n",
      "thinkprogress.org/climate/2014/09/03/3478373/propane-from-e-coli/\n",
      "22400\n",
      "post-gazette.com/business/powersource/2017/09/05/former-consol-exec-tapped-to-lead-federal-fossil-fuel-office-carbon-capture-trump-senate-battelle-energy-technology/stories/201709050111\n",
      "22500\n",
      "startribune.com/world/378580256.html\n",
      "22600\n",
      "opednews.com/articles/Fossil-Fuel-Industry-Is-Ki-by-EcoWatch-Algae_Coral-Reef_Exxon_Fossil-Fuel-160821-638.html\n",
      "22700\n",
      "arkansasonline.com/news/2017/nov/07/fossil-fuels-will-be-main-energy-source-decades-op/\n",
      "22800\n",
      "wnd.com/news/article.asp?ARTICLE_ID=42476\n",
      "22900\n",
      "feedproxy.google.com/~r/motherjones/main/~3/J1d3oA-3owk/fracking-water-poisoning-protest-movement\n",
      "23000\n",
      "nytimes.com/2017/07/06/business/energy-environment/france-cars-ban-gas-diesel.html?_r=1\n",
      "23100\n",
      "feedproxy.google.com/~r/reason/HitandRun/~3/0s5HJ4RwMB8/free-speech-and-climate-change-skepticis\n",
      "23200\n",
      "mercurynews.com/2019/12/11/friedman-trump-must-be-impeached-if-americas-democracy-is-to-remain-intact/\n",
      "23300\n",
      "online.wsj.com/article/SB10001424052970203554104577001843790269560.html?mod=rss_US_News\n",
      "23400\n",
      "newsmax.com/finance/markets/furchtgott-roth-green-energy-renewable/2012/10/25/id/461507/\n",
      "23500\n",
      "newsmax.com/Newsfront/gallup-fears-global-warming/2016/03/16/id/719476/\n",
      "23600\n",
      "foxnews.com/us/2018/04/15/gay-rights-lawyer-immolates-self-in-nyc-in-ecology-protest.html\n",
      "23700\n",
      "wnd.com/2013/11/george-clooney-global-warming-skeptics-stupid/\n",
      "23800\n",
      "cnsnews.com/news/article/german-minister-links-katrina-global-warming-bush-policies\n",
      "23900\n",
      "newsmax.com/hostetter/global-warming/2007/12/19/id/322455/\n",
      "24000\n",
      "dailysignal.com/2010/06/22/glacier-melting-not-from-climate-change/\n",
      "24100\n",
      "salon.com/2016/06/02/global_energy_leaders_look_to_nitty_gritty_of_climate_accord/\n",
      "24200\n",
      "nytimes.com/2007/07/08/magazine/08wwln-idealab-t.html\n",
      "24300\n",
      "nationalreview.com/planet-gore/global-warming-causing-islamic-fascism-maldives-greg-pollowitz/\n",
      "24400\n",
      "rare.us/story/global-warming-gets-nearly-twice-as-much-taxpayer-money-as-border-security/\n",
      "24500\n",
      "washingtonpost.com/business/economy/2014/08/26/0704955e-2d66-11e4-994d-202962a9150c_story.html\n",
      "24600\n",
      "infowars.com/global-warming-researchers-cancel-trip-due-to-severe-ice/\n",
      "24700\n",
      "motherjones.com/politics/2007/05/global-warmings-effect-whales-and-dolphins/\n",
      "24800\n",
      "nationalreview.com/planet-gore/global-warming-computer-models-garbage-gospel-out-greg-pollowitz/\n",
      "24900\n",
      "thegatewaypundit.com/2011/10/good-lord-the-occupy-wall-street-imbeciles-release-their-idiotic-demands-20-minimum-wage-and-across-the-board-debt-forgiveness-for-all/\n",
      "25000\n",
      "washingtontimes.com/news/2016/jun/16/gop-ags-dems-climate-alarmists-can-be-prosecuted/?platform=hootsuite\n",
      "25100\n",
      "foxnews.com/politics/gop-senator-tells-climate-change-researchers-to-retain-controversial-e-mails\n",
      "25200\n",
      "sacbee.com/2013/01/29/5150047/gore-hits-corporate-media-defends.html#mi_rss=Wire%20TV%20News\n",
      "25300\n",
      "seattletimes.com/seattle-news/politics/gov-inslee-ore-governor-vow-to-fight-trump-environmental-proposals/?utm_source=RSS&utm_medium=Referral&utm_campaign=RSS_all\n",
      "25400\n",
      "www2.bostonglobe.com/metro/2019/03/06/gov-baker-touts-promise-clean-energy-new-technology/mj4CTa5b8OfPiUHbzpkN2M/story.html?p1=Article_Inline_Text_Link\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25500\n",
      "dailycaller.com/2016/04/28/green-activists-push-colorado-to-consider-fracking-ban/\n",
      "25600\n",
      "denverpost.com/nationworld/ci_25033471/green-groups-obama-not-doing-enough-climate?source=rss\n",
      "25700\n",
      "newsday.com/opinion/commentary/green-new-deal-washington-legislation-economy-energy-1.28770274\n",
      "25800\n",
      "buzzfeednews.com/article/danvergano/greenhouse-gas-emissions-are-flattening\n",
      "25900\n",
      "infowars.com/greenpeace-founder-no-proof-of-global-warming/\n",
      "26000\n",
      "breitbart.com/environment/2019/08/29/greta-thunberg-arrives-nyc-keep-fossil-fuels-ground-stop-war-nature/\n",
      "26100\n",
      "breitbart.com/news/grim-tidings-from-science-on-climate-change-2/\n",
      "26200\n",
      "staradvertiser.com/2016/09/25/editorial/grow-food-for-hawaii-not-experimental-seed/\n",
      "26300\n",
      "feedproxy.google.com/~r/breitbart/~3/CY2wDk3wVBU/\n",
      "26400\n",
      "foxnews.com/printer_friendly_wires/2009Mar29/0,4675,BigOilOpportunity,00.html\n",
      "26500\n",
      "sacbee.com/news/nation-world/article237706704.html#storylink=rss\n",
      "26600\n",
      "washingtontimes.com/news/2017/apr/21/hawaiian-electric-touts-renewable-energy-progress/?utm_source=RSS_Feed&utm_medium=RSS\n",
      "26700\n",
      "salon.com/2017/08/07/heat-waves-threaten-city-dwellers-especially-minorities-and-the-poor_partner/\n",
      "26800\n",
      "feedproxy.google.com/~r/motherjones/main/~3/ljK151IwFcg/second-debate-energy-fact-check\n",
      "26900\n",
      "thenation.com/article/archive/heres-the-one-thing-countries-have-to-do-to-meet-the-2-degree-climate-target/\n",
      "27000\n",
      "thinkprogress.org/heres-how-much-the-world-s-biggest-economies-spend-on-fossil-fuel-subsidies-5fc58562ef86/\n",
      "27100\n",
      "feedproxy.google.com/~r/motherjones/main/~3/K8ysk7fhAjc/heres-why-obamas-new-pact-canada-big-deal\n",
      "27200\n",
      "commondreams.org/news/2016/06/02/highlighting-contrast-clinton-sanders-vows-nationwide-ban-fracking\n",
      "27300\n",
      "feedproxy.google.com/~r/reason/HitandRun/~3/5kNAWF2UFag/hillary-clinton-so-sick-and-tired-of-ber\n",
      "27400\n",
      "truth-out.org/news/item/34368-historic-trial-lets-activists-who-blocked-oil-train-cite-climate-change-threat-in-their-defense\n",
      "27500\n",
      "americanthinker.com/articles/2017/09/hooray_for_carbon_dioxide_its_helping_to_feed_the_worlds_hungry.html\n",
      "27600\n",
      "startribune.com/house-dflers-sidestep-green-new-deal-amendment-meant-to-divide/508979252/\n",
      "27700\n",
      "washingtontimes.com/news/2015/feb/18/house-votes-to-stay-in-cap-and-trade-program/?utm_source=RSS_Feed&utm_medium=RSS\n",
      "27800\n",
      "ocregister.com/2019/03/16/how-areas-flood-even-on-sunny-days-its-a-thing/\n",
      "27900\n",
      "forbes.com/sites/johnmcquaid/2012/08/21/how-climate-change-got-caught-in-the-culture-wars/\n",
      "28000\n",
      "truth-out.org/news/item/26773-how-does-your-state-rank-on-greenhouse-gas-emissions\n",
      "28100\n",
      "nytimes.com/2017/06/03/us/politics/republican-leaders-climate-change.html?partner=rss&emc=rss&smid=tw-nytimesscience&smtyp=cur\n",
      "28200\n",
      "money.cnn.com/2009/09/11/magazines/fortune/medical_marijuana_legalizing.fortune/?postversion=2009091116\n",
      "28300\n",
      "thenation.com/article/progressives-election-cities-housing-fracking-water/\n",
      "28400\n",
      "alternet.org/economy/how-democrats-lost-west-virginia-and-coal-miners-trump\n",
      "28500\n",
      "foxnews.com/us/how-this-beer-growler-went-from-concept-to-market.amp\n",
      "28600\n",
      "forbes.com/sites/steveforbes/2015/04/01/how-to-reenergize-the-hard-hit-oil-gas-industry/\n",
      "28700\n",
      "opednews.com/articles/How-We-Can-Build-a-Hardier-by-Bill-McKibben-Climate_Coronavirus-Pandemic_Drought_Inequality-200417-794.html\n",
      "28800\n",
      "time.com/4800747/china-climate-change-paris-agreement-trump/?utm_campaign=time&utm_source=twitter.com&utm_medium=social&xid=time_socialflow_twitter\n",
      "28900\n",
      "salon.com/2018/05/09/humans-didnt-exist-the-last-time-there-was-this-much-co2-in-the-air_partner/\n",
      "29000\n",
      "nytimes.com/2017/09/11/climate/hurricane-irma-climate-change.html\n",
      "29100\n",
      "opednews.com/articles/I-Submitted-This-Plank-to-by-Sheila-Parks-Ed-D-Chernobyl_Democratic-National-Convention_Fukushima_Leukemia-160619-304.html\n",
      "29200\n",
      "breitbart.com/news/iea-praises-canadian-carbon-capture-initiative/\n",
      "29300\n",
      "twincities.com/national/ci_19691715?source=rss\n",
      "29400\n",
      "thedailybeast.com/rep-ilhan-omar-i-unequivocally-apologize-for-tweets-on-israel\n",
      "29500\n",
      "opednews.com/articles/Improve-the-Green-New-Deal-by-Roger-Copple-Capitalism_Consumption_Design_Ecology-190503-838.html\n",
      "29600\n",
      "newsmax.com/newsfront/us-trump-epa-administrator/2017/01/18/id/769172/\n",
      "29700\n",
      "therealnews.com/idirect.php?i=20210\n",
      "29800\n",
      "nytimes.com/2012/06/21/world/asia/global-demand-for-air-conditioning-forces-tough-environmental-choices.html\n",
      "29900\n",
      "ocregister.com/2019/02/06/in-their-first-town-halls-new-so-cal-democrats-pressed-about-progressive-campaign-pledges/\n",
      "30000\n",
      "dailysignal.com/2009/07/24/india-balks-at-hillary-clinton%E2%80%99s-carbon-reduction-talk-questions-global-warming-science/\n",
      "30100\n",
      "commondreams.org/view/2013/04/28-5\n",
      "30200\n",
      "feedproxy.google.com/~r/thedailybeast/articles/~3/HueF1Mn6e9g/inside-los-angeles-s-long-lost-temple-to-oil.html\n",
      "30300\n",
      "dailysignal.com/2014/09/22/instead-protesting-climate-marchers-read/\n",
      "30400\n",
      "vox.com/identities/2020/3/7/21163193/international-womens-day-2020\n",
      "30500\n",
      "vox.com/2014/4/1/5570388/the-big-question-just-how-bad-is-global-warming-going-to-get\n",
      "30600\n",
      "nationalreview.com/article/414611/america-clean-energy-laggard-robert-bryce\n",
      "30700\n",
      "commondreams.org/view/2013/06/11-6\n",
      "30800\n",
      "sgtreport.com/2018/10/is-the-long-anticipated-crash-now-upon-us/\n",
      "30900\n",
      "washingtonpost.com/world/israel-harnessing-sunshine-with-worlds-tallest-solar-tower/2017/01/05/ad4572f0-d311-11e6-9651-54a0154cf5b3_story.html\n",
      "31000\n",
      "vox.com/2020/1/23/21078895/greta-thunberg-climate-change-steven-mnuchin\n",
      "31100\n",
      "townhall.com/columnists/brianmcnicoll/2018/02/13/its-like-obama-never-left-on-the-federal-energy-regulatory-commission-n2448111\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    376\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Python 2.7, use buffering of HTTP responses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m                 \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffering\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Python 3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: getresponse() got an unexpected keyword argument 'buffering'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mWantReadError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/urllib3/contrib/pyopenssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mOpenSSL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSSL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSysCallError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/OpenSSL/SSL.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1839\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSSL_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ssl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1840\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_ssl_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ssl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/OpenSSL/SSL.py\u001b[0m in \u001b[0;36m_raise_ssl_error\u001b[0;34m(self, ssl, result)\u001b[0m\n\u001b[1;32m   1645\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0merror\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSSL_ERROR_WANT_READ\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1646\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mWantReadError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1647\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0merror\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSSL_ERROR_WANT_WRITE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mWantReadError\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-109-108b3076fcda>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mscrape_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'https://'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m#print(url,scrape_url)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnewspaper_parse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscrape_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mtitle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-108-5e7e1ce0a05d>\u001b[0m in \u001b[0;36mnewspaper_parse\u001b[0;34m(url)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0marticle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mArticle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0marticle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0marticle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         return (article.title,article.publish_date,\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/newspaper/article.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(self, input_html, title, recursion_counter)\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minput_html\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m                 \u001b[0mhtml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_html_2XX_only\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRequestException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mArticleDownloadState\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFAILED_RESPONSE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/newspaper/network.py\u001b[0m in \u001b[0;36mget_html_2XX_only\u001b[0;34m(url, config, response)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     response = requests.get(\n\u001b[0;32m---> 63\u001b[0;31m         url=url, **get_request_kwargs(timeout, useragent, proxies, headers))\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0mhtml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_html_from_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/requests/api.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'allow_redirects'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'get'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    531\u001b[0m         }\n\u001b[1;32m    532\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 533\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 646\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    647\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    447\u001b[0m                     \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m                     \u001b[0mretries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m                     \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m                 )\n\u001b[1;32m    451\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    598\u001b[0m                                                   \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout_obj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m                                                   \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m                                                   chunked=chunked)\n\u001b[0m\u001b[1;32m    601\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m             \u001b[0;31m# If we're going to release the connection in ``finally:``, then\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    378\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Python 3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m                     \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    381\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m                     \u001b[0;31m# Remove the TypeError from the exception chain in Python 3;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1319\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1321\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1322\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;31m# read until we get a non-100 response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iso-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"status line\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/urllib3/contrib/pyopenssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    304\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mOpenSSL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSSL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWantReadError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msocket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgettimeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'The read operation timed out'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/urllib3/util/wait.py\u001b[0m in \u001b[0;36mwait_for_read\u001b[0;34m(sock, timeout)\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[0mReturns\u001b[0m \u001b[0;32mTrue\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msocket\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mreadable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mFalse\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0mexpired\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m     \"\"\"\n\u001b[0;32m--> 143\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mwait_for_socket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/urllib3/util/wait.py\u001b[0m in \u001b[0;36mpoll_wait_for_socket\u001b[0;34m(sock, read, write, timeout)\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpoll_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_retry_on_intr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdo_poll\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/urllib3/util/wait.py\u001b[0m in \u001b[0;36m_retry_on_intr\u001b[0;34m(fn, timeout)\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;31m# Modern Python, that retries syscalls by default\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_retry_on_intr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;31m# Old and broken Pythons.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/urllib3/util/wait.py\u001b[0m in \u001b[0;36mdo_poll\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m             \u001b[0mt\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpoll_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_retry_on_intr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdo_poll\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for ix in range(31199,len(combined_df)):\n",
    "    row = combined_df.iloc[ix]\n",
    "    url = row['url']\n",
    "    scrape_url = 'https://'+url\n",
    "    #print(url,scrape_url)\n",
    "    res = newspaper_parse(scrape_url)\n",
    "    #if res[0] is not None:\n",
    "    title = res[0]\n",
    "    date = res[1]\n",
    "    if title is None:\n",
    "        title = guess_title(scrape_url)\n",
    "    if date is None:\n",
    "        date = get_guess_date(scrape_url)\n",
    "    if title is None and date is None:\n",
    "        pass\n",
    "    else:\n",
    "        json_name = row['guid']\n",
    "        with open(os.path.join('url_meta',json_name+'.json'),'w') as f:\n",
    "            json_object = json.dumps({\n",
    "                    \"title\":title,\n",
    "                    \"date\":date.isoformat() if date is not None else None,\n",
    "                    \"text\":res[2]\n",
    "            }, indent = 4) \n",
    "            f.write(json_object)\n",
    "    if ix % 100 == 0:\n",
    "        print(ix)\n",
    "        print(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_ix = 31199"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31199"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
