{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:15: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import glob\n",
    "from collections import Counter,defaultdict\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from numpy.random import RandomState\n",
    "from sklearn import metrics\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split,KFold\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "STANCES = [\"agree\", \"neutral\", \"disagree\"]\n",
    "CLASS_NUMS = {s: i for i, s in enumerate(STANCES)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "code_folding": [
     1,
     5,
     11
    ]
   },
   "outputs": [],
   "source": [
    "# move to utils.py later\n",
    "nli2stance = {'entailment': CLASS_NUMS['agree'], \n",
    "              'neutral': CLASS_NUMS['neutral'], \n",
    "              'contradiction': CLASS_NUMS['disagree']}\n",
    "\n",
    "float2stance = {1.0: CLASS_NUMS['agree'],\n",
    "               0.0: CLASS_NUMS['neutral'],\n",
    "               -1.0: CLASS_NUMS['disagree']}\n",
    "\n",
    "stance2nli = {0: 'entailment', 1: 'neutral', 2: 'contradiction'}\n",
    "                \n",
    "def stance_reg(label):\n",
    "    \"\"\"\n",
    "    Regularize the stance labels \n",
    "    :param label: a label of str (agree(s)/entailment, neutral, disagree(s)/contradiction), \n",
    "     int (0, 1, 2) or str of int, or float (1.0, 0.0, -1.0)\n",
    "    :return: the label as the corresponding class_num\n",
    "    \"\"\"\n",
    "    \n",
    "    if type(label) == str:\n",
    "        if label.isalpha(): # could be a,n,d or NLI labels\n",
    "            if label in STANCES:\n",
    "                return CLASS_NUMS[label]\n",
    "            elif label[-1] == 's':\n",
    "                return CLASS_NUMS[label[:-1]]\n",
    "            else:\n",
    "                return nli2stance[label]\n",
    "        else: # label is str of (0, 1, 2)\n",
    "            return int(label)\n",
    "    elif type(label) == float:\n",
    "        return float2stance[label]\n",
    "    else:\n",
    "        return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def add_backtrans_train(train_df,language,upsample=False):\n",
    "    \"\"\"\n",
    "    Create df with backtranslations of train_df \n",
    "    :param train_df: base training data\n",
    "    :param language: 'fr' or 'zh'\n",
    "    :return: new df with previous training data + augmented data\n",
    "    \"\"\"\n",
    "    \n",
    "    backtrans_df = pd.DataFrame({\n",
    "        'round':train_df['round'].values,\n",
    "        'batch':train_df.batch.values,\n",
    "        'sent_id':train_df.sent_id.values,\n",
    "        'stance':train_df.stance.values,\n",
    "        'sentence':[get_backtrans(guid,language) for guid in train_df.guid],\n",
    "        'guid':[guid+'_'+language for guid in train_df.guid]\n",
    "    })\n",
    "    \n",
    "    \n",
    "    if upsample:\n",
    "        backtrans_df = backtrans_df.loc[backtrans_df.stance.isin({'disagrees','disagree'})].append(\n",
    "            train_df,ignore_index=True)\n",
    "    else:\n",
    "        backtrans_df = backtrans_df.append(train_df,ignore_index=True)\n",
    "        \n",
    "    return backtrans_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labeled_data = pd.read_pickle('./data/labeled_data_df.pkl')\n",
    "# labeled_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# labeled_data.type.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimated labels (MTurk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2050, 8), (2042, 8))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est_labels = pd.read_csv('/Users/yiweiluo/scientific-debates/\\\n",
    "3_cc_stance/MTurk/MTurk_results/sent_scores_df.tsv',delimiter='\\t',index_col=0)\n",
    "est_labels['max_prob_label'] = est_labels[['disagree','neutral','agree']].idxmax(axis=1)\n",
    "dedup_est_labels = est_labels.drop_duplicates('sentence',keep='first')\n",
    "est_labels.shape, dedup_est_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "assert len(dedup_est_labels) == 2042\n",
    "dedup_est_labels['guid'] = [\"{}_{}_{}\".format(row['round'],row['batch'],row['sent_id']) \n",
    "                      for _,row in dedup_est_labels.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>round</th>\n",
       "      <th>batch</th>\n",
       "      <th>sent_id</th>\n",
       "      <th>disagree</th>\n",
       "      <th>neutral</th>\n",
       "      <th>agree</th>\n",
       "      <th>sentence</th>\n",
       "      <th>max_prob_label</th>\n",
       "      <th>guid</th>\n",
       "      <th>stance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>t0</td>\n",
       "      <td>0.004241</td>\n",
       "      <td>0.260963</td>\n",
       "      <td>0.734797</td>\n",
       "      <td>Warmer-than-normal sea surface temperatures are a key player in the development of hurricanes such as Katrina and superstorm Sandy, which hit the U.S. east coast in 2011.</td>\n",
       "      <td>agree</td>\n",
       "      <td>1_0_t0</td>\n",
       "      <td>agree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>t1</td>\n",
       "      <td>0.001548</td>\n",
       "      <td>0.996214</td>\n",
       "      <td>0.002239</td>\n",
       "      <td>We will continue to rely in part on fossil fuels while we transition to a low-carbon economy .</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1_0_t1</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>t10</td>\n",
       "      <td>0.001440</td>\n",
       "      <td>0.996503</td>\n",
       "      <td>0.002057</td>\n",
       "      <td>The actual rise in sea levels measured only 1.2 millimeters instead of the previously accepted 1.6 to 1.9 millimeters.</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1_0_t10</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>t11</td>\n",
       "      <td>0.996815</td>\n",
       "      <td>0.001588</td>\n",
       "      <td>0.001596</td>\n",
       "      <td>Claims of global warming have been greatly exaggerated.</td>\n",
       "      <td>disagree</td>\n",
       "      <td>1_0_t11</td>\n",
       "      <td>disagree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>t12</td>\n",
       "      <td>0.035201</td>\n",
       "      <td>0.959757</td>\n",
       "      <td>0.005042</td>\n",
       "      <td>The Intergovernmental Panel on Climate Change should be clearer on how it draws conclusions from the body of research it assesses when gauging the impacts of global warming.</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1_0_t12</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   round  batch sent_id  disagree   neutral     agree  \\\n",
       "0  1      0      t0      0.004241  0.260963  0.734797   \n",
       "1  1      0      t1      0.001548  0.996214  0.002239   \n",
       "2  1      0      t10     0.001440  0.996503  0.002057   \n",
       "3  1      0      t11     0.996815  0.001588  0.001596   \n",
       "4  1      0      t12     0.035201  0.959757  0.005042   \n",
       "\n",
       "                                                                                                                                                                        sentence  \\\n",
       "0  Warmer-than-normal sea surface temperatures are a key player in the development of hurricanes such as Katrina and superstorm Sandy, which hit the U.S. east coast in 2011.      \n",
       "1  We will continue to rely in part on fossil fuels while we transition to a low-carbon economy .                                                                                  \n",
       "2  The actual rise in sea levels measured only 1.2 millimeters instead of the previously accepted 1.6 to 1.9 millimeters.                                                          \n",
       "3  Claims of global warming have been greatly exaggerated.                                                                                                                         \n",
       "4  The Intergovernmental Panel on Climate Change should be clearer on how it draws conclusions from the body of research it assesses when gauging the impacts of global warming.   \n",
       "\n",
       "  max_prob_label     guid    stance  \n",
       "0  agree          1_0_t0   agree     \n",
       "1  neutral        1_0_t1   neutral   \n",
       "2  neutral        1_0_t10  neutral   \n",
       "3  disagree       1_0_t11  disagree  \n",
       "4  neutral        1_0_t12  neutral   "
      ]
     },
     "execution_count": 472,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dedup_est_labels['stance'] = dedup_est_labels['max_prob_label']\n",
    "dedup_est_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 674,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "held_out_test = pd.read_pickle('./save/held_out_balanced_test.pkl')\n",
    "#held_out_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 715,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1838, 11)"
      ]
     },
     "execution_count": 715,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dedup_est_labels = dedup_est_labels.loc[~dedup_est_labels.index.isin(held_out_test.index)]\n",
    "dedup_est_labels.reset_index(drop=True,inplace=True)\n",
    "dedup_est_labels.shape # Expect 2042-204 = 1838"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 716,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert set(dedup_est_labels.guid.values).intersection(\n",
    "    set(held_out_test.guid.values)) == set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 717,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 717,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(dedup_est_labels.sentence.values).intersection(\n",
    "set(held_out_test.sentence.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw labels (MTurk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "worker_labels_per_round = pickle.load(open('../MTurk/MTurk_results/full_ratings_per_round.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROP_AGREE = 0.75\n",
    "NUM_ROUNDS, NUM_BATCHES, NUM_WORKERS = 5, 10, 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 683,
   "metadata": {
    "code_folding": [
     1
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2042, 7)"
      ]
     },
     "execution_count": 683,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round_df,batch_df,sentid_df,stance_df,text_df,high_iaa_df,guid_df = [],[],[],[],[],[],[]\n",
    "for r in range(1,1+NUM_ROUNDS):\n",
    "    for b in range(NUM_BATCHES):\n",
    "        labels = worker_labels_per_round[r][b]\n",
    "        for s_id in labels.index[5:-1]:\n",
    "            round_df.append(r)\n",
    "            batch_df.append(b)\n",
    "            sentid_df.append(s_id)\n",
    "            text_df.append(labels.loc[s_id].sentence)\n",
    "            guid_df.append(\"{}_{}_{}\".format(r,b,s_id))\n",
    "            \n",
    "            ratings = labels.loc[s_id][['worker_{}'.format(w_id) for w_id in range(NUM_WORKERS)]].values\n",
    "            top_rating = Counter(ratings).most_common()[0]\n",
    "            if top_rating[-1] >= PROP_AGREE*NUM_WORKERS:\n",
    "                stance_df.append(top_rating[0])\n",
    "                high_iaa_df.append(True)\n",
    "            else:\n",
    "                stance_df.append(est_labels.loc[(est_labels['round'] == r) & \n",
    "                                             (est_labels['batch'] == b) & \n",
    "                                             (est_labels['sent_id'] == s_id)].max_prob_label.values[0])\n",
    "                high_iaa_df.append(False)\n",
    "\n",
    "mturk_df = pd.DataFrame({'round':round_df,\"batch\":batch_df,\"sent_id\":sentid_df,\"stance\":stance_df,\n",
    "                 \"sentence\":text_df,'is_high_iaa':high_iaa_df,'guid':guid_df})\n",
    "mturk_df = mturk_df.drop_duplicates('sentence',keep='first')\n",
    "mturk_df.reset_index(drop=True,inplace=True)\n",
    "mturk_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>round</th>\n",
       "      <th>batch</th>\n",
       "      <th>sent_id</th>\n",
       "      <th>stance</th>\n",
       "      <th>sentence</th>\n",
       "      <th>is_high_iaa</th>\n",
       "      <th>guid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>t0</td>\n",
       "      <td>agree</td>\n",
       "      <td>Warmer-than-normal sea surface temperatures are a key player in the development of hurricanes such as Katrina and superstorm Sandy, which hit the U.S. east coast in 2011.</td>\n",
       "      <td>False</td>\n",
       "      <td>1_0_t0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>t1</td>\n",
       "      <td>neutral</td>\n",
       "      <td>We will continue to rely in part on fossil fuels while we transition to a low-carbon economy .</td>\n",
       "      <td>True</td>\n",
       "      <td>1_0_t1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>t10</td>\n",
       "      <td>neutral</td>\n",
       "      <td>The actual rise in sea levels measured only 1.2 millimeters instead of the previously accepted 1.6 to 1.9 millimeters.</td>\n",
       "      <td>True</td>\n",
       "      <td>1_0_t10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>t11</td>\n",
       "      <td>disagrees</td>\n",
       "      <td>Claims of global warming have been greatly exaggerated.</td>\n",
       "      <td>True</td>\n",
       "      <td>1_0_t11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>t12</td>\n",
       "      <td>neutral</td>\n",
       "      <td>The Intergovernmental Panel on Climate Change should be clearer on how it draws conclusions from the body of research it assesses when gauging the impacts of global warming.</td>\n",
       "      <td>True</td>\n",
       "      <td>1_0_t12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   round  batch sent_id     stance  \\\n",
       "0  1      0      t0      agree       \n",
       "1  1      0      t1      neutral     \n",
       "2  1      0      t10     neutral     \n",
       "3  1      0      t11     disagrees   \n",
       "4  1      0      t12     neutral     \n",
       "\n",
       "                                                                                                                                                                        sentence  \\\n",
       "0  Warmer-than-normal sea surface temperatures are a key player in the development of hurricanes such as Katrina and superstorm Sandy, which hit the U.S. east coast in 2011.      \n",
       "1  We will continue to rely in part on fossil fuels while we transition to a low-carbon economy .                                                                                  \n",
       "2  The actual rise in sea levels measured only 1.2 millimeters instead of the previously accepted 1.6 to 1.9 millimeters.                                                          \n",
       "3  Claims of global warming have been greatly exaggerated.                                                                                                                         \n",
       "4  The Intergovernmental Panel on Climate Change should be clearer on how it draws conclusions from the body of research it assesses when gauging the impacts of global warming.   \n",
       "\n",
       "   is_high_iaa     guid  \n",
       "0  False        1_0_t0   \n",
       "1  True         1_0_t1   \n",
       "2  True         1_0_t10  \n",
       "3  True         1_0_t11  \n",
       "4  True         1_0_t12  "
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mturk_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 713,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1838, 7)"
      ]
     },
     "execution_count": 713,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mturk_df = mturk_df.loc[~mturk_df['guid'].isin(set(held_out_test.guid.values))]\n",
    "mturk_df.reset_index(drop=True,inplace=True)\n",
    "mturk_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 714,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     1003\n",
       "False    835 \n",
       "Name: is_high_iaa, dtype: int64"
      ]
     },
     "execution_count": 714,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mturk_df.is_high_iaa.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 718,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert set(mturk_df.guid.values).intersection(\n",
    "    set(held_out_test.guid.values)) == set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 719,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 719,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(mturk_df.sentence.values).intersection(\n",
    "set(held_out_test.sentence.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Back translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "back_trans_fr = pd.read_csv('../datasets/mturk_french_backtranslations.tsv',sep='\\t',\n",
    "                        header=0,index_col=0)\n",
    "back_trans_zh = pd.read_csv('../datasets/mturk_zh_backtranslations.tsv',sep='\\t',\n",
    "                        header=0,index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_backtrans(guid,language):\n",
    "    r,b,s_id = guid.split('_')\n",
    "    if language == 'fr':\n",
    "        return back_trans_fr.loc[(back_trans_fr['round'] == int(r)) &\n",
    "                                (back_trans_fr['batch'] == int(b)) &\n",
    "                                (back_trans_fr['sent_id'] == s_id)].backtranslation.values[0]\n",
    "    else:\n",
    "        return back_trans_zh.loc[(back_trans_fr['round'] == int(r)) &\n",
    "                                (back_trans_fr['batch'] == int(b)) &\n",
    "                                (back_trans_fr['sent_id'] == s_id)].backtranslation_zh_en.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Warmer than normal sea surface temperatures are a key player in the development of hurricanes such as Katrina and Sandstorm Sandy, which hit the east coast of the United States in 2011.'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_backtrans('1_0_t0','fr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Above-normal sea-level temperatures were a key factor in the development of hurricanes such as Hurricane Katrina and Sandy, which hit the US East Coast in 2011.'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_backtrans('1_0_t0','zh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Sentence windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fnames = os.listdir('../../1_data_scraping/fulltexts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "all_round_data = {r: {} for r in range(1,6)}\n",
    "for round_no in range(1,6):\n",
    "    all_round_data[round_no] = pickle.load(open('/Users/yiweiluo/Dropbox/research/QP2/code/Fox_and_friends/\\\n",
    "LIVE_ROUND{}_BATCH_DATA.pkl'.format(round_no),'rb'))\n",
    "    \n",
    "data_for_mturk_df = pd.read_pickle('/Users/yiweiluo/Dropbox/research/QP2/code/Fox_and_friends/\\\n",
    "data_for_mturk_2020.pkl')\n",
    "data_for_mturk_df_old = pd.read_pickle('/Users/yiweiluo/Dropbox/research/QP2/code/Fox_and_friends/\\\n",
    "data_for_mturk.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "code_folding": [
     3
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "from fuzzywuzzy import process\n",
    "\n",
    "def get_window(guid,window_size):\n",
    "    r,b,s_id = guid.split('_')\n",
    "    target_sent = mturk_df.loc[(mturk_df['round'] == int(r)) &\n",
    "                                (mturk_df['batch'] == int(b)) &\n",
    "                                (mturk_df['sent_id'] == s_id)].sentence.values[0]\n",
    "\n",
    "#     print('Target sent:',target_sent)\n",
    "#     print('Round: {}, batch: {}, sent_id: {}'.format(r,b,s_id))\n",
    "    rb_df = pd.DataFrame(all_round_data[int(r)][int(b)])\n",
    "    df_key = rb_df.loc[rb_df.sent_id == s_id].df_key.values[0]\n",
    "#     print('df key:',df_key)\n",
    "    \n",
    "    if int(r) < 5:\n",
    "        sent_key = data_for_mturk_df_old.loc[df_key].sent_key\n",
    "    else:\n",
    "        sent_key = data_for_mturk_df.loc[df_key].sent_key\n",
    "        \n",
    "    url = sent_key.split(' of ')[-1].split('://')[-1]\n",
    "    #print('url:',url)\n",
    "    \n",
    "    fname = url.replace('/','[SEP]')\n",
    "    fname = '{}.txt'.format(fname) if '{}.txt'.format(fname) in fnames else '{}.txt'.format(fname[:90])\n",
    "    #print('fname:',fname)\n",
    "    \n",
    "    if fname in fnames:\n",
    "        with open(os.path.join('../../1_data_scraping/fulltexts',fname)) as f:\n",
    "            text = f.readlines()\n",
    "        if len(text) > 0:\n",
    "            text = text[0]\n",
    "\n",
    "            text_sents = sent_tokenize(text)\n",
    "            sent_with_target = process.extract(target_sent, text_sents, limit=1)\n",
    "            #print('Found sentence containing target sent:',sent_with_target)\n",
    "            ix_target_sent = text_sents.index(sent_with_target[0][0])\n",
    "\n",
    "            w_start = max(0,ix_target_sent-window_size)\n",
    "            w_end = min(ix_target_sent+window_size,len(text_sents)-1)\n",
    "            w_left = text_sents[w_start:ix_target_sent]\n",
    "            w_right = text_sents[ix_target_sent+1:w_end+1]\n",
    "            #print('Left sentence(s):',w_left)\n",
    "            #print('Right sentence(s):',w_right)\n",
    "            BERT_input = '[SEP] '.join(w_left)+' [SEP] [CLS] '+target_sent+' [SEP] '+' [SEP] '.join(w_right)\n",
    "            if BERT_input[:6] != ' [SEP]':\n",
    "                #print('Padding beginning with [SEP]...')\n",
    "                BERT_input = '[SEP] '+BERT_input\n",
    "                \n",
    "            return BERT_input\n",
    "        else:\n",
    "            print('Fulltext is empty!')\n",
    "    else:\n",
    "        print('Fulltext file not found!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[SEP] “I think it’s very important to remind people the scope of what can happen with the hurricane season.”  Nonetheless, the events surrounding the hurricane, which caused $108 billion of damage, continue to interest to the scientific community. [SEP] [CLS] Warmer-than-normal sea surface temperatures are a key player in the development of hurricanes such as Katrina and superstorm Sandy, which hit the U.S. east coast in 2011. [SEP] “These storms may not have been caused by global warming, but because the ocean’s surface is warmer, it makes the storm more powerful,” Thomas Wagner, cryosphere program manager at NASA headquarters in Washington, D.C. told FoxNews.com.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_window('1_0_t0',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[SEP] “We haven’t had a Category 3 hit the U.S. in 10 years – I think there’s a lot of complacency out there,” she said during a panel discussion at an American Meteorological Society conference in June.[SEP] “I think it’s very important to remind people the scope of what can happen with the hurricane season.”  Nonetheless, the events surrounding the hurricane, which caused $108 billion of damage, continue to interest to the scientific community. [SEP] [CLS] Warmer-than-normal sea surface temperatures are a key player in the development of hurricanes such as Katrina and superstorm Sandy, which hit the U.S. east coast in 2011. [SEP] “These storms may not have been caused by global warming, but because the ocean’s surface is warmer, it makes the storm more powerful,” Thomas Wagner, cryosphere program manager at NASA headquarters in Washington, D.C. told FoxNews.com. [SEP] “Then, because sea level is higher, the water can go further inland from the storm surge.”  President Obama briefly addressed the issue of climate change during a speech in New Orleans Thursday.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_window('1_0_t0',2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## SemEval tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(169, 395)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "semeval_test = pd.read_csv('../datasets/StanceDataset/test.csv',header=0,encoding='utf-8',engine='python')\n",
    "semeval_test = semeval_test[semeval_test['Target'] == 'Climate Change is a Real Concern']\n",
    "\n",
    "semeval_train = pd.read_csv('../datasets/StanceDataset/train.csv',header=0,encoding='utf-8', engine='python')\n",
    "semeval_train = semeval_train[semeval_train['Target'] == 'Climate Change is a Real Concern']\n",
    "\n",
    "len(semeval_test),len(semeval_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "semeval_test = semeval_test[['Tweet','Stance']]\n",
    "semeval_train = semeval_train[['Tweet','Stance']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tweetstance2label = {'NONE': CLASS_NUMS['neutral'],\n",
    "                    'FAVOR': CLASS_NUMS['agree'],\n",
    "                    'AGAINST': CLASS_NUMS['disagree']}\n",
    "\n",
    "semeval_test['stance'] = semeval_test['Stance'].apply(lambda x: tweetstance2label[x])\n",
    "semeval_train['stance'] = semeval_train['Stance'].apply(lambda x: tweetstance2label[x])\n",
    "semeval_df = semeval_test.append(semeval_train,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    335\n",
       "1    203\n",
       "2    26 \n",
       "Name: stance, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "semeval_df.stance.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Add additional info: original source media leaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_orig_media_slant(guid):\n",
    "    r,b,s_id = guid.split('_')\n",
    "    if int(r) < 5:\n",
    "        df_ = data_for_mturk_df_old\n",
    "    else:\n",
    "        df_ = data_for_mturk_df\n",
    "    \n",
    "    b_df_ = pd.DataFrame(all_round_data[int(r)][int(b)])\n",
    "    df_key = b_df_.loc[b_df_.sent_id == s_id].df_key.values[0]\n",
    "    \n",
    "    def str_to_int(s):\n",
    "        return int(s == 'pro') # 1 for pro, 0 for anti\n",
    "        \n",
    "    return str_to_int(df_.iloc[df_key].bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 513,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int('pro' == 'pro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Titles, with source media outlet as proxy label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44582, 10)"
      ]
     },
     "execution_count": 412,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle('../../1_data_scraping/dedup_combined_df.pkl')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 667,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df.loc[(df.stance=='pro') & \n",
    "#       (df.topic=='cc')].domain.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 668,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df.loc[(df.stance=='anti') & \n",
    "#       (df.topic=='cc')].domain.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Other extreme L candidates:\n",
    "# grist, inthesetimes, guardian_us (2307 total)\n",
    "\n",
    "# Other extreme R candidates:\n",
    "# daily_caller, drudgereport, infowars (1153 total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "CC_KEYWORDS = {'warming','climate','carbon','co2','fossil',\n",
    "              'temperature','environment','ice','antarctica','sea','seas',\n",
    "              'IPCC','gore','green'}\n",
    "\n",
    "def has_keyword(title):\n",
    "    return len(set(title.lower().split()).intersection(CC_KEYWORDS)) > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4037, 1365)"
      ]
     },
     "execution_count": 432,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counted_breitbart_titles = Counter(df.loc[df.domain == 'breitbart'].title.values)\n",
    "keyword_breitbart_titles = [x for x in counted_breitbart_titles if has_keyword(x)]\n",
    "len(counted_breitbart_titles),len(keyword_breitbart_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3430, 896)"
      ]
     },
     "execution_count": 434,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counted_mj_titles = Counter(df.loc[df.domain == 'mj'].title.values)\n",
    "keyword_mj_titles = [x for x in counted_mj_titles if has_keyword(x)]\n",
    "len(counted_mj_titles),len(keyword_mj_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "titles_df = pd.DataFrame({\"sentence\":keyword_breitbart_titles+keyword_mj_titles,\n",
    "                                  \"stance\":['disagrees']*len(keyword_breitbart_titles)+\\\n",
    "                                  ['agrees']*len(keyword_mj_titles)\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#titles_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create train/dev/test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 694,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(mturk_df) == 2042-len(held_out_test)\n",
    "assert len(dedup_est_labels) == 1838"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "\n",
      "\n",
      "[SEP] “I think it’s very important to remind people the scope of what can happen with the hurricane season.”  Nonetheless, the events surrounding the hurricane, which caused $108 billion of damage, continue to interest to the scientific community. [SEP] [CLS] Warmer-than-normal sea surface temperatures are a key player in the development of hurricanes such as Katrina and superstorm Sandy, which hit the U.S. east coast in 2011. [SEP] “These storms may not have been caused by global warming, but because the ocean’s surface is warmer, it makes the storm more powerful,” Thomas Wagner, cryosphere program manager at NASA headquarters in Washington, D.C. told FoxNews.com.\n",
      "\n",
      "\n",
      "How the Intergovernmental Panel on Climate Change should draw clearer conclusions from the research findings it assesses when assessing the effects of global warming.\n"
     ]
    }
   ],
   "source": [
    "df_getter = {'raw_mturk': mturk_df,\n",
    "            'est_mturk': dedup_est_labels,\n",
    "            'semeval': semeval_df}\n",
    "\n",
    "print(get_orig_media_slant('1_0_t12'))\n",
    "print('\\n')\n",
    "print(get_window('1_0_t0',1))\n",
    "print('\\n')\n",
    "print(get_backtrans('1_0_t12','zh'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>round</th>\n",
       "      <th>batch</th>\n",
       "      <th>sent_id</th>\n",
       "      <th>stance</th>\n",
       "      <th>sentence</th>\n",
       "      <th>is_high_iaa</th>\n",
       "      <th>guid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>t12</td>\n",
       "      <td>neutral</td>\n",
       "      <td>The Intergovernmental Panel on Climate Change should be clearer on how it draws conclusions from the body of research it assesses when gauging the impacts of global warming.</td>\n",
       "      <td>True</td>\n",
       "      <td>1_0_t12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   round  batch sent_id   stance  \\\n",
       "4  1      0      t12     neutral   \n",
       "\n",
       "                                                                                                                                                                        sentence  \\\n",
       "4  The Intergovernmental Panel on Climate Change should be clearer on how it draws conclusions from the body of research it assesses when gauging the impacts of global warming.   \n",
       "\n",
       "   is_high_iaa     guid  \n",
       "4  True         1_0_t12  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_getter['raw_mturk'].loc[df_getter['raw_mturk'].guid == '1_0_t12']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def write_data(name,desc,train_df,test_df,dev_df=None,do_downsample=False,\n",
    "              add_titles=False):\n",
    "    \"\"\"\n",
    "    Writes data to a directory containing train.tsv, test.tsv, and optionally dev.tsv.\n",
    "    :param name: name of directory (type of train/eval data)\n",
    "    :param desc: list of type str with manipulations made (e.g., downsampled, upsampled, backtrans_fr, window_1)\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    \n",
    "    # Check that train and eval text are deduplicated\n",
    "    train_guids = set([x.replace('_fr','').replace('_zh','') for x in train_df.guid])\n",
    "    test_guids = set([x.replace('_fr','').replace('_zh','') for x in test_df.guid])\n",
    "    assert train_guids.intersection(test_guids) == set()\n",
    "    print(\"Train/test text overlap:\",set(train_df.sentence).intersection(set(test_df.sentence)))\n",
    "    if dev_df is not None:\n",
    "        dev_guids = set([x.replace('_fr','').replace('_zh','') for x in dev_df.guid])\n",
    "        assert train_guids.intersection(dev_guids) == set()\n",
    "        print(\"Train/dev text overlap:\",set(train_df.sentence).intersection(set(dev_df.sentence)))\n",
    "    train_df = train_df[['stance','sentence']]\n",
    "    test_df = test_df[['stance','sentence']]\n",
    "    if dev_df is not None:\n",
    "        dev_df = dev_df[['stance','sentence']]\n",
    "    \n",
    "    # Make save_dir\n",
    "    if do_downsample:\n",
    "        desc.append('downsampled')\n",
    "    save_dir = os.path.join('save',\"_\".join([name]+desc))\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.mkdir(save_dir)\n",
    "        \n",
    "    # Add titles from Breitbart and MJ--TODO: make outlets a parameter\n",
    "    if add_titles:\n",
    "        print('Adding Breitbart and MJ titles to train_df...')\n",
    "        train_df = train_df.append(titles_df,ignore_index=True)\n",
    "        \n",
    "    # Regularize labels\n",
    "    train_df['reg_stance'] = train_df['stance'].apply(stance_reg)\n",
    "    test_df['reg_stance'] = test_df['stance'].apply(stance_reg)\n",
    "    if dev_df is not None:\n",
    "        dev_df['reg_stance'] = dev_df['stance'].apply(stance_reg) \n",
    "        \n",
    "    # Aggregate examples by stance for downsampling/upsampling needs\n",
    "    train_df_by_stance = {s: train_df.loc[train_df.reg_stance == i] for i,s in enumerate(STANCES)} \n",
    "    test_df_by_stance = {s: test_df.loc[test_df.reg_stance == i] for i,s in enumerate(STANCES)}\n",
    "    dev_df_by_stance = {s: dev_df.loc[dev_df.reg_stance == i] for i,s in enumerate(STANCES)} if dev_df is not None else None\n",
    "\n",
    "    # Split X, Y\n",
    "    train_X_by_stance = {s: train_df_by_stance[s].sentence.values for s in STANCES}\n",
    "    test_X_by_stance = {s: test_df_by_stance[s].sentence.values for s in STANCES}\n",
    "    dev_X_by_stance = {s: dev_df_by_stance[s].sentence.values for s in STANCES} if dev_df is not None else None\n",
    "    \n",
    "    train_Y_by_stance = {s: train_df_by_stance[s].reg_stance.values for s in STANCES} \n",
    "    dev_Y_by_stance = {s: dev_df_by_stance[s].reg_stance.values for s in STANCES} if dev_df is not None else None\n",
    "    test_Y_by_stance = {s: test_df_by_stance[s].reg_stance.values for s in STANCES}\n",
    "\n",
    "    train_nli_by_stance = {s: train_df_by_stance[s].reg_stance.apply(lambda x: stance2nli[x]).values for s in STANCES}\n",
    "    dev_nli_by_stance = {s: dev_df_by_stance[s].reg_stance.apply(lambda x: stance2nli[x]).values for s in STANCES} if dev_df is not None else None\n",
    "    test_nli_by_stance = {s: test_df_by_stance[s].reg_stance.apply(lambda x: stance2nli[x]).values for s in STANCES}\n",
    "\n",
    "    if do_downsample:\n",
    "        min_N = min([len(train_X_by_stance[s]) for s in STANCES])\n",
    "        print('Downsampling to ~{} examples per stance.'.format(min_N))\n",
    "        for s in STANCES:\n",
    "            train_X_by_stance[s] = np.random.choice(train_X_by_stance[s],size=min_N,replace=False)\n",
    "\n",
    "    trX = []\n",
    "    trB = []\n",
    "    trY = []\n",
    "    trNLI = []\n",
    "    for i,s in enumerate(STANCES):\n",
    "        for t, y, nli in zip(train_X_by_stance[s], train_Y_by_stance[s], train_nli_by_stance[s]):\n",
    "            #for text_b in TEXT_BS:\n",
    "            trX.append(t)\n",
    "            #trB.append(text_b)\n",
    "            trY.append(y)\n",
    "            trNLI.append(nli)\n",
    "\n",
    "    teX = []\n",
    "    teB = []\n",
    "    teY = []\n",
    "    teNLI = []\n",
    "    for i,s in enumerate(STANCES):\n",
    "        for t, y, nli in zip(test_X_by_stance[s], test_Y_by_stance[s], test_nli_by_stance[s]):\n",
    "            #for text_b in TEXT_BS:\n",
    "            teX.append(t)\n",
    "            #teB.append(text_b)\n",
    "            teY.append(y)\n",
    "            teNLI.append(nli)\n",
    "\n",
    "    if dev_df is not None:\n",
    "        vaX = []\n",
    "        vaY = []\n",
    "        vaNLI = []\n",
    "        for i,s in enumerate(STANCES):\n",
    "            for t, y, nli in zip(dev_X_by_stance[s], dev_Y_by_stance[s], dev_nli_by_stance[s]):\n",
    "                vaX.append(t)\n",
    "                vaY.append(y)\n",
    "                vaNLI.append(nli)\n",
    "\n",
    "\n",
    "    test_dat = pd.DataFrame({'sentence':teX,'stance':teY,'nli_label':teNLI})\n",
    "    train_dat = pd.DataFrame({'sentence':trX,'stance':trY,'nli_label':trNLI}) \n",
    "    val_dat = pd.DataFrame({'sentence':vaX,'stance':vaY,'nli_label':vaNLI}) if dev_df is not None else None\n",
    "    \n",
    "    print('Train distribution:')\n",
    "    print(train_dat.stance.value_counts()) \n",
    "    print(train_dat.nli_label.value_counts())\n",
    "    if dev_df is not None:\n",
    "        print('\\nDev distribution:')\n",
    "        print(val_dat.stance.value_counts())\n",
    "        print(val_dat.nli_label.value_counts())\n",
    "    print('\\nTest distribution:')\n",
    "    print(test_dat.stance.value_counts())\n",
    "    print(test_dat.stance.value_counts()/np.sum(test_dat.stance.value_counts().values))\n",
    "    print(test_dat.nli_label.value_counts())\n",
    "\n",
    "    print('Writing to save_dir:',save_dir)\n",
    "    train_dat.to_csv(save_dir+'/train.tsv',sep='\\t',header=None,index=False)\n",
    "    if dev_df is not None:\n",
    "        val_dat.to_csv(save_dir+'/dev.tsv',sep='\\t',header=None,index=False)\n",
    "    test_dat.to_csv(save_dir+'/test.tsv',sep='\\t',header=None,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Completely held-out, second test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Drawn from all MTurk labels, balanced over outlet sources and annotator ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "dedup_est_labels['outlet_stance'] = dedup_est_labels['guid'].apply(get_orig_media_slant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1038\n",
       "1    1004\n",
       "Name: outlet_stance, dtype: int64"
      ]
     },
     "execution_count": 506,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dedup_est_labels.outlet_stance.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neutral     862\n",
       "agree       779\n",
       "disagree    401\n",
       "Name: stance, dtype: int64"
      ]
     },
     "execution_count": 508,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dedup_est_labels.stance.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "metadata": {
    "code_folding": [],
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anti agree (314, 11)\n",
      "anti neutral (437, 11)\n",
      "anti disagree (287, 11)\n",
      "pro agree (465, 11)\n",
      "pro neutral (425, 11)\n",
      "pro disagree (114, 11)\n"
     ]
    }
   ],
   "source": [
    "# Want 34*3=102 to come from each outlet\n",
    "# Want 34 to come from each stance\n",
    "indices_per_outlet_stance = defaultdict(dict)\n",
    "for outlet_stance in [0,1]:\n",
    "    for stance in ['agree','neutral','disagree']:\n",
    "        sub_df = dedup_est_labels.loc[(dedup_est_labels.stance == stance) & \n",
    "                                     (dedup_est_labels.outlet_stance == outlet_stance)]\n",
    "        str_outlet_stance = 'pro' if outlet_stance == 1 else 'anti'\n",
    "        print(str_outlet_stance,stance,sub_df.shape)\n",
    "        indices_per_outlet_stance[outlet_stance][stance] = np.random.choice(\n",
    "            sub_df.index,size=34,replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "204"
      ]
     },
     "execution_count": 596,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_test_ix = []\n",
    "for outlet_stance in indices_per_outlet_stance:\n",
    "    for stance in STANCES:\n",
    "        balanced_test_ix.extend(indices_per_outlet_stance[outlet_stance][stance])\n",
    "len(balanced_test_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "agree       68\n",
       "neutral     68\n",
       "disagree    68\n",
       "Name: stance, dtype: int64"
      ]
     },
     "execution_count": 598,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dedup_est_labels.loc[balanced_test_ix].stance.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    102\n",
       "0    102\n",
       "Name: outlet_stance, dtype: int64"
      ]
     },
     "execution_count": 599,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dedup_est_labels.loc[balanced_test_ix].outlet_stance.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Inspect sentences manually to filter out problematic cases\n",
    "#list(zip(balanced_test_ix,list(dedup_est_labels.loc[balanced_test_ix].sentence.values),dedup_est_labels.loc[balanced_test_ix].stance.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "problematic = [1582,1983,667,1586,1960,592,1647,771,10,1123,1683,354,1067,\n",
    "              432,241,1959,832,1518,545,1270,144,1940,1262,1474,938,1516,296,1269,1197,\n",
    "              1784,855,801]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#dedup_est_labels.loc[problematic]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neutral     12\n",
       "agree       1 \n",
       "disagree    1 \n",
       "Name: stance, dtype: int64"
      ]
     },
     "execution_count": 612,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dedup_est_labels.loc[problematic].loc[\n",
    "    dedup_est_labels.loc[problematic].outlet_stance == 0].stance.value_counts()\n",
    "# Need 12 more neutrals, 1 agree, and 1 disagree from R-wing outlets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neutral     12\n",
       "disagree    4 \n",
       "agree       2 \n",
       "Name: stance, dtype: int64"
      ]
     },
     "execution_count": 610,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dedup_est_labels.loc[problematic].loc[\n",
    "    dedup_est_labels.loc[problematic].outlet_stance == 1].stance.value_counts()\n",
    "# Need 12 more neutrals, 2 agrees, and 4 disagrees from L-wing outlets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "N_needed_per_outlet_stance = {0: {\n",
    "    \"agree\": 1, \"disagree\": 1, \"neutral\": 12\n",
    "},\n",
    "                             1: {\n",
    "                                 \"agree\": 2, \"disagree\": 4, \"neutral\": 12\n",
    "                             }}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anti agree (280, 11)\n",
      "anti neutral (403, 11)\n",
      "anti disagree (253, 11)\n",
      "pro agree (431, 11)\n",
      "pro neutral (391, 11)\n",
      "pro disagree (80, 11)\n"
     ]
    }
   ],
   "source": [
    "new_indices_per_outlet_stance = defaultdict(dict)\n",
    "for outlet_stance in [0,1]:\n",
    "    for stance in ['agree','neutral','disagree']:\n",
    "        sub_df = dedup_est_labels.loc[(dedup_est_labels.stance == stance) & \n",
    "                                     (dedup_est_labels.outlet_stance == outlet_stance) &\n",
    "                                     (~dedup_est_labels.index.isin(\n",
    "                                         indices_per_outlet_stance[outlet_stance][stance]))]\n",
    "        str_outlet_stance = 'pro' if outlet_stance == 1 else 'anti'\n",
    "        print(str_outlet_stance,stance,sub_df.shape)\n",
    "        new_indices_per_outlet_stance[outlet_stance][stance] = np.random.choice(\n",
    "            sub_df.index,size=N_needed_per_outlet_stance[outlet_stance][stance],replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 agree 1\n",
      "0 neutral 12\n",
      "0 disagree 1\n",
      "1 agree 2\n",
      "1 neutral 12\n",
      "1 disagree 4\n"
     ]
    }
   ],
   "source": [
    "for outlet_stance in [0,1]:\n",
    "    for stance in STANCES:\n",
    "        print(outlet_stance,stance,len(new_indices_per_outlet_stance[outlet_stance][stance]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 616,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_balanced_test_ix = []\n",
    "for outlet_stance in new_indices_per_outlet_stance:\n",
    "    for stance in STANCES:\n",
    "        new_balanced_test_ix.extend([x for x in \n",
    "                                 new_indices_per_outlet_stance[outlet_stance][stance] \n",
    "                                if x not in problematic])\n",
    "len(new_balanced_test_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    18\n",
       "0    14\n",
       "Name: outlet_stance, dtype: int64"
      ]
     },
     "execution_count": 617,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dedup_est_labels.loc[new_balanced_test_ix].outlet_stance.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neutral     12\n",
       "agree       1 \n",
       "disagree    1 \n",
       "Name: stance, dtype: int64"
      ]
     },
     "execution_count": 618,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dedup_est_labels.loc[new_balanced_test_ix][\n",
    "    dedup_est_labels.loc[new_balanced_test_ix]['outlet_stance'] == 0].stance.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neutral     12\n",
       "disagree    4 \n",
       "agree       2 \n",
       "Name: stance, dtype: int64"
      ]
     },
     "execution_count": 619,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dedup_est_labels.loc[new_balanced_test_ix][\n",
    "    dedup_est_labels.loc[new_balanced_test_ix]['outlet_stance'] == 1].stance.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Re-nspect sentences manually to filter out problematic cases\n",
    "#list(zip(new_balanced_test_ix,list(dedup_est_labels.loc[new_balanced_test_ix].sentence.values),dedup_est_labels.loc[new_balanced_test_ix].stance.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "problematic_2 = [1279,240,709,141,1469,1612,913]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Add everything that's not problematic to base list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 agree 1\n",
      "0 neutral 12\n",
      "0 disagree 1\n",
      "1 agree 2\n",
      "1 neutral 12\n",
      "1 disagree 4\n"
     ]
    }
   ],
   "source": [
    "for outlet_stance in new_indices_per_outlet_stance:\n",
    "    for stance in STANCES:\n",
    "        print(outlet_stance,stance,len(new_indices_per_outlet_stance[outlet_stance][stance]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "197"
      ]
     },
     "execution_count": 632,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_problematic_balanced_test_ix = []\n",
    "for outlet_stance in indices_per_outlet_stance:\n",
    "    for stance in STANCES:\n",
    "        non_problematic_balanced_test_ix.extend([x for x in indices_per_outlet_stance[outlet_stance][stance]\n",
    "                                if x not in problematic])\n",
    "        non_problematic_balanced_test_ix.extend([x for x in new_indices_per_outlet_stance[outlet_stance][stance]\n",
    "                                if x not in problematic_2])\n",
    "len(non_problematic_balanced_test_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    100\n",
       "1    97 \n",
       "Name: outlet_stance, dtype: int64"
      ]
     },
     "execution_count": 633,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dedup_est_labels.loc[non_problematic_balanced_test_ix].outlet_stance.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "agree       34\n",
       "disagree    34\n",
       "neutral     32\n",
       "Name: stance, dtype: int64"
      ]
     },
     "execution_count": 635,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dedup_est_labels.loc[non_problematic_balanced_test_ix][\n",
    "    dedup_est_labels.loc[non_problematic_balanced_test_ix].outlet_stance == 0\n",
    "].stance.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "agree       34\n",
       "disagree    33\n",
       "neutral     30\n",
       "Name: stance, dtype: int64"
      ]
     },
     "execution_count": 636,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dedup_est_labels.loc[non_problematic_balanced_test_ix][\n",
    "    dedup_est_labels.loc[non_problematic_balanced_test_ix].outlet_stance == 1\n",
    "].stance.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "new_N_needed_per_outlet_stance = {0: {\n",
    "    \"agree\": 0, \"disagree\": 0, \"neutral\": 2\n",
    "},\n",
    "                             1: {\n",
    "                                 \"agree\": 0, \"disagree\": 1, \"neutral\": 4\n",
    "                             }}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anti agree (279, 11)\n",
      "anti neutral (391, 11)\n",
      "anti disagree (252, 11)\n",
      "pro agree (429, 11)\n",
      "pro neutral (379, 11)\n",
      "pro disagree (76, 11)\n"
     ]
    }
   ],
   "source": [
    "# New random sample to bring up numbers\n",
    "new_indices_per_outlet_stance_2 = defaultdict(dict)\n",
    "for outlet_stance in [0,1]:\n",
    "    for stance in ['agree','neutral','disagree']:\n",
    "        sub_df = dedup_est_labels.loc[(dedup_est_labels.stance == stance) & \n",
    "                                     (dedup_est_labels.outlet_stance == outlet_stance) &\n",
    "                                     (~dedup_est_labels.index.isin(\n",
    "                                         indices_per_outlet_stance[outlet_stance][stance])) & \n",
    "                                     (~dedup_est_labels.index.isin(\n",
    "                                     new_indices_per_outlet_stance[outlet_stance][stance]))]\n",
    "        str_outlet_stance = 'pro' if outlet_stance == 1 else 'anti'\n",
    "        print(str_outlet_stance,stance,sub_df.shape)\n",
    "        new_indices_per_outlet_stance_2[outlet_stance][stance] = np.random.choice(\n",
    "            sub_df.index,size=new_N_needed_per_outlet_stance[outlet_stance][stance],\n",
    "            replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 agree 0\n",
      "0 neutral 2\n",
      "0 disagree 0\n",
      "1 agree 0\n",
      "1 neutral 4\n",
      "1 disagree 1\n"
     ]
    }
   ],
   "source": [
    "for outlet_stance in new_indices_per_outlet_stance_2:\n",
    "    for stance in STANCES:\n",
    "        print(outlet_stance,stance,len(new_indices_per_outlet_stance_2[outlet_stance][stance]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 642,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_test_ix_2 = []\n",
    "for outlet_stance in new_indices_per_outlet_stance_2:\n",
    "    for stance in STANCES:\n",
    "        balanced_test_ix_2.extend(new_indices_per_outlet_stance_2[outlet_stance][stance])\n",
    "len(balanced_test_ix_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Inspect sentences manually to filter out problematic cases\n",
    "# list(zip(balanced_test_ix_2,\n",
    "#          list(dedup_est_labels.loc[balanced_test_ix_2].sentence.values),\n",
    "#          dedup_est_labels.loc[balanced_test_ix_2].stance.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "problematic_3 = [168,133,1218]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>round</th>\n",
       "      <th>batch</th>\n",
       "      <th>sent_id</th>\n",
       "      <th>disagree</th>\n",
       "      <th>neutral</th>\n",
       "      <th>agree</th>\n",
       "      <th>sentence</th>\n",
       "      <th>max_prob_label</th>\n",
       "      <th>guid</th>\n",
       "      <th>stance</th>\n",
       "      <th>outlet_stance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>t25</td>\n",
       "      <td>0.001220</td>\n",
       "      <td>0.997152</td>\n",
       "      <td>0.001628</td>\n",
       "      <td>The nation that leads the clean energy economy is likely to lead the global economy.</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1_5_t25</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>t20</td>\n",
       "      <td>0.001729</td>\n",
       "      <td>0.994535</td>\n",
       "      <td>0.003735</td>\n",
       "      <td>Natural variability is large for sea ice.</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1_4_t20</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1218</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>t28</td>\n",
       "      <td>0.212514</td>\n",
       "      <td>0.780922</td>\n",
       "      <td>0.006563</td>\n",
       "      <td>Global emissions of carbon dioxide are slowing somewhat from the rapid pace of the last decade.</td>\n",
       "      <td>neutral</td>\n",
       "      <td>4_2_t28</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      round  batch sent_id  disagree   neutral     agree  \\\n",
       "168   1      5      t25     0.001220  0.997152  0.001628   \n",
       "133   1      4      t20     0.001729  0.994535  0.003735   \n",
       "1218  4      2      t28     0.212514  0.780922  0.006563   \n",
       "\n",
       "                                                                                             sentence  \\\n",
       "168   The nation that leads the clean energy economy is likely to lead the global economy.              \n",
       "133   Natural variability is large for sea ice.                                                         \n",
       "1218  Global emissions of carbon dioxide are slowing somewhat from the rapid pace of the last decade.   \n",
       "\n",
       "     max_prob_label     guid   stance  outlet_stance  \n",
       "168   neutral        1_5_t25  neutral  1              \n",
       "133   neutral        1_4_t20  neutral  1              \n",
       "1218  neutral        4_2_t28  neutral  1              "
      ]
     },
     "execution_count": 647,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dedup_est_labels.loc[problematic_3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "201"
      ]
     },
     "execution_count": 648,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for outlet_stance in indices_per_outlet_stance:\n",
    "    for stance in STANCES:\n",
    "        non_problematic_balanced_test_ix.extend([x for x in new_indices_per_outlet_stance_2[outlet_stance][stance]\n",
    "                                if x not in problematic_3])\n",
    "len(non_problematic_balanced_test_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    102\n",
       "1    99 \n",
       "Name: outlet_stance, dtype: int64"
      ]
     },
     "execution_count": 649,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dedup_est_labels.loc[non_problematic_balanced_test_ix].outlet_stance.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "agree       34\n",
       "neutral     34\n",
       "disagree    34\n",
       "Name: stance, dtype: int64"
      ]
     },
     "execution_count": 650,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dedup_est_labels.loc[non_problematic_balanced_test_ix][\n",
    "    dedup_est_labels.loc[non_problematic_balanced_test_ix].outlet_stance == 0\n",
    "].stance.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "agree       34\n",
       "disagree    34\n",
       "neutral     31\n",
       "Name: stance, dtype: int64"
      ]
     },
     "execution_count": 651,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dedup_est_labels.loc[non_problematic_balanced_test_ix][\n",
    "    dedup_est_labels.loc[non_problematic_balanced_test_ix].outlet_stance == 1\n",
    "].stance.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "new_N_needed_per_outlet_stance_2 = {0: {\n",
    "    \"agree\": 0, \"disagree\": 0, \"neutral\": 0\n",
    "},\n",
    "                             1: {\n",
    "                                 \"agree\": 0, \"disagree\": 0, \"neutral\": 3\n",
    "                             }}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anti agree (279, 11)\n",
      "anti neutral (389, 11)\n",
      "anti disagree (252, 11)\n",
      "pro agree (429, 11)\n",
      "pro neutral (375, 11)\n",
      "pro disagree (75, 11)\n"
     ]
    }
   ],
   "source": [
    "# New random sample to bring up numbers\n",
    "new_indices_per_outlet_stance_3 = defaultdict(dict)\n",
    "for outlet_stance in [0,1]:\n",
    "    for stance in ['agree','neutral','disagree']:\n",
    "        sub_df = dedup_est_labels.loc[(dedup_est_labels.stance == stance) & \n",
    "                                     (dedup_est_labels.outlet_stance == outlet_stance) &\n",
    "                                     (~dedup_est_labels.index.isin(\n",
    "                                         indices_per_outlet_stance[outlet_stance][stance])) & \n",
    "                                     (~dedup_est_labels.index.isin(\n",
    "                                     new_indices_per_outlet_stance[outlet_stance][stance])) &\n",
    "                                     (~dedup_est_labels.index.isin(\n",
    "                                     new_indices_per_outlet_stance_2[outlet_stance][stance]))]\n",
    "        str_outlet_stance = 'pro' if outlet_stance == 1 else 'anti'\n",
    "        print(str_outlet_stance,stance,sub_df.shape)\n",
    "        new_indices_per_outlet_stance_3[outlet_stance][stance] = np.random.choice(\n",
    "            sub_df.index,size=new_N_needed_per_outlet_stance_2[outlet_stance][stance],\n",
    "            replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 agree 0\n",
      "0 neutral 0\n",
      "0 disagree 0\n",
      "1 agree 0\n",
      "1 neutral 3\n",
      "1 disagree 0\n"
     ]
    }
   ],
   "source": [
    "for outlet_stance in new_indices_per_outlet_stance_3:\n",
    "    for stance in STANCES:\n",
    "        print(outlet_stance,stance,len(new_indices_per_outlet_stance_3[outlet_stance][stance]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 655,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_test_ix_3 = []\n",
    "for outlet_stance in new_indices_per_outlet_stance_3:\n",
    "    for stance in STANCES:\n",
    "        balanced_test_ix_3.extend(new_indices_per_outlet_stance_3[outlet_stance][stance])\n",
    "len(balanced_test_ix_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(986,\n",
       "  'China has already overtaken the United States when it comes to being the biggest emitter of carbon dioxide.',\n",
       "  'neutral'),\n",
       " (1918,\n",
       "  \"There's no one way to talk to people about climate change.\",\n",
       "  'neutral'),\n",
       " (1066,\n",
       "  'Americans between the ages of 18 and 34 are, for the most part, split on the issue of global warming and, on some indicators, relatively disengaged when compared to older generations.',\n",
       "  'neutral')]"
      ]
     },
     "execution_count": 656,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect sentences manually to filter out problematic cases\n",
    "list(zip(balanced_test_ix_3,\n",
    "         list(dedup_est_labels.loc[balanced_test_ix_3].sentence.values),\n",
    "         dedup_est_labels.loc[balanced_test_ix_3].stance.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "204"
      ]
     },
     "execution_count": 657,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for outlet_stance in indices_per_outlet_stance:\n",
    "    for stance in STANCES:\n",
    "        non_problematic_balanced_test_ix.extend([x for x in new_indices_per_outlet_stance_3[outlet_stance][stance]\n",
    "                                ])\n",
    "len(non_problematic_balanced_test_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 659,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    102\n",
       "0    102\n",
       "Name: outlet_stance, dtype: int64"
      ]
     },
     "execution_count": 659,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dedup_est_labels.loc[non_problematic_balanced_test_ix].outlet_stance.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 660,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "agree       34\n",
       "neutral     34\n",
       "disagree    34\n",
       "Name: stance, dtype: int64"
      ]
     },
     "execution_count": 660,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dedup_est_labels.loc[non_problematic_balanced_test_ix][\n",
    "    dedup_est_labels.loc[non_problematic_balanced_test_ix].outlet_stance == 0\n",
    "].stance.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 661,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "agree       34\n",
       "neutral     34\n",
       "disagree    34\n",
       "Name: stance, dtype: int64"
      ]
     },
     "execution_count": 661,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dedup_est_labels.loc[non_problematic_balanced_test_ix][\n",
    "    dedup_est_labels.loc[non_problematic_balanced_test_ix].outlet_stance == 1\n",
    "].stance.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 664,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dedup_est_labels.loc[non_problematic_balanced_test_ix].to_pickle('./save/held_out_balanced_test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 666,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dedup_est_labels.loc[non_problematic_balanced_test_ix].to_csv('./save/held_out_balanced_test.tsv',\n",
    "                                                             sep='\\t',header=True,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## All SemEval tweets as eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "semeval_df['nli_label'] = semeval_df['stance'].apply(lambda x: stance2nli[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "os.mkdir('./save/semeval_test')\n",
    "semeval_df[['Tweet','stance','nli_label']].to_csv('./save/semeval_test'+'/test.tsv',sep='\\t',header=None,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## SemEval as train, dev, and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(394, 76, 94)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "semeval_df['nli_label'] = semeval_df['stance'].apply(lambda x: stance2nli[x])\n",
    "semeval_df['sentence'] = semeval_df['Tweet']\n",
    "train_ix,eval_ix = train_test_split(list(semeval_df.index),test_size=0.3,random_state=42)\n",
    "dev_ix,test_ix = train_test_split(eval_ix,test_size=0.55,random_state=42)\n",
    "len(train_ix),len(dev_ix),len(test_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((394, 5), (76, 5), (94, 5))"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = semeval_df.loc[semeval_df.index.isin(train_ix)]\n",
    "dev_df = semeval_df.loc[semeval_df.index.isin(dev_ix)]\n",
    "test_df = semeval_df.loc[semeval_df.index.isin(test_ix)]\n",
    "train_df.shape,dev_df.shape,test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#write_data('semeval_train_eval',42,[],train_df,test_df,dev_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-val splits (test on item-response est. label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 695,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 696,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1838"
      ]
     },
     "execution_count": 696,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "order = np.arange(len(mturk_df))\n",
    "np.random.shuffle(order)\n",
    "len(order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 697,
   "metadata": {
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1838 1838 184 184 1470\n",
      "1838 1838 184 184 1470\n",
      "1838 1838 184 184 1470\n",
      "1838 1838 184 184 1470\n",
      "1838 1838 184 184 1470\n",
      "1838 1838 184 184 1470\n",
      "1838 1838 184 184 1470\n",
      "1838 1838 184 184 1470\n",
      "1838 1838 183 183 1472\n",
      "1838 1838 183 183 1472\n"
     ]
    }
   ],
   "source": [
    "indices_per_fold = {}\n",
    "n_folds = 10\n",
    "for f in range(n_folds):\n",
    "    test_indices = [order[i] for i in np.arange(len(mturk_df)) if i % n_folds == f]\n",
    "    nontest_indices = list(set(np.arange(len(mturk_df))) - set(test_indices))\n",
    "    dev_indices = list(np.random.choice(nontest_indices, size=len(test_indices), replace=False))\n",
    "    train_indices = list(set(nontest_indices) - set(dev_indices))\n",
    "    all_indices = set(test_indices).union(set(dev_indices)).union(set(train_indices))\n",
    "    indices_per_fold[f] = {'train':train_indices,'dev':dev_indices,'test':test_indices}\n",
    "    print(len(all_indices), len(test_indices) + len(dev_indices) + len(train_indices), len(test_indices), len(dev_indices), len(train_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 698,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(indices_per_fold,open('cross_val_10_seed_42_indices.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 699,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_per_fold = pickle.load(open('cross_val_10_seed_42_indices.pkl','rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Title-augmented train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 728,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for f in range(n_folds):\n",
    "#     fold_ix = indices_per_fold[f]\n",
    "#     train_ix = fold_ix['train']\n",
    "#     test_ix = fold_ix['test']\n",
    "#     dev_ix = fold_ix['dev']\n",
    "    \n",
    "#     train_df = mturk_df.loc[mturk_df.index.isin(train_ix)]\n",
    "#     dev_df = mturk_df.loc[mturk_df.index.isin(dev_ix)]\n",
    "#     test_df = mturk_df.loc[mturk_df.index.isin(test_ix)]\n",
    "#     print(train_df.shape,dev_df.shape,test_df.shape)\n",
    "#     write_data('all_mturk_with_titles_train_{}_fold_{}'.format(42,f),[],train_df,test_df,dev_df,\n",
    "#            add_titles=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Oops, accidentally re-wrote with vanilla (non-title-augmented) data splits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vanilla MTurk (est. labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 745,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for f in range(n_folds):\n",
    "#     fold_0_ix = indices_per_fold[f]\n",
    "#     train_ix = fold_0_ix['train']\n",
    "#     test_ix = fold_0_ix['test']\n",
    "#     dev_ix = fold_0_ix['dev']\n",
    "\n",
    "#     train_df = dedup_est_labels.loc[dedup_est_labels.index.isin(train_ix)]\n",
    "#     dev_df = dedup_est_labels.loc[dedup_est_labels.index.isin(dev_ix)]\n",
    "#     test_df = dedup_est_labels.loc[dedup_est_labels.index.isin(test_ix)]\n",
    "#     print(train_df.shape,dev_df.shape,test_df.shape)\n",
    "#     write_data('all_mturk_train_{}_fold_{}'.format(seed,f),[],train_df,test_df,dev_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 746,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    635\n",
       "0    568\n",
       "2    267\n",
       "Name: 1, dtype: int64"
      ]
     },
     "execution_count": 746,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('./save/all_mturk_train_42_fold_0/train.tsv',sep='\\t',header=None)[1].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 750,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1270\n",
       "0    1136\n",
       "2    534 \n",
       "Name: 1, dtype: int64"
      ]
     },
     "execution_count": 750,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('./save/all_mturk_train_backtrans_fr_42_fold_0/train.tsv',sep='\\t',header=None)[1].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 751,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    635\n",
       "0    568\n",
       "2    534\n",
       "Name: 1, dtype: int64"
      ]
     },
     "execution_count": 751,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('./save/all_mturk_train_backtrans_fr_upsampled_42_fold_0/train.tsv',sep='\\t',\n",
    "            header=None)[1].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1961"
      ]
     },
     "execution_count": 410,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "677+658+626"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 752,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    534\n",
       "1    534\n",
       "0    534\n",
       "Name: 1, dtype: int64"
      ]
     },
     "execution_count": 752,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('./save/all_mturk_train_backtrans_fr_42_fold_0_downsampled/train.tsv',sep='\\t',\n",
    "            header=None)[1].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Back translation augmented train, with and without downsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 749,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#Add backtranslations of the train_ix examples to training\n",
    "# for f in range(n_folds):\n",
    "#     fold_0_ix = indices_per_fold[f]\n",
    "#     train_ix = fold_0_ix['train']\n",
    "#     test_ix = fold_0_ix['test']\n",
    "#     dev_ix = fold_0_ix['dev']\n",
    "\n",
    "#     train_df = dedup_est_labels.loc[dedup_est_labels.index.isin(train_ix)]\n",
    "#     dev_df = dedup_est_labels.loc[dedup_est_labels.index.isin(dev_ix)]\n",
    "#     test_df = dedup_est_labels.loc[dedup_est_labels.index.isin(test_ix)]\n",
    "#     backtrans_fr_df = add_backtrans_train(train_df,'fr')\n",
    "#     backtrans_zh_df = add_backtrans_train(train_df,'zh')\n",
    "#     backtrans_both_df = backtrans_fr_df.append(backtrans_zh_df,ignore_index=True).drop_duplicates('guid',keep='first')\n",
    "#     print(backtrans_fr_df.shape,backtrans_zh_df.shape,backtrans_both_df.shape,dev_df.shape,test_df.shape)\n",
    "#     write_data('all_mturk_train_backtrans_fr_{}_fold_{}'.format(seed,f),[],backtrans_fr_df,test_df,dev_df)\n",
    "#     write_data('all_mturk_train_backtrans_zh_{}_fold_{}'.format(seed,f),[],backtrans_zh_df,test_df,dev_df)\n",
    "#     write_data('all_mturk_train_backtrans_both_{}_fold_{}'.format(seed,f),[],backtrans_both_df,test_df,dev_df)\n",
    "#     write_data('all_mturk_train_backtrans_fr_{}_fold_{}'.format(seed,f),[],backtrans_fr_df,test_df,dev_df,do_downsample=True)\n",
    "#     write_data('all_mturk_train_backtrans_zh_{}_fold_{}'.format(seed,f),[],backtrans_zh_df,test_df,dev_df,do_downsample=True)\n",
    "#     write_data('all_mturk_train_backtrans_both_{}_fold_{}'.format(seed,f),[],backtrans_both_df,test_df,dev_df,do_downsample=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Back translation + upsample minority class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 753,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# for f in range(n_folds):\n",
    "#     fold_0_ix = indices_per_fold[f]\n",
    "#     train_ix = fold_0_ix['train']\n",
    "#     test_ix = fold_0_ix['test']\n",
    "#     dev_ix = fold_0_ix['dev']\n",
    "\n",
    "#     train_df = dedup_est_labels.loc[dedup_est_labels.index.isin(train_ix)]\n",
    "#     dev_df = dedup_est_labels.loc[dedup_est_labels.index.isin(dev_ix)]\n",
    "#     test_df = dedup_est_labels.loc[dedup_est_labels.index.isin(test_ix)]\n",
    "#     backtrans_fr_df = add_backtrans_train(train_df,'fr',upsample=True)\n",
    "#     backtrans_zh_df = add_backtrans_train(train_df,'zh',upsample=True)\n",
    "#     backtrans_both_df = backtrans_fr_df.append(backtrans_zh_df,ignore_index=True).drop_duplicates('guid',keep='first')\n",
    "#     print(backtrans_fr_df.shape,backtrans_zh_df.shape,backtrans_both_df.shape,dev_df.shape,test_df.shape)\n",
    "#     write_data('all_mturk_train_backtrans_fr_upsampled_{}_fold_{}'.format(seed,f),[],backtrans_fr_df,test_df,dev_df)\n",
    "#     write_data('all_mturk_train_backtrans_zh_upsampled_{}_fold_{}'.format(seed,f),[],backtrans_zh_df,test_df,dev_df)\n",
    "#     write_data('all_mturk_train_backtrans_both_upsampled_{}_fold_{}'.format(seed,f),[],backtrans_both_df,test_df,dev_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### High IAA train, eval on rest (splits differ only in dev/test distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_indices = mturk_df.loc[mturk_df.is_high_iaa].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "code_folding": [
     2
    ],
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "923 2042 462 461 1119\n",
      "923 2042 462 461 1119\n",
      "923 2042 462 461 1119\n",
      "923 2042 462 461 1119\n",
      "923 2042 462 461 1119\n",
      "923 2042 462 461 1119\n",
      "923 2042 462 461 1119\n",
      "923 2042 462 461 1119\n",
      "923 2042 462 461 1119\n",
      "923 2042 462 461 1119\n"
     ]
    }
   ],
   "source": [
    "indices_per_fold = {}\n",
    "n_folds = 10\n",
    "for f in range(n_folds):\n",
    "    all_indices = list(low_iaa_df.index)\n",
    "    test_indices = list(np.random.choice(all_indices, size=round(len(all_indices)/2), replace=False))\n",
    "    dev_indices = list(set(all_indices) - set(test_indices))\n",
    "    all_indices = set(test_indices).union(set(dev_indices))#.union(set(train_indices))\n",
    "    indices_per_fold[f] = {'train':train_indices,'dev':dev_indices,'test':test_indices}\n",
    "    print(len(all_indices), len(test_indices) + len(dev_indices) + len(train_indices), len(test_indices), len(dev_indices), len(train_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(indices_per_fold,open('high_iaa_cross_val_10_seed_42_high_iaa_indices.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# for f in range(0,n_folds):\n",
    "#     fold_0_ix = indices_per_fold[f]\n",
    "#     train_ix = fold_0_ix['train']\n",
    "#     test_ix = fold_0_ix['test']\n",
    "#     dev_ix = fold_0_ix['dev']\n",
    "\n",
    "#     train_df = mturk_df.loc[mturk_df.index.isin(train_ix)]\n",
    "#     dev_df = mturk_df.loc[mturk_df.index.isin(dev_ix)]\n",
    "#     test_df = mturk_df.loc[mturk_df.index.isin(test_ix)]\n",
    "#     print(train_df.shape,dev_df.shape,test_df.shape)\n",
    "#     write_data('high_iaa_train_fold_{}'.format(f),42,[],train_df,test_df,dev_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Augment w/ back translations, with and without downsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# for f in range(n_folds):\n",
    "#     fold_0_ix = indices_per_fold[f]\n",
    "#     train_ix = fold_0_ix['train']\n",
    "#     test_ix = fold_0_ix['test']\n",
    "#     dev_ix = fold_0_ix['dev']\n",
    "\n",
    "#     train_df = mturk_df.loc[mturk_df.index.isin(train_ix)]\n",
    "#     dev_df = mturk_df.loc[mturk_df.index.isin(dev_ix)]\n",
    "#     test_df = mturk_df.loc[mturk_df.index.isin(test_ix)]\n",
    "#     print(train_df.shape,dev_df.shape,test_df.shape)\n",
    "#     backtrans_fr_df = add_backtrans_train(train_df,'fr')\n",
    "#     backtrans_zh_df = add_backtrans_train(train_df,'zh')\n",
    "#     backtrans_both_df = backtrans_fr_df.append(backtrans_zh_df,ignore_index=True).drop_duplicates('guid',keep='first')\n",
    "#     print(backtrans_fr_df.shape,backtrans_zh_df.shape,backtrans_both_df.shape,dev_df.shape,test_df.shape)\n",
    "#     write_data('high_iaa_train_fold_{}'.format(f),seed,['backtrans_fr'],backtrans_fr_df,test_df,dev_df)\n",
    "#     write_data('high_iaa_train_fold_{}'.format(f),seed,['backtrans_zh'],backtrans_zh_df,test_df,dev_df)\n",
    "#     write_data('high_iaa_train_fold_{}'.format(f),seed,['backtrans_both'],backtrans_both_df,test_df,dev_df)\n",
    "#     write_data('high_iaa_train_fold_{}'.format(f),seed,['backtrans_fr'],backtrans_fr_df,test_df,dev_df,do_downsample=True)\n",
    "#     write_data('high_iaa_train_fold_{}'.format(f),seed,['backtrans_zh'],backtrans_zh_df,test_df,dev_df,do_downsample=True)\n",
    "#     write_data('high_iaa_train_fold_{}'.format(f),seed,['backtrans_both'],backtrans_both_df,test_df,dev_df,do_downsample=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Back translation + upsample minority class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# for f in range(n_folds):\n",
    "#     fold_0_ix = indices_per_fold[f]\n",
    "#     train_ix = fold_0_ix['train']\n",
    "#     test_ix = fold_0_ix['test']\n",
    "#     dev_ix = fold_0_ix['dev']\n",
    "\n",
    "#     train_df = mturk_df.loc[mturk_df.index.isin(train_ix)]\n",
    "#     dev_df = mturk_df.loc[mturk_df.index.isin(dev_ix)]\n",
    "#     test_df = mturk_df.loc[mturk_df.index.isin(test_ix)]\n",
    "#     print(train_df.shape,dev_df.shape,test_df.shape)\n",
    "#     backtrans_fr_df = add_backtrans_train(train_df,'fr',upsample=True)\n",
    "#     backtrans_zh_df = add_backtrans_train(train_df,'zh',upsample=True)\n",
    "#     backtrans_both_df = backtrans_fr_df.append(backtrans_zh_df,ignore_index=True).drop_duplicates('guid',keep='first')\n",
    "#     print(backtrans_fr_df.shape,backtrans_zh_df.shape,backtrans_both_df.shape,dev_df.shape,test_df.shape)\n",
    "#     write_data('high_iaa_train_fold_{}'.format(f),seed,['backtrans_fr_upsampled'],backtrans_fr_df,test_df,dev_df)\n",
    "#     write_data('high_iaa_train_fold_{}'.format(f),seed,['backtrans_zh_upsampled'],backtrans_zh_df,test_df,dev_df)\n",
    "#     write_data('high_iaa_train_fold_{}'.format(f),seed,['backtrans_both_upsampled'],backtrans_both_df,test_df,dev_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SCP to cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename first so that all of data is followed by fold, seed info\n",
    "os.rename('./save/high_iaa_train_','./save/high_iaa_train_HELLO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "for fold in range(0,10):\n",
    "    for f in glob.glob(os.path.join('save','all_mturk_train_fold_{}_*'.format(fold))):\n",
    "        split_f = f.split('all_mturk_train_fold_{}_'.format(fold))\n",
    "        new_f = split_f[0] + 'all_mturk_train_' + split_f[-1] + '_fold_{}'.format(fold)\n",
    "        #print(f,new_f)\n",
    "        os.rename(f,new_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [],
   "source": [
    "from paramiko import SSHClient\n",
    "from scp import SCPClient\n",
    "\n",
    "ssh = SSHClient()\n",
    "ssh.load_system_host_keys()\n",
    "ssh.connect(hostname='jacob.stanford.edu',username='yiweil',password='yldwuaeo2699zhishao15')\n",
    "\n",
    "# Define progress callback that prints the current percentage completed for the file\n",
    "def progress(filename, size, sent):\n",
    "    print(\"%s\\'s progress: %.2f%%   \\r\" % (filename, float(sent)/float(size)*100) )\n",
    "    \n",
    "cluster_data_dir = '/u/scr/yiweil/sci-debates/cc_stance/climate_data'\n",
    "local_data_dir = './save'\n",
    "\n",
    "# SCPCLient takes a paramiko transport and progress callback as its arguments.\n",
    "scp = SCPClient(ssh.get_transport(), progress=progress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./save/all_mturk_with_titles_train_42_fold_0',\n",
       " './save/all_mturk_with_titles_train_42_fold_1',\n",
       " './save/all_mturk_with_titles_train_42_fold_2',\n",
       " './save/all_mturk_with_titles_train_42_fold_3',\n",
       " './save/all_mturk_with_titles_train_42_fold_4',\n",
       " './save/all_mturk_with_titles_train_42_fold_5',\n",
       " './save/all_mturk_with_titles_train_42_fold_6',\n",
       " './save/all_mturk_with_titles_train_42_fold_7',\n",
       " './save/all_mturk_with_titles_train_42_fold_8',\n",
       " './save/all_mturk_with_titles_train_42_fold_9']"
      ]
     },
     "execution_count": 469,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glob.glob(local_data_dir+'/all_mturk_with_titles_*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'dev.tsv''s progress: 0.00%   \n",
      "b'dev.tsv''s progress: 66.12%   \n",
      "b'dev.tsv''s progress: 100.00%   \n",
      "b'test.tsv''s progress: 0.00%   \n",
      "b'test.tsv''s progress: 62.81%   \n",
      "b'test.tsv''s progress: 100.00%   \n",
      "b'train.tsv''s progress: 0.00%   \n",
      "b'train.tsv''s progress: 4.18%   \n",
      "b'train.tsv''s progress: 8.36%   \n",
      "b'train.tsv''s progress: 12.54%   \n",
      "b'train.tsv''s progress: 16.72%   \n",
      "b'train.tsv''s progress: 20.90%   \n",
      "b'train.tsv''s progress: 25.07%   \n",
      "b'train.tsv''s progress: 29.25%   \n",
      "b'train.tsv''s progress: 33.43%   \n",
      "b'train.tsv''s progress: 37.61%   \n",
      "b'train.tsv''s progress: 41.79%   \n",
      "b'train.tsv''s progress: 45.97%   \n",
      "b'train.tsv''s progress: 50.15%   \n",
      "b'train.tsv''s progress: 54.33%   \n",
      "b'train.tsv''s progress: 58.51%   \n",
      "b'train.tsv''s progress: 62.69%   \n",
      "b'train.tsv''s progress: 66.87%   \n",
      "b'train.tsv''s progress: 71.05%   \n",
      "b'train.tsv''s progress: 75.22%   \n",
      "b'train.tsv''s progress: 79.40%   \n",
      "b'train.tsv''s progress: 83.58%   \n",
      "b'train.tsv''s progress: 87.76%   \n",
      "b'train.tsv''s progress: 91.94%   \n",
      "b'train.tsv''s progress: 96.12%   \n",
      "b'train.tsv''s progress: 100.00%   \n",
      "b'dev.tsv''s progress: 0.00%   \n",
      "b'dev.tsv''s progress: 63.77%   \n",
      "b'dev.tsv''s progress: 100.00%   \n",
      "b'test.tsv''s progress: 0.00%   \n",
      "b'test.tsv''s progress: 65.38%   \n",
      "b'test.tsv''s progress: 100.00%   \n",
      "b'train.tsv''s progress: 0.00%   \n",
      "b'train.tsv''s progress: 4.18%   \n",
      "b'train.tsv''s progress: 8.36%   \n",
      "b'train.tsv''s progress: 12.53%   \n",
      "b'train.tsv''s progress: 16.71%   \n",
      "b'train.tsv''s progress: 20.89%   \n",
      "b'train.tsv''s progress: 25.07%   \n",
      "b'train.tsv''s progress: 29.25%   \n",
      "b'train.tsv''s progress: 33.42%   \n",
      "b'train.tsv''s progress: 37.60%   \n",
      "b'train.tsv''s progress: 41.78%   \n",
      "b'train.tsv''s progress: 45.96%   \n",
      "b'train.tsv''s progress: 50.14%   \n",
      "b'train.tsv''s progress: 54.31%   \n",
      "b'train.tsv''s progress: 58.49%   \n",
      "b'train.tsv''s progress: 62.67%   \n",
      "b'train.tsv''s progress: 66.85%   \n",
      "b'train.tsv''s progress: 71.03%   \n",
      "b'train.tsv''s progress: 75.20%   \n",
      "b'train.tsv''s progress: 79.38%   \n",
      "b'train.tsv''s progress: 83.56%   \n",
      "b'train.tsv''s progress: 87.74%   \n",
      "b'train.tsv''s progress: 91.91%   \n",
      "b'train.tsv''s progress: 96.09%   \n",
      "b'train.tsv''s progress: 100.00%   \n",
      "b'dev.tsv''s progress: 0.00%   \n",
      "b'dev.tsv''s progress: 63.67%   \n",
      "b'dev.tsv''s progress: 100.00%   \n",
      "b'test.tsv''s progress: 0.00%   \n",
      "b'test.tsv''s progress: 59.74%   \n",
      "b'test.tsv''s progress: 100.00%   \n",
      "b'train.tsv''s progress: 0.00%   \n",
      "b'train.tsv''s progress: 4.20%   \n",
      "b'train.tsv''s progress: 8.41%   \n",
      "b'train.tsv''s progress: 12.61%   \n",
      "b'train.tsv''s progress: 16.82%   \n",
      "b'train.tsv''s progress: 21.02%   \n",
      "b'train.tsv''s progress: 25.22%   \n",
      "b'train.tsv''s progress: 29.43%   \n",
      "b'train.tsv''s progress: 33.63%   \n",
      "b'train.tsv''s progress: 37.83%   \n",
      "b'train.tsv''s progress: 42.04%   \n",
      "b'train.tsv''s progress: 46.24%   \n",
      "b'train.tsv''s progress: 50.45%   \n",
      "b'train.tsv''s progress: 54.65%   \n",
      "b'train.tsv''s progress: 58.85%   \n",
      "b'train.tsv''s progress: 63.06%   \n",
      "b'train.tsv''s progress: 67.26%   \n",
      "b'train.tsv''s progress: 71.46%   \n",
      "b'train.tsv''s progress: 75.67%   \n",
      "b'train.tsv''s progress: 79.87%   \n",
      "b'train.tsv''s progress: 84.08%   \n",
      "b'train.tsv''s progress: 88.28%   \n",
      "b'train.tsv''s progress: 92.48%   \n",
      "b'train.tsv''s progress: 96.69%   \n",
      "b'train.tsv''s progress: 100.00%   \n",
      "b'dev.tsv''s progress: 0.00%   \n",
      "b'dev.tsv''s progress: 61.87%   \n",
      "b'dev.tsv''s progress: 100.00%   \n",
      "b'test.tsv''s progress: 0.00%   \n",
      "b'test.tsv''s progress: 65.17%   \n",
      "b'test.tsv''s progress: 100.00%   \n",
      "b'train.tsv''s progress: 0.00%   \n",
      "b'train.tsv''s progress: 4.19%   \n",
      "b'train.tsv''s progress: 8.37%   \n",
      "b'train.tsv''s progress: 12.56%   \n",
      "b'train.tsv''s progress: 16.75%   \n",
      "b'train.tsv''s progress: 20.94%   \n",
      "b'train.tsv''s progress: 25.12%   \n",
      "b'train.tsv''s progress: 29.31%   \n",
      "b'train.tsv''s progress: 33.50%   \n",
      "b'train.tsv''s progress: 37.69%   \n",
      "b'train.tsv''s progress: 41.87%   \n",
      "b'train.tsv''s progress: 46.06%   \n",
      "b'train.tsv''s progress: 50.25%   \n",
      "b'train.tsv''s progress: 54.43%   \n",
      "b'train.tsv''s progress: 58.62%   \n",
      "b'train.tsv''s progress: 62.81%   \n",
      "b'train.tsv''s progress: 67.00%   \n",
      "b'train.tsv''s progress: 71.18%   \n",
      "b'train.tsv''s progress: 75.37%   \n",
      "b'train.tsv''s progress: 79.56%   \n",
      "b'train.tsv''s progress: 83.74%   \n",
      "b'train.tsv''s progress: 87.93%   \n",
      "b'train.tsv''s progress: 92.12%   \n",
      "b'train.tsv''s progress: 96.31%   \n",
      "b'train.tsv''s progress: 100.00%   \n",
      "b'dev.tsv''s progress: 0.00%   \n",
      "b'dev.tsv''s progress: 62.80%   \n",
      "b'dev.tsv''s progress: 100.00%   \n",
      "b'test.tsv''s progress: 0.00%   \n",
      "b'test.tsv''s progress: 60.52%   \n",
      "b'test.tsv''s progress: 100.00%   \n",
      "b'train.tsv''s progress: 0.00%   \n",
      "b'train.tsv''s progress: 4.20%   \n",
      "b'train.tsv''s progress: 8.41%   \n",
      "b'train.tsv''s progress: 12.61%   \n",
      "b'train.tsv''s progress: 16.82%   \n",
      "b'train.tsv''s progress: 21.02%   \n",
      "b'train.tsv''s progress: 25.22%   \n",
      "b'train.tsv''s progress: 29.43%   \n",
      "b'train.tsv''s progress: 33.63%   \n",
      "b'train.tsv''s progress: 37.83%   \n",
      "b'train.tsv''s progress: 42.04%   \n",
      "b'train.tsv''s progress: 46.24%   \n",
      "b'train.tsv''s progress: 50.45%   \n",
      "b'train.tsv''s progress: 54.65%   \n",
      "b'train.tsv''s progress: 58.85%   \n",
      "b'train.tsv''s progress: 63.06%   \n",
      "b'train.tsv''s progress: 67.26%   \n",
      "b'train.tsv''s progress: 71.46%   \n",
      "b'train.tsv''s progress: 75.67%   \n",
      "b'train.tsv''s progress: 79.87%   \n",
      "b'train.tsv''s progress: 84.08%   \n",
      "b'train.tsv''s progress: 88.28%   \n",
      "b'train.tsv''s progress: 92.48%   \n",
      "b'train.tsv''s progress: 96.69%   \n",
      "b'train.tsv''s progress: 100.00%   \n",
      "b'dev.tsv''s progress: 0.00%   \n",
      "b'dev.tsv''s progress: 63.46%   \n",
      "b'dev.tsv''s progress: 100.00%   \n",
      "b'test.tsv''s progress: 0.00%   \n",
      "b'test.tsv''s progress: 62.76%   \n",
      "b'test.tsv''s progress: 100.00%   \n",
      "b'train.tsv''s progress: 0.00%   \n",
      "b'train.tsv''s progress: 4.19%   \n",
      "b'train.tsv''s progress: 8.38%   \n",
      "b'train.tsv''s progress: 12.57%   \n",
      "b'train.tsv''s progress: 16.76%   \n",
      "b'train.tsv''s progress: 20.95%   \n",
      "b'train.tsv''s progress: 25.14%   \n",
      "b'train.tsv''s progress: 29.33%   \n",
      "b'train.tsv''s progress: 33.52%   \n",
      "b'train.tsv''s progress: 37.71%   \n",
      "b'train.tsv''s progress: 41.90%   \n",
      "b'train.tsv''s progress: 46.10%   \n",
      "b'train.tsv''s progress: 50.29%   \n",
      "b'train.tsv''s progress: 54.48%   \n",
      "b'train.tsv''s progress: 58.67%   \n",
      "b'train.tsv''s progress: 62.86%   \n",
      "b'train.tsv''s progress: 67.05%   \n",
      "b'train.tsv''s progress: 71.24%   \n",
      "b'train.tsv''s progress: 75.43%   \n",
      "b'train.tsv''s progress: 79.62%   \n",
      "b'train.tsv''s progress: 83.81%   \n",
      "b'train.tsv''s progress: 88.00%   \n",
      "b'train.tsv''s progress: 92.19%   \n",
      "b'train.tsv''s progress: 96.38%   \n",
      "b'train.tsv''s progress: 100.00%   \n",
      "b'dev.tsv''s progress: 0.00%   \n",
      "b'dev.tsv''s progress: 61.47%   \n",
      "b'dev.tsv''s progress: 100.00%   \n",
      "b'test.tsv''s progress: 0.00%   \n",
      "b'test.tsv''s progress: 59.36%   \n",
      "b'test.tsv''s progress: 100.00%   \n",
      "b'train.tsv''s progress: 0.00%   \n",
      "b'train.tsv''s progress: 4.22%   \n",
      "b'train.tsv''s progress: 8.43%   \n",
      "b'train.tsv''s progress: 12.65%   \n",
      "b'train.tsv''s progress: 16.86%   \n",
      "b'train.tsv''s progress: 21.08%   \n",
      "b'train.tsv''s progress: 25.29%   \n",
      "b'train.tsv''s progress: 29.51%   \n",
      "b'train.tsv''s progress: 33.72%   \n",
      "b'train.tsv''s progress: 37.94%   \n",
      "b'train.tsv''s progress: 42.16%   \n",
      "b'train.tsv''s progress: 46.37%   \n",
      "b'train.tsv''s progress: 50.59%   \n",
      "b'train.tsv''s progress: 54.80%   \n",
      "b'train.tsv''s progress: 59.02%   \n",
      "b'train.tsv''s progress: 63.23%   \n",
      "b'train.tsv''s progress: 67.45%   \n",
      "b'train.tsv''s progress: 71.66%   \n",
      "b'train.tsv''s progress: 75.88%   \n",
      "b'train.tsv''s progress: 80.10%   \n",
      "b'train.tsv''s progress: 84.31%   \n",
      "b'train.tsv''s progress: 88.53%   \n",
      "b'train.tsv''s progress: 92.74%   \n",
      "b'train.tsv''s progress: 96.96%   \n",
      "b'train.tsv''s progress: 100.00%   \n",
      "b'dev.tsv''s progress: 0.00%   \n",
      "b'dev.tsv''s progress: 63.38%   \n",
      "b'dev.tsv''s progress: 100.00%   \n",
      "b'test.tsv''s progress: 0.00%   \n",
      "b'test.tsv''s progress: 64.76%   \n",
      "b'test.tsv''s progress: 100.00%   \n",
      "b'train.tsv''s progress: 0.00%   \n",
      "b'train.tsv''s progress: 4.18%   \n",
      "b'train.tsv''s progress: 8.36%   \n",
      "b'train.tsv''s progress: 12.55%   \n",
      "b'train.tsv''s progress: 16.73%   \n",
      "b'train.tsv''s progress: 20.91%   \n",
      "b'train.tsv''s progress: 25.09%   \n",
      "b'train.tsv''s progress: 29.28%   \n",
      "b'train.tsv''s progress: 33.46%   \n",
      "b'train.tsv''s progress: 37.64%   \n",
      "b'train.tsv''s progress: 41.82%   \n",
      "b'train.tsv''s progress: 46.00%   \n",
      "b'train.tsv''s progress: 50.19%   \n",
      "b'train.tsv''s progress: 54.37%   \n",
      "b'train.tsv''s progress: 58.55%   \n",
      "b'train.tsv''s progress: 62.73%   \n",
      "b'train.tsv''s progress: 66.92%   \n",
      "b'train.tsv''s progress: 71.10%   \n",
      "b'train.tsv''s progress: 75.28%   \n",
      "b'train.tsv''s progress: 79.46%   \n",
      "b'train.tsv''s progress: 83.64%   \n",
      "b'train.tsv''s progress: 87.83%   \n",
      "b'train.tsv''s progress: 92.01%   \n",
      "b'train.tsv''s progress: 96.19%   \n",
      "b'train.tsv''s progress: 100.00%   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'dev.tsv''s progress: 0.00%   \n",
      "b'dev.tsv''s progress: 62.39%   \n",
      "b'dev.tsv''s progress: 100.00%   \n",
      "b'test.tsv''s progress: 0.00%   \n",
      "b'test.tsv''s progress: 62.39%   \n",
      "b'test.tsv''s progress: 100.00%   \n",
      "b'train.tsv''s progress: 0.00%   \n",
      "b'train.tsv''s progress: 4.20%   \n",
      "b'train.tsv''s progress: 8.39%   \n",
      "b'train.tsv''s progress: 12.59%   \n",
      "b'train.tsv''s progress: 16.79%   \n",
      "b'train.tsv''s progress: 20.98%   \n",
      "b'train.tsv''s progress: 25.18%   \n",
      "b'train.tsv''s progress: 29.38%   \n",
      "b'train.tsv''s progress: 33.58%   \n",
      "b'train.tsv''s progress: 37.77%   \n",
      "b'train.tsv''s progress: 41.97%   \n",
      "b'train.tsv''s progress: 46.17%   \n",
      "b'train.tsv''s progress: 50.36%   \n",
      "b'train.tsv''s progress: 54.56%   \n",
      "b'train.tsv''s progress: 58.76%   \n",
      "b'train.tsv''s progress: 62.95%   \n",
      "b'train.tsv''s progress: 67.15%   \n",
      "b'train.tsv''s progress: 71.35%   \n",
      "b'train.tsv''s progress: 75.54%   \n",
      "b'train.tsv''s progress: 79.74%   \n",
      "b'train.tsv''s progress: 83.94%   \n",
      "b'train.tsv''s progress: 88.13%   \n",
      "b'train.tsv''s progress: 92.33%   \n",
      "b'train.tsv''s progress: 96.53%   \n",
      "b'train.tsv''s progress: 100.00%   \n",
      "b'dev.tsv''s progress: 0.00%   \n",
      "b'dev.tsv''s progress: 60.39%   \n",
      "b'dev.tsv''s progress: 100.00%   \n",
      "b'test.tsv''s progress: 0.00%   \n",
      "b'test.tsv''s progress: 62.71%   \n",
      "b'test.tsv''s progress: 100.00%   \n",
      "b'train.tsv''s progress: 0.00%   \n",
      "b'train.tsv''s progress: 4.20%   \n",
      "b'train.tsv''s progress: 8.41%   \n",
      "b'train.tsv''s progress: 12.61%   \n",
      "b'train.tsv''s progress: 16.82%   \n",
      "b'train.tsv''s progress: 21.02%   \n",
      "b'train.tsv''s progress: 25.23%   \n",
      "b'train.tsv''s progress: 29.43%   \n",
      "b'train.tsv''s progress: 33.64%   \n",
      "b'train.tsv''s progress: 37.84%   \n",
      "b'train.tsv''s progress: 42.05%   \n",
      "b'train.tsv''s progress: 46.25%   \n",
      "b'train.tsv''s progress: 50.46%   \n",
      "b'train.tsv''s progress: 54.66%   \n",
      "b'train.tsv''s progress: 58.87%   \n",
      "b'train.tsv''s progress: 63.07%   \n",
      "b'train.tsv''s progress: 67.28%   \n",
      "b'train.tsv''s progress: 71.48%   \n",
      "b'train.tsv''s progress: 75.69%   \n",
      "b'train.tsv''s progress: 79.89%   \n",
      "b'train.tsv''s progress: 84.10%   \n",
      "b'train.tsv''s progress: 88.30%   \n",
      "b'train.tsv''s progress: 92.51%   \n",
      "b'train.tsv''s progress: 96.71%   \n",
      "b'train.tsv''s progress: 100.00%   \n"
     ]
    }
   ],
   "source": [
    "# for file in glob.glob(local_data_dir+'/high_iaa_train_42*'):\n",
    "#     scp.put(file, recursive=True, remote_path=cluster_data_dir)\n",
    "    \n",
    "for file in glob.glob(local_data_dir+'/all_mturk_with_titles_*'):\n",
    "    scp.put(file, recursive=True, remote_path=cluster_data_dir)\n",
    "\n",
    "scp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
