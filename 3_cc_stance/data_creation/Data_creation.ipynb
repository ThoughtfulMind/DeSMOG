{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:15: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import glob\n",
    "from collections import Counter,defaultdict\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from numpy.random import RandomState\n",
    "from sklearn import metrics\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split,KFold\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "STANCES = [\"agree\", \"neutral\", \"disagree\"]\n",
    "CLASS_NUMS = {s: i for i, s in enumerate(STANCES)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [
     1,
     5,
     11
    ]
   },
   "outputs": [],
   "source": [
    "# move to utils.py later\n",
    "nli2stance = {'entailment': CLASS_NUMS['agree'], \n",
    "              'neutral': CLASS_NUMS['neutral'], \n",
    "              'contradiction': CLASS_NUMS['disagree']}\n",
    "\n",
    "float2stance = {1.0: CLASS_NUMS['agree'],\n",
    "               0.0: CLASS_NUMS['neutral'],\n",
    "               -1.0: CLASS_NUMS['disagree']}\n",
    "\n",
    "stance2nli = {0: 'entailment', 1: 'neutral', 2: 'contradiction'}\n",
    "                \n",
    "def stance_reg(label):\n",
    "    \"\"\"\n",
    "    Regularize the stance labels \n",
    "    :param label: a label of str (agree(s)/entailment, neutral, disagree(s)/contradiction), \n",
    "     int (0, 1, 2) or str of int, or float (1.0, 0.0, -1.0)\n",
    "    :return: the label as the corresponding class_num\n",
    "    \"\"\"\n",
    "    \n",
    "    if type(label) == str:\n",
    "        if label.isalpha(): # could be a,n,d or NLI labels\n",
    "            if label in STANCES:\n",
    "                return CLASS_NUMS[label]\n",
    "            elif label[-1] == 's':\n",
    "                return CLASS_NUMS[label[:-1]]\n",
    "            else:\n",
    "                return nli2stance[label]\n",
    "        else: # label is str of (0, 1, 2)\n",
    "            return int(label)\n",
    "    elif type(label) == float:\n",
    "        return float2stance[label]\n",
    "    else:\n",
    "        return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def add_backtrans_train(train_df,language,upsample=False):\n",
    "    \"\"\"\n",
    "    Create df with backtranslations of train_df \n",
    "    :param train_df: base training data\n",
    "    :param language: 'fr' or 'zh'\n",
    "    :return: new df with previous training data + augmented data\n",
    "    \"\"\"\n",
    "    \n",
    "    backtrans_df = pd.DataFrame({\n",
    "        'round':train_df['round'].values,\n",
    "        'batch':train_df.batch.values,\n",
    "        'sent_id':train_df.sent_id.values,\n",
    "        'stance':train_df.stance.values,\n",
    "        'sentence':[get_backtrans(guid,language) for guid in train_df.guid],\n",
    "        'guid':[guid+'_'+language for guid in train_df.guid]\n",
    "    })\n",
    "    \n",
    "    \n",
    "    if upsample:\n",
    "        backtrans_df = backtrans_df.loc[backtrans_df.stance.isin({'disagrees','disagree'})].append(\n",
    "            train_df,ignore_index=True)\n",
    "    else:\n",
    "        backtrans_df = backtrans_df.append(train_df,ignore_index=True)\n",
    "        \n",
    "    return backtrans_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labeled_data = pd.read_pickle('./data/labeled_data_df.pkl')\n",
    "# labeled_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# labeled_data.type.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimated labels (MTurk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2050, 8), (2042, 8))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est_labels = pd.read_csv('/Users/yiweiluo/scientific-debates/\\\n",
    "3_cc_stance/MTurk/MTurk_results/sent_scores_df_final.tsv',delimiter='\\t',index_col=0)\n",
    "est_labels['max_prob_label'] = est_labels[['disagree','neutral','agree']].idxmax(axis=1)\n",
    "dedup_est_labels = est_labels.drop_duplicates('sentence',keep='first')\n",
    "est_labels.shape, dedup_est_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "assert len(dedup_est_labels) == 2042\n",
    "dedup_est_labels['guid'] = [\"{}_{}_{}\".format(row['round'],row['batch'],row['sent_id']) \n",
    "                      for _,row in dedup_est_labels.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>round</th>\n",
       "      <th>batch</th>\n",
       "      <th>sent_id</th>\n",
       "      <th>disagree</th>\n",
       "      <th>neutral</th>\n",
       "      <th>agree</th>\n",
       "      <th>sentence</th>\n",
       "      <th>max_prob_label</th>\n",
       "      <th>guid</th>\n",
       "      <th>stance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>t0</td>\n",
       "      <td>0.003105</td>\n",
       "      <td>0.285634</td>\n",
       "      <td>0.711260</td>\n",
       "      <td>Warmer-than-normal sea surface temperatures are a key player in the development of hurricanes such as Katrina and superstorm Sandy, which hit the U.S. east coast in 2011.</td>\n",
       "      <td>agree</td>\n",
       "      <td>1_0_t0</td>\n",
       "      <td>agree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>t1</td>\n",
       "      <td>0.000830</td>\n",
       "      <td>0.998006</td>\n",
       "      <td>0.001163</td>\n",
       "      <td>We will continue to rely in part on fossil fuels while we transition to a low-carbon economy .</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1_0_t1</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>t10</td>\n",
       "      <td>0.000802</td>\n",
       "      <td>0.998023</td>\n",
       "      <td>0.001174</td>\n",
       "      <td>The actual rise in sea levels measured only 1.2 millimeters instead of the previously accepted 1.6 to 1.9 millimeters.</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1_0_t10</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>t11</td>\n",
       "      <td>0.997695</td>\n",
       "      <td>0.001134</td>\n",
       "      <td>0.001171</td>\n",
       "      <td>Claims of global warming have been greatly exaggerated.</td>\n",
       "      <td>disagree</td>\n",
       "      <td>1_0_t11</td>\n",
       "      <td>disagree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>t12</td>\n",
       "      <td>0.031351</td>\n",
       "      <td>0.965687</td>\n",
       "      <td>0.002962</td>\n",
       "      <td>The Intergovernmental Panel on Climate Change should be clearer on how it draws conclusions from the body of research it assesses when gauging the impacts of global warming.</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1_0_t12</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   round  batch sent_id  disagree   neutral     agree  \\\n",
       "0  1      0      t0      0.003105  0.285634  0.711260   \n",
       "1  1      0      t1      0.000830  0.998006  0.001163   \n",
       "2  1      0      t10     0.000802  0.998023  0.001174   \n",
       "3  1      0      t11     0.997695  0.001134  0.001171   \n",
       "4  1      0      t12     0.031351  0.965687  0.002962   \n",
       "\n",
       "                                                                                                                                                                        sentence  \\\n",
       "0  Warmer-than-normal sea surface temperatures are a key player in the development of hurricanes such as Katrina and superstorm Sandy, which hit the U.S. east coast in 2011.      \n",
       "1  We will continue to rely in part on fossil fuels while we transition to a low-carbon economy .                                                                                  \n",
       "2  The actual rise in sea levels measured only 1.2 millimeters instead of the previously accepted 1.6 to 1.9 millimeters.                                                          \n",
       "3  Claims of global warming have been greatly exaggerated.                                                                                                                         \n",
       "4  The Intergovernmental Panel on Climate Change should be clearer on how it draws conclusions from the body of research it assesses when gauging the impacts of global warming.   \n",
       "\n",
       "  max_prob_label     guid    stance  \n",
       "0  agree          1_0_t0   agree     \n",
       "1  neutral        1_0_t1   neutral   \n",
       "2  neutral        1_0_t10  neutral   \n",
       "3  disagree       1_0_t11  disagree  \n",
       "4  neutral        1_0_t12  neutral   "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dedup_est_labels['stance'] = dedup_est_labels['max_prob_label']\n",
    "dedup_est_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "held_out_test = pd.read_csv('./save/held_out_balanced_test.tsv',sep='\\t',header=0)\n",
    "#held_out_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neutral     86\n",
       "agree       76\n",
       "disagree    38\n",
       "Name: stance, dtype: int64"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "held_out_test.stance.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1842, 11)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dedup_est_labels = dedup_est_labels.loc[~dedup_est_labels.index.isin(held_out_test.index)]\n",
    "dedup_est_labels.reset_index(drop=True,inplace=True)\n",
    "dedup_est_labels.shape # Expect 2042-200 = 1842"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert set(dedup_est_labels.guid.values).intersection(\n",
    "    set(held_out_test.guid.values)) == set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(dedup_est_labels.sentence.values).intersection(\n",
    "set(held_out_test.sentence.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Raw labels (MTurk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "worker_labels_per_round = pickle.load(open('../MTurk/MTurk_results/full_ratings_per_round.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "PROP_AGREE = 0.75\n",
    "NUM_ROUNDS, NUM_BATCHES, NUM_WORKERS = 5, 10, 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "code_folding": [
     1
    ],
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2042, 7)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round_df,batch_df,sentid_df,stance_df,text_df,high_iaa_df,guid_df = [],[],[],[],[],[],[]\n",
    "for r in range(1,1+NUM_ROUNDS):\n",
    "    for b in range(NUM_BATCHES):\n",
    "        labels = worker_labels_per_round[r][b]\n",
    "        for s_id in labels.index[5:-1]:\n",
    "            round_df.append(r)\n",
    "            batch_df.append(b)\n",
    "            sentid_df.append(s_id)\n",
    "            text_df.append(labels.loc[s_id].sentence)\n",
    "            guid_df.append(\"{}_{}_{}\".format(r,b,s_id))\n",
    "            \n",
    "            ratings = labels.loc[s_id][['worker_{}'.format(w_id) for w_id in range(NUM_WORKERS)]].values\n",
    "            top_rating = Counter(ratings).most_common()[0]\n",
    "            if top_rating[-1] >= PROP_AGREE*NUM_WORKERS:\n",
    "                stance_df.append(top_rating[0])\n",
    "                high_iaa_df.append(True)\n",
    "            else:\n",
    "                stance_df.append(est_labels.loc[(est_labels['round'] == r) & \n",
    "                                             (est_labels['batch'] == b) & \n",
    "                                             (est_labels['sent_id'] == s_id)].max_prob_label.values[0])\n",
    "                high_iaa_df.append(False)\n",
    "\n",
    "mturk_df = pd.DataFrame({'round':round_df,\"batch\":batch_df,\"sent_id\":sentid_df,\"stance\":stance_df,\n",
    "                 \"sentence\":text_df,'is_high_iaa':high_iaa_df,'guid':guid_df})\n",
    "mturk_df = mturk_df.drop_duplicates('sentence',keep='first')\n",
    "mturk_df.reset_index(drop=True,inplace=True)\n",
    "mturk_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>round</th>\n",
       "      <th>batch</th>\n",
       "      <th>sent_id</th>\n",
       "      <th>stance</th>\n",
       "      <th>sentence</th>\n",
       "      <th>is_high_iaa</th>\n",
       "      <th>guid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>t0</td>\n",
       "      <td>agree</td>\n",
       "      <td>Warmer-than-normal sea surface temperatures are a key player in the development of hurricanes such as Katrina and superstorm Sandy, which hit the U.S. east coast in 2011.</td>\n",
       "      <td>False</td>\n",
       "      <td>1_0_t0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>t1</td>\n",
       "      <td>neutral</td>\n",
       "      <td>We will continue to rely in part on fossil fuels while we transition to a low-carbon economy .</td>\n",
       "      <td>True</td>\n",
       "      <td>1_0_t1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>t10</td>\n",
       "      <td>neutral</td>\n",
       "      <td>The actual rise in sea levels measured only 1.2 millimeters instead of the previously accepted 1.6 to 1.9 millimeters.</td>\n",
       "      <td>True</td>\n",
       "      <td>1_0_t10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>t11</td>\n",
       "      <td>disagrees</td>\n",
       "      <td>Claims of global warming have been greatly exaggerated.</td>\n",
       "      <td>True</td>\n",
       "      <td>1_0_t11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>t12</td>\n",
       "      <td>neutral</td>\n",
       "      <td>The Intergovernmental Panel on Climate Change should be clearer on how it draws conclusions from the body of research it assesses when gauging the impacts of global warming.</td>\n",
       "      <td>True</td>\n",
       "      <td>1_0_t12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   round  batch sent_id     stance  \\\n",
       "0  1      0      t0      agree       \n",
       "1  1      0      t1      neutral     \n",
       "2  1      0      t10     neutral     \n",
       "3  1      0      t11     disagrees   \n",
       "4  1      0      t12     neutral     \n",
       "\n",
       "                                                                                                                                                                        sentence  \\\n",
       "0  Warmer-than-normal sea surface temperatures are a key player in the development of hurricanes such as Katrina and superstorm Sandy, which hit the U.S. east coast in 2011.      \n",
       "1  We will continue to rely in part on fossil fuels while we transition to a low-carbon economy .                                                                                  \n",
       "2  The actual rise in sea levels measured only 1.2 millimeters instead of the previously accepted 1.6 to 1.9 millimeters.                                                          \n",
       "3  Claims of global warming have been greatly exaggerated.                                                                                                                         \n",
       "4  The Intergovernmental Panel on Climate Change should be clearer on how it draws conclusions from the body of research it assesses when gauging the impacts of global warming.   \n",
       "\n",
       "   is_high_iaa     guid  \n",
       "0  False        1_0_t0   \n",
       "1  True         1_0_t1   \n",
       "2  True         1_0_t10  \n",
       "3  True         1_0_t11  \n",
       "4  True         1_0_t12  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mturk_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1842, 7)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mturk_df = mturk_df.loc[~mturk_df['guid'].isin(set(held_out_test.guid.values))]\n",
    "mturk_df.reset_index(drop=True,inplace=True)\n",
    "mturk_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     1014\n",
       "False    828 \n",
       "Name: is_high_iaa, dtype: int64"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mturk_df.is_high_iaa.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "assert set(mturk_df.guid.values).intersection(\n",
    "    set(held_out_test.guid.values)) == set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(mturk_df.sentence.values).intersection(\n",
    "set(held_out_test.sentence.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Back translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "back_trans_fr = pd.read_csv('../datasets/mturk_french_backtranslations.tsv',sep='\\t',\n",
    "                        header=0,index_col=0)\n",
    "back_trans_zh = pd.read_csv('../datasets/mturk_zh_backtranslations.tsv',sep='\\t',\n",
    "                        header=0,index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_backtrans(guid,language):\n",
    "    r,b,s_id = guid.split('_')\n",
    "    if language == 'fr':\n",
    "        return back_trans_fr.loc[(back_trans_fr['round'] == int(r)) &\n",
    "                                (back_trans_fr['batch'] == int(b)) &\n",
    "                                (back_trans_fr['sent_id'] == s_id)].backtranslation.values[0]\n",
    "    else:\n",
    "        return back_trans_zh.loc[(back_trans_fr['round'] == int(r)) &\n",
    "                                (back_trans_fr['batch'] == int(b)) &\n",
    "                                (back_trans_fr['sent_id'] == s_id)].backtranslation_zh_en.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Warmer than normal sea surface temperatures are a key player in the development of hurricanes such as Katrina and Sandstorm Sandy, which hit the east coast of the United States in 2011.'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_backtrans('1_0_t0','fr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Above-normal sea-level temperatures were a key factor in the development of hurricanes such as Hurricane Katrina and Sandy, which hit the US East Coast in 2011.'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_backtrans('1_0_t0','zh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Sentence windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fnames = os.listdir('../../1_data_scraping/cc_texts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "all_round_data = {r: {} for r in range(1,6)}\n",
    "for round_no in range(1,6):\n",
    "    all_round_data[round_no] = pickle.load(open('/Users/yiweiluo/Dropbox/research/QP2/code/Fox_and_friends/\\\n",
    "LIVE_ROUND{}_BATCH_DATA.pkl'.format(round_no),'rb'))\n",
    "    \n",
    "data_for_mturk_df = pd.read_pickle('/Users/yiweiluo/Dropbox/research/QP2/code/Fox_and_friends/\\\n",
    "data_for_mturk_2020.pkl')\n",
    "data_for_mturk_df_old = pd.read_pickle('/Users/yiweiluo/Dropbox/research/QP2/code/Fox_and_friends/\\\n",
    "data_for_mturk.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "code_folding": [
     3
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "from fuzzywuzzy import process\n",
    "\n",
    "def get_window(guid,window_size):\n",
    "    r,b,s_id = guid.split('_')\n",
    "    target_sent = mturk_df.loc[(mturk_df['round'] == int(r)) &\n",
    "                                (mturk_df['batch'] == int(b)) &\n",
    "                                (mturk_df['sent_id'] == s_id)].sentence.values[0]\n",
    "\n",
    "#     print('Target sent:',target_sent)\n",
    "#     print('Round: {}, batch: {}, sent_id: {}'.format(r,b,s_id))\n",
    "    rb_df = pd.DataFrame(all_round_data[int(r)][int(b)])\n",
    "    df_key = rb_df.loc[rb_df.sent_id == s_id].df_key.values[0]\n",
    "#     print('df key:',df_key)\n",
    "    \n",
    "    if int(r) < 5:\n",
    "        sent_key = data_for_mturk_df_old.loc[df_key].sent_key\n",
    "    else:\n",
    "        sent_key = data_for_mturk_df.loc[df_key].sent_key\n",
    "        \n",
    "    url = sent_key.split(' of ')[-1].split('://')[-1]\n",
    "    #print('url:',url)\n",
    "    \n",
    "    fname = url.replace('/','[SEP]')\n",
    "    fname = '{}.txt'.format(fname) if '{}.txt'.format(fname) in fnames else '{}.txt'.format(fname[:90])\n",
    "    #print('fname:',fname)\n",
    "    \n",
    "    if fname in fnames:\n",
    "        with open(os.path.join('../../1_data_scraping/cc_texts',fname)) as f:\n",
    "            text = f.readlines()\n",
    "        if len(text) > 0:\n",
    "            text = text[0]\n",
    "\n",
    "            text_sents = sent_tokenize(text)\n",
    "            sent_with_target = process.extract(target_sent, text_sents, limit=1)\n",
    "            #print('Found sentence containing target sent:',sent_with_target)\n",
    "            ix_target_sent = text_sents.index(sent_with_target[0][0])\n",
    "\n",
    "            w_start = max(0,ix_target_sent-window_size)\n",
    "            w_end = min(ix_target_sent+window_size,len(text_sents)-1)\n",
    "            w_left = text_sents[w_start:ix_target_sent]\n",
    "            w_right = text_sents[ix_target_sent+1:w_end+1]\n",
    "            #print('Left sentence(s):',w_left)\n",
    "            #print('Right sentence(s):',w_right)\n",
    "            BERT_input = '[SEP] '.join(w_left)+' [SEP] [CLS] '+target_sent+' [SEP] '+' [SEP] '.join(w_right)\n",
    "            if BERT_input[:6] != ' [SEP]':\n",
    "                #print('Padding beginning with [SEP]...')\n",
    "                BERT_input = '[SEP] '+BERT_input\n",
    "                \n",
    "            return BERT_input\n",
    "        else:\n",
    "            print('Fulltext is empty!')\n",
    "    else:\n",
    "        print('Fulltext file not found!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[SEP] “I think it’s very important to remind people the scope of what can happen with the hurricane season.”  Nonetheless, the events surrounding the hurricane, which caused $108 billion of damage, continue to interest to the scientific community. [SEP] [CLS] Warmer-than-normal sea surface temperatures are a key player in the development of hurricanes such as Katrina and superstorm Sandy, which hit the U.S. east coast in 2011. [SEP] “These storms may not have been caused by global warming, but because the ocean’s surface is warmer, it makes the storm more powerful,” Thomas Wagner, cryosphere program manager at NASA headquarters in Washington, D.C. told FoxNews.com.'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_window('1_0_t0',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[SEP] “We haven’t had a Category 3 hit the U.S. in 10 years – I think there’s a lot of complacency out there,” she said during a panel discussion at an American Meteorological Society conference in June.[SEP] “I think it’s very important to remind people the scope of what can happen with the hurricane season.”  Nonetheless, the events surrounding the hurricane, which caused $108 billion of damage, continue to interest to the scientific community. [SEP] [CLS] Warmer-than-normal sea surface temperatures are a key player in the development of hurricanes such as Katrina and superstorm Sandy, which hit the U.S. east coast in 2011. [SEP] “These storms may not have been caused by global warming, but because the ocean’s surface is warmer, it makes the storm more powerful,” Thomas Wagner, cryosphere program manager at NASA headquarters in Washington, D.C. told FoxNews.com. [SEP] “Then, because sea level is higher, the water can go further inland from the storm surge.”  President Obama briefly addressed the issue of climate change during a speech in New Orleans Thursday.'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_window('1_0_t0',2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## SemEval tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(169, 395)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "semeval_test = pd.read_csv('../datasets/StanceDataset/test.csv',header=0,encoding='utf-8',engine='python')\n",
    "semeval_test = semeval_test[semeval_test['Target'] == 'Climate Change is a Real Concern']\n",
    "\n",
    "semeval_train = pd.read_csv('../datasets/StanceDataset/train.csv',header=0,encoding='utf-8', engine='python')\n",
    "semeval_train = semeval_train[semeval_train['Target'] == 'Climate Change is a Real Concern']\n",
    "\n",
    "len(semeval_test),len(semeval_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "semeval_test = semeval_test[['Tweet','Stance']]\n",
    "semeval_train = semeval_train[['Tweet','Stance']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tweetstance2label = {'NONE': CLASS_NUMS['neutral'],\n",
    "                    'FAVOR': CLASS_NUMS['agree'],\n",
    "                    'AGAINST': CLASS_NUMS['disagree']}\n",
    "\n",
    "semeval_test['stance'] = semeval_test['Stance'].apply(lambda x: tweetstance2label[x])\n",
    "semeval_train['stance'] = semeval_train['Stance'].apply(lambda x: tweetstance2label[x])\n",
    "semeval_df = semeval_test.append(semeval_train,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    335\n",
       "1    203\n",
       "2    26 \n",
       "Name: stance, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "semeval_df.stance.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Add additional info: original source media leaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_orig_media_slant(guid):\n",
    "    r,b,s_id = guid.split('_')\n",
    "    if int(r) < 5:\n",
    "        df_ = data_for_mturk_df_old\n",
    "    else:\n",
    "        df_ = data_for_mturk_df\n",
    "    \n",
    "    b_df_ = pd.DataFrame(all_round_data[int(r)][int(b)])\n",
    "    df_key = b_df_.loc[b_df_.sent_id == s_id].df_key.values[0]\n",
    "    \n",
    "    def str_to_int(s):\n",
    "        return int(s == 'pro') # 1 for pro, 0 for anti\n",
    "        \n",
    "    return str_to_int(df_.iloc[df_key].bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int('pro' == 'pro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Titles, with source media outlet as proxy label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44582, 10)"
      ]
     },
     "execution_count": 412,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle('../../1_data_scraping/dedup_combined_df.pkl')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 667,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df.loc[(df.stance=='pro') & \n",
    "#       (df.topic=='cc')].domain.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 668,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df.loc[(df.stance=='anti') & \n",
    "#       (df.topic=='cc')].domain.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Other extreme L candidates:\n",
    "# grist, inthesetimes, guardian_us (2307 total)\n",
    "\n",
    "# Other extreme R candidates:\n",
    "# daily_caller, drudgereport, infowars (1153 total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "CC_KEYWORDS = {'warming','climate','carbon','co2','fossil',\n",
    "              'temperature','environment','ice','antarctica','sea','seas',\n",
    "              'IPCC','gore','green'}\n",
    "\n",
    "def has_keyword(title):\n",
    "    return len(set(title.lower().split()).intersection(CC_KEYWORDS)) > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4037, 1365)"
      ]
     },
     "execution_count": 432,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counted_breitbart_titles = Counter(df.loc[df.domain == 'breitbart'].title.values)\n",
    "keyword_breitbart_titles = [x for x in counted_breitbart_titles if has_keyword(x)]\n",
    "len(counted_breitbart_titles),len(keyword_breitbart_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3430, 896)"
      ]
     },
     "execution_count": 434,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counted_mj_titles = Counter(df.loc[df.domain == 'mj'].title.values)\n",
    "keyword_mj_titles = [x for x in counted_mj_titles if has_keyword(x)]\n",
    "len(counted_mj_titles),len(keyword_mj_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "titles_df = pd.DataFrame({\"sentence\":keyword_breitbart_titles+keyword_mj_titles,\n",
    "                                  \"stance\":['disagrees']*len(keyword_breitbart_titles)+\\\n",
    "                                  ['agrees']*len(keyword_mj_titles)\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#titles_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create train/dev/test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(mturk_df) == 2042-len(held_out_test)\n",
    "assert len(dedup_est_labels) == 2042-len(held_out_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "\n",
      "\n",
      "[SEP] “I think it’s very important to remind people the scope of what can happen with the hurricane season.”  Nonetheless, the events surrounding the hurricane, which caused $108 billion of damage, continue to interest to the scientific community. [SEP] [CLS] Warmer-than-normal sea surface temperatures are a key player in the development of hurricanes such as Katrina and superstorm Sandy, which hit the U.S. east coast in 2011. [SEP] “These storms may not have been caused by global warming, but because the ocean’s surface is warmer, it makes the storm more powerful,” Thomas Wagner, cryosphere program manager at NASA headquarters in Washington, D.C. told FoxNews.com.\n",
      "\n",
      "\n",
      "How the Intergovernmental Panel on Climate Change should draw clearer conclusions from the research findings it assesses when assessing the effects of global warming.\n"
     ]
    }
   ],
   "source": [
    "df_getter = {'raw_mturk': mturk_df,\n",
    "            'est_mturk': dedup_est_labels,\n",
    "            'semeval': semeval_df}\n",
    "\n",
    "print(get_orig_media_slant('1_0_t12'))\n",
    "print('\\n')\n",
    "print(get_window('1_0_t0',1))\n",
    "print('\\n')\n",
    "print(get_backtrans('1_0_t12','zh'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>round</th>\n",
       "      <th>batch</th>\n",
       "      <th>sent_id</th>\n",
       "      <th>stance</th>\n",
       "      <th>sentence</th>\n",
       "      <th>is_high_iaa</th>\n",
       "      <th>guid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>t12</td>\n",
       "      <td>neutral</td>\n",
       "      <td>The Intergovernmental Panel on Climate Change should be clearer on how it draws conclusions from the body of research it assesses when gauging the impacts of global warming.</td>\n",
       "      <td>True</td>\n",
       "      <td>1_0_t12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   round  batch sent_id   stance  \\\n",
       "4  1      0      t12     neutral   \n",
       "\n",
       "                                                                                                                                                                        sentence  \\\n",
       "4  The Intergovernmental Panel on Climate Change should be clearer on how it draws conclusions from the body of research it assesses when gauging the impacts of global warming.   \n",
       "\n",
       "   is_high_iaa     guid  \n",
       "4  True         1_0_t12  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_getter['raw_mturk'].loc[df_getter['raw_mturk'].guid == '1_0_t12']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def write_data(name,desc,train_df,test_df,dev_df=None,do_downsample=False,\n",
    "              add_titles=False):\n",
    "    \"\"\"\n",
    "    Writes data to a directory containing train.tsv, test.tsv, and optionally dev.tsv.\n",
    "    :param name: name of directory (type of train/eval data)\n",
    "    :param desc: list of type str with manipulations made (e.g., downsampled, upsampled, backtrans_fr, window_1)\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    \n",
    "    # Check that train and eval text are deduplicated\n",
    "    train_guids = set([x.replace('_fr','').replace('_zh','') for x in train_df.guid])\n",
    "    test_guids = set([x.replace('_fr','').replace('_zh','') for x in test_df.guid])\n",
    "    assert train_guids.intersection(test_guids) == set()\n",
    "    print(\"Train/test text overlap:\",set(train_df.sentence).intersection(set(test_df.sentence)))\n",
    "    if dev_df is not None:\n",
    "        dev_guids = set([x.replace('_fr','').replace('_zh','') for x in dev_df.guid])\n",
    "        assert train_guids.intersection(dev_guids) == set()\n",
    "        print(\"Train/dev text overlap:\",set(train_df.sentence).intersection(set(dev_df.sentence)))\n",
    "    train_df = train_df[['stance','sentence']]\n",
    "    test_df = test_df[['stance','sentence']]\n",
    "    if dev_df is not None:\n",
    "        dev_df = dev_df[['stance','sentence']]\n",
    "    \n",
    "    # Make save_dir\n",
    "    if do_downsample:\n",
    "        desc.append('downsampled')\n",
    "    save_dir = os.path.join('save',\"_\".join([name]+desc))\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.mkdir(save_dir)\n",
    "        \n",
    "    # Add titles from Breitbart and MJ--TODO: make outlets a parameter\n",
    "    if add_titles:\n",
    "        print('Adding Breitbart and MJ titles to train_df...')\n",
    "        train_df = train_df.append(titles_df,ignore_index=True)\n",
    "        \n",
    "    # Regularize labels\n",
    "    train_df['reg_stance'] = train_df['stance'].apply(stance_reg)\n",
    "    test_df['reg_stance'] = test_df['stance'].apply(stance_reg)\n",
    "    if dev_df is not None:\n",
    "        dev_df['reg_stance'] = dev_df['stance'].apply(stance_reg) \n",
    "        \n",
    "    # Aggregate examples by stance for downsampling/upsampling needs\n",
    "    train_df_by_stance = {s: train_df.loc[train_df.reg_stance == i] for i,s in enumerate(STANCES)} \n",
    "    test_df_by_stance = {s: test_df.loc[test_df.reg_stance == i] for i,s in enumerate(STANCES)}\n",
    "    dev_df_by_stance = {s: dev_df.loc[dev_df.reg_stance == i] for i,s in enumerate(STANCES)} if dev_df is not None else None\n",
    "\n",
    "    # Split X, Y\n",
    "    train_X_by_stance = {s: train_df_by_stance[s].sentence.values for s in STANCES}\n",
    "    test_X_by_stance = {s: test_df_by_stance[s].sentence.values for s in STANCES}\n",
    "    dev_X_by_stance = {s: dev_df_by_stance[s].sentence.values for s in STANCES} if dev_df is not None else None\n",
    "    \n",
    "    train_Y_by_stance = {s: train_df_by_stance[s].reg_stance.values for s in STANCES} \n",
    "    dev_Y_by_stance = {s: dev_df_by_stance[s].reg_stance.values for s in STANCES} if dev_df is not None else None\n",
    "    test_Y_by_stance = {s: test_df_by_stance[s].reg_stance.values for s in STANCES}\n",
    "\n",
    "    train_nli_by_stance = {s: train_df_by_stance[s].reg_stance.apply(lambda x: stance2nli[x]).values for s in STANCES}\n",
    "    dev_nli_by_stance = {s: dev_df_by_stance[s].reg_stance.apply(lambda x: stance2nli[x]).values for s in STANCES} if dev_df is not None else None\n",
    "    test_nli_by_stance = {s: test_df_by_stance[s].reg_stance.apply(lambda x: stance2nli[x]).values for s in STANCES}\n",
    "\n",
    "    if do_downsample:\n",
    "        min_N = min([len(train_X_by_stance[s]) for s in STANCES])\n",
    "        print('Downsampling to ~{} examples per stance.'.format(min_N))\n",
    "        for s in STANCES:\n",
    "            train_X_by_stance[s] = np.random.choice(train_X_by_stance[s],size=min_N,replace=False)\n",
    "\n",
    "    trX = []\n",
    "    trB = []\n",
    "    trY = []\n",
    "    trNLI = []\n",
    "    for i,s in enumerate(STANCES):\n",
    "        for t, y, nli in zip(train_X_by_stance[s], train_Y_by_stance[s], train_nli_by_stance[s]):\n",
    "            #for text_b in TEXT_BS:\n",
    "            trX.append(t)\n",
    "            #trB.append(text_b)\n",
    "            trY.append(y)\n",
    "            trNLI.append(nli)\n",
    "\n",
    "    teX = []\n",
    "    teB = []\n",
    "    teY = []\n",
    "    teNLI = []\n",
    "    for i,s in enumerate(STANCES):\n",
    "        for t, y, nli in zip(test_X_by_stance[s], test_Y_by_stance[s], test_nli_by_stance[s]):\n",
    "            #for text_b in TEXT_BS:\n",
    "            teX.append(t)\n",
    "            #teB.append(text_b)\n",
    "            teY.append(y)\n",
    "            teNLI.append(nli)\n",
    "\n",
    "    if dev_df is not None:\n",
    "        vaX = []\n",
    "        vaY = []\n",
    "        vaNLI = []\n",
    "        for i,s in enumerate(STANCES):\n",
    "            for t, y, nli in zip(dev_X_by_stance[s], dev_Y_by_stance[s], dev_nli_by_stance[s]):\n",
    "                vaX.append(t)\n",
    "                vaY.append(y)\n",
    "                vaNLI.append(nli)\n",
    "\n",
    "\n",
    "    test_dat = pd.DataFrame({'sentence':teX,'stance':teY,'nli_label':teNLI})\n",
    "    train_dat = pd.DataFrame({'sentence':trX,'stance':trY,'nli_label':trNLI}) \n",
    "    val_dat = pd.DataFrame({'sentence':vaX,'stance':vaY,'nli_label':vaNLI}) if dev_df is not None else None\n",
    "    \n",
    "    print('Train distribution:')\n",
    "    print(train_dat.stance.value_counts()) \n",
    "    print(train_dat.nli_label.value_counts())\n",
    "    if dev_df is not None:\n",
    "        print('\\nDev distribution:')\n",
    "        print(val_dat.stance.value_counts())\n",
    "        print(val_dat.nli_label.value_counts())\n",
    "    print('\\nTest distribution:')\n",
    "    print(test_dat.stance.value_counts())\n",
    "    print(test_dat.stance.value_counts()/np.sum(test_dat.stance.value_counts().values))\n",
    "    print(test_dat.nli_label.value_counts())\n",
    "\n",
    "    print('Writing to save_dir:',save_dir)\n",
    "    train_dat.to_csv(save_dir+'/train.tsv',sep='\\t',header=None,index=False)\n",
    "    if dev_df is not None:\n",
    "        val_dat.to_csv(save_dir+'/dev.tsv',sep='\\t',header=None,index=False)\n",
    "    test_dat.to_csv(save_dir+'/test.tsv',sep='\\t',header=None,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Completely held-out, second test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drawn from all MTurk labels, balanced over outlet sources and annotator ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "dedup_est_labels['outlet_stance'] = dedup_est_labels['guid'].apply(get_orig_media_slant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1038\n",
       "1    1004\n",
       "Name: outlet_stance, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dedup_est_labels.outlet_stance.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neutral     0.427032\n",
       "agree       0.378550\n",
       "disagree    0.194417\n",
       "Name: stance, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dedup_est_labels.stance.value_counts()/dedup_est_labels.stance.value_counts().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Want held-out test set that's 43% neutral, 38% agree, 19% disagree\n",
    "N_needed = round(dedup_est_labels.stance.value_counts()/dedup_est_labels.stance.value_counts().sum()*100)\n",
    "N_needed['neutral']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anti agree (311, 11)\n",
      "anti neutral (447, 11)\n",
      "anti disagree (280, 11)\n",
      "pro agree (462, 11)\n",
      "pro neutral (425, 11)\n",
      "pro disagree (117, 11)\n"
     ]
    }
   ],
   "source": [
    "indices_per_outlet_stance = defaultdict(dict)\n",
    "for outlet_stance in [0,1]:\n",
    "    for stance in ['agree','neutral','disagree']:\n",
    "        sub_df = dedup_est_labels.loc[(dedup_est_labels.stance == stance) & \n",
    "                                     (dedup_est_labels.outlet_stance == outlet_stance)]\n",
    "        str_outlet_stance = 'pro' if outlet_stance == 1 else 'anti'\n",
    "        print(str_outlet_stance,stance,sub_df.shape)\n",
    "        indices_per_outlet_stance[outlet_stance][stance] = np.random.choice(\n",
    "            sub_df.index,size=int(N_needed[stance]),replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_test_ix = []\n",
    "for outlet_stance in indices_per_outlet_stance:\n",
    "    for stance in STANCES:\n",
    "        balanced_test_ix.extend(indices_per_outlet_stance[outlet_stance][stance])\n",
    "len(balanced_test_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neutral     86\n",
       "agree       76\n",
       "disagree    38\n",
       "Name: stance, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dedup_est_labels.loc[balanced_test_ix].stance.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    100\n",
       "0    100\n",
       "Name: outlet_stance, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dedup_est_labels.loc[balanced_test_ix].outlet_stance.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect sentences manually to filter out problematic cases\n",
    "#list(zip(balanced_test_ix,list(dedup_est_labels.loc[balanced_test_ix].sentence.values),dedup_est_labels.loc[balanced_test_ix].stance.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "problematic = [1278,1797,367,253,416,1259,49,1629,1048,1281,592,1543,67,2000,1122,1159,874,1061,152,1018,\n",
    "              1914]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>round</th>\n",
       "      <th>batch</th>\n",
       "      <th>sent_id</th>\n",
       "      <th>disagree</th>\n",
       "      <th>neutral</th>\n",
       "      <th>agree</th>\n",
       "      <th>sentence</th>\n",
       "      <th>max_prob_label</th>\n",
       "      <th>guid</th>\n",
       "      <th>stance</th>\n",
       "      <th>outlet_stance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>t26</td>\n",
       "      <td>0.047172</td>\n",
       "      <td>0.828441</td>\n",
       "      <td>0.124388</td>\n",
       "      <td>Climate change models predict a 15 year period of global cooling.</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1_1_t26</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>t15</td>\n",
       "      <td>0.004749</td>\n",
       "      <td>0.509881</td>\n",
       "      <td>0.485370</td>\n",
       "      <td>Since 1978, the winter Arctic ice cap has shrunk by 12 percent per decade.</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1_2_t15</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>t10</td>\n",
       "      <td>0.244323</td>\n",
       "      <td>0.499343</td>\n",
       "      <td>0.256334</td>\n",
       "      <td>Much of the rise in sea level we’ve seen since the 1880s is the result of thermal expansion.</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1_5_t10</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>t20</td>\n",
       "      <td>0.204515</td>\n",
       "      <td>0.791507</td>\n",
       "      <td>0.003978</td>\n",
       "      <td>Global temperatures drop further still.</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1_8_t20</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>t27</td>\n",
       "      <td>0.003177</td>\n",
       "      <td>0.866938</td>\n",
       "      <td>0.129885</td>\n",
       "      <td>Global warming would raise average annual temperatures nationwide 2 degrees by 2020.</td>\n",
       "      <td>neutral</td>\n",
       "      <td>2_1_t27</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>t36</td>\n",
       "      <td>0.263754</td>\n",
       "      <td>0.458614</td>\n",
       "      <td>0.277631</td>\n",
       "      <td>Sea level rise in the 20th century is mostly man-made.</td>\n",
       "      <td>neutral</td>\n",
       "      <td>2_2_t36</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>t12</td>\n",
       "      <td>0.106303</td>\n",
       "      <td>0.890153</td>\n",
       "      <td>0.003543</td>\n",
       "      <td>The South Pole is gaining more ice than it’s losing.</td>\n",
       "      <td>neutral</td>\n",
       "      <td>2_7_t12</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>874</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>t14</td>\n",
       "      <td>0.002878</td>\n",
       "      <td>0.871371</td>\n",
       "      <td>0.125751</td>\n",
       "      <td>The planet’s remaining fossil fuels must be kept in the ground.</td>\n",
       "      <td>neutral</td>\n",
       "      <td>3_4_t14</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1018</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>t38</td>\n",
       "      <td>0.511689</td>\n",
       "      <td>0.463602</td>\n",
       "      <td>0.024710</td>\n",
       "      <td>Humanity will not alter its energy course as consequences of burning all fossil fuels become clearer.</td>\n",
       "      <td>disagree</td>\n",
       "      <td>3_7_t38</td>\n",
       "      <td>disagree</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>t28</td>\n",
       "      <td>0.194955</td>\n",
       "      <td>0.723724</td>\n",
       "      <td>0.081321</td>\n",
       "      <td>The scientific community is under tremendous financial and peer pressure to reach the conclusion that global industry is damaging the environment.</td>\n",
       "      <td>neutral</td>\n",
       "      <td>3_8_t28</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1061</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>t1</td>\n",
       "      <td>0.002453</td>\n",
       "      <td>0.978159</td>\n",
       "      <td>0.019388</td>\n",
       "      <td>This summer is seeing record lows for Arctic ice.</td>\n",
       "      <td>neutral</td>\n",
       "      <td>3_9_t1</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1122</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>t22</td>\n",
       "      <td>0.003899</td>\n",
       "      <td>0.856392</td>\n",
       "      <td>0.139709</td>\n",
       "      <td>The typical American diet of something like 600 pounds of animal products a year is inconsistent with a progressive or even realistic view of slowing global warming.</td>\n",
       "      <td>neutral</td>\n",
       "      <td>4_0_t22</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1159</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>t14</td>\n",
       "      <td>0.001739</td>\n",
       "      <td>0.972478</td>\n",
       "      <td>0.025783</td>\n",
       "      <td>Burning all fossil fuels might raise the average temperature of the planet by something like 20 degrees Fahrenheit.</td>\n",
       "      <td>neutral</td>\n",
       "      <td>4_1_t14</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1259</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>t24</td>\n",
       "      <td>0.294195</td>\n",
       "      <td>0.700098</td>\n",
       "      <td>0.005706</td>\n",
       "      <td>The U.S. going back to the stone age will not do anything to stop global warming.</td>\n",
       "      <td>neutral</td>\n",
       "      <td>4_3_t24</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1278</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>t43</td>\n",
       "      <td>0.004707</td>\n",
       "      <td>0.259451</td>\n",
       "      <td>0.735843</td>\n",
       "      <td>Global warming can increase snowfall by boosting the amount of moisture in the air.</td>\n",
       "      <td>agree</td>\n",
       "      <td>4_3_t43</td>\n",
       "      <td>agree</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1281</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>t1</td>\n",
       "      <td>0.042773</td>\n",
       "      <td>0.954102</td>\n",
       "      <td>0.003125</td>\n",
       "      <td>Averaged over the period, sea-surface temperatures in the eastern equatorial Pacific are cooler than normal.</td>\n",
       "      <td>neutral</td>\n",
       "      <td>4_4_t1</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1543</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>t38</td>\n",
       "      <td>0.066863</td>\n",
       "      <td>0.914377</td>\n",
       "      <td>0.018760</td>\n",
       "      <td>The document, which climate change believers hope will urge Catholics to accept the theory of anthropogenic global warming and cast the issue in religious terms, may be delayed and will be greatly reduced in scope from what advocates originally hoped.</td>\n",
       "      <td>neutral</td>\n",
       "      <td>4_9_t38</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1629</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>t29</td>\n",
       "      <td>0.002943</td>\n",
       "      <td>0.858364</td>\n",
       "      <td>0.138693</td>\n",
       "      <td>These are the effects of climate change.</td>\n",
       "      <td>neutral</td>\n",
       "      <td>5_1_t29</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1797</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>t47</td>\n",
       "      <td>0.006469</td>\n",
       "      <td>0.188807</td>\n",
       "      <td>0.804724</td>\n",
       "      <td>Climate change is a man-made problem, which is why women should rule the world.</td>\n",
       "      <td>agree</td>\n",
       "      <td>5_4_t47</td>\n",
       "      <td>agree</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1914</th>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>t14</td>\n",
       "      <td>0.396366</td>\n",
       "      <td>0.358954</td>\n",
       "      <td>0.244680</td>\n",
       "      <td>My climate angst is an extension of my melancholic leanings, which struck me as plausible, but not quite right.</td>\n",
       "      <td>disagree</td>\n",
       "      <td>5_7_t14</td>\n",
       "      <td>disagree</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>t0</td>\n",
       "      <td>0.003241</td>\n",
       "      <td>0.297675</td>\n",
       "      <td>0.699084</td>\n",
       "      <td>Mr. Steyer top priorities are addressing climate change and getting money out of politics.</td>\n",
       "      <td>agree</td>\n",
       "      <td>5_9_t0</td>\n",
       "      <td>agree</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      round  batch sent_id  disagree   neutral     agree  \\\n",
       "49    1      1      t26     0.047172  0.828441  0.124388   \n",
       "67    1      2      t15     0.004749  0.509881  0.485370   \n",
       "152   1      5      t10     0.244323  0.499343  0.256334   \n",
       "253   1      8      t20     0.204515  0.791507  0.003978   \n",
       "367   2      1      t27     0.003177  0.866938  0.129885   \n",
       "416   2      2      t36     0.263754  0.458614  0.277631   \n",
       "592   2      7      t12     0.106303  0.890153  0.003543   \n",
       "874   3      4      t14     0.002878  0.871371  0.125751   \n",
       "1018  3      7      t38     0.511689  0.463602  0.024710   \n",
       "1048  3      8      t28     0.194955  0.723724  0.081321   \n",
       "1061  3      9      t1      0.002453  0.978159  0.019388   \n",
       "1122  4      0      t22     0.003899  0.856392  0.139709   \n",
       "1159  4      1      t14     0.001739  0.972478  0.025783   \n",
       "1259  4      3      t24     0.294195  0.700098  0.005706   \n",
       "1278  4      3      t43     0.004707  0.259451  0.735843   \n",
       "1281  4      4      t1      0.042773  0.954102  0.003125   \n",
       "1543  4      9      t38     0.066863  0.914377  0.018760   \n",
       "1629  5      1      t29     0.002943  0.858364  0.138693   \n",
       "1797  5      4      t47     0.006469  0.188807  0.804724   \n",
       "1914  5      7      t14     0.396366  0.358954  0.244680   \n",
       "2000  5      9      t0      0.003241  0.297675  0.699084   \n",
       "\n",
       "                                                                                                                                                                                                                                                         sentence  \\\n",
       "49    Climate change models predict a 15 year period of global cooling.                                                                                                                                                                                             \n",
       "67    Since 1978, the winter Arctic ice cap has shrunk by 12 percent per decade.                                                                                                                                                                                    \n",
       "152   Much of the rise in sea level we’ve seen since the 1880s is the result of thermal expansion.                                                                                                                                                                  \n",
       "253   Global temperatures drop further still.                                                                                                                                                                                                                       \n",
       "367   Global warming would raise average annual temperatures nationwide 2 degrees by 2020.                                                                                                                                                                          \n",
       "416   Sea level rise in the 20th century is mostly man-made.                                                                                                                                                                                                        \n",
       "592   The South Pole is gaining more ice than it’s losing.                                                                                                                                                                                                          \n",
       "874   The planet’s remaining fossil fuels must be kept in the ground.                                                                                                                                                                                               \n",
       "1018  Humanity will not alter its energy course as consequences of burning all fossil fuels become clearer.                                                                                                                                                         \n",
       "1048  The scientific community is under tremendous financial and peer pressure to reach the conclusion that global industry is damaging the environment.                                                                                                            \n",
       "1061  This summer is seeing record lows for Arctic ice.                                                                                                                                                                                                             \n",
       "1122  The typical American diet of something like 600 pounds of animal products a year is inconsistent with a progressive or even realistic view of slowing global warming.                                                                                         \n",
       "1159  Burning all fossil fuels might raise the average temperature of the planet by something like 20 degrees Fahrenheit.                                                                                                                                           \n",
       "1259  The U.S. going back to the stone age will not do anything to stop global warming.                                                                                                                                                                             \n",
       "1278  Global warming can increase snowfall by boosting the amount of moisture in the air.                                                                                                                                                                           \n",
       "1281  Averaged over the period, sea-surface temperatures in the eastern equatorial Pacific are cooler than normal.                                                                                                                                                  \n",
       "1543  The document, which climate change believers hope will urge Catholics to accept the theory of anthropogenic global warming and cast the issue in religious terms, may be delayed and will be greatly reduced in scope from what advocates originally hoped.   \n",
       "1629  These are the effects of climate change.                                                                                                                                                                                                                      \n",
       "1797  Climate change is a man-made problem, which is why women should rule the world.                                                                                                                                                                               \n",
       "1914  My climate angst is an extension of my melancholic leanings, which struck me as plausible, but not quite right.                                                                                                                                               \n",
       "2000  Mr. Steyer top priorities are addressing climate change and getting money out of politics.                                                                                                                                                                    \n",
       "\n",
       "     max_prob_label     guid    stance  outlet_stance  \n",
       "49    neutral        1_1_t26  neutral   0              \n",
       "67    neutral        1_2_t15  neutral   0              \n",
       "152   neutral        1_5_t10  neutral   1              \n",
       "253   neutral        1_8_t20  neutral   0              \n",
       "367   neutral        2_1_t27  neutral   0              \n",
       "416   neutral        2_2_t36  neutral   0              \n",
       "592   neutral        2_7_t12  neutral   0              \n",
       "874   neutral        3_4_t14  neutral   1              \n",
       "1018  disagree       3_7_t38  disagree  1              \n",
       "1048  neutral        3_8_t28  neutral   0              \n",
       "1061  neutral        3_9_t1   neutral   1              \n",
       "1122  neutral        4_0_t22  neutral   1              \n",
       "1159  neutral        4_1_t14  neutral   1              \n",
       "1259  neutral        4_3_t24  neutral   0              \n",
       "1278  agree          4_3_t43  agree     0              \n",
       "1281  neutral        4_4_t1   neutral   0              \n",
       "1543  neutral        4_9_t38  neutral   0              \n",
       "1629  neutral        5_1_t29  neutral   0              \n",
       "1797  agree          5_4_t47  agree     0              \n",
       "1914  disagree       5_7_t14  disagree  1              \n",
       "2000  agree          5_9_t0   agree     1              "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dedup_est_labels.loc[problematic].sort_values('guid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#mturk_df.loc[mturk_df.guid.isin(dedup_est_labels.loc[problematic].guid.values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neutral    11\n",
       "agree      2 \n",
       "Name: stance, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dedup_est_labels.loc[problematic].loc[\n",
    "    dedup_est_labels.loc[problematic].outlet_stance == 0].stance.value_counts()\n",
    "# Need 11 more neutrals, 2 agrees from R-wing outlets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neutral     5\n",
       "disagree    2\n",
       "agree       1\n",
       "Name: stance, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dedup_est_labels.loc[problematic].loc[\n",
    "    dedup_est_labels.loc[problematic].outlet_stance == 1].stance.value_counts()\n",
    "# Need 5 more neutrals, 1 agree, and 2 disagrees from L-wing outlets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "N_needed_per_outlet_stance = {0: {\n",
    "    \"agree\": 2, \"disagree\": 0, \"neutral\": 11\n",
    "},\n",
    "                             1: {\n",
    "                                 \"agree\": 1, \"disagree\": 2, \"neutral\": 5\n",
    "                             }}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anti agree (273, 11)\n",
      "anti neutral (404, 11)\n",
      "anti disagree (261, 11)\n",
      "pro agree (424, 11)\n",
      "pro neutral (382, 11)\n",
      "pro disagree (98, 11)\n"
     ]
    }
   ],
   "source": [
    "new_indices_per_outlet_stance = defaultdict(dict)\n",
    "for outlet_stance in [0,1]:\n",
    "    for stance in ['agree','neutral','disagree']:\n",
    "        sub_df = dedup_est_labels.loc[(dedup_est_labels.stance == stance) & \n",
    "                                     (dedup_est_labels.outlet_stance == outlet_stance) &\n",
    "                                     (~dedup_est_labels.index.isin(\n",
    "                                         indices_per_outlet_stance[outlet_stance][stance]))]\n",
    "        str_outlet_stance = 'pro' if outlet_stance == 1 else 'anti'\n",
    "        print(str_outlet_stance,stance,sub_df.shape)\n",
    "        new_indices_per_outlet_stance[outlet_stance][stance] = np.random.choice(\n",
    "            sub_df.index,size=N_needed_per_outlet_stance[outlet_stance][stance],replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 agree 2\n",
      "0 neutral 11\n",
      "0 disagree 0\n",
      "1 agree 1\n",
      "1 neutral 5\n",
      "1 disagree 2\n"
     ]
    }
   ],
   "source": [
    "for outlet_stance in [0,1]:\n",
    "    for stance in STANCES:\n",
    "        print(outlet_stance,stance,len(new_indices_per_outlet_stance[outlet_stance][stance]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_balanced_test_ix = []\n",
    "for outlet_stance in new_indices_per_outlet_stance:\n",
    "    for stance in STANCES:\n",
    "        new_balanced_test_ix.extend([x for x in \n",
    "                                 new_indices_per_outlet_stance[outlet_stance][stance] \n",
    "                                if x not in problematic])\n",
    "len(new_balanced_test_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    13\n",
       "1    8 \n",
       "Name: outlet_stance, dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dedup_est_labels.loc[new_balanced_test_ix].outlet_stance.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neutral    11\n",
       "agree      2 \n",
       "Name: stance, dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dedup_est_labels.loc[new_balanced_test_ix][\n",
    "    dedup_est_labels.loc[new_balanced_test_ix]['outlet_stance'] == 0].stance.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neutral     5\n",
       "disagree    2\n",
       "agree       1\n",
       "Name: stance, dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dedup_est_labels.loc[new_balanced_test_ix][\n",
    "    dedup_est_labels.loc[new_balanced_test_ix]['outlet_stance'] == 1].stance.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Re-nspect sentences manually to filter out problematic cases\n",
    "#list(zip(new_balanced_test_ix,list(dedup_est_labels.loc[new_balanced_test_ix].sentence.values),dedup_est_labels.loc[new_balanced_test_ix].stance.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "problematic_2 = [1467]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add everything that's not problematic to base list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "199"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_problematic_balanced_test_ix = []\n",
    "for outlet_stance in indices_per_outlet_stance:\n",
    "    for stance in STANCES:\n",
    "        non_problematic_balanced_test_ix.extend([x for x in indices_per_outlet_stance[outlet_stance][stance]\n",
    "                                if x not in problematic])\n",
    "        non_problematic_balanced_test_ix.extend([x for x in new_indices_per_outlet_stance[outlet_stance][stance]\n",
    "                                if x not in problematic_2])\n",
    "len(non_problematic_balanced_test_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    100\n",
       "1    99 \n",
       "Name: outlet_stance, dtype: int64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dedup_est_labels.loc[non_problematic_balanced_test_ix].outlet_stance.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neutral     43\n",
       "agree       38\n",
       "disagree    19\n",
       "Name: stance, dtype: int64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dedup_est_labels.loc[non_problematic_balanced_test_ix][\n",
    "    dedup_est_labels.loc[non_problematic_balanced_test_ix].outlet_stance == 0\n",
    "].stance.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neutral     42\n",
       "agree       38\n",
       "disagree    19\n",
       "Name: stance, dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dedup_est_labels.loc[non_problematic_balanced_test_ix][\n",
    "    dedup_est_labels.loc[non_problematic_balanced_test_ix].outlet_stance == 1\n",
    "].stance.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_N_needed_per_outlet_stance = {0: {\n",
    "    \"agree\": 0, \"disagree\": 0, \"neutral\": 0\n",
    "},\n",
    "                             1: {\n",
    "                                 \"agree\": 0, \"disagree\": 0, \"neutral\": 1\n",
    "                             }}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anti agree (271, 11)\n",
      "anti neutral (393, 11)\n",
      "anti disagree (261, 11)\n",
      "pro agree (423, 11)\n",
      "pro neutral (377, 11)\n",
      "pro disagree (96, 11)\n"
     ]
    }
   ],
   "source": [
    "# New random sample to bring up numbers\n",
    "new_indices_per_outlet_stance_2 = defaultdict(dict)\n",
    "for outlet_stance in [0,1]:\n",
    "    for stance in ['agree','neutral','disagree']:\n",
    "        sub_df = dedup_est_labels.loc[(dedup_est_labels.stance == stance) & \n",
    "                                     (dedup_est_labels.outlet_stance == outlet_stance) &\n",
    "                                     (~dedup_est_labels.index.isin(\n",
    "                                         indices_per_outlet_stance[outlet_stance][stance])) & \n",
    "                                     (~dedup_est_labels.index.isin(\n",
    "                                     new_indices_per_outlet_stance[outlet_stance][stance]))]\n",
    "        str_outlet_stance = 'pro' if outlet_stance == 1 else 'anti'\n",
    "        print(str_outlet_stance,stance,sub_df.shape)\n",
    "        new_indices_per_outlet_stance_2[outlet_stance][stance] = np.random.choice(\n",
    "            sub_df.index,size=new_N_needed_per_outlet_stance[outlet_stance][stance],\n",
    "            replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 agree 0\n",
      "0 neutral 0\n",
      "0 disagree 0\n",
      "1 agree 0\n",
      "1 neutral 1\n",
      "1 disagree 0\n"
     ]
    }
   ],
   "source": [
    "for outlet_stance in new_indices_per_outlet_stance_2:\n",
    "    for stance in STANCES:\n",
    "        print(outlet_stance,stance,len(new_indices_per_outlet_stance_2[outlet_stance][stance]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_test_ix_2 = []\n",
    "for outlet_stance in new_indices_per_outlet_stance_2:\n",
    "    for stance in STANCES:\n",
    "        balanced_test_ix_2.extend(new_indices_per_outlet_stance_2[outlet_stance][stance])\n",
    "len(balanced_test_ix_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1673,\n",
       "  'A number of countries around the world, including Canada and Norway, have made plans to reduce emissions at home while expanding fossil-fuel production for sale abroad.',\n",
       "  'neutral')]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect sentences manually to filter out problematic cases\n",
    "list(zip(balanced_test_ix_2,\n",
    "         list(dedup_est_labels.loc[balanced_test_ix_2].sentence.values),\n",
    "         dedup_est_labels.loc[balanced_test_ix_2].stance.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "problematic_3 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for outlet_stance in indices_per_outlet_stance:\n",
    "    for stance in STANCES:\n",
    "        non_problematic_balanced_test_ix.extend([x for x in new_indices_per_outlet_stance_2[outlet_stance][stance]\n",
    "                                if x not in problematic_3])\n",
    "len(non_problematic_balanced_test_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#dedup_est_labels.loc[non_problematic_balanced_test_ix].outlet_stance.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neutral     43\n",
       "agree       38\n",
       "disagree    19\n",
       "Name: stance, dtype: int64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dedup_est_labels.loc[non_problematic_balanced_test_ix][\n",
    "    dedup_est_labels.loc[non_problematic_balanced_test_ix].outlet_stance == 0\n",
    "].stance.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neutral     43\n",
       "agree       38\n",
       "disagree    19\n",
       "Name: stance, dtype: int64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dedup_est_labels.loc[non_problematic_balanced_test_ix][\n",
    "    dedup_est_labels.loc[non_problematic_balanced_test_ix].outlet_stance == 1\n",
    "].stance.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "dedup_est_labels.loc[non_problematic_balanced_test_ix].to_pickle('./save/held_out_balanced_test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# dedup_est_labels.loc[non_problematic_balanced_test_ix].to_csv('./save/held_out_balanced_test.tsv',\n",
    "#                                                              sep='\\t',header=True,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## All SemEval tweets as eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "semeval_df['nli_label'] = semeval_df['stance'].apply(lambda x: stance2nli[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "os.mkdir('./save/semeval_test')\n",
    "semeval_df[['Tweet','stance','nli_label']].to_csv('./save/semeval_test'+'/test.tsv',sep='\\t',header=None,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## SemEval as train, dev, and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(394, 76, 94)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "semeval_df['nli_label'] = semeval_df['stance'].apply(lambda x: stance2nli[x])\n",
    "semeval_df['sentence'] = semeval_df['Tweet']\n",
    "train_ix,eval_ix = train_test_split(list(semeval_df.index),test_size=0.3,random_state=42)\n",
    "dev_ix,test_ix = train_test_split(eval_ix,test_size=0.55,random_state=42)\n",
    "len(train_ix),len(dev_ix),len(test_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((394, 5), (76, 5), (94, 5))"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = semeval_df.loc[semeval_df.index.isin(train_ix)]\n",
    "dev_df = semeval_df.loc[semeval_df.index.isin(dev_ix)]\n",
    "test_df = semeval_df.loc[semeval_df.index.isin(test_ix)]\n",
    "train_df.shape,dev_df.shape,test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#write_data('semeval_train_eval',42,[],train_df,test_df,dev_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-val splits (test on item-response est. label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1842"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "order = np.arange(len(mturk_df))\n",
    "np.random.shuffle(order)\n",
    "len(order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1842 1842 185 185 1472\n",
      "1842 1842 185 185 1472\n",
      "1842 1842 184 184 1474\n",
      "1842 1842 184 184 1474\n",
      "1842 1842 184 184 1474\n",
      "1842 1842 184 184 1474\n",
      "1842 1842 184 184 1474\n",
      "1842 1842 184 184 1474\n",
      "1842 1842 184 184 1474\n",
      "1842 1842 184 184 1474\n"
     ]
    }
   ],
   "source": [
    "indices_per_fold = {}\n",
    "n_folds = 10\n",
    "for f in range(n_folds):\n",
    "    test_indices = [order[i] for i in np.arange(len(mturk_df)) if i % n_folds == f]\n",
    "    nontest_indices = list(set(np.arange(len(mturk_df))) - set(test_indices))\n",
    "    dev_indices = list(np.random.choice(nontest_indices, size=len(test_indices), replace=False))\n",
    "    train_indices = list(set(nontest_indices) - set(dev_indices))\n",
    "    all_indices = set(test_indices).union(set(dev_indices)).union(set(train_indices))\n",
    "    indices_per_fold[f] = {'train':train_indices,'dev':dev_indices,'test':test_indices}\n",
    "    print(len(all_indices), len(test_indices) + len(dev_indices) + len(train_indices), len(test_indices), len(dev_indices), len(train_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(indices_per_fold,open('cross_val_10_seed_42_indices.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_per_fold = pickle.load(open('cross_val_10_seed_42_indices.pkl','rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Title-augmented train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 728,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for f in range(n_folds):\n",
    "#     fold_ix = indices_per_fold[f]\n",
    "#     train_ix = fold_ix['train']\n",
    "#     test_ix = fold_ix['test']\n",
    "#     dev_ix = fold_ix['dev']\n",
    "    \n",
    "#     train_df = mturk_df.loc[mturk_df.index.isin(train_ix)]\n",
    "#     dev_df = mturk_df.loc[mturk_df.index.isin(dev_ix)]\n",
    "#     test_df = mturk_df.loc[mturk_df.index.isin(test_ix)]\n",
    "#     print(train_df.shape,dev_df.shape,test_df.shape)\n",
    "#     write_data('all_mturk_with_titles_train_{}_fold_{}'.format(42,f),[],train_df,test_df,dev_df,\n",
    "#            add_titles=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Oops, accidentally re-wrote with vanilla (non-title-augmented) data splits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vanilla MTurk (est. labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1472, 11) (185, 11) (185, 11)\n",
      "Train/test text overlap: set()\n",
      "Train/dev text overlap: set()\n",
      "Train distribution:\n",
      "1    625\n",
      "0    552\n",
      "2    295\n",
      "Name: stance, dtype: int64\n",
      "neutral          625\n",
      "entailment       552\n",
      "contradiction    295\n",
      "Name: nli_label, dtype: int64\n",
      "\n",
      "Dev distribution:\n",
      "1    81\n",
      "0    73\n",
      "2    31\n",
      "Name: stance, dtype: int64\n",
      "neutral          81\n",
      "entailment       73\n",
      "contradiction    31\n",
      "Name: nli_label, dtype: int64\n",
      "\n",
      "Test distribution:\n",
      "1    80\n",
      "0    72\n",
      "2    33\n",
      "Name: stance, dtype: int64\n",
      "1    0.432432\n",
      "0    0.389189\n",
      "2    0.178378\n",
      "Name: stance, dtype: float64\n",
      "neutral          80\n",
      "entailment       72\n",
      "contradiction    33\n",
      "Name: nli_label, dtype: int64\n",
      "Writing to save_dir: save/all_mturk_train_42_fold_0\n",
      "(1472, 11) (185, 11) (185, 11)\n",
      "Train/test text overlap: set()\n",
      "Train/dev text overlap: set()\n",
      "Train distribution:\n",
      "1    637\n",
      "0    548\n",
      "2    287\n",
      "Name: stance, dtype: int64\n",
      "neutral          637\n",
      "entailment       548\n",
      "contradiction    287\n",
      "Name: nli_label, dtype: int64\n",
      "\n",
      "Dev distribution:\n",
      "1    74\n",
      "0    74\n",
      "2    37\n",
      "Name: stance, dtype: int64\n",
      "neutral          74\n",
      "entailment       74\n",
      "contradiction    37\n",
      "Name: nli_label, dtype: int64\n",
      "\n",
      "Test distribution:\n",
      "1    75\n",
      "0    75\n",
      "2    35\n",
      "Name: stance, dtype: int64\n",
      "1    0.405405\n",
      "0    0.405405\n",
      "2    0.189189\n",
      "Name: stance, dtype: float64\n",
      "neutral          75\n",
      "entailment       75\n",
      "contradiction    35\n",
      "Name: nli_label, dtype: int64\n",
      "Writing to save_dir: save/all_mturk_train_42_fold_1\n",
      "(1474, 11) (184, 11) (184, 11)\n",
      "Train/test text overlap: set()\n",
      "Train/dev text overlap: set()\n",
      "Train distribution:\n",
      "1    622\n",
      "0    578\n",
      "2    274\n",
      "Name: stance, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neutral          622\n",
      "entailment       578\n",
      "contradiction    274\n",
      "Name: nli_label, dtype: int64\n",
      "\n",
      "Dev distribution:\n",
      "1    78\n",
      "0    61\n",
      "2    45\n",
      "Name: stance, dtype: int64\n",
      "neutral          78\n",
      "entailment       61\n",
      "contradiction    45\n",
      "Name: nli_label, dtype: int64\n",
      "\n",
      "Test distribution:\n",
      "1    86\n",
      "0    58\n",
      "2    40\n",
      "Name: stance, dtype: int64\n",
      "1    0.467391\n",
      "0    0.315217\n",
      "2    0.217391\n",
      "Name: stance, dtype: float64\n",
      "neutral          86\n",
      "entailment       58\n",
      "contradiction    40\n",
      "Name: nli_label, dtype: int64\n",
      "Writing to save_dir: save/all_mturk_train_42_fold_2\n",
      "(1474, 11) (184, 11) (184, 11)\n",
      "Train/test text overlap: set()\n",
      "Train/dev text overlap: set()\n",
      "Train distribution:\n",
      "1    628\n",
      "0    557\n",
      "2    289\n",
      "Name: stance, dtype: int64\n",
      "neutral          628\n",
      "entailment       557\n",
      "contradiction    289\n",
      "Name: nli_label, dtype: int64\n",
      "\n",
      "Dev distribution:\n",
      "1    77\n",
      "0    65\n",
      "2    42\n",
      "Name: stance, dtype: int64\n",
      "neutral          77\n",
      "entailment       65\n",
      "contradiction    42\n",
      "Name: nli_label, dtype: int64\n",
      "\n",
      "Test distribution:\n",
      "1    81\n",
      "0    75\n",
      "2    28\n",
      "Name: stance, dtype: int64\n",
      "1    0.440217\n",
      "0    0.407609\n",
      "2    0.152174\n",
      "Name: stance, dtype: float64\n",
      "neutral          81\n",
      "entailment       75\n",
      "contradiction    28\n",
      "Name: nli_label, dtype: int64\n",
      "Writing to save_dir: save/all_mturk_train_42_fold_3\n",
      "(1474, 11) (184, 11) (184, 11)\n",
      "Train/test text overlap: set()\n",
      "Train/dev text overlap: set()\n",
      "Train distribution:\n",
      "1    615\n",
      "0    574\n",
      "2    285\n",
      "Name: stance, dtype: int64\n",
      "neutral          615\n",
      "entailment       574\n",
      "contradiction    285\n",
      "Name: nli_label, dtype: int64\n",
      "\n",
      "Dev distribution:\n",
      "1    80\n",
      "0    74\n",
      "2    30\n",
      "Name: stance, dtype: int64\n",
      "neutral          80\n",
      "entailment       74\n",
      "contradiction    30\n",
      "Name: nli_label, dtype: int64\n",
      "\n",
      "Test distribution:\n",
      "1    91\n",
      "0    49\n",
      "2    44\n",
      "Name: stance, dtype: int64\n",
      "1    0.494565\n",
      "0    0.266304\n",
      "2    0.239130\n",
      "Name: stance, dtype: float64\n",
      "neutral          91\n",
      "entailment       49\n",
      "contradiction    44\n",
      "Name: nli_label, dtype: int64\n",
      "Writing to save_dir: save/all_mturk_train_42_fold_4\n",
      "(1474, 11) (184, 11) (184, 11)\n",
      "Train/test text overlap: set()\n",
      "Train/dev text overlap: set()\n",
      "Train distribution:\n",
      "1    635\n",
      "0    554\n",
      "2    285\n",
      "Name: stance, dtype: int64\n",
      "neutral          635\n",
      "entailment       554\n",
      "contradiction    285\n",
      "Name: nli_label, dtype: int64\n",
      "\n",
      "Dev distribution:\n",
      "1    82\n",
      "0    58\n",
      "2    44\n",
      "Name: stance, dtype: int64\n",
      "neutral          82\n",
      "entailment       58\n",
      "contradiction    44\n",
      "Name: nli_label, dtype: int64\n",
      "\n",
      "Test distribution:\n",
      "0    85\n",
      "1    69\n",
      "2    30\n",
      "Name: stance, dtype: int64\n",
      "0    0.461957\n",
      "1    0.375000\n",
      "2    0.163043\n",
      "Name: stance, dtype: float64\n",
      "entailment       85\n",
      "neutral          69\n",
      "contradiction    30\n",
      "Name: nli_label, dtype: int64\n",
      "Writing to save_dir: save/all_mturk_train_42_fold_5\n",
      "(1474, 11) (184, 11) (184, 11)\n",
      "Train/test text overlap: set()\n",
      "Train/dev text overlap: set()\n",
      "Train distribution:\n",
      "1    613\n",
      "0    563\n",
      "2    298\n",
      "Name: stance, dtype: int64\n",
      "neutral          613\n",
      "entailment       563\n",
      "contradiction    298\n",
      "Name: nli_label, dtype: int64\n",
      "\n",
      "Dev distribution:\n",
      "1    90\n",
      "0    65\n",
      "2    29\n",
      "Name: stance, dtype: int64\n",
      "neutral          90\n",
      "entailment       65\n",
      "contradiction    29\n",
      "Name: nli_label, dtype: int64\n",
      "\n",
      "Test distribution:\n",
      "1    83\n",
      "0    69\n",
      "2    32\n",
      "Name: stance, dtype: int64\n",
      "1    0.451087\n",
      "0    0.375000\n",
      "2    0.173913\n",
      "Name: stance, dtype: float64\n",
      "neutral          83\n",
      "entailment       69\n",
      "contradiction    32\n",
      "Name: nli_label, dtype: int64\n",
      "Writing to save_dir: save/all_mturk_train_42_fold_6\n",
      "(1474, 11) (184, 11) (184, 11)\n",
      "Train/test text overlap: set()\n",
      "Train/dev text overlap: set()\n",
      "Train distribution:\n",
      "1    648\n",
      "0    545\n",
      "2    281\n",
      "Name: stance, dtype: int64\n",
      "neutral          648\n",
      "entailment       545\n",
      "contradiction    281\n",
      "Name: nli_label, dtype: int64\n",
      "\n",
      "Dev distribution:\n",
      "0    77\n",
      "1    74\n",
      "2    33\n",
      "Name: stance, dtype: int64\n",
      "entailment       77\n",
      "neutral          74\n",
      "contradiction    33\n",
      "Name: nli_label, dtype: int64\n",
      "\n",
      "Test distribution:\n",
      "0    75\n",
      "1    64\n",
      "2    45\n",
      "Name: stance, dtype: int64\n",
      "0    0.407609\n",
      "1    0.347826\n",
      "2    0.244565\n",
      "Name: stance, dtype: float64\n",
      "entailment       75\n",
      "neutral          64\n",
      "contradiction    45\n",
      "Name: nli_label, dtype: int64\n",
      "Writing to save_dir: save/all_mturk_train_42_fold_7\n",
      "(1474, 11) (184, 11) (184, 11)\n",
      "Train/test text overlap: set()\n",
      "Train/dev text overlap: set()\n",
      "Train distribution:\n",
      "1    642\n",
      "0    546\n",
      "2    286\n",
      "Name: stance, dtype: int64\n",
      "neutral          642\n",
      "entailment       546\n",
      "contradiction    286\n",
      "Name: nli_label, dtype: int64\n",
      "\n",
      "Dev distribution:\n",
      "0    78\n",
      "1    71\n",
      "2    35\n",
      "Name: stance, dtype: int64\n",
      "entailment       78\n",
      "neutral          71\n",
      "contradiction    35\n",
      "Name: nli_label, dtype: int64\n",
      "\n",
      "Test distribution:\n",
      "1    73\n",
      "0    73\n",
      "2    38\n",
      "Name: stance, dtype: int64\n",
      "1    0.396739\n",
      "0    0.396739\n",
      "2    0.206522\n",
      "Name: stance, dtype: float64\n",
      "neutral          73\n",
      "entailment       73\n",
      "contradiction    38\n",
      "Name: nli_label, dtype: int64\n",
      "Writing to save_dir: save/all_mturk_train_42_fold_8\n",
      "(1474, 11) (184, 11) (184, 11)\n",
      "Train/test text overlap: set()\n",
      "Train/dev text overlap: set()\n",
      "Train distribution:\n",
      "1    621\n",
      "0    561\n",
      "2    292\n",
      "Name: stance, dtype: int64\n",
      "neutral          621\n",
      "entailment       561\n",
      "contradiction    292\n",
      "Name: nli_label, dtype: int64\n",
      "\n",
      "Dev distribution:\n",
      "1    81\n",
      "0    70\n",
      "2    33\n",
      "Name: stance, dtype: int64\n",
      "neutral          81\n",
      "entailment       70\n",
      "contradiction    33\n",
      "Name: nli_label, dtype: int64\n",
      "\n",
      "Test distribution:\n",
      "1    84\n",
      "0    66\n",
      "2    34\n",
      "Name: stance, dtype: int64\n",
      "1    0.456522\n",
      "0    0.358696\n",
      "2    0.184783\n",
      "Name: stance, dtype: float64\n",
      "neutral          84\n",
      "entailment       66\n",
      "contradiction    34\n",
      "Name: nli_label, dtype: int64\n",
      "Writing to save_dir: save/all_mturk_train_42_fold_9\n"
     ]
    }
   ],
   "source": [
    "for f in range(n_folds):\n",
    "    fold_0_ix = indices_per_fold[f]\n",
    "    train_ix = fold_0_ix['train']\n",
    "    test_ix = fold_0_ix['test']\n",
    "    dev_ix = fold_0_ix['dev']\n",
    "\n",
    "    train_df = dedup_est_labels.loc[dedup_est_labels.index.isin(train_ix)]\n",
    "    dev_df = dedup_est_labels.loc[dedup_est_labels.index.isin(dev_ix)]\n",
    "    test_df = dedup_est_labels.loc[dedup_est_labels.index.isin(test_ix)]\n",
    "    print(train_df.shape,dev_df.shape,test_df.shape)\n",
    "    write_data('all_mturk_train_{}_fold_{}'.format(seed,f),[],train_df,test_df,dev_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 746,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    635\n",
       "0    568\n",
       "2    267\n",
       "Name: 1, dtype: int64"
      ]
     },
     "execution_count": 746,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('./save/all_mturk_train_42_fold_0/train.tsv',sep='\\t',header=None)[1].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 750,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1270\n",
       "0    1136\n",
       "2    534 \n",
       "Name: 1, dtype: int64"
      ]
     },
     "execution_count": 750,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('./save/all_mturk_train_backtrans_fr_42_fold_0/train.tsv',sep='\\t',header=None)[1].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 751,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    635\n",
       "0    568\n",
       "2    534\n",
       "Name: 1, dtype: int64"
      ]
     },
     "execution_count": 751,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('./save/all_mturk_train_backtrans_fr_upsampled_42_fold_0/train.tsv',sep='\\t',\n",
    "            header=None)[1].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1961"
      ]
     },
     "execution_count": 410,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "677+658+626"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 752,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    534\n",
       "1    534\n",
       "0    534\n",
       "Name: 1, dtype: int64"
      ]
     },
     "execution_count": 752,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('./save/all_mturk_train_backtrans_fr_42_fold_0_downsampled/train.tsv',sep='\\t',\n",
    "            header=None)[1].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Back translation augmented train, with and without downsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#Add backtranslations of the train_ix examples to training\n",
    "# for f in range(n_folds):\n",
    "#     fold_0_ix = indices_per_fold[f]\n",
    "#     train_ix = fold_0_ix['train']\n",
    "#     test_ix = fold_0_ix['test']\n",
    "#     dev_ix = fold_0_ix['dev']\n",
    "\n",
    "#     train_df = dedup_est_labels.loc[dedup_est_labels.index.isin(train_ix)]\n",
    "#     dev_df = dedup_est_labels.loc[dedup_est_labels.index.isin(dev_ix)]\n",
    "#     test_df = dedup_est_labels.loc[dedup_est_labels.index.isin(test_ix)]\n",
    "#     backtrans_fr_df = add_backtrans_train(train_df,'fr')\n",
    "#     backtrans_zh_df = add_backtrans_train(train_df,'zh')\n",
    "#     backtrans_both_df = backtrans_fr_df.append(backtrans_zh_df,ignore_index=True).drop_duplicates('guid',keep='first')\n",
    "#     print(backtrans_fr_df.shape,backtrans_zh_df.shape,backtrans_both_df.shape,dev_df.shape,test_df.shape)\n",
    "#     write_data('all_mturk_train_backtrans_fr_{}_fold_{}'.format(seed,f),[],backtrans_fr_df,test_df,dev_df)\n",
    "#     write_data('all_mturk_train_backtrans_zh_{}_fold_{}'.format(seed,f),[],backtrans_zh_df,test_df,dev_df)\n",
    "#     write_data('all_mturk_train_backtrans_both_{}_fold_{}'.format(seed,f),[],backtrans_both_df,test_df,dev_df)\n",
    "#     write_data('all_mturk_train_backtrans_fr_{}_fold_{}'.format(seed,f),[],backtrans_fr_df,test_df,dev_df,do_downsample=True)\n",
    "#     write_data('all_mturk_train_backtrans_zh_{}_fold_{}'.format(seed,f),[],backtrans_zh_df,test_df,dev_df,do_downsample=True)\n",
    "#     write_data('all_mturk_train_backtrans_both_{}_fold_{}'.format(seed,f),[],backtrans_both_df,test_df,dev_df,do_downsample=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Back translation + upsample minority class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# for f in range(n_folds):\n",
    "#     fold_0_ix = indices_per_fold[f]\n",
    "#     train_ix = fold_0_ix['train']\n",
    "#     test_ix = fold_0_ix['test']\n",
    "#     dev_ix = fold_0_ix['dev']\n",
    "\n",
    "#     train_df = dedup_est_labels.loc[dedup_est_labels.index.isin(train_ix)]\n",
    "#     dev_df = dedup_est_labels.loc[dedup_est_labels.index.isin(dev_ix)]\n",
    "#     test_df = dedup_est_labels.loc[dedup_est_labels.index.isin(test_ix)]\n",
    "#     backtrans_fr_df = add_backtrans_train(train_df,'fr',upsample=True)\n",
    "#     backtrans_zh_df = add_backtrans_train(train_df,'zh',upsample=True)\n",
    "#     backtrans_both_df = backtrans_fr_df.append(backtrans_zh_df,ignore_index=True).drop_duplicates('guid',keep='first')\n",
    "#     print(backtrans_fr_df.shape,backtrans_zh_df.shape,backtrans_both_df.shape,dev_df.shape,test_df.shape)\n",
    "#     write_data('all_mturk_train_backtrans_fr_upsampled_{}_fold_{}'.format(seed,f),[],backtrans_fr_df,test_df,dev_df)\n",
    "#     write_data('all_mturk_train_backtrans_zh_upsampled_{}_fold_{}'.format(seed,f),[],backtrans_zh_df,test_df,dev_df)\n",
    "#     write_data('all_mturk_train_backtrans_both_upsampled_{}_fold_{}'.format(seed,f),[],backtrans_both_df,test_df,dev_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### High IAA train, eval on rest (splits differ only in dev/test distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_indices = mturk_df.loc[mturk_df.is_high_iaa].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "code_folding": [
     2
    ],
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "923 2042 462 461 1119\n",
      "923 2042 462 461 1119\n",
      "923 2042 462 461 1119\n",
      "923 2042 462 461 1119\n",
      "923 2042 462 461 1119\n",
      "923 2042 462 461 1119\n",
      "923 2042 462 461 1119\n",
      "923 2042 462 461 1119\n",
      "923 2042 462 461 1119\n",
      "923 2042 462 461 1119\n"
     ]
    }
   ],
   "source": [
    "indices_per_fold = {}\n",
    "n_folds = 10\n",
    "for f in range(n_folds):\n",
    "    all_indices = list(low_iaa_df.index)\n",
    "    test_indices = list(np.random.choice(all_indices, size=round(len(all_indices)/2), replace=False))\n",
    "    dev_indices = list(set(all_indices) - set(test_indices))\n",
    "    all_indices = set(test_indices).union(set(dev_indices))#.union(set(train_indices))\n",
    "    indices_per_fold[f] = {'train':train_indices,'dev':dev_indices,'test':test_indices}\n",
    "    print(len(all_indices), len(test_indices) + len(dev_indices) + len(train_indices), len(test_indices), len(dev_indices), len(train_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(indices_per_fold,open('high_iaa_cross_val_10_seed_42_high_iaa_indices.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# for f in range(0,n_folds):\n",
    "#     fold_0_ix = indices_per_fold[f]\n",
    "#     train_ix = fold_0_ix['train']\n",
    "#     test_ix = fold_0_ix['test']\n",
    "#     dev_ix = fold_0_ix['dev']\n",
    "\n",
    "#     train_df = mturk_df.loc[mturk_df.index.isin(train_ix)]\n",
    "#     dev_df = mturk_df.loc[mturk_df.index.isin(dev_ix)]\n",
    "#     test_df = mturk_df.loc[mturk_df.index.isin(test_ix)]\n",
    "#     print(train_df.shape,dev_df.shape,test_df.shape)\n",
    "#     write_data('high_iaa_train_fold_{}'.format(f),42,[],train_df,test_df,dev_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Augment w/ back translations, with and without downsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# for f in range(n_folds):\n",
    "#     fold_0_ix = indices_per_fold[f]\n",
    "#     train_ix = fold_0_ix['train']\n",
    "#     test_ix = fold_0_ix['test']\n",
    "#     dev_ix = fold_0_ix['dev']\n",
    "\n",
    "#     train_df = mturk_df.loc[mturk_df.index.isin(train_ix)]\n",
    "#     dev_df = mturk_df.loc[mturk_df.index.isin(dev_ix)]\n",
    "#     test_df = mturk_df.loc[mturk_df.index.isin(test_ix)]\n",
    "#     print(train_df.shape,dev_df.shape,test_df.shape)\n",
    "#     backtrans_fr_df = add_backtrans_train(train_df,'fr')\n",
    "#     backtrans_zh_df = add_backtrans_train(train_df,'zh')\n",
    "#     backtrans_both_df = backtrans_fr_df.append(backtrans_zh_df,ignore_index=True).drop_duplicates('guid',keep='first')\n",
    "#     print(backtrans_fr_df.shape,backtrans_zh_df.shape,backtrans_both_df.shape,dev_df.shape,test_df.shape)\n",
    "#     write_data('high_iaa_train_fold_{}'.format(f),seed,['backtrans_fr'],backtrans_fr_df,test_df,dev_df)\n",
    "#     write_data('high_iaa_train_fold_{}'.format(f),seed,['backtrans_zh'],backtrans_zh_df,test_df,dev_df)\n",
    "#     write_data('high_iaa_train_fold_{}'.format(f),seed,['backtrans_both'],backtrans_both_df,test_df,dev_df)\n",
    "#     write_data('high_iaa_train_fold_{}'.format(f),seed,['backtrans_fr'],backtrans_fr_df,test_df,dev_df,do_downsample=True)\n",
    "#     write_data('high_iaa_train_fold_{}'.format(f),seed,['backtrans_zh'],backtrans_zh_df,test_df,dev_df,do_downsample=True)\n",
    "#     write_data('high_iaa_train_fold_{}'.format(f),seed,['backtrans_both'],backtrans_both_df,test_df,dev_df,do_downsample=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Back translation + upsample minority class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# for f in range(n_folds):\n",
    "#     fold_0_ix = indices_per_fold[f]\n",
    "#     train_ix = fold_0_ix['train']\n",
    "#     test_ix = fold_0_ix['test']\n",
    "#     dev_ix = fold_0_ix['dev']\n",
    "\n",
    "#     train_df = mturk_df.loc[mturk_df.index.isin(train_ix)]\n",
    "#     dev_df = mturk_df.loc[mturk_df.index.isin(dev_ix)]\n",
    "#     test_df = mturk_df.loc[mturk_df.index.isin(test_ix)]\n",
    "#     print(train_df.shape,dev_df.shape,test_df.shape)\n",
    "#     backtrans_fr_df = add_backtrans_train(train_df,'fr',upsample=True)\n",
    "#     backtrans_zh_df = add_backtrans_train(train_df,'zh',upsample=True)\n",
    "#     backtrans_both_df = backtrans_fr_df.append(backtrans_zh_df,ignore_index=True).drop_duplicates('guid',keep='first')\n",
    "#     print(backtrans_fr_df.shape,backtrans_zh_df.shape,backtrans_both_df.shape,dev_df.shape,test_df.shape)\n",
    "#     write_data('high_iaa_train_fold_{}'.format(f),seed,['backtrans_fr_upsampled'],backtrans_fr_df,test_df,dev_df)\n",
    "#     write_data('high_iaa_train_fold_{}'.format(f),seed,['backtrans_zh_upsampled'],backtrans_zh_df,test_df,dev_df)\n",
    "#     write_data('high_iaa_train_fold_{}'.format(f),seed,['backtrans_both_upsampled'],backtrans_both_df,test_df,dev_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SCP to cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename first so that all of data is followed by fold, seed info\n",
    "os.rename('./save/high_iaa_train_','./save/high_iaa_train_HELLO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "for fold in range(0,10):\n",
    "    for f in glob.glob(os.path.join('save','all_mturk_train_fold_{}_*'.format(fold))):\n",
    "        split_f = f.split('all_mturk_train_fold_{}_'.format(fold))\n",
    "        new_f = split_f[0] + 'all_mturk_train_' + split_f[-1] + '_fold_{}'.format(fold)\n",
    "        #print(f,new_f)\n",
    "        os.rename(f,new_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [],
   "source": [
    "from paramiko import SSHClient\n",
    "from scp import SCPClient\n",
    "\n",
    "ssh = SSHClient()\n",
    "ssh.load_system_host_keys()\n",
    "ssh.connect(hostname='jacob.stanford.edu',username='yiweil',password='yldwuaeo2699zhishao15')\n",
    "\n",
    "# Define progress callback that prints the current percentage completed for the file\n",
    "def progress(filename, size, sent):\n",
    "    print(\"%s\\'s progress: %.2f%%   \\r\" % (filename, float(sent)/float(size)*100) )\n",
    "    \n",
    "cluster_data_dir = '/u/scr/yiweil/sci-debates/cc_stance/climate_data'\n",
    "local_data_dir = './save'\n",
    "\n",
    "# SCPCLient takes a paramiko transport and progress callback as its arguments.\n",
    "scp = SCPClient(ssh.get_transport(), progress=progress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./save/all_mturk_with_titles_train_42_fold_0',\n",
       " './save/all_mturk_with_titles_train_42_fold_1',\n",
       " './save/all_mturk_with_titles_train_42_fold_2',\n",
       " './save/all_mturk_with_titles_train_42_fold_3',\n",
       " './save/all_mturk_with_titles_train_42_fold_4',\n",
       " './save/all_mturk_with_titles_train_42_fold_5',\n",
       " './save/all_mturk_with_titles_train_42_fold_6',\n",
       " './save/all_mturk_with_titles_train_42_fold_7',\n",
       " './save/all_mturk_with_titles_train_42_fold_8',\n",
       " './save/all_mturk_with_titles_train_42_fold_9']"
      ]
     },
     "execution_count": 469,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glob.glob(local_data_dir+'/all_mturk_with_titles_*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'dev.tsv''s progress: 0.00%   \n",
      "b'dev.tsv''s progress: 66.12%   \n",
      "b'dev.tsv''s progress: 100.00%   \n",
      "b'test.tsv''s progress: 0.00%   \n",
      "b'test.tsv''s progress: 62.81%   \n",
      "b'test.tsv''s progress: 100.00%   \n",
      "b'train.tsv''s progress: 0.00%   \n",
      "b'train.tsv''s progress: 4.18%   \n",
      "b'train.tsv''s progress: 8.36%   \n",
      "b'train.tsv''s progress: 12.54%   \n",
      "b'train.tsv''s progress: 16.72%   \n",
      "b'train.tsv''s progress: 20.90%   \n",
      "b'train.tsv''s progress: 25.07%   \n",
      "b'train.tsv''s progress: 29.25%   \n",
      "b'train.tsv''s progress: 33.43%   \n",
      "b'train.tsv''s progress: 37.61%   \n",
      "b'train.tsv''s progress: 41.79%   \n",
      "b'train.tsv''s progress: 45.97%   \n",
      "b'train.tsv''s progress: 50.15%   \n",
      "b'train.tsv''s progress: 54.33%   \n",
      "b'train.tsv''s progress: 58.51%   \n",
      "b'train.tsv''s progress: 62.69%   \n",
      "b'train.tsv''s progress: 66.87%   \n",
      "b'train.tsv''s progress: 71.05%   \n",
      "b'train.tsv''s progress: 75.22%   \n",
      "b'train.tsv''s progress: 79.40%   \n",
      "b'train.tsv''s progress: 83.58%   \n",
      "b'train.tsv''s progress: 87.76%   \n",
      "b'train.tsv''s progress: 91.94%   \n",
      "b'train.tsv''s progress: 96.12%   \n",
      "b'train.tsv''s progress: 100.00%   \n",
      "b'dev.tsv''s progress: 0.00%   \n",
      "b'dev.tsv''s progress: 63.77%   \n",
      "b'dev.tsv''s progress: 100.00%   \n",
      "b'test.tsv''s progress: 0.00%   \n",
      "b'test.tsv''s progress: 65.38%   \n",
      "b'test.tsv''s progress: 100.00%   \n",
      "b'train.tsv''s progress: 0.00%   \n",
      "b'train.tsv''s progress: 4.18%   \n",
      "b'train.tsv''s progress: 8.36%   \n",
      "b'train.tsv''s progress: 12.53%   \n",
      "b'train.tsv''s progress: 16.71%   \n",
      "b'train.tsv''s progress: 20.89%   \n",
      "b'train.tsv''s progress: 25.07%   \n",
      "b'train.tsv''s progress: 29.25%   \n",
      "b'train.tsv''s progress: 33.42%   \n",
      "b'train.tsv''s progress: 37.60%   \n",
      "b'train.tsv''s progress: 41.78%   \n",
      "b'train.tsv''s progress: 45.96%   \n",
      "b'train.tsv''s progress: 50.14%   \n",
      "b'train.tsv''s progress: 54.31%   \n",
      "b'train.tsv''s progress: 58.49%   \n",
      "b'train.tsv''s progress: 62.67%   \n",
      "b'train.tsv''s progress: 66.85%   \n",
      "b'train.tsv''s progress: 71.03%   \n",
      "b'train.tsv''s progress: 75.20%   \n",
      "b'train.tsv''s progress: 79.38%   \n",
      "b'train.tsv''s progress: 83.56%   \n",
      "b'train.tsv''s progress: 87.74%   \n",
      "b'train.tsv''s progress: 91.91%   \n",
      "b'train.tsv''s progress: 96.09%   \n",
      "b'train.tsv''s progress: 100.00%   \n",
      "b'dev.tsv''s progress: 0.00%   \n",
      "b'dev.tsv''s progress: 63.67%   \n",
      "b'dev.tsv''s progress: 100.00%   \n",
      "b'test.tsv''s progress: 0.00%   \n",
      "b'test.tsv''s progress: 59.74%   \n",
      "b'test.tsv''s progress: 100.00%   \n",
      "b'train.tsv''s progress: 0.00%   \n",
      "b'train.tsv''s progress: 4.20%   \n",
      "b'train.tsv''s progress: 8.41%   \n",
      "b'train.tsv''s progress: 12.61%   \n",
      "b'train.tsv''s progress: 16.82%   \n",
      "b'train.tsv''s progress: 21.02%   \n",
      "b'train.tsv''s progress: 25.22%   \n",
      "b'train.tsv''s progress: 29.43%   \n",
      "b'train.tsv''s progress: 33.63%   \n",
      "b'train.tsv''s progress: 37.83%   \n",
      "b'train.tsv''s progress: 42.04%   \n",
      "b'train.tsv''s progress: 46.24%   \n",
      "b'train.tsv''s progress: 50.45%   \n",
      "b'train.tsv''s progress: 54.65%   \n",
      "b'train.tsv''s progress: 58.85%   \n",
      "b'train.tsv''s progress: 63.06%   \n",
      "b'train.tsv''s progress: 67.26%   \n",
      "b'train.tsv''s progress: 71.46%   \n",
      "b'train.tsv''s progress: 75.67%   \n",
      "b'train.tsv''s progress: 79.87%   \n",
      "b'train.tsv''s progress: 84.08%   \n",
      "b'train.tsv''s progress: 88.28%   \n",
      "b'train.tsv''s progress: 92.48%   \n",
      "b'train.tsv''s progress: 96.69%   \n",
      "b'train.tsv''s progress: 100.00%   \n",
      "b'dev.tsv''s progress: 0.00%   \n",
      "b'dev.tsv''s progress: 61.87%   \n",
      "b'dev.tsv''s progress: 100.00%   \n",
      "b'test.tsv''s progress: 0.00%   \n",
      "b'test.tsv''s progress: 65.17%   \n",
      "b'test.tsv''s progress: 100.00%   \n",
      "b'train.tsv''s progress: 0.00%   \n",
      "b'train.tsv''s progress: 4.19%   \n",
      "b'train.tsv''s progress: 8.37%   \n",
      "b'train.tsv''s progress: 12.56%   \n",
      "b'train.tsv''s progress: 16.75%   \n",
      "b'train.tsv''s progress: 20.94%   \n",
      "b'train.tsv''s progress: 25.12%   \n",
      "b'train.tsv''s progress: 29.31%   \n",
      "b'train.tsv''s progress: 33.50%   \n",
      "b'train.tsv''s progress: 37.69%   \n",
      "b'train.tsv''s progress: 41.87%   \n",
      "b'train.tsv''s progress: 46.06%   \n",
      "b'train.tsv''s progress: 50.25%   \n",
      "b'train.tsv''s progress: 54.43%   \n",
      "b'train.tsv''s progress: 58.62%   \n",
      "b'train.tsv''s progress: 62.81%   \n",
      "b'train.tsv''s progress: 67.00%   \n",
      "b'train.tsv''s progress: 71.18%   \n",
      "b'train.tsv''s progress: 75.37%   \n",
      "b'train.tsv''s progress: 79.56%   \n",
      "b'train.tsv''s progress: 83.74%   \n",
      "b'train.tsv''s progress: 87.93%   \n",
      "b'train.tsv''s progress: 92.12%   \n",
      "b'train.tsv''s progress: 96.31%   \n",
      "b'train.tsv''s progress: 100.00%   \n",
      "b'dev.tsv''s progress: 0.00%   \n",
      "b'dev.tsv''s progress: 62.80%   \n",
      "b'dev.tsv''s progress: 100.00%   \n",
      "b'test.tsv''s progress: 0.00%   \n",
      "b'test.tsv''s progress: 60.52%   \n",
      "b'test.tsv''s progress: 100.00%   \n",
      "b'train.tsv''s progress: 0.00%   \n",
      "b'train.tsv''s progress: 4.20%   \n",
      "b'train.tsv''s progress: 8.41%   \n",
      "b'train.tsv''s progress: 12.61%   \n",
      "b'train.tsv''s progress: 16.82%   \n",
      "b'train.tsv''s progress: 21.02%   \n",
      "b'train.tsv''s progress: 25.22%   \n",
      "b'train.tsv''s progress: 29.43%   \n",
      "b'train.tsv''s progress: 33.63%   \n",
      "b'train.tsv''s progress: 37.83%   \n",
      "b'train.tsv''s progress: 42.04%   \n",
      "b'train.tsv''s progress: 46.24%   \n",
      "b'train.tsv''s progress: 50.45%   \n",
      "b'train.tsv''s progress: 54.65%   \n",
      "b'train.tsv''s progress: 58.85%   \n",
      "b'train.tsv''s progress: 63.06%   \n",
      "b'train.tsv''s progress: 67.26%   \n",
      "b'train.tsv''s progress: 71.46%   \n",
      "b'train.tsv''s progress: 75.67%   \n",
      "b'train.tsv''s progress: 79.87%   \n",
      "b'train.tsv''s progress: 84.08%   \n",
      "b'train.tsv''s progress: 88.28%   \n",
      "b'train.tsv''s progress: 92.48%   \n",
      "b'train.tsv''s progress: 96.69%   \n",
      "b'train.tsv''s progress: 100.00%   \n",
      "b'dev.tsv''s progress: 0.00%   \n",
      "b'dev.tsv''s progress: 63.46%   \n",
      "b'dev.tsv''s progress: 100.00%   \n",
      "b'test.tsv''s progress: 0.00%   \n",
      "b'test.tsv''s progress: 62.76%   \n",
      "b'test.tsv''s progress: 100.00%   \n",
      "b'train.tsv''s progress: 0.00%   \n",
      "b'train.tsv''s progress: 4.19%   \n",
      "b'train.tsv''s progress: 8.38%   \n",
      "b'train.tsv''s progress: 12.57%   \n",
      "b'train.tsv''s progress: 16.76%   \n",
      "b'train.tsv''s progress: 20.95%   \n",
      "b'train.tsv''s progress: 25.14%   \n",
      "b'train.tsv''s progress: 29.33%   \n",
      "b'train.tsv''s progress: 33.52%   \n",
      "b'train.tsv''s progress: 37.71%   \n",
      "b'train.tsv''s progress: 41.90%   \n",
      "b'train.tsv''s progress: 46.10%   \n",
      "b'train.tsv''s progress: 50.29%   \n",
      "b'train.tsv''s progress: 54.48%   \n",
      "b'train.tsv''s progress: 58.67%   \n",
      "b'train.tsv''s progress: 62.86%   \n",
      "b'train.tsv''s progress: 67.05%   \n",
      "b'train.tsv''s progress: 71.24%   \n",
      "b'train.tsv''s progress: 75.43%   \n",
      "b'train.tsv''s progress: 79.62%   \n",
      "b'train.tsv''s progress: 83.81%   \n",
      "b'train.tsv''s progress: 88.00%   \n",
      "b'train.tsv''s progress: 92.19%   \n",
      "b'train.tsv''s progress: 96.38%   \n",
      "b'train.tsv''s progress: 100.00%   \n",
      "b'dev.tsv''s progress: 0.00%   \n",
      "b'dev.tsv''s progress: 61.47%   \n",
      "b'dev.tsv''s progress: 100.00%   \n",
      "b'test.tsv''s progress: 0.00%   \n",
      "b'test.tsv''s progress: 59.36%   \n",
      "b'test.tsv''s progress: 100.00%   \n",
      "b'train.tsv''s progress: 0.00%   \n",
      "b'train.tsv''s progress: 4.22%   \n",
      "b'train.tsv''s progress: 8.43%   \n",
      "b'train.tsv''s progress: 12.65%   \n",
      "b'train.tsv''s progress: 16.86%   \n",
      "b'train.tsv''s progress: 21.08%   \n",
      "b'train.tsv''s progress: 25.29%   \n",
      "b'train.tsv''s progress: 29.51%   \n",
      "b'train.tsv''s progress: 33.72%   \n",
      "b'train.tsv''s progress: 37.94%   \n",
      "b'train.tsv''s progress: 42.16%   \n",
      "b'train.tsv''s progress: 46.37%   \n",
      "b'train.tsv''s progress: 50.59%   \n",
      "b'train.tsv''s progress: 54.80%   \n",
      "b'train.tsv''s progress: 59.02%   \n",
      "b'train.tsv''s progress: 63.23%   \n",
      "b'train.tsv''s progress: 67.45%   \n",
      "b'train.tsv''s progress: 71.66%   \n",
      "b'train.tsv''s progress: 75.88%   \n",
      "b'train.tsv''s progress: 80.10%   \n",
      "b'train.tsv''s progress: 84.31%   \n",
      "b'train.tsv''s progress: 88.53%   \n",
      "b'train.tsv''s progress: 92.74%   \n",
      "b'train.tsv''s progress: 96.96%   \n",
      "b'train.tsv''s progress: 100.00%   \n",
      "b'dev.tsv''s progress: 0.00%   \n",
      "b'dev.tsv''s progress: 63.38%   \n",
      "b'dev.tsv''s progress: 100.00%   \n",
      "b'test.tsv''s progress: 0.00%   \n",
      "b'test.tsv''s progress: 64.76%   \n",
      "b'test.tsv''s progress: 100.00%   \n",
      "b'train.tsv''s progress: 0.00%   \n",
      "b'train.tsv''s progress: 4.18%   \n",
      "b'train.tsv''s progress: 8.36%   \n",
      "b'train.tsv''s progress: 12.55%   \n",
      "b'train.tsv''s progress: 16.73%   \n",
      "b'train.tsv''s progress: 20.91%   \n",
      "b'train.tsv''s progress: 25.09%   \n",
      "b'train.tsv''s progress: 29.28%   \n",
      "b'train.tsv''s progress: 33.46%   \n",
      "b'train.tsv''s progress: 37.64%   \n",
      "b'train.tsv''s progress: 41.82%   \n",
      "b'train.tsv''s progress: 46.00%   \n",
      "b'train.tsv''s progress: 50.19%   \n",
      "b'train.tsv''s progress: 54.37%   \n",
      "b'train.tsv''s progress: 58.55%   \n",
      "b'train.tsv''s progress: 62.73%   \n",
      "b'train.tsv''s progress: 66.92%   \n",
      "b'train.tsv''s progress: 71.10%   \n",
      "b'train.tsv''s progress: 75.28%   \n",
      "b'train.tsv''s progress: 79.46%   \n",
      "b'train.tsv''s progress: 83.64%   \n",
      "b'train.tsv''s progress: 87.83%   \n",
      "b'train.tsv''s progress: 92.01%   \n",
      "b'train.tsv''s progress: 96.19%   \n",
      "b'train.tsv''s progress: 100.00%   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'dev.tsv''s progress: 0.00%   \n",
      "b'dev.tsv''s progress: 62.39%   \n",
      "b'dev.tsv''s progress: 100.00%   \n",
      "b'test.tsv''s progress: 0.00%   \n",
      "b'test.tsv''s progress: 62.39%   \n",
      "b'test.tsv''s progress: 100.00%   \n",
      "b'train.tsv''s progress: 0.00%   \n",
      "b'train.tsv''s progress: 4.20%   \n",
      "b'train.tsv''s progress: 8.39%   \n",
      "b'train.tsv''s progress: 12.59%   \n",
      "b'train.tsv''s progress: 16.79%   \n",
      "b'train.tsv''s progress: 20.98%   \n",
      "b'train.tsv''s progress: 25.18%   \n",
      "b'train.tsv''s progress: 29.38%   \n",
      "b'train.tsv''s progress: 33.58%   \n",
      "b'train.tsv''s progress: 37.77%   \n",
      "b'train.tsv''s progress: 41.97%   \n",
      "b'train.tsv''s progress: 46.17%   \n",
      "b'train.tsv''s progress: 50.36%   \n",
      "b'train.tsv''s progress: 54.56%   \n",
      "b'train.tsv''s progress: 58.76%   \n",
      "b'train.tsv''s progress: 62.95%   \n",
      "b'train.tsv''s progress: 67.15%   \n",
      "b'train.tsv''s progress: 71.35%   \n",
      "b'train.tsv''s progress: 75.54%   \n",
      "b'train.tsv''s progress: 79.74%   \n",
      "b'train.tsv''s progress: 83.94%   \n",
      "b'train.tsv''s progress: 88.13%   \n",
      "b'train.tsv''s progress: 92.33%   \n",
      "b'train.tsv''s progress: 96.53%   \n",
      "b'train.tsv''s progress: 100.00%   \n",
      "b'dev.tsv''s progress: 0.00%   \n",
      "b'dev.tsv''s progress: 60.39%   \n",
      "b'dev.tsv''s progress: 100.00%   \n",
      "b'test.tsv''s progress: 0.00%   \n",
      "b'test.tsv''s progress: 62.71%   \n",
      "b'test.tsv''s progress: 100.00%   \n",
      "b'train.tsv''s progress: 0.00%   \n",
      "b'train.tsv''s progress: 4.20%   \n",
      "b'train.tsv''s progress: 8.41%   \n",
      "b'train.tsv''s progress: 12.61%   \n",
      "b'train.tsv''s progress: 16.82%   \n",
      "b'train.tsv''s progress: 21.02%   \n",
      "b'train.tsv''s progress: 25.23%   \n",
      "b'train.tsv''s progress: 29.43%   \n",
      "b'train.tsv''s progress: 33.64%   \n",
      "b'train.tsv''s progress: 37.84%   \n",
      "b'train.tsv''s progress: 42.05%   \n",
      "b'train.tsv''s progress: 46.25%   \n",
      "b'train.tsv''s progress: 50.46%   \n",
      "b'train.tsv''s progress: 54.66%   \n",
      "b'train.tsv''s progress: 58.87%   \n",
      "b'train.tsv''s progress: 63.07%   \n",
      "b'train.tsv''s progress: 67.28%   \n",
      "b'train.tsv''s progress: 71.48%   \n",
      "b'train.tsv''s progress: 75.69%   \n",
      "b'train.tsv''s progress: 79.89%   \n",
      "b'train.tsv''s progress: 84.10%   \n",
      "b'train.tsv''s progress: 88.30%   \n",
      "b'train.tsv''s progress: 92.51%   \n",
      "b'train.tsv''s progress: 96.71%   \n",
      "b'train.tsv''s progress: 100.00%   \n"
     ]
    }
   ],
   "source": [
    "# for file in glob.glob(local_data_dir+'/high_iaa_train_42*'):\n",
    "#     scp.put(file, recursive=True, remote_path=cluster_data_dir)\n",
    "    \n",
    "for file in glob.glob(local_data_dir+'/all_mturk_with_titles_*'):\n",
    "    scp.put(file, recursive=True, remote_path=cluster_data_dir)\n",
    "\n",
    "scp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
