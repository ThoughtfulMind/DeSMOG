{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:15: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import glob\n",
    "from collections import Counter,defaultdict\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from numpy.random import RandomState\n",
    "from sklearn import metrics\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split,KFold\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "STANCES = [\"agree\", \"neutral\", \"disagree\"]\n",
    "CLASS_NUMS = {s: i for i, s in enumerate(STANCES)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [
     1,
     5,
     11
    ]
   },
   "outputs": [],
   "source": [
    "# move to utils.py later\n",
    "nli2stance = {'entailment': CLASS_NUMS['agree'], \n",
    "              'neutral': CLASS_NUMS['neutral'], \n",
    "              'contradiction': CLASS_NUMS['disagree']}\n",
    "\n",
    "float2stance = {1.0: CLASS_NUMS['agree'],\n",
    "               0.0: CLASS_NUMS['neutral'],\n",
    "               -1.0: CLASS_NUMS['disagree']}\n",
    "\n",
    "stance2nli = {0: 'entailment', 1: 'neutral', 2: 'contradiction'}\n",
    "                \n",
    "def stance_reg(label):\n",
    "    \"\"\"\n",
    "    Regularize the stance labels \n",
    "    :param label: a label of str (agree(s)/entailment, neutral, disagree(s)/contradiction), \n",
    "     int (0, 1, 2) or str of int, or float (1.0, 0.0, -1.0)\n",
    "    :return: the label as the corresponding class_num\n",
    "    \"\"\"\n",
    "    \n",
    "    if type(label) == str:\n",
    "        if label.isalpha(): # could be a,n,d or NLI labels\n",
    "            if label in STANCES:\n",
    "                return CLASS_NUMS[label]\n",
    "            elif label[-1] == 's':\n",
    "                return CLASS_NUMS[label[:-1]]\n",
    "            else:\n",
    "                return nli2stance[label]\n",
    "        else: # label is str of (0, 1, 2)\n",
    "            return int(label)\n",
    "    elif type(label) == float:\n",
    "        return float2stance[label]\n",
    "    else:\n",
    "        return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def add_backtrans_train(train_df,language,upsample=False):\n",
    "    \"\"\"\n",
    "    Create df with backtranslations of train_df \n",
    "    :param train_df: base training data\n",
    "    :param language: 'fr' or 'zh'\n",
    "    :return: new df with previous training data + augmented data\n",
    "    \"\"\"\n",
    "    \n",
    "    backtrans_df = pd.DataFrame({\n",
    "        'round':train_df['round'].values,\n",
    "        'batch':train_df.batch.values,\n",
    "        'sent_id':train_df.sent_id.values,\n",
    "        'stance':train_df.stance.values,\n",
    "        'sentence':[get_backtrans(guid,language) for guid in train_df.guid],\n",
    "        'guid':[guid+'_'+language for guid in train_df.guid]\n",
    "    })\n",
    "    \n",
    "    \n",
    "    if upsample:\n",
    "        backtrans_df = backtrans_df.loc[backtrans_df.stance.isin({'disagrees','disagree'})].append(\n",
    "            train_df,ignore_index=True)\n",
    "    else:\n",
    "        backtrans_df = backtrans_df.append(train_df,ignore_index=True)\n",
    "        \n",
    "    return backtrans_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labeled_data = pd.read_pickle('./data/labeled_data_df.pkl')\n",
    "# labeled_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# labeled_data.type.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimated labels (MTurk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2050, 8), (2042, 8))"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est_labels = pd.read_csv('/Users/yiweiluo/scientific-debates/\\\n",
    "3_cc_stance/MTurk/MTurk_results/sent_scores_df_final.tsv',delimiter='\\t',index_col=0)\n",
    "est_labels['max_prob_label'] = est_labels[['disagree','neutral','agree']].idxmax(axis=1)\n",
    "dedup_est_labels = est_labels.drop_duplicates('sentence',keep='first')\n",
    "est_labels.shape, dedup_est_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "assert len(dedup_est_labels) == 2042\n",
    "dedup_est_labels['guid'] = [\"{}_{}_{}\".format(row['round'],row['batch'],row['sent_id']) \n",
    "                      for _,row in dedup_est_labels.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>round</th>\n",
       "      <th>batch</th>\n",
       "      <th>sent_id</th>\n",
       "      <th>disagree</th>\n",
       "      <th>neutral</th>\n",
       "      <th>agree</th>\n",
       "      <th>sentence</th>\n",
       "      <th>max_prob_label</th>\n",
       "      <th>guid</th>\n",
       "      <th>stance</th>\n",
       "      <th>max_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>t0</td>\n",
       "      <td>0.003105</td>\n",
       "      <td>0.285634</td>\n",
       "      <td>0.711260</td>\n",
       "      <td>Warmer-than-normal sea surface temperatures are a key player in the development of hurricanes such as Katrina and superstorm Sandy, which hit the U.S. east coast in 2011.</td>\n",
       "      <td>agree</td>\n",
       "      <td>1_0_t0</td>\n",
       "      <td>agree</td>\n",
       "      <td>0.711260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>t1</td>\n",
       "      <td>0.000830</td>\n",
       "      <td>0.998006</td>\n",
       "      <td>0.001163</td>\n",
       "      <td>We will continue to rely in part on fossil fuels while we transition to a low-carbon economy .</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1_0_t1</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.998006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>t10</td>\n",
       "      <td>0.000802</td>\n",
       "      <td>0.998023</td>\n",
       "      <td>0.001174</td>\n",
       "      <td>The actual rise in sea levels measured only 1.2 millimeters instead of the previously accepted 1.6 to 1.9 millimeters.</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1_0_t10</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.998023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>t11</td>\n",
       "      <td>0.997695</td>\n",
       "      <td>0.001134</td>\n",
       "      <td>0.001171</td>\n",
       "      <td>Claims of global warming have been greatly exaggerated.</td>\n",
       "      <td>disagree</td>\n",
       "      <td>1_0_t11</td>\n",
       "      <td>disagree</td>\n",
       "      <td>0.997695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>t12</td>\n",
       "      <td>0.031351</td>\n",
       "      <td>0.965687</td>\n",
       "      <td>0.002962</td>\n",
       "      <td>The Intergovernmental Panel on Climate Change should be clearer on how it draws conclusions from the body of research it assesses when gauging the impacts of global warming.</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1_0_t12</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.965687</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   round  batch sent_id  disagree   neutral     agree  \\\n",
       "0  1      0      t0      0.003105  0.285634  0.711260   \n",
       "1  1      0      t1      0.000830  0.998006  0.001163   \n",
       "2  1      0      t10     0.000802  0.998023  0.001174   \n",
       "3  1      0      t11     0.997695  0.001134  0.001171   \n",
       "4  1      0      t12     0.031351  0.965687  0.002962   \n",
       "\n",
       "                                                                                                                                                                        sentence  \\\n",
       "0  Warmer-than-normal sea surface temperatures are a key player in the development of hurricanes such as Katrina and superstorm Sandy, which hit the U.S. east coast in 2011.      \n",
       "1  We will continue to rely in part on fossil fuels while we transition to a low-carbon economy .                                                                                  \n",
       "2  The actual rise in sea levels measured only 1.2 millimeters instead of the previously accepted 1.6 to 1.9 millimeters.                                                          \n",
       "3  Claims of global warming have been greatly exaggerated.                                                                                                                         \n",
       "4  The Intergovernmental Panel on Climate Change should be clearer on how it draws conclusions from the body of research it assesses when gauging the impacts of global warming.   \n",
       "\n",
       "  max_prob_label     guid    stance  max_prob  \n",
       "0  agree          1_0_t0   agree     0.711260  \n",
       "1  neutral        1_0_t1   neutral   0.998006  \n",
       "2  neutral        1_0_t10  neutral   0.998023  \n",
       "3  disagree       1_0_t11  disagree  0.997695  \n",
       "4  neutral        1_0_t12  neutral   0.965687  "
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dedup_est_labels['stance'] = dedup_est_labels['max_prob_label']\n",
    "dedup_est_labels['max_prob'] = dedup_est_labels[['disagree','neutral','agree']].max(axis=1)\n",
    "dedup_est_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "held_out_test = pd.read_csv('./save/held_out_balanced_test.tsv',sep='\\t',header=0)\n",
    "#held_out_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "held_out_test.stance.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1842, 11)"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dedup_est_labels = dedup_est_labels.loc[~dedup_est_labels.guid.isin(held_out_test.guid)]\n",
    "dedup_est_labels.reset_index(drop=True,inplace=True)\n",
    "dedup_est_labels.shape # Expect 2042-200 = 1842"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert set(dedup_est_labels.guid.values).intersection(\n",
    "    set(held_out_test.guid.values)) == set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(dedup_est_labels.sentence.values).intersection(\n",
    "set(held_out_test.sentence.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw labels (MTurk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "worker_labels_per_round = pickle.load(open('../MTurk/MTurk_results/full_ratings_per_round.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROP_AGREE = 0.75\n",
    "NUM_ROUNDS, NUM_BATCHES, NUM_WORKERS = 5, 10, 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "code_folding": [
     1
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2042, 7)"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round_df,batch_df,sentid_df,stance_df,text_df,high_iaa_df,guid_df = [],[],[],[],[],[],[]\n",
    "for r in range(1,1+NUM_ROUNDS):\n",
    "    for b in range(NUM_BATCHES):\n",
    "        labels = worker_labels_per_round[r][b]\n",
    "        for s_id in labels.index[5:-1]:\n",
    "            round_df.append(r)\n",
    "            batch_df.append(b)\n",
    "            sentid_df.append(s_id)\n",
    "            text_df.append(labels.loc[s_id].sentence)\n",
    "            guid_df.append(\"{}_{}_{}\".format(r,b,s_id))\n",
    "            \n",
    "            ratings = labels.loc[s_id][['worker_{}'.format(w_id) for w_id in range(NUM_WORKERS)]].values\n",
    "            top_rating = Counter(ratings).most_common()[0]\n",
    "            if top_rating[-1] >= PROP_AGREE*NUM_WORKERS:\n",
    "                stance_df.append(top_rating[0])\n",
    "                high_iaa_df.append(True)\n",
    "            else:\n",
    "                stance_df.append(est_labels.loc[(est_labels['round'] == r) & \n",
    "                                             (est_labels['batch'] == b) & \n",
    "                                             (est_labels['sent_id'] == s_id)].max_prob_label.values[0])\n",
    "                high_iaa_df.append(False)\n",
    "\n",
    "mturk_df = pd.DataFrame({'round':round_df,\"batch\":batch_df,\"sent_id\":sentid_df,\"stance\":stance_df,\n",
    "                 \"sentence\":text_df,'is_high_iaa':high_iaa_df,'guid':guid_df})\n",
    "mturk_df = mturk_df.drop_duplicates('sentence',keep='first')\n",
    "mturk_df.reset_index(drop=True,inplace=True)\n",
    "mturk_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>round</th>\n",
       "      <th>batch</th>\n",
       "      <th>sent_id</th>\n",
       "      <th>stance</th>\n",
       "      <th>sentence</th>\n",
       "      <th>is_high_iaa</th>\n",
       "      <th>guid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>t0</td>\n",
       "      <td>agree</td>\n",
       "      <td>Warmer-than-normal sea surface temperatures are a key player in the development of hurricanes such as Katrina and superstorm Sandy, which hit the U.S. east coast in 2011.</td>\n",
       "      <td>False</td>\n",
       "      <td>1_0_t0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>t1</td>\n",
       "      <td>neutral</td>\n",
       "      <td>We will continue to rely in part on fossil fuels while we transition to a low-carbon economy .</td>\n",
       "      <td>True</td>\n",
       "      <td>1_0_t1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>t10</td>\n",
       "      <td>neutral</td>\n",
       "      <td>The actual rise in sea levels measured only 1.2 millimeters instead of the previously accepted 1.6 to 1.9 millimeters.</td>\n",
       "      <td>True</td>\n",
       "      <td>1_0_t10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>t11</td>\n",
       "      <td>disagrees</td>\n",
       "      <td>Claims of global warming have been greatly exaggerated.</td>\n",
       "      <td>True</td>\n",
       "      <td>1_0_t11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>t12</td>\n",
       "      <td>neutral</td>\n",
       "      <td>The Intergovernmental Panel on Climate Change should be clearer on how it draws conclusions from the body of research it assesses when gauging the impacts of global warming.</td>\n",
       "      <td>True</td>\n",
       "      <td>1_0_t12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   round  batch sent_id     stance  \\\n",
       "0  1      0      t0      agree       \n",
       "1  1      0      t1      neutral     \n",
       "2  1      0      t10     neutral     \n",
       "3  1      0      t11     disagrees   \n",
       "4  1      0      t12     neutral     \n",
       "\n",
       "                                                                                                                                                                        sentence  \\\n",
       "0  Warmer-than-normal sea surface temperatures are a key player in the development of hurricanes such as Katrina and superstorm Sandy, which hit the U.S. east coast in 2011.      \n",
       "1  We will continue to rely in part on fossil fuels while we transition to a low-carbon economy .                                                                                  \n",
       "2  The actual rise in sea levels measured only 1.2 millimeters instead of the previously accepted 1.6 to 1.9 millimeters.                                                          \n",
       "3  Claims of global warming have been greatly exaggerated.                                                                                                                         \n",
       "4  The Intergovernmental Panel on Climate Change should be clearer on how it draws conclusions from the body of research it assesses when gauging the impacts of global warming.   \n",
       "\n",
       "   is_high_iaa     guid  \n",
       "0  False        1_0_t0   \n",
       "1  True         1_0_t1   \n",
       "2  True         1_0_t10  \n",
       "3  True         1_0_t11  \n",
       "4  True         1_0_t12  "
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mturk_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1842, 7)"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mturk_df = mturk_df.loc[~mturk_df['guid'].isin(set(held_out_test.guid.values))]\n",
    "mturk_df.reset_index(drop=True,inplace=True)\n",
    "mturk_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     1010\n",
       "False    832 \n",
       "Name: is_high_iaa, dtype: int64"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mturk_df.is_high_iaa.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert set(mturk_df.guid.values).intersection(\n",
    "    set(held_out_test.guid.values)) == set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(mturk_df.sentence.values).intersection(\n",
    "set(held_out_test.sentence.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Back translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "back_trans_fr = pd.read_csv('../datasets/mturk_french_backtranslations.tsv',sep='\\t',\n",
    "                        header=0,index_col=0)\n",
    "back_trans_zh = pd.read_csv('../datasets/mturk_zh_backtranslations.tsv',sep='\\t',\n",
    "                        header=0,index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_backtrans(guid,language):\n",
    "    r,b,s_id = guid.split('_')\n",
    "    if language == 'fr':\n",
    "        return back_trans_fr.loc[(back_trans_fr['round'] == int(r)) &\n",
    "                                (back_trans_fr['batch'] == int(b)) &\n",
    "                                (back_trans_fr['sent_id'] == s_id)].backtranslation.values[0]\n",
    "    else:\n",
    "        return back_trans_zh.loc[(back_trans_fr['round'] == int(r)) &\n",
    "                                (back_trans_fr['batch'] == int(b)) &\n",
    "                                (back_trans_fr['sent_id'] == s_id)].backtranslation_zh_en.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Warmer than normal sea surface temperatures are a key player in the development of hurricanes such as Katrina and Sandstorm Sandy, which hit the east coast of the United States in 2011.'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_backtrans('1_0_t0','fr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Above-normal sea-level temperatures were a key factor in the development of hurricanes such as Hurricane Katrina and Sandy, which hit the US East Coast in 2011.'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_backtrans('1_0_t0','zh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Sentence windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fnames = os.listdir('../../1_data_scraping/cc_texts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "all_round_data = {r: {} for r in range(1,6)}\n",
    "for round_no in range(1,6):\n",
    "    all_round_data[round_no] = pickle.load(open('/Users/yiweiluo/Dropbox/research/QP2/code/Fox_and_friends/\\\n",
    "LIVE_ROUND{}_BATCH_DATA.pkl'.format(round_no),'rb'))\n",
    "    \n",
    "data_for_mturk_df = pd.read_pickle('/Users/yiweiluo/Dropbox/research/QP2/code/Fox_and_friends/\\\n",
    "data_for_mturk_2020.pkl')\n",
    "data_for_mturk_df_old = pd.read_pickle('/Users/yiweiluo/Dropbox/research/QP2/code/Fox_and_friends/\\\n",
    "data_for_mturk.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "code_folding": [
     3
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "from fuzzywuzzy import process\n",
    "\n",
    "def get_window(guid,window_size):\n",
    "    r,b,s_id = guid.split('_')\n",
    "    target_sent = mturk_df.loc[(mturk_df['round'] == int(r)) &\n",
    "                                (mturk_df['batch'] == int(b)) &\n",
    "                                (mturk_df['sent_id'] == s_id)].sentence.values[0]\n",
    "\n",
    "#     print('Target sent:',target_sent)\n",
    "#     print('Round: {}, batch: {}, sent_id: {}'.format(r,b,s_id))\n",
    "    rb_df = pd.DataFrame(all_round_data[int(r)][int(b)])\n",
    "    df_key = rb_df.loc[rb_df.sent_id == s_id].df_key.values[0]\n",
    "#     print('df key:',df_key)\n",
    "    \n",
    "    if int(r) < 5:\n",
    "        sent_key = data_for_mturk_df_old.loc[df_key].sent_key\n",
    "    else:\n",
    "        sent_key = data_for_mturk_df.loc[df_key].sent_key\n",
    "        \n",
    "    url = sent_key.split(' of ')[-1].split('://')[-1]\n",
    "    #print('url:',url)\n",
    "    \n",
    "    fname = url.replace('/','[SEP]')\n",
    "    fname = '{}.txt'.format(fname) if '{}.txt'.format(fname) in fnames else '{}.txt'.format(fname[:90])\n",
    "    #print('fname:',fname)\n",
    "    \n",
    "    if fname in fnames:\n",
    "        with open(os.path.join('../../1_data_scraping/cc_texts',fname)) as f:\n",
    "            text = f.readlines()\n",
    "        if len(text) > 0:\n",
    "            text = text[0]\n",
    "\n",
    "            text_sents = sent_tokenize(text)\n",
    "            sent_with_target = process.extract(target_sent, text_sents, limit=1)\n",
    "            #print('Found sentence containing target sent:',sent_with_target)\n",
    "            ix_target_sent = text_sents.index(sent_with_target[0][0])\n",
    "\n",
    "            w_start = max(0,ix_target_sent-window_size)\n",
    "            w_end = min(ix_target_sent+window_size,len(text_sents)-1)\n",
    "            w_left = text_sents[w_start:ix_target_sent]\n",
    "            w_right = text_sents[ix_target_sent+1:w_end+1]\n",
    "            #print('Left sentence(s):',w_left)\n",
    "            #print('Right sentence(s):',w_right)\n",
    "            BERT_input = '[SEP] '.join(w_left)+' [SEP] [CLS] '+target_sent+' [SEP] '+' [SEP] '.join(w_right)\n",
    "            if BERT_input[:6] != ' [SEP]':\n",
    "                #print('Padding beginning with [SEP]...')\n",
    "                BERT_input = '[SEP] '+BERT_input\n",
    "                \n",
    "            return BERT_input\n",
    "        else:\n",
    "            print('Fulltext is empty!')\n",
    "    else:\n",
    "        print('Fulltext file not found!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[SEP] “I think it’s very important to remind people the scope of what can happen with the hurricane season.”  Nonetheless, the events surrounding the hurricane, which caused $108 billion of damage, continue to interest to the scientific community. [SEP] [CLS] Warmer-than-normal sea surface temperatures are a key player in the development of hurricanes such as Katrina and superstorm Sandy, which hit the U.S. east coast in 2011. [SEP] “These storms may not have been caused by global warming, but because the ocean’s surface is warmer, it makes the storm more powerful,” Thomas Wagner, cryosphere program manager at NASA headquarters in Washington, D.C. told FoxNews.com.'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_window('1_0_t0',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[SEP] “We haven’t had a Category 3 hit the U.S. in 10 years – I think there’s a lot of complacency out there,” she said during a panel discussion at an American Meteorological Society conference in June.[SEP] “I think it’s very important to remind people the scope of what can happen with the hurricane season.”  Nonetheless, the events surrounding the hurricane, which caused $108 billion of damage, continue to interest to the scientific community. [SEP] [CLS] Warmer-than-normal sea surface temperatures are a key player in the development of hurricanes such as Katrina and superstorm Sandy, which hit the U.S. east coast in 2011. [SEP] “These storms may not have been caused by global warming, but because the ocean’s surface is warmer, it makes the storm more powerful,” Thomas Wagner, cryosphere program manager at NASA headquarters in Washington, D.C. told FoxNews.com. [SEP] “Then, because sea level is higher, the water can go further inland from the storm surge.”  President Obama briefly addressed the issue of climate change during a speech in New Orleans Thursday.'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_window('1_0_t0',2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## SemEval tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(169, 395)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "semeval_test = pd.read_csv('../datasets/StanceDataset/test.csv',header=0,encoding='utf-8',engine='python')\n",
    "semeval_test = semeval_test[semeval_test['Target'] == 'Climate Change is a Real Concern']\n",
    "\n",
    "semeval_train = pd.read_csv('../datasets/StanceDataset/train.csv',header=0,encoding='utf-8', engine='python')\n",
    "semeval_train = semeval_train[semeval_train['Target'] == 'Climate Change is a Real Concern']\n",
    "\n",
    "len(semeval_test),len(semeval_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "semeval_test = semeval_test[['Tweet','Stance']]\n",
    "semeval_train = semeval_train[['Tweet','Stance']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tweetstance2label = {'NONE': CLASS_NUMS['neutral'],\n",
    "                    'FAVOR': CLASS_NUMS['agree'],\n",
    "                    'AGAINST': CLASS_NUMS['disagree']}\n",
    "\n",
    "semeval_test['stance'] = semeval_test['Stance'].apply(lambda x: tweetstance2label[x])\n",
    "semeval_train['stance'] = semeval_train['Stance'].apply(lambda x: tweetstance2label[x])\n",
    "semeval_df = semeval_test.append(semeval_train,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    335\n",
       "1    203\n",
       "2    26 \n",
       "Name: stance, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "semeval_df.stance.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Add additional info: original source media leaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_orig_media_slant(guid):\n",
    "    r,b,s_id = guid.split('_')\n",
    "    if int(r) < 5:\n",
    "        df_ = data_for_mturk_df_old\n",
    "    else:\n",
    "        df_ = data_for_mturk_df\n",
    "    \n",
    "    b_df_ = pd.DataFrame(all_round_data[int(r)][int(b)])\n",
    "    df_key = b_df_.loc[b_df_.sent_id == s_id].df_key.values[0]\n",
    "    \n",
    "    def str_to_int(s):\n",
    "        return int(s == 'pro') # 1 for pro, 0 for anti\n",
    "        \n",
    "    return str_to_int(df_.iloc[df_key].bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int('pro' == 'pro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Titles, with source media outlet as proxy label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44582, 10)"
      ]
     },
     "execution_count": 412,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle('../../1_data_scraping/dedup_combined_df.pkl')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 667,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df.loc[(df.stance=='pro') & \n",
    "#       (df.topic=='cc')].domain.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 668,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df.loc[(df.stance=='anti') & \n",
    "#       (df.topic=='cc')].domain.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Other extreme L candidates:\n",
    "# grist, inthesetimes, guardian_us (2307 total)\n",
    "\n",
    "# Other extreme R candidates:\n",
    "# daily_caller, drudgereport, infowars (1153 total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "CC_KEYWORDS = {'warming','climate','carbon','co2','fossil',\n",
    "              'temperature','environment','ice','antarctica','sea','seas',\n",
    "              'IPCC','gore','green'}\n",
    "\n",
    "def has_keyword(title):\n",
    "    return len(set(title.lower().split()).intersection(CC_KEYWORDS)) > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4037, 1365)"
      ]
     },
     "execution_count": 432,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counted_breitbart_titles = Counter(df.loc[df.domain == 'breitbart'].title.values)\n",
    "keyword_breitbart_titles = [x for x in counted_breitbart_titles if has_keyword(x)]\n",
    "len(counted_breitbart_titles),len(keyword_breitbart_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3430, 896)"
      ]
     },
     "execution_count": 434,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counted_mj_titles = Counter(df.loc[df.domain == 'mj'].title.values)\n",
    "keyword_mj_titles = [x for x in counted_mj_titles if has_keyword(x)]\n",
    "len(counted_mj_titles),len(keyword_mj_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "titles_df = pd.DataFrame({\"sentence\":keyword_breitbart_titles+keyword_mj_titles,\n",
    "                                  \"stance\":['disagrees']*len(keyword_breitbart_titles)+\\\n",
    "                                  ['agrees']*len(keyword_mj_titles)\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#titles_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create train/dev/test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(mturk_df) == 2042-len(held_out_test)\n",
    "assert len(dedup_est_labels) == 2042-len(held_out_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "\n",
      "\n",
      "[SEP] “I think it’s very important to remind people the scope of what can happen with the hurricane season.”  Nonetheless, the events surrounding the hurricane, which caused $108 billion of damage, continue to interest to the scientific community. [SEP] [CLS] Warmer-than-normal sea surface temperatures are a key player in the development of hurricanes such as Katrina and superstorm Sandy, which hit the U.S. east coast in 2011. [SEP] “These storms may not have been caused by global warming, but because the ocean’s surface is warmer, it makes the storm more powerful,” Thomas Wagner, cryosphere program manager at NASA headquarters in Washington, D.C. told FoxNews.com.\n",
      "\n",
      "\n",
      "How the Intergovernmental Panel on Climate Change should draw clearer conclusions from the research findings it assesses when assessing the effects of global warming.\n"
     ]
    }
   ],
   "source": [
    "df_getter = {'raw_mturk': mturk_df,\n",
    "            'est_mturk': dedup_est_labels,\n",
    "            'semeval': semeval_df}\n",
    "\n",
    "print(get_orig_media_slant('1_0_t12'))\n",
    "print('\\n')\n",
    "print(get_window('1_0_t0',1))\n",
    "print('\\n')\n",
    "print(get_backtrans('1_0_t12','zh'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>round</th>\n",
       "      <th>batch</th>\n",
       "      <th>sent_id</th>\n",
       "      <th>stance</th>\n",
       "      <th>sentence</th>\n",
       "      <th>is_high_iaa</th>\n",
       "      <th>guid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>t12</td>\n",
       "      <td>neutral</td>\n",
       "      <td>The Intergovernmental Panel on Climate Change should be clearer on how it draws conclusions from the body of research it assesses when gauging the impacts of global warming.</td>\n",
       "      <td>True</td>\n",
       "      <td>1_0_t12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   round  batch sent_id   stance  \\\n",
       "4  1      0      t12     neutral   \n",
       "\n",
       "                                                                                                                                                                        sentence  \\\n",
       "4  The Intergovernmental Panel on Climate Change should be clearer on how it draws conclusions from the body of research it assesses when gauging the impacts of global warming.   \n",
       "\n",
       "   is_high_iaa     guid  \n",
       "4  True         1_0_t12  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_getter['raw_mturk'].loc[df_getter['raw_mturk'].guid == '1_0_t12']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "code_folding": [
     26,
     28,
     30,
     37
    ]
   },
   "outputs": [],
   "source": [
    "def write_data(name,fold_no,train_df,test_df,dev_df=None,weights=True,do_downsample=False,\n",
    "              add_titles=False):\n",
    "    \"\"\"\n",
    "    Writes data to a directory containing train.tsv, test.tsv, and optionally dev.tsv.\n",
    "    :param name: name of directory (type of train/eval data)\n",
    "    :param desc: list of type str with manipulations made (e.g., downsampled, upsampled, backtrans_fr, window_1)\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    \n",
    "    # Check that train and eval text are deduplicated\n",
    "    train_guids = set([x.replace('_fr','').replace('_zh','') for x in train_df.guid])\n",
    "    test_guids = set([x.replace('_fr','').replace('_zh','') for x in test_df.guid])\n",
    "    assert train_guids.intersection(test_guids) == set()\n",
    "    print(\"Train/test text overlap:\",set(train_df.sentence).intersection(set(test_df.sentence)))\n",
    "    if dev_df is not None:\n",
    "        dev_guids = set([x.replace('_fr','').replace('_zh','') for x in dev_df.guid])\n",
    "        assert train_guids.intersection(dev_guids) == set()\n",
    "        print(\"Train/dev text overlap:\",set(train_df.sentence).intersection(set(dev_df.sentence)))\n",
    "    train_df = train_df[['stance','sentence','max_prob']+STANCES]\n",
    "    test_df = test_df[['stance','sentence','max_prob']+STANCES]\n",
    "    if dev_df is not None:\n",
    "        dev_df = dev_df[['stance','sentence','max_prob']+STANCES]\n",
    "    \n",
    "    # Make save_dir\n",
    "    # Want: ./new_save/datatype_or_name/folds/fold_no/\n",
    "    # os.path.join(basedir, task, datatype, subdir, str(fold)),\n",
    "    if do_downsample:\n",
    "        name += '_downsampled'\n",
    "    if weights:\n",
    "        name += '_weights'\n",
    "    if add_titles:\n",
    "        name += '_with_titles'\n",
    "    print(name)\n",
    "    save_dir = os.path.join('new_save',name,'folds',str(fold_no))\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "        \n",
    "    # Add titles from Breitbart and MJ--TODO: make outlets a parameter\n",
    "    if add_titles:\n",
    "        print('Adding Breitbart and MJ titles to train_df...')\n",
    "        train_df = train_df.append(titles_df,ignore_index=True)\n",
    "        \n",
    "    # Regularize labels\n",
    "    train_df['reg_stance'] = train_df['stance'].apply(stance_reg)\n",
    "    test_df['reg_stance'] = test_df['stance'].apply(stance_reg)\n",
    "    if dev_df is not None:\n",
    "        dev_df['reg_stance'] = dev_df['stance'].apply(stance_reg) \n",
    "        \n",
    "    # Aggregate examples by stance for downsampling/upsampling needs\n",
    "    train_df_by_stance = {s: train_df.loc[train_df.reg_stance == i] for i,s in enumerate(STANCES)} \n",
    "    test_df_by_stance = {s: test_df.loc[test_df.reg_stance == i] for i,s in enumerate(STANCES)}\n",
    "    dev_df_by_stance = {s: dev_df.loc[dev_df.reg_stance == i] for i,s in enumerate(STANCES)} if dev_df is not None else None\n",
    "    \n",
    "    if do_downsample:\n",
    "        min_N = min([len(train_df_by_stance[s]) for s in STANCES])\n",
    "        print('Downsampling to ~{} examples per stance.'.format(min_N))\n",
    "        for s in STANCES:\n",
    "            train_df_by_stance[s] = train_df_by_stance[s].loc[np.random.choice(train_df_by_stance[s].index,\n",
    "                                                                               size=min_N,replace=False)]\n",
    "\n",
    "\n",
    "    trX = []\n",
    "    trY = []\n",
    "    trNLI = []\n",
    "    trW = []\n",
    "    for i,s in enumerate(STANCES):\n",
    "        for _,row in train_df_by_stance[s].iterrows():\n",
    "            if weights:\n",
    "                trX.extend([row['sentence']]*3)\n",
    "                trW.extend([row[x] for x in STANCES])\n",
    "                trY.extend([x for x in STANCES])\n",
    "                trNLI.extend([stance2nli[stance_reg(x)] for x in STANCES])\n",
    "            else:\n",
    "                trX.append(row['sentence'])\n",
    "                trY.append(row['stance'])\n",
    "                trNLI.append(stance2nli[row['reg_stance']])\n",
    "\n",
    "    teX = []\n",
    "    teY = []\n",
    "    teNLI = []\n",
    "    teW = []\n",
    "    for i,s in enumerate(STANCES):\n",
    "        for _,row in test_df_by_stance[s].iterrows():\n",
    "            teX.append(row['sentence'])\n",
    "            teY.append(row['stance'])\n",
    "            teNLI.append(stance2nli[row['reg_stance']])\n",
    "            if weights:\n",
    "                teW.append(row['max_prob'])\n",
    "\n",
    "    if dev_df is not None:\n",
    "        vaX = []\n",
    "        vaY = []\n",
    "        vaNLI = []\n",
    "        vaW = []\n",
    "        for i,s in enumerate(STANCES):\n",
    "            for _,row in dev_df_by_stance[s].iterrows():\n",
    "                vaX.append(row['sentence'])\n",
    "                vaY.append(row['stance'])\n",
    "                vaNLI.append(stance2nli[row['reg_stance']])\n",
    "                if weights:\n",
    "                    vaW.append(row['max_prob'])\n",
    "\n",
    "\n",
    "    if weights:\n",
    "        train_dat = pd.DataFrame({'sentence':trX,'stance':trY,'nli_label':trNLI,'weight':trW}) \n",
    "        test_dat = pd.DataFrame({'sentence':teX,'stance':teY,'nli_label':teNLI,'weight':teW})\n",
    "        val_dat = pd.DataFrame({'sentence':vaX,'stance':vaY,'nli_label':vaNLI,'weight':vaW}) if dev_df is not None else None\n",
    "    else:\n",
    "        train_dat = pd.DataFrame({'sentence':trX,'stance':trY,'nli_label':trNLI})\n",
    "        test_dat = pd.DataFrame({'sentence':teX,'stance':teY,'nli_label':teNLI})\n",
    "        val_dat = pd.DataFrame({'sentence':vaX,'stance':vaY,'nli_label':vaNLI}) if dev_df is not None else None\n",
    "    \n",
    "    print('Train distribution:')\n",
    "    print(train_dat.stance.value_counts()) \n",
    "    print(train_dat.nli_label.value_counts())\n",
    "    if dev_df is not None:\n",
    "        print('\\nDev distribution:')\n",
    "        print(val_dat.stance.value_counts())\n",
    "        print(val_dat.nli_label.value_counts())\n",
    "    print('\\nTest distribution:')\n",
    "    print(test_dat.stance.value_counts())\n",
    "    print(test_dat.stance.value_counts()/np.sum(test_dat.stance.value_counts().values))\n",
    "    print(test_dat.nli_label.value_counts())\n",
    "\n",
    "    print('Writing to save_dir:',save_dir)\n",
    "    train_dat.to_csv(save_dir+'/train.tsv',sep='\\t',header=None,index=False)\n",
    "    if dev_df is not None:\n",
    "        val_dat.to_csv(save_dir+'/dev.tsv',sep='\\t',header=None,index=False)\n",
    "    test_dat.to_csv(save_dir+'/test.tsv',sep='\\t',header=None,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Completely held-out, second test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Drawn from all MTurk labels, balanced over outlet sources and annotator ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "dedup_est_labels['outlet_stance'] = dedup_est_labels['guid'].apply(get_orig_media_slant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1038\n",
       "1    1004\n",
       "Name: outlet_stance, dtype: int64"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dedup_est_labels.outlet_stance.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neutral     0.427032\n",
       "agree       0.378550\n",
       "disagree    0.194417\n",
       "Name: stance, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dedup_est_labels.stance.value_counts()/dedup_est_labels.stance.value_counts().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "agree       0.460159\n",
       "neutral     0.423307\n",
       "disagree    0.116534\n",
       "Name: stance, dtype: float64"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dedup_est_labels.loc[dedup_est_labels.outlet_stance==1].stance.value_counts()/\\\n",
    "dedup_est_labels.loc[dedup_est_labels.outlet_stance==1].stance.value_counts().sum() # L-wing stance dist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neutral     0.430636\n",
       "agree       0.299615\n",
       "disagree    0.269750\n",
       "Name: stance, dtype: float64"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dedup_est_labels.loc[dedup_est_labels.outlet_stance==0].stance.value_counts()/\\\n",
    "dedup_est_labels.loc[dedup_est_labels.outlet_stance==0].stance.value_counts().sum() # R-wing stance dist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: agree       46.0\n",
       " neutral     42.0\n",
       " disagree    12.0\n",
       " Name: stance, dtype: float64, 0: neutral     43.0\n",
       " agree       30.0\n",
       " disagree    27.0\n",
       " Name: stance, dtype: float64}"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Want held-out test set that's 46% agree+L, 42% neutral+L, 12% disagree+L\n",
    "# 30% agree+R, 43% neutral+R, 27% disagree+R\n",
    "N_needed = {1: round(dedup_est_labels.loc[dedup_est_labels.outlet_stance==1].stance.value_counts()/\\\n",
    "dedup_est_labels.loc[dedup_est_labels.outlet_stance==1].stance.value_counts().sum()*100),\n",
    "            0: round(dedup_est_labels.loc[dedup_est_labels.outlet_stance==0].stance.value_counts()/\\\n",
    "dedup_est_labels.loc[dedup_est_labels.outlet_stance==0].stance.value_counts().sum()*100)}\n",
    "N_needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "code_folding": [],
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anti agree (311, 12)\n",
      "anti neutral (447, 12)\n",
      "anti disagree (280, 12)\n",
      "pro agree (462, 12)\n",
      "pro neutral (425, 12)\n",
      "pro disagree (117, 12)\n"
     ]
    }
   ],
   "source": [
    "indices_per_outlet_stance = defaultdict(dict)\n",
    "for outlet_stance in [0,1]:\n",
    "    for stance in ['agree','neutral','disagree']:\n",
    "        sub_df = dedup_est_labels.loc[(dedup_est_labels.stance == stance) & \n",
    "                                     (dedup_est_labels.outlet_stance == outlet_stance)]\n",
    "        str_outlet_stance = 'pro' if outlet_stance == 1 else 'anti'\n",
    "        print(str_outlet_stance,stance,sub_df.shape)\n",
    "        indices_per_outlet_stance[outlet_stance][stance] = np.random.choice(\n",
    "            sub_df.index,size=int(N_needed[outlet_stance][stance]),replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_test_ix = []\n",
    "for outlet_stance in indices_per_outlet_stance:\n",
    "    for stance in STANCES:\n",
    "        balanced_test_ix.extend(indices_per_outlet_stance[outlet_stance][stance])\n",
    "len(balanced_test_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neutral     85\n",
       "agree       76\n",
       "disagree    39\n",
       "Name: stance, dtype: int64"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dedup_est_labels.loc[balanced_test_ix].stance.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "agree       46\n",
       "neutral     42\n",
       "disagree    12\n",
       "Name: stance, dtype: int64"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dedup_est_labels.loc[balanced_test_ix][dedup_est_labels.outlet_stance==1].stance.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "neutral     43\n",
       "agree       30\n",
       "disagree    27\n",
       "Name: stance, dtype: int64"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dedup_est_labels.loc[balanced_test_ix][dedup_est_labels.outlet_stance==0].stance.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Inspect sentences manually to filter out problematic cases\n",
    "#list(zip(balanced_test_ix,list(dedup_est_labels.loc[balanced_test_ix].sentence.values),dedup_est_labels.loc[balanced_test_ix].stance.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "problematic = [2006,1797,1331,667,927,177,216,1685,191,826,417,438,412,846,1448,1310,1802,801]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#dedup_est_labels.loc[problematic].sort_values('guid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#mturk_df.loc[mturk_df.guid.isin(dedup_est_labels.loc[problematic].guid.values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neutral     9\n",
       "agree       2\n",
       "disagree    1\n",
       "Name: stance, dtype: int64"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dedup_est_labels.loc[problematic].loc[\n",
    "    dedup_est_labels.loc[problematic].outlet_stance == 0].stance.value_counts()\n",
    "# Need 9 more neutrals, 2 agrees, 1 disagree from R-wing outlets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neutral     3\n",
       "agree       2\n",
       "disagree    1\n",
       "Name: stance, dtype: int64"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dedup_est_labels.loc[problematic].loc[\n",
    "    dedup_est_labels.loc[problematic].outlet_stance == 1].stance.value_counts()\n",
    "# Need 3 more neutrals, 2 agree, and 1 disagree from L-wing outlets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "N_needed_per_outlet_stance = {0: dedup_est_labels.loc[problematic].loc[\n",
    "    dedup_est_labels.loc[problematic].outlet_stance == 0].stance.value_counts(),\n",
    "                             1: dedup_est_labels.loc[problematic].loc[\n",
    "    dedup_est_labels.loc[problematic].outlet_stance == 1].stance.value_counts()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N_needed_per_outlet_stance[0]['neutral']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anti agree (281, 12)\n",
      "anti neutral (404, 12)\n",
      "anti disagree (253, 12)\n",
      "pro agree (416, 12)\n",
      "pro neutral (383, 12)\n",
      "pro disagree (105, 12)\n"
     ]
    }
   ],
   "source": [
    "new_indices_per_outlet_stance = defaultdict(dict)\n",
    "for outlet_stance in [0,1]:\n",
    "    for stance in ['agree','neutral','disagree']:\n",
    "        sub_df = dedup_est_labels.loc[(dedup_est_labels.stance == stance) & \n",
    "                                     (dedup_est_labels.outlet_stance == outlet_stance) &\n",
    "                                     (~dedup_est_labels.index.isin(\n",
    "                                         indices_per_outlet_stance[outlet_stance][stance]))]\n",
    "        str_outlet_stance = 'pro' if outlet_stance == 1 else 'anti'\n",
    "        print(str_outlet_stance,stance,sub_df.shape)\n",
    "        new_indices_per_outlet_stance[outlet_stance][stance] = np.random.choice(\n",
    "            sub_df.index,size=N_needed_per_outlet_stance[outlet_stance][stance],replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 agree 2\n",
      "0 neutral 9\n",
      "0 disagree 1\n",
      "1 agree 2\n",
      "1 neutral 3\n",
      "1 disagree 1\n"
     ]
    }
   ],
   "source": [
    "for outlet_stance in [0,1]:\n",
    "    for stance in STANCES:\n",
    "        print(outlet_stance,stance,len(new_indices_per_outlet_stance[outlet_stance][stance]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_balanced_test_ix = []\n",
    "for outlet_stance in new_indices_per_outlet_stance:\n",
    "    for stance in STANCES:\n",
    "        new_balanced_test_ix.extend([x for x in \n",
    "                                 new_indices_per_outlet_stance[outlet_stance][stance] \n",
    "                                if x not in problematic])\n",
    "len(new_balanced_test_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    12\n",
       "1    6 \n",
       "Name: outlet_stance, dtype: int64"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dedup_est_labels.loc[new_balanced_test_ix].outlet_stance.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neutral     9\n",
       "agree       2\n",
       "disagree    1\n",
       "Name: stance, dtype: int64"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dedup_est_labels.loc[new_balanced_test_ix][\n",
    "    dedup_est_labels.loc[new_balanced_test_ix]['outlet_stance'] == 0].stance.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neutral     3\n",
       "agree       2\n",
       "disagree    1\n",
       "Name: stance, dtype: int64"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dedup_est_labels.loc[new_balanced_test_ix][\n",
    "    dedup_est_labels.loc[new_balanced_test_ix]['outlet_stance'] == 1].stance.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Re-nspect sentences manually to filter out problematic cases\n",
    "#list(zip(new_balanced_test_ix,list(dedup_est_labels.loc[new_balanced_test_ix].sentence.values),dedup_est_labels.loc[new_balanced_test_ix].stance.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "problematic_2 = [158,677,1165,1547]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Add everything that's not problematic to base list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "196"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_problematic_balanced_test_ix = []\n",
    "for outlet_stance in indices_per_outlet_stance:\n",
    "    for stance in STANCES:\n",
    "        non_problematic_balanced_test_ix.extend([x for x in indices_per_outlet_stance[outlet_stance][stance]\n",
    "                                if x not in problematic])\n",
    "        non_problematic_balanced_test_ix.extend([x for x in new_indices_per_outlet_stance[outlet_stance][stance]\n",
    "                                if x not in problematic_2])\n",
    "len(non_problematic_balanced_test_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    100\n",
       "0    96 \n",
       "Name: outlet_stance, dtype: int64"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dedup_est_labels.loc[non_problematic_balanced_test_ix].outlet_stance.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neutral     39\n",
       "agree       30\n",
       "disagree    27\n",
       "Name: stance, dtype: int64"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dedup_est_labels.loc[non_problematic_balanced_test_ix][\n",
    "    dedup_est_labels.loc[non_problematic_balanced_test_ix].outlet_stance == 0\n",
    "].stance.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "agree       46\n",
       "neutral     42\n",
       "disagree    12\n",
       "Name: stance, dtype: int64"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dedup_est_labels.loc[non_problematic_balanced_test_ix][\n",
    "    dedup_est_labels.loc[non_problematic_balanced_test_ix].outlet_stance == 1\n",
    "].stance.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neutral    4\n",
       "Name: stance, dtype: int64"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dedup_est_labels.loc[problematic_2].loc[\n",
    "    dedup_est_labels.loc[problematic_2].outlet_stance == 0].stance.value_counts()\n",
    "# Need 4 more neutrals from R-wing outlets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: stance, dtype: int64)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dedup_est_labels.loc[problematic_2].loc[\n",
    "    dedup_est_labels.loc[problematic_2].outlet_stance == 1].stance.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "new_N_needed_per_outlet_stance = {0: {\n",
    "    \"agree\": 0, \"disagree\": 0, \"neutral\": 4\n",
    "},\n",
    "                             1: {\n",
    "                                 \"agree\": 0, \"disagree\": 0, \"neutral\": 0\n",
    "                             }}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anti agree (279, 12)\n",
      "anti neutral (395, 12)\n",
      "anti disagree (252, 12)\n",
      "pro agree (414, 12)\n",
      "pro neutral (380, 12)\n",
      "pro disagree (104, 12)\n"
     ]
    }
   ],
   "source": [
    "# New random sample to bring up numbers\n",
    "new_indices_per_outlet_stance_2 = defaultdict(dict)\n",
    "for outlet_stance in [0,1]:\n",
    "    for stance in ['agree','neutral','disagree']:\n",
    "        sub_df = dedup_est_labels.loc[(dedup_est_labels.stance == stance) & \n",
    "                                     (dedup_est_labels.outlet_stance == outlet_stance) &\n",
    "                                     (~dedup_est_labels.index.isin(\n",
    "                                         indices_per_outlet_stance[outlet_stance][stance])) & \n",
    "                                     (~dedup_est_labels.index.isin(\n",
    "                                     new_indices_per_outlet_stance[outlet_stance][stance]))]\n",
    "        str_outlet_stance = 'pro' if outlet_stance == 1 else 'anti'\n",
    "        print(str_outlet_stance,stance,sub_df.shape)\n",
    "        new_indices_per_outlet_stance_2[outlet_stance][stance] = np.random.choice(\n",
    "            sub_df.index,size=new_N_needed_per_outlet_stance[outlet_stance][stance],\n",
    "            replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 agree 0\n",
      "0 neutral 4\n",
      "0 disagree 0\n",
      "1 agree 0\n",
      "1 neutral 0\n",
      "1 disagree 0\n"
     ]
    }
   ],
   "source": [
    "for outlet_stance in new_indices_per_outlet_stance_2:\n",
    "    for stance in STANCES:\n",
    "        print(outlet_stance,stance,len(new_indices_per_outlet_stance_2[outlet_stance][stance]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_test_ix_2 = []\n",
    "for outlet_stance in new_indices_per_outlet_stance_2:\n",
    "    for stance in STANCES:\n",
    "        balanced_test_ix_2.extend(new_indices_per_outlet_stance_2[outlet_stance][stance])\n",
    "len(balanced_test_ix_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1708,\n",
       "  \"But if we ground every plane, leveled every building in America, and lived in huts, the United States' amount of carbon emissions only accounts for 15 percent of the entire world.\",\n",
       "  'neutral'),\n",
       " (1194, 'People would never accept carbon rationing.', 'neutral'),\n",
       " (1977,\n",
       "  '224 of the 386 \"climate change contrarians\" quoted by the media have at least one publication in peer-reviewed scientific journals.',\n",
       "  'neutral'),\n",
       " (862,\n",
       "  'The fossil fuel industry may be emitting twice as much methane as previously thought.',\n",
       "  'neutral')]"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect sentences manually to filter out problematic cases\n",
    "list(zip(balanced_test_ix_2,\n",
    "         list(dedup_est_labels.loc[balanced_test_ix_2].sentence.values),\n",
    "         dedup_est_labels.loc[balanced_test_ix_2].stance.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "problematic_3 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "203"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for outlet_stance in indices_per_outlet_stance:\n",
    "    for stance in STANCES:\n",
    "        non_problematic_balanced_test_ix.extend([x for x in new_indices_per_outlet_stance_2[outlet_stance][stance]\n",
    "                                if x not in problematic_3])\n",
    "len(non_problematic_balanced_test_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "non_problematic_balanced_test_ix = np.unique(non_problematic_balanced_test_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    100\n",
       "0    100\n",
       "Name: outlet_stance, dtype: int64"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dedup_est_labels.loc[non_problematic_balanced_test_ix].outlet_stance.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neutral     43\n",
       "agree       30\n",
       "disagree    27\n",
       "Name: stance, dtype: int64"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dedup_est_labels.loc[non_problematic_balanced_test_ix][\n",
    "    dedup_est_labels.loc[non_problematic_balanced_test_ix].outlet_stance == 0\n",
    "].stance.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "agree       46\n",
       "neutral     42\n",
       "disagree    12\n",
       "Name: stance, dtype: int64"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dedup_est_labels.loc[non_problematic_balanced_test_ix][\n",
    "    dedup_est_labels.loc[non_problematic_balanced_test_ix].outlet_stance == 1\n",
    "].stance.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dedup_est_labels.loc[non_problematic_balanced_test_ix].to_pickle('./save/held_out_balanced_test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dedup_est_labels.loc[non_problematic_balanced_test_ix].to_csv('./save/held_out_balanced_test.tsv',\n",
    "                                                             sep='\\t',header=True,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## All SemEval tweets as eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "semeval_df['nli_label'] = semeval_df['stance'].apply(lambda x: stance2nli[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "os.mkdir('./save/semeval_test')\n",
    "semeval_df[['Tweet','stance','nli_label']].to_csv('./save/semeval_test'+'/test.tsv',sep='\\t',header=None,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## SemEval as train, dev, and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(394, 76, 94)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "semeval_df['nli_label'] = semeval_df['stance'].apply(lambda x: stance2nli[x])\n",
    "semeval_df['sentence'] = semeval_df['Tweet']\n",
    "train_ix,eval_ix = train_test_split(list(semeval_df.index),test_size=0.3,random_state=42)\n",
    "dev_ix,test_ix = train_test_split(eval_ix,test_size=0.55,random_state=42)\n",
    "len(train_ix),len(dev_ix),len(test_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((394, 5), (76, 5), (94, 5))"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = semeval_df.loc[semeval_df.index.isin(train_ix)]\n",
    "dev_df = semeval_df.loc[semeval_df.index.isin(dev_ix)]\n",
    "test_df = semeval_df.loc[semeval_df.index.isin(test_ix)]\n",
    "train_df.shape,dev_df.shape,test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#write_data('semeval_train_eval',42,[],train_df,test_df,dev_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-val splits (test on item-response est. label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1842"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "order = np.arange(len(mturk_df))\n",
    "np.random.shuffle(order)\n",
    "len(order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1842 1842 185 185 1472\n",
      "1842 1842 185 185 1472\n",
      "1842 1842 184 184 1474\n",
      "1842 1842 184 184 1474\n",
      "1842 1842 184 184 1474\n",
      "1842 1842 184 184 1474\n",
      "1842 1842 184 184 1474\n",
      "1842 1842 184 184 1474\n",
      "1842 1842 184 184 1474\n",
      "1842 1842 184 184 1474\n"
     ]
    }
   ],
   "source": [
    "indices_per_fold = {}\n",
    "n_folds = 10\n",
    "for f in range(n_folds):\n",
    "    test_indices = [order[i] for i in np.arange(len(mturk_df)) if i % n_folds == f]\n",
    "    nontest_indices = list(set(np.arange(len(mturk_df))) - set(test_indices))\n",
    "    dev_indices = list(np.random.choice(nontest_indices, size=len(test_indices), replace=False))\n",
    "    train_indices = list(set(nontest_indices) - set(dev_indices))\n",
    "    all_indices = set(test_indices).union(set(dev_indices)).union(set(train_indices))\n",
    "    indices_per_fold[f] = {'train':train_indices,'dev':dev_indices,'test':test_indices}\n",
    "    print(len(all_indices), len(test_indices) + len(dev_indices) + len(train_indices), len(test_indices), len(dev_indices), len(train_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(indices_per_fold,open('cross_val_10_seed_42_indices.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_per_fold = pickle.load(open('cross_val_10_seed_42_indices.pkl','rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Title-augmented train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 728,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for f in range(n_folds):\n",
    "#     fold_ix = indices_per_fold[f]\n",
    "#     train_ix = fold_ix['train']\n",
    "#     test_ix = fold_ix['test']\n",
    "#     dev_ix = fold_ix['dev']\n",
    "    \n",
    "#     train_df = mturk_df.loc[mturk_df.index.isin(train_ix)]\n",
    "#     dev_df = mturk_df.loc[mturk_df.index.isin(dev_ix)]\n",
    "#     test_df = mturk_df.loc[mturk_df.index.isin(test_ix)]\n",
    "#     print(train_df.shape,dev_df.shape,test_df.shape)\n",
    "#     write_data('all_mturk_with_titles_train_{}_fold_{}'.format(42,f),[],train_df,test_df,dev_df,\n",
    "#            add_titles=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Oops, accidentally re-wrote with vanilla (non-title-augmented) data splits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vanilla MTurk (est. labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=1842, step=1)"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dedup_est_labels.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1472, 11) (185, 11) (185, 11)\n",
      "Train/test text overlap: set()\n",
      "Train/dev text overlap: set()\n",
      "all_mturk_train_42_weights\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:44: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train distribution:\n",
      "disagree    1472\n",
      "agree       1472\n",
      "neutral     1472\n",
      "Name: stance, dtype: int64\n",
      "contradiction    1472\n",
      "neutral          1472\n",
      "entailment       1472\n",
      "Name: nli_label, dtype: int64\n",
      "\n",
      "Dev distribution:\n",
      "neutral     83\n",
      "agree       64\n",
      "disagree    38\n",
      "Name: stance, dtype: int64\n",
      "neutral          83\n",
      "entailment       64\n",
      "contradiction    38\n",
      "Name: nli_label, dtype: int64\n",
      "\n",
      "Test distribution:\n",
      "neutral     85\n",
      "agree       75\n",
      "disagree    25\n",
      "Name: stance, dtype: int64\n",
      "neutral     0.459459\n",
      "agree       0.405405\n",
      "disagree    0.135135\n",
      "Name: stance, dtype: float64\n",
      "neutral          85\n",
      "entailment       75\n",
      "contradiction    25\n",
      "Name: nli_label, dtype: int64\n",
      "Writing to save_dir: new_save/all_mturk_train_42_weights/folds/0\n",
      "(1472, 11) (185, 11) (185, 11)\n",
      "Train/test text overlap: set()\n",
      "Train/dev text overlap: set()\n",
      "all_mturk_train_42_weights\n",
      "Train distribution:\n",
      "disagree    1472\n",
      "agree       1472\n",
      "neutral     1472\n",
      "Name: stance, dtype: int64\n",
      "contradiction    1472\n",
      "neutral          1472\n",
      "entailment       1472\n",
      "Name: nli_label, dtype: int64\n",
      "\n",
      "Dev distribution:\n",
      "neutral     85\n",
      "agree       68\n",
      "disagree    32\n",
      "Name: stance, dtype: int64\n",
      "neutral          85\n",
      "entailment       68\n",
      "contradiction    32\n",
      "Name: nli_label, dtype: int64\n",
      "\n",
      "Test distribution:\n",
      "neutral     85\n",
      "agree       64\n",
      "disagree    36\n",
      "Name: stance, dtype: int64\n",
      "neutral     0.459459\n",
      "agree       0.345946\n",
      "disagree    0.194595\n",
      "Name: stance, dtype: float64\n",
      "neutral          85\n",
      "entailment       64\n",
      "contradiction    36\n",
      "Name: nli_label, dtype: int64\n",
      "Writing to save_dir: new_save/all_mturk_train_42_weights/folds/1\n",
      "(1474, 11) (184, 11) (184, 11)\n",
      "Train/test text overlap: set()\n",
      "Train/dev text overlap: set()\n",
      "all_mturk_train_42_weights\n",
      "Train distribution:\n",
      "disagree    1474\n",
      "agree       1474\n",
      "neutral     1474\n",
      "Name: stance, dtype: int64\n",
      "contradiction    1474\n",
      "neutral          1474\n",
      "entailment       1474\n",
      "Name: nli_label, dtype: int64\n",
      "\n",
      "Dev distribution:\n",
      "neutral     74\n",
      "agree       74\n",
      "disagree    36\n",
      "Name: stance, dtype: int64\n",
      "neutral          74\n",
      "entailment       74\n",
      "contradiction    36\n",
      "Name: nli_label, dtype: int64\n",
      "\n",
      "Test distribution:\n",
      "agree       76\n",
      "neutral     67\n",
      "disagree    41\n",
      "Name: stance, dtype: int64\n",
      "agree       0.413043\n",
      "neutral     0.364130\n",
      "disagree    0.222826\n",
      "Name: stance, dtype: float64\n",
      "entailment       76\n",
      "neutral          67\n",
      "contradiction    41\n",
      "Name: nli_label, dtype: int64\n",
      "Writing to save_dir: new_save/all_mturk_train_42_weights/folds/2\n",
      "(1474, 11) (184, 11) (184, 11)\n",
      "Train/test text overlap: set()\n",
      "Train/dev text overlap: set()\n",
      "all_mturk_train_42_weights\n",
      "Train distribution:\n",
      "disagree    1474\n",
      "agree       1474\n",
      "neutral     1474\n",
      "Name: stance, dtype: int64\n",
      "contradiction    1474\n",
      "neutral          1474\n",
      "entailment       1474\n",
      "Name: nli_label, dtype: int64\n",
      "\n",
      "Dev distribution:\n",
      "neutral     83\n",
      "agree       64\n",
      "disagree    37\n",
      "Name: stance, dtype: int64\n",
      "neutral          83\n",
      "entailment       64\n",
      "contradiction    37\n",
      "Name: nli_label, dtype: int64\n",
      "\n",
      "Test distribution:\n",
      "neutral     85\n",
      "agree       71\n",
      "disagree    28\n",
      "Name: stance, dtype: int64\n",
      "neutral     0.461957\n",
      "agree       0.385870\n",
      "disagree    0.152174\n",
      "Name: stance, dtype: float64\n",
      "neutral          85\n",
      "entailment       71\n",
      "contradiction    28\n",
      "Name: nli_label, dtype: int64\n",
      "Writing to save_dir: new_save/all_mturk_train_42_weights/folds/3\n",
      "(1474, 11) (184, 11) (184, 11)\n",
      "Train/test text overlap: set()\n",
      "Train/dev text overlap: set()\n",
      "all_mturk_train_42_weights\n",
      "Train distribution:\n",
      "disagree    1474\n",
      "agree       1474\n",
      "neutral     1474\n",
      "Name: stance, dtype: int64\n",
      "contradiction    1474\n",
      "neutral          1474\n",
      "entailment       1474\n",
      "Name: nli_label, dtype: int64\n",
      "\n",
      "Dev distribution:\n",
      "neutral     81\n",
      "agree       74\n",
      "disagree    29\n",
      "Name: stance, dtype: int64\n",
      "neutral          81\n",
      "entailment       74\n",
      "contradiction    29\n",
      "Name: nli_label, dtype: int64\n",
      "\n",
      "Test distribution:\n",
      "neutral     71\n",
      "agree       61\n",
      "disagree    52\n",
      "Name: stance, dtype: int64\n",
      "neutral     0.385870\n",
      "agree       0.331522\n",
      "disagree    0.282609\n",
      "Name: stance, dtype: float64\n",
      "neutral          71\n",
      "entailment       61\n",
      "contradiction    52\n",
      "Name: nli_label, dtype: int64\n",
      "Writing to save_dir: new_save/all_mturk_train_42_weights/folds/4\n",
      "(1474, 11) (184, 11) (184, 11)\n",
      "Train/test text overlap: set()\n",
      "Train/dev text overlap: set()\n",
      "all_mturk_train_42_weights\n",
      "Train distribution:\n",
      "disagree    1474\n",
      "agree       1474\n",
      "neutral     1474\n",
      "Name: stance, dtype: int64\n",
      "contradiction    1474\n",
      "neutral          1474\n",
      "entailment       1474\n",
      "Name: nli_label, dtype: int64\n",
      "\n",
      "Dev distribution:\n",
      "neutral     77\n",
      "agree       70\n",
      "disagree    37\n",
      "Name: stance, dtype: int64\n",
      "neutral          77\n",
      "entailment       70\n",
      "contradiction    37\n",
      "Name: nli_label, dtype: int64\n",
      "\n",
      "Test distribution:\n",
      "neutral     76\n",
      "agree       73\n",
      "disagree    35\n",
      "Name: stance, dtype: int64\n",
      "neutral     0.413043\n",
      "agree       0.396739\n",
      "disagree    0.190217\n",
      "Name: stance, dtype: float64\n",
      "neutral          76\n",
      "entailment       73\n",
      "contradiction    35\n",
      "Name: nli_label, dtype: int64\n",
      "Writing to save_dir: new_save/all_mturk_train_42_weights/folds/5\n",
      "(1474, 11) (184, 11) (184, 11)\n",
      "Train/test text overlap: set()\n",
      "Train/dev text overlap: set()\n",
      "all_mturk_train_42_weights\n",
      "Train distribution:\n",
      "disagree    1474\n",
      "agree       1474\n",
      "neutral     1474\n",
      "Name: stance, dtype: int64\n",
      "contradiction    1474\n",
      "neutral          1474\n",
      "entailment       1474\n",
      "Name: nli_label, dtype: int64\n",
      "\n",
      "Dev distribution:\n",
      "neutral     85\n",
      "agree       70\n",
      "disagree    29\n",
      "Name: stance, dtype: int64\n",
      "neutral          85\n",
      "entailment       70\n",
      "contradiction    29\n",
      "Name: nli_label, dtype: int64\n",
      "\n",
      "Test distribution:\n",
      "agree       72\n",
      "neutral     71\n",
      "disagree    41\n",
      "Name: stance, dtype: int64\n",
      "agree       0.391304\n",
      "neutral     0.385870\n",
      "disagree    0.222826\n",
      "Name: stance, dtype: float64\n",
      "entailment       72\n",
      "neutral          71\n",
      "contradiction    41\n",
      "Name: nli_label, dtype: int64\n",
      "Writing to save_dir: new_save/all_mturk_train_42_weights/folds/6\n",
      "(1474, 11) (184, 11) (184, 11)\n",
      "Train/test text overlap: set()\n",
      "Train/dev text overlap: set()\n",
      "all_mturk_train_42_weights\n",
      "Train distribution:\n",
      "disagree    1474\n",
      "agree       1474\n",
      "neutral     1474\n",
      "Name: stance, dtype: int64\n",
      "contradiction    1474\n",
      "neutral          1474\n",
      "entailment       1474\n",
      "Name: nli_label, dtype: int64\n",
      "\n",
      "Dev distribution:\n",
      "neutral     86\n",
      "agree       69\n",
      "disagree    29\n",
      "Name: stance, dtype: int64\n",
      "neutral          86\n",
      "entailment       69\n",
      "contradiction    29\n",
      "Name: nli_label, dtype: int64\n",
      "\n",
      "Test distribution:\n",
      "neutral     81\n",
      "agree       67\n",
      "disagree    36\n",
      "Name: stance, dtype: int64\n",
      "neutral     0.440217\n",
      "agree       0.364130\n",
      "disagree    0.195652\n",
      "Name: stance, dtype: float64\n",
      "neutral          81\n",
      "entailment       67\n",
      "contradiction    36\n",
      "Name: nli_label, dtype: int64\n",
      "Writing to save_dir: new_save/all_mturk_train_42_weights/folds/7\n",
      "(1474, 11) (184, 11) (184, 11)\n",
      "Train/test text overlap: set()\n",
      "Train/dev text overlap: set()\n",
      "all_mturk_train_42_weights\n",
      "Train distribution:\n",
      "disagree    1474\n",
      "agree       1474\n",
      "neutral     1474\n",
      "Name: stance, dtype: int64\n",
      "contradiction    1474\n",
      "neutral          1474\n",
      "entailment       1474\n",
      "Name: nli_label, dtype: int64\n",
      "\n",
      "Dev distribution:\n",
      "neutral     82\n",
      "agree       81\n",
      "disagree    21\n",
      "Name: stance, dtype: int64\n",
      "neutral          82\n",
      "entailment       81\n",
      "contradiction    21\n",
      "Name: nli_label, dtype: int64\n",
      "\n",
      "Test distribution:\n",
      "neutral     84\n",
      "agree       74\n",
      "disagree    26\n",
      "Name: stance, dtype: int64\n",
      "neutral     0.456522\n",
      "agree       0.402174\n",
      "disagree    0.141304\n",
      "Name: stance, dtype: float64\n",
      "neutral          84\n",
      "entailment       74\n",
      "contradiction    26\n",
      "Name: nli_label, dtype: int64\n",
      "Writing to save_dir: new_save/all_mturk_train_42_weights/folds/8\n",
      "(1474, 11) (184, 11) (184, 11)\n",
      "Train/test text overlap: set()\n",
      "Train/dev text overlap: set()\n",
      "all_mturk_train_42_weights\n",
      "Train distribution:\n",
      "disagree    1474\n",
      "agree       1474\n",
      "neutral     1474\n",
      "Name: stance, dtype: int64\n",
      "contradiction    1474\n",
      "neutral          1474\n",
      "entailment       1474\n",
      "Name: nli_label, dtype: int64\n",
      "\n",
      "Dev distribution:\n",
      "agree       78\n",
      "neutral     66\n",
      "disagree    40\n",
      "Name: stance, dtype: int64\n",
      "entailment       78\n",
      "neutral          66\n",
      "contradiction    40\n",
      "Name: nli_label, dtype: int64\n",
      "\n",
      "Test distribution:\n",
      "neutral     82\n",
      "agree       64\n",
      "disagree    38\n",
      "Name: stance, dtype: int64\n",
      "neutral     0.445652\n",
      "agree       0.347826\n",
      "disagree    0.206522\n",
      "Name: stance, dtype: float64\n",
      "neutral          82\n",
      "entailment       64\n",
      "contradiction    38\n",
      "Name: nli_label, dtype: int64\n",
      "Writing to save_dir: new_save/all_mturk_train_42_weights/folds/9\n"
     ]
    }
   ],
   "source": [
    "for f in range(0,n_folds):\n",
    "    fold_0_ix = indices_per_fold[f]\n",
    "    train_ix = fold_0_ix['train']\n",
    "    test_ix = fold_0_ix['test']\n",
    "    dev_ix = fold_0_ix['dev']\n",
    "\n",
    "    train_df = dedup_est_labels.loc[dedup_est_labels.index.isin(train_ix)]\n",
    "    dev_df = dedup_est_labels.loc[dedup_est_labels.index.isin(dev_ix)]\n",
    "    test_df = dedup_est_labels.loc[dedup_est_labels.index.isin(test_ix)]\n",
    "    print(train_df.shape,dev_df.shape,test_df.shape)\n",
    "    write_data('all_mturk_train_{}'.format(seed),f,train_df,test_df,dev_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 746,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    635\n",
       "0    568\n",
       "2    267\n",
       "Name: 1, dtype: int64"
      ]
     },
     "execution_count": 746,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('./save/all_mturk_train_42_fold_0/train.tsv',sep='\\t',header=None)[1].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 750,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1270\n",
       "0    1136\n",
       "2    534 \n",
       "Name: 1, dtype: int64"
      ]
     },
     "execution_count": 750,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('./save/all_mturk_train_backtrans_fr_42_fold_0/train.tsv',sep='\\t',header=None)[1].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 751,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    635\n",
       "0    568\n",
       "2    534\n",
       "Name: 1, dtype: int64"
      ]
     },
     "execution_count": 751,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('./save/all_mturk_train_backtrans_fr_upsampled_42_fold_0/train.tsv',sep='\\t',\n",
    "            header=None)[1].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1961"
      ]
     },
     "execution_count": 410,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "677+658+626"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 752,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    534\n",
       "1    534\n",
       "0    534\n",
       "Name: 1, dtype: int64"
      ]
     },
     "execution_count": 752,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('./save/all_mturk_train_backtrans_fr_42_fold_0_downsampled/train.tsv',sep='\\t',\n",
    "            header=None)[1].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Back translation augmented train, with and without downsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#Add backtranslations of the train_ix examples to training\n",
    "# for f in range(n_folds):\n",
    "#     fold_0_ix = indices_per_fold[f]\n",
    "#     train_ix = fold_0_ix['train']\n",
    "#     test_ix = fold_0_ix['test']\n",
    "#     dev_ix = fold_0_ix['dev']\n",
    "\n",
    "#     train_df = dedup_est_labels.loc[dedup_est_labels.index.isin(train_ix)]\n",
    "#     dev_df = dedup_est_labels.loc[dedup_est_labels.index.isin(dev_ix)]\n",
    "#     test_df = dedup_est_labels.loc[dedup_est_labels.index.isin(test_ix)]\n",
    "#     backtrans_fr_df = add_backtrans_train(train_df,'fr')\n",
    "#     backtrans_zh_df = add_backtrans_train(train_df,'zh')\n",
    "#     backtrans_both_df = backtrans_fr_df.append(backtrans_zh_df,ignore_index=True).drop_duplicates('guid',keep='first')\n",
    "#     print(backtrans_fr_df.shape,backtrans_zh_df.shape,backtrans_both_df.shape,dev_df.shape,test_df.shape)\n",
    "#     write_data('all_mturk_train_backtrans_fr_{}_fold_{}'.format(seed,f),[],backtrans_fr_df,test_df,dev_df)\n",
    "#     write_data('all_mturk_train_backtrans_zh_{}_fold_{}'.format(seed,f),[],backtrans_zh_df,test_df,dev_df)\n",
    "#     write_data('all_mturk_train_backtrans_both_{}_fold_{}'.format(seed,f),[],backtrans_both_df,test_df,dev_df)\n",
    "#     write_data('all_mturk_train_backtrans_fr_{}_fold_{}'.format(seed,f),[],backtrans_fr_df,test_df,dev_df,do_downsample=True)\n",
    "#     write_data('all_mturk_train_backtrans_zh_{}_fold_{}'.format(seed,f),[],backtrans_zh_df,test_df,dev_df,do_downsample=True)\n",
    "#     write_data('all_mturk_train_backtrans_both_{}_fold_{}'.format(seed,f),[],backtrans_both_df,test_df,dev_df,do_downsample=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Back translation + upsample minority class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# for f in range(n_folds):\n",
    "#     fold_0_ix = indices_per_fold[f]\n",
    "#     train_ix = fold_0_ix['train']\n",
    "#     test_ix = fold_0_ix['test']\n",
    "#     dev_ix = fold_0_ix['dev']\n",
    "\n",
    "#     train_df = dedup_est_labels.loc[dedup_est_labels.index.isin(train_ix)]\n",
    "#     dev_df = dedup_est_labels.loc[dedup_est_labels.index.isin(dev_ix)]\n",
    "#     test_df = dedup_est_labels.loc[dedup_est_labels.index.isin(test_ix)]\n",
    "#     backtrans_fr_df = add_backtrans_train(train_df,'fr',upsample=True)\n",
    "#     backtrans_zh_df = add_backtrans_train(train_df,'zh',upsample=True)\n",
    "#     backtrans_both_df = backtrans_fr_df.append(backtrans_zh_df,ignore_index=True).drop_duplicates('guid',keep='first')\n",
    "#     print(backtrans_fr_df.shape,backtrans_zh_df.shape,backtrans_both_df.shape,dev_df.shape,test_df.shape)\n",
    "#     write_data('all_mturk_train_backtrans_fr_upsampled_{}_fold_{}'.format(seed,f),[],backtrans_fr_df,test_df,dev_df)\n",
    "#     write_data('all_mturk_train_backtrans_zh_upsampled_{}_fold_{}'.format(seed,f),[],backtrans_zh_df,test_df,dev_df)\n",
    "#     write_data('all_mturk_train_backtrans_both_upsampled_{}_fold_{}'.format(seed,f),[],backtrans_both_df,test_df,dev_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### High IAA train, eval on rest (splits differ only in dev/test distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_indices = mturk_df.loc[mturk_df.is_high_iaa].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "code_folding": [
     2
    ],
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "923 2042 462 461 1119\n",
      "923 2042 462 461 1119\n",
      "923 2042 462 461 1119\n",
      "923 2042 462 461 1119\n",
      "923 2042 462 461 1119\n",
      "923 2042 462 461 1119\n",
      "923 2042 462 461 1119\n",
      "923 2042 462 461 1119\n",
      "923 2042 462 461 1119\n",
      "923 2042 462 461 1119\n"
     ]
    }
   ],
   "source": [
    "indices_per_fold = {}\n",
    "n_folds = 10\n",
    "for f in range(n_folds):\n",
    "    all_indices = list(low_iaa_df.index)\n",
    "    test_indices = list(np.random.choice(all_indices, size=round(len(all_indices)/2), replace=False))\n",
    "    dev_indices = list(set(all_indices) - set(test_indices))\n",
    "    all_indices = set(test_indices).union(set(dev_indices))#.union(set(train_indices))\n",
    "    indices_per_fold[f] = {'train':train_indices,'dev':dev_indices,'test':test_indices}\n",
    "    print(len(all_indices), len(test_indices) + len(dev_indices) + len(train_indices), len(test_indices), len(dev_indices), len(train_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(indices_per_fold,open('high_iaa_cross_val_10_seed_42_high_iaa_indices.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# for f in range(0,n_folds):\n",
    "#     fold_0_ix = indices_per_fold[f]\n",
    "#     train_ix = fold_0_ix['train']\n",
    "#     test_ix = fold_0_ix['test']\n",
    "#     dev_ix = fold_0_ix['dev']\n",
    "\n",
    "#     train_df = mturk_df.loc[mturk_df.index.isin(train_ix)]\n",
    "#     dev_df = mturk_df.loc[mturk_df.index.isin(dev_ix)]\n",
    "#     test_df = mturk_df.loc[mturk_df.index.isin(test_ix)]\n",
    "#     print(train_df.shape,dev_df.shape,test_df.shape)\n",
    "#     write_data('high_iaa_train_fold_{}'.format(f),42,[],train_df,test_df,dev_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Augment w/ back translations, with and without downsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# for f in range(n_folds):\n",
    "#     fold_0_ix = indices_per_fold[f]\n",
    "#     train_ix = fold_0_ix['train']\n",
    "#     test_ix = fold_0_ix['test']\n",
    "#     dev_ix = fold_0_ix['dev']\n",
    "\n",
    "#     train_df = mturk_df.loc[mturk_df.index.isin(train_ix)]\n",
    "#     dev_df = mturk_df.loc[mturk_df.index.isin(dev_ix)]\n",
    "#     test_df = mturk_df.loc[mturk_df.index.isin(test_ix)]\n",
    "#     print(train_df.shape,dev_df.shape,test_df.shape)\n",
    "#     backtrans_fr_df = add_backtrans_train(train_df,'fr')\n",
    "#     backtrans_zh_df = add_backtrans_train(train_df,'zh')\n",
    "#     backtrans_both_df = backtrans_fr_df.append(backtrans_zh_df,ignore_index=True).drop_duplicates('guid',keep='first')\n",
    "#     print(backtrans_fr_df.shape,backtrans_zh_df.shape,backtrans_both_df.shape,dev_df.shape,test_df.shape)\n",
    "#     write_data('high_iaa_train_fold_{}'.format(f),seed,['backtrans_fr'],backtrans_fr_df,test_df,dev_df)\n",
    "#     write_data('high_iaa_train_fold_{}'.format(f),seed,['backtrans_zh'],backtrans_zh_df,test_df,dev_df)\n",
    "#     write_data('high_iaa_train_fold_{}'.format(f),seed,['backtrans_both'],backtrans_both_df,test_df,dev_df)\n",
    "#     write_data('high_iaa_train_fold_{}'.format(f),seed,['backtrans_fr'],backtrans_fr_df,test_df,dev_df,do_downsample=True)\n",
    "#     write_data('high_iaa_train_fold_{}'.format(f),seed,['backtrans_zh'],backtrans_zh_df,test_df,dev_df,do_downsample=True)\n",
    "#     write_data('high_iaa_train_fold_{}'.format(f),seed,['backtrans_both'],backtrans_both_df,test_df,dev_df,do_downsample=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Back translation + upsample minority class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# for f in range(n_folds):\n",
    "#     fold_0_ix = indices_per_fold[f]\n",
    "#     train_ix = fold_0_ix['train']\n",
    "#     test_ix = fold_0_ix['test']\n",
    "#     dev_ix = fold_0_ix['dev']\n",
    "\n",
    "#     train_df = mturk_df.loc[mturk_df.index.isin(train_ix)]\n",
    "#     dev_df = mturk_df.loc[mturk_df.index.isin(dev_ix)]\n",
    "#     test_df = mturk_df.loc[mturk_df.index.isin(test_ix)]\n",
    "#     print(train_df.shape,dev_df.shape,test_df.shape)\n",
    "#     backtrans_fr_df = add_backtrans_train(train_df,'fr',upsample=True)\n",
    "#     backtrans_zh_df = add_backtrans_train(train_df,'zh',upsample=True)\n",
    "#     backtrans_both_df = backtrans_fr_df.append(backtrans_zh_df,ignore_index=True).drop_duplicates('guid',keep='first')\n",
    "#     print(backtrans_fr_df.shape,backtrans_zh_df.shape,backtrans_both_df.shape,dev_df.shape,test_df.shape)\n",
    "#     write_data('high_iaa_train_fold_{}'.format(f),seed,['backtrans_fr_upsampled'],backtrans_fr_df,test_df,dev_df)\n",
    "#     write_data('high_iaa_train_fold_{}'.format(f),seed,['backtrans_zh_upsampled'],backtrans_zh_df,test_df,dev_df)\n",
    "#     write_data('high_iaa_train_fold_{}'.format(f),seed,['backtrans_both_upsampled'],backtrans_both_df,test_df,dev_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SCP to cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "from paramiko import SSHClient\n",
    "from scp import SCPClient\n",
    "\n",
    "ssh = SSHClient()\n",
    "ssh.load_system_host_keys()\n",
    "ssh.connect(hostname='jacob.stanford.edu',username='yiweil',password='yldwuaeo2699zhishao15')\n",
    "\n",
    "# Define progress callback that prints the current percentage completed for the file\n",
    "def progress(filename, size, sent):\n",
    "    print(\"%s\\'s progress: %.2f%%   \\r\" % (filename, float(sent)/float(size)*100) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_data_type = 'all_mturk_train_42_weights'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_data_dir = os.path.join('/u/scr/yiweil/sci_debates/cc_stance/climate_data/climate-weight',\n",
    "                                local_data_type,'folds')\n",
    "local_data_base_dir = './new_save'\n",
    "\n",
    "# SCPCLient takes a paramiko transport and progress callback as its arguments.\n",
    "scp = SCPClient(ssh.get_transport(), progress=progress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./new_save/all_mturk_train_42_weights/folds/0',\n",
       " './new_save/all_mturk_train_42_weights/folds/1',\n",
       " './new_save/all_mturk_train_42_weights/folds/2',\n",
       " './new_save/all_mturk_train_42_weights/folds/3',\n",
       " './new_save/all_mturk_train_42_weights/folds/4',\n",
       " './new_save/all_mturk_train_42_weights/folds/5',\n",
       " './new_save/all_mturk_train_42_weights/folds/6',\n",
       " './new_save/all_mturk_train_42_weights/folds/7',\n",
       " './new_save/all_mturk_train_42_weights/folds/8',\n",
       " './new_save/all_mturk_train_42_weights/folds/9']"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glob.glob(os.path.join(local_data_base_dir,local_data_type,'folds/*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'dev.tsv''s progress: 0.00%   \n",
      "b'dev.tsv''s progress: 58.18%   \n",
      "b'dev.tsv''s progress: 100.00%   \n",
      "b'test.tsv''s progress: 0.00%   \n",
      "b'test.tsv''s progress: 56.39%   \n",
      "b'test.tsv''s progress: 100.00%   \n",
      "b'train.tsv''s progress: 0.00%   \n",
      "b'train.tsv''s progress: 2.41%   \n",
      "b'train.tsv''s progress: 4.81%   \n",
      "b'train.tsv''s progress: 7.22%   \n",
      "b'train.tsv''s progress: 9.62%   \n",
      "b'train.tsv''s progress: 12.03%   \n",
      "b'train.tsv''s progress: 14.44%   \n",
      "b'train.tsv''s progress: 16.84%   \n",
      "b'train.tsv''s progress: 19.25%   \n",
      "b'train.tsv''s progress: 21.65%   \n",
      "b'train.tsv''s progress: 24.06%   \n",
      "b'train.tsv''s progress: 26.47%   \n",
      "b'train.tsv''s progress: 28.87%   \n",
      "b'train.tsv''s progress: 31.28%   \n",
      "b'train.tsv''s progress: 33.68%   \n",
      "b'train.tsv''s progress: 36.09%   \n",
      "b'train.tsv''s progress: 38.49%   \n",
      "b'train.tsv''s progress: 40.90%   \n",
      "b'train.tsv''s progress: 43.31%   \n",
      "b'train.tsv''s progress: 45.71%   \n",
      "b'train.tsv''s progress: 48.12%   \n",
      "b'train.tsv''s progress: 50.52%   \n",
      "b'train.tsv''s progress: 52.93%   \n",
      "b'train.tsv''s progress: 55.34%   \n",
      "b'train.tsv''s progress: 57.74%   \n",
      "b'train.tsv''s progress: 60.15%   \n",
      "b'train.tsv''s progress: 62.55%   \n",
      "b'train.tsv''s progress: 64.96%   \n",
      "b'train.tsv''s progress: 67.37%   \n",
      "b'train.tsv''s progress: 69.77%   \n",
      "b'train.tsv''s progress: 72.18%   \n",
      "b'train.tsv''s progress: 74.58%   \n",
      "b'train.tsv''s progress: 76.99%   \n",
      "b'train.tsv''s progress: 79.40%   \n",
      "b'train.tsv''s progress: 81.80%   \n",
      "b'train.tsv''s progress: 84.21%   \n",
      "b'train.tsv''s progress: 86.61%   \n",
      "b'train.tsv''s progress: 89.02%   \n",
      "b'train.tsv''s progress: 91.43%   \n",
      "b'train.tsv''s progress: 93.83%   \n",
      "b'train.tsv''s progress: 96.24%   \n",
      "b'train.tsv''s progress: 98.64%   \n",
      "b'train.tsv''s progress: 100.00%   \n",
      "b'dev.tsv''s progress: 0.00%   \n",
      "b'dev.tsv''s progress: 58.02%   \n",
      "b'dev.tsv''s progress: 100.00%   \n",
      "b'test.tsv''s progress: 0.00%   \n",
      "b'test.tsv''s progress: 58.37%   \n",
      "b'test.tsv''s progress: 100.00%   \n",
      "b'train.tsv''s progress: 0.00%   \n",
      "b'train.tsv''s progress: 2.40%   \n",
      "b'train.tsv''s progress: 4.79%   \n",
      "b'train.tsv''s progress: 7.19%   \n",
      "b'train.tsv''s progress: 9.58%   \n",
      "b'train.tsv''s progress: 11.98%   \n",
      "b'train.tsv''s progress: 14.38%   \n",
      "b'train.tsv''s progress: 16.77%   \n",
      "b'train.tsv''s progress: 19.17%   \n",
      "b'train.tsv''s progress: 21.56%   \n",
      "b'train.tsv''s progress: 23.96%   \n",
      "b'train.tsv''s progress: 26.36%   \n",
      "b'train.tsv''s progress: 28.75%   \n",
      "b'train.tsv''s progress: 31.15%   \n",
      "b'train.tsv''s progress: 33.54%   \n",
      "b'train.tsv''s progress: 35.94%   \n",
      "b'train.tsv''s progress: 38.34%   \n",
      "b'train.tsv''s progress: 40.73%   \n",
      "b'train.tsv''s progress: 43.13%   \n",
      "b'train.tsv''s progress: 45.52%   \n",
      "b'train.tsv''s progress: 47.92%   \n",
      "b'train.tsv''s progress: 50.32%   \n",
      "b'train.tsv''s progress: 52.71%   \n",
      "b'train.tsv''s progress: 55.11%   \n",
      "b'train.tsv''s progress: 57.50%   \n",
      "b'train.tsv''s progress: 59.90%   \n",
      "b'train.tsv''s progress: 62.30%   \n",
      "b'train.tsv''s progress: 64.69%   \n",
      "b'train.tsv''s progress: 67.09%   \n",
      "b'train.tsv''s progress: 69.49%   \n",
      "b'train.tsv''s progress: 71.88%   \n",
      "b'train.tsv''s progress: 74.28%   \n",
      "b'train.tsv''s progress: 76.67%   \n",
      "b'train.tsv''s progress: 79.07%   \n",
      "b'train.tsv''s progress: 81.47%   \n",
      "b'train.tsv''s progress: 83.86%   \n",
      "b'train.tsv''s progress: 86.26%   \n",
      "b'train.tsv''s progress: 88.65%   \n",
      "b'train.tsv''s progress: 91.05%   \n",
      "b'train.tsv''s progress: 93.45%   \n",
      "b'train.tsv''s progress: 95.84%   \n",
      "b'train.tsv''s progress: 98.24%   \n",
      "b'train.tsv''s progress: 100.00%   \n",
      "b'dev.tsv''s progress: 0.00%   \n",
      "b'dev.tsv''s progress: 57.36%   \n",
      "b'dev.tsv''s progress: 100.00%   \n",
      "b'test.tsv''s progress: 0.00%   \n",
      "b'test.tsv''s progress: 59.42%   \n",
      "b'test.tsv''s progress: 100.00%   \n",
      "b'train.tsv''s progress: 0.00%   \n",
      "b'train.tsv''s progress: 2.39%   \n",
      "b'train.tsv''s progress: 4.79%   \n",
      "b'train.tsv''s progress: 7.18%   \n",
      "b'train.tsv''s progress: 9.57%   \n",
      "b'train.tsv''s progress: 11.97%   \n",
      "b'train.tsv''s progress: 14.36%   \n",
      "b'train.tsv''s progress: 16.75%   \n",
      "b'train.tsv''s progress: 19.15%   \n",
      "b'train.tsv''s progress: 21.54%   \n",
      "b'train.tsv''s progress: 23.93%   \n",
      "b'train.tsv''s progress: 26.33%   \n",
      "b'train.tsv''s progress: 28.72%   \n",
      "b'train.tsv''s progress: 31.12%   \n",
      "b'train.tsv''s progress: 33.51%   \n",
      "b'train.tsv''s progress: 35.90%   \n",
      "b'train.tsv''s progress: 38.30%   \n",
      "b'train.tsv''s progress: 40.69%   \n",
      "b'train.tsv''s progress: 43.08%   \n",
      "b'train.tsv''s progress: 45.48%   \n",
      "b'train.tsv''s progress: 47.87%   \n",
      "b'train.tsv''s progress: 50.26%   \n",
      "b'train.tsv''s progress: 52.66%   \n",
      "b'train.tsv''s progress: 55.05%   \n",
      "b'train.tsv''s progress: 57.44%   \n",
      "b'train.tsv''s progress: 59.84%   \n",
      "b'train.tsv''s progress: 62.23%   \n",
      "b'train.tsv''s progress: 64.62%   \n",
      "b'train.tsv''s progress: 67.02%   \n",
      "b'train.tsv''s progress: 69.41%   \n",
      "b'train.tsv''s progress: 71.80%   \n",
      "b'train.tsv''s progress: 74.20%   \n",
      "b'train.tsv''s progress: 76.59%   \n",
      "b'train.tsv''s progress: 78.98%   \n",
      "b'train.tsv''s progress: 81.38%   \n",
      "b'train.tsv''s progress: 83.77%   \n",
      "b'train.tsv''s progress: 86.16%   \n",
      "b'train.tsv''s progress: 88.56%   \n",
      "b'train.tsv''s progress: 90.95%   \n",
      "b'train.tsv''s progress: 93.35%   \n",
      "b'train.tsv''s progress: 95.74%   \n",
      "b'train.tsv''s progress: 98.13%   \n",
      "b'train.tsv''s progress: 100.00%   \n",
      "b'dev.tsv''s progress: 0.00%   \n",
      "b'dev.tsv''s progress: 57.91%   \n",
      "b'dev.tsv''s progress: 100.00%   \n",
      "b'test.tsv''s progress: 0.00%   \n",
      "b'test.tsv''s progress: 58.82%   \n",
      "b'test.tsv''s progress: 100.00%   \n",
      "b'train.tsv''s progress: 0.00%   \n",
      "b'train.tsv''s progress: 2.39%   \n",
      "b'train.tsv''s progress: 4.79%   \n",
      "b'train.tsv''s progress: 7.18%   \n",
      "b'train.tsv''s progress: 9.58%   \n",
      "b'train.tsv''s progress: 11.97%   \n",
      "b'train.tsv''s progress: 14.37%   \n",
      "b'train.tsv''s progress: 16.76%   \n",
      "b'train.tsv''s progress: 19.15%   \n",
      "b'train.tsv''s progress: 21.55%   \n",
      "b'train.tsv''s progress: 23.94%   \n",
      "b'train.tsv''s progress: 26.34%   \n",
      "b'train.tsv''s progress: 28.73%   \n",
      "b'train.tsv''s progress: 31.13%   \n",
      "b'train.tsv''s progress: 33.52%   \n",
      "b'train.tsv''s progress: 35.92%   \n",
      "b'train.tsv''s progress: 38.31%   \n",
      "b'train.tsv''s progress: 40.70%   \n",
      "b'train.tsv''s progress: 43.10%   \n",
      "b'train.tsv''s progress: 45.49%   \n",
      "b'train.tsv''s progress: 47.89%   \n",
      "b'train.tsv''s progress: 50.28%   \n",
      "b'train.tsv''s progress: 52.68%   \n",
      "b'train.tsv''s progress: 55.07%   \n",
      "b'train.tsv''s progress: 57.46%   \n",
      "b'train.tsv''s progress: 59.86%   \n",
      "b'train.tsv''s progress: 62.25%   \n",
      "b'train.tsv''s progress: 64.65%   \n",
      "b'train.tsv''s progress: 67.04%   \n",
      "b'train.tsv''s progress: 69.44%   \n",
      "b'train.tsv''s progress: 71.83%   \n",
      "b'train.tsv''s progress: 74.23%   \n",
      "b'train.tsv''s progress: 76.62%   \n",
      "b'train.tsv''s progress: 79.01%   \n",
      "b'train.tsv''s progress: 81.41%   \n",
      "b'train.tsv''s progress: 83.80%   \n",
      "b'train.tsv''s progress: 86.20%   \n",
      "b'train.tsv''s progress: 88.59%   \n",
      "b'train.tsv''s progress: 90.99%   \n",
      "b'train.tsv''s progress: 93.38%   \n",
      "b'train.tsv''s progress: 95.77%   \n",
      "b'train.tsv''s progress: 98.17%   \n",
      "b'train.tsv''s progress: 100.00%   \n",
      "b'dev.tsv''s progress: 0.00%   \n",
      "b'dev.tsv''s progress: 57.24%   \n",
      "b'dev.tsv''s progress: 100.00%   \n",
      "b'test.tsv''s progress: 0.00%   \n",
      "b'test.tsv''s progress: 55.74%   \n",
      "b'test.tsv''s progress: 100.00%   \n",
      "b'train.tsv''s progress: 0.00%   \n",
      "b'train.tsv''s progress: 2.41%   \n",
      "b'train.tsv''s progress: 4.83%   \n",
      "b'train.tsv''s progress: 7.24%   \n",
      "b'train.tsv''s progress: 9.65%   \n",
      "b'train.tsv''s progress: 12.06%   \n",
      "b'train.tsv''s progress: 14.48%   \n",
      "b'train.tsv''s progress: 16.89%   \n",
      "b'train.tsv''s progress: 19.30%   \n",
      "b'train.tsv''s progress: 21.72%   \n",
      "b'train.tsv''s progress: 24.13%   \n",
      "b'train.tsv''s progress: 26.54%   \n",
      "b'train.tsv''s progress: 28.96%   \n",
      "b'train.tsv''s progress: 31.37%   \n",
      "b'train.tsv''s progress: 33.78%   \n",
      "b'train.tsv''s progress: 36.19%   \n",
      "b'train.tsv''s progress: 38.61%   \n",
      "b'train.tsv''s progress: 41.02%   \n",
      "b'train.tsv''s progress: 43.43%   \n",
      "b'train.tsv''s progress: 45.85%   \n",
      "b'train.tsv''s progress: 48.26%   \n",
      "b'train.tsv''s progress: 50.67%   \n",
      "b'train.tsv''s progress: 53.09%   \n",
      "b'train.tsv''s progress: 55.50%   \n",
      "b'train.tsv''s progress: 57.91%   \n",
      "b'train.tsv''s progress: 60.32%   \n",
      "b'train.tsv''s progress: 62.74%   \n",
      "b'train.tsv''s progress: 65.15%   \n",
      "b'train.tsv''s progress: 67.56%   \n",
      "b'train.tsv''s progress: 69.98%   \n",
      "b'train.tsv''s progress: 72.39%   \n",
      "b'train.tsv''s progress: 74.80%   \n",
      "b'train.tsv''s progress: 77.22%   \n",
      "b'train.tsv''s progress: 79.63%   \n",
      "b'train.tsv''s progress: 82.04%   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'train.tsv''s progress: 84.45%   \n",
      "b'train.tsv''s progress: 86.87%   \n",
      "b'train.tsv''s progress: 89.28%   \n",
      "b'train.tsv''s progress: 91.69%   \n",
      "b'train.tsv''s progress: 94.11%   \n",
      "b'train.tsv''s progress: 96.52%   \n",
      "b'train.tsv''s progress: 98.93%   \n",
      "b'train.tsv''s progress: 100.00%   \n",
      "b'dev.tsv''s progress: 0.00%   \n",
      "b'dev.tsv''s progress: 59.92%   \n",
      "b'dev.tsv''s progress: 100.00%   \n",
      "b'test.tsv''s progress: 0.00%   \n",
      "b'test.tsv''s progress: 57.89%   \n",
      "b'test.tsv''s progress: 100.00%   \n",
      "b'train.tsv''s progress: 0.00%   \n",
      "b'train.tsv''s progress: 2.39%   \n",
      "b'train.tsv''s progress: 4.78%   \n",
      "b'train.tsv''s progress: 7.17%   \n",
      "b'train.tsv''s progress: 9.56%   \n",
      "b'train.tsv''s progress: 11.94%   \n",
      "b'train.tsv''s progress: 14.33%   \n",
      "b'train.tsv''s progress: 16.72%   \n",
      "b'train.tsv''s progress: 19.11%   \n",
      "b'train.tsv''s progress: 21.50%   \n",
      "b'train.tsv''s progress: 23.89%   \n",
      "b'train.tsv''s progress: 26.28%   \n",
      "b'train.tsv''s progress: 28.67%   \n",
      "b'train.tsv''s progress: 31.05%   \n",
      "b'train.tsv''s progress: 33.44%   \n",
      "b'train.tsv''s progress: 35.83%   \n",
      "b'train.tsv''s progress: 38.22%   \n",
      "b'train.tsv''s progress: 40.61%   \n",
      "b'train.tsv''s progress: 43.00%   \n",
      "b'train.tsv''s progress: 45.39%   \n",
      "b'train.tsv''s progress: 47.78%   \n",
      "b'train.tsv''s progress: 50.17%   \n",
      "b'train.tsv''s progress: 52.55%   \n",
      "b'train.tsv''s progress: 54.94%   \n",
      "b'train.tsv''s progress: 57.33%   \n",
      "b'train.tsv''s progress: 59.72%   \n",
      "b'train.tsv''s progress: 62.11%   \n",
      "b'train.tsv''s progress: 64.50%   \n",
      "b'train.tsv''s progress: 66.89%   \n",
      "b'train.tsv''s progress: 69.28%   \n",
      "b'train.tsv''s progress: 71.66%   \n",
      "b'train.tsv''s progress: 74.05%   \n",
      "b'train.tsv''s progress: 76.44%   \n",
      "b'train.tsv''s progress: 78.83%   \n",
      "b'train.tsv''s progress: 81.22%   \n",
      "b'train.tsv''s progress: 83.61%   \n",
      "b'train.tsv''s progress: 86.00%   \n",
      "b'train.tsv''s progress: 88.39%   \n",
      "b'train.tsv''s progress: 90.78%   \n",
      "b'train.tsv''s progress: 93.16%   \n",
      "b'train.tsv''s progress: 95.55%   \n",
      "b'train.tsv''s progress: 97.94%   \n",
      "b'train.tsv''s progress: 100.00%   \n",
      "b'dev.tsv''s progress: 0.00%   \n",
      "b'dev.tsv''s progress: 57.50%   \n",
      "b'dev.tsv''s progress: 100.00%   \n",
      "b'test.tsv''s progress: 0.00%   \n",
      "b'test.tsv''s progress: 59.37%   \n",
      "b'test.tsv''s progress: 100.00%   \n",
      "b'train.tsv''s progress: 0.00%   \n",
      "b'train.tsv''s progress: 2.39%   \n",
      "b'train.tsv''s progress: 4.79%   \n",
      "b'train.tsv''s progress: 7.18%   \n",
      "b'train.tsv''s progress: 9.57%   \n",
      "b'train.tsv''s progress: 11.97%   \n",
      "b'train.tsv''s progress: 14.36%   \n",
      "b'train.tsv''s progress: 16.76%   \n",
      "b'train.tsv''s progress: 19.15%   \n",
      "b'train.tsv''s progress: 21.54%   \n",
      "b'train.tsv''s progress: 23.94%   \n",
      "b'train.tsv''s progress: 26.33%   \n",
      "b'train.tsv''s progress: 28.72%   \n",
      "b'train.tsv''s progress: 31.12%   \n",
      "b'train.tsv''s progress: 33.51%   \n",
      "b'train.tsv''s progress: 35.90%   \n",
      "b'train.tsv''s progress: 38.30%   \n",
      "b'train.tsv''s progress: 40.69%   \n",
      "b'train.tsv''s progress: 43.09%   \n",
      "b'train.tsv''s progress: 45.48%   \n",
      "b'train.tsv''s progress: 47.87%   \n",
      "b'train.tsv''s progress: 50.27%   \n",
      "b'train.tsv''s progress: 52.66%   \n",
      "b'train.tsv''s progress: 55.05%   \n",
      "b'train.tsv''s progress: 57.45%   \n",
      "b'train.tsv''s progress: 59.84%   \n",
      "b'train.tsv''s progress: 62.23%   \n",
      "b'train.tsv''s progress: 64.63%   \n",
      "b'train.tsv''s progress: 67.02%   \n",
      "b'train.tsv''s progress: 69.42%   \n",
      "b'train.tsv''s progress: 71.81%   \n",
      "b'train.tsv''s progress: 74.20%   \n",
      "b'train.tsv''s progress: 76.60%   \n",
      "b'train.tsv''s progress: 78.99%   \n",
      "b'train.tsv''s progress: 81.38%   \n",
      "b'train.tsv''s progress: 83.78%   \n",
      "b'train.tsv''s progress: 86.17%   \n",
      "b'train.tsv''s progress: 88.57%   \n",
      "b'train.tsv''s progress: 90.96%   \n",
      "b'train.tsv''s progress: 93.35%   \n",
      "b'train.tsv''s progress: 95.75%   \n",
      "b'train.tsv''s progress: 98.14%   \n",
      "b'train.tsv''s progress: 100.00%   \n",
      "b'dev.tsv''s progress: 0.00%   \n",
      "b'dev.tsv''s progress: 57.25%   \n",
      "b'dev.tsv''s progress: 100.00%   \n",
      "b'test.tsv''s progress: 0.00%   \n",
      "b'test.tsv''s progress: 59.86%   \n",
      "b'test.tsv''s progress: 100.00%   \n",
      "b'train.tsv''s progress: 0.00%   \n",
      "b'train.tsv''s progress: 2.39%   \n",
      "b'train.tsv''s progress: 4.79%   \n",
      "b'train.tsv''s progress: 7.18%   \n",
      "b'train.tsv''s progress: 9.57%   \n",
      "b'train.tsv''s progress: 11.96%   \n",
      "b'train.tsv''s progress: 14.36%   \n",
      "b'train.tsv''s progress: 16.75%   \n",
      "b'train.tsv''s progress: 19.14%   \n",
      "b'train.tsv''s progress: 21.54%   \n",
      "b'train.tsv''s progress: 23.93%   \n",
      "b'train.tsv''s progress: 26.32%   \n",
      "b'train.tsv''s progress: 28.71%   \n",
      "b'train.tsv''s progress: 31.11%   \n",
      "b'train.tsv''s progress: 33.50%   \n",
      "b'train.tsv''s progress: 35.89%   \n",
      "b'train.tsv''s progress: 38.28%   \n",
      "b'train.tsv''s progress: 40.68%   \n",
      "b'train.tsv''s progress: 43.07%   \n",
      "b'train.tsv''s progress: 45.46%   \n",
      "b'train.tsv''s progress: 47.86%   \n",
      "b'train.tsv''s progress: 50.25%   \n",
      "b'train.tsv''s progress: 52.64%   \n",
      "b'train.tsv''s progress: 55.03%   \n",
      "b'train.tsv''s progress: 57.43%   \n",
      "b'train.tsv''s progress: 59.82%   \n",
      "b'train.tsv''s progress: 62.21%   \n",
      "b'train.tsv''s progress: 64.61%   \n",
      "b'train.tsv''s progress: 67.00%   \n",
      "b'train.tsv''s progress: 69.39%   \n",
      "b'train.tsv''s progress: 71.78%   \n",
      "b'train.tsv''s progress: 74.18%   \n",
      "b'train.tsv''s progress: 76.57%   \n",
      "b'train.tsv''s progress: 78.96%   \n",
      "b'train.tsv''s progress: 81.35%   \n",
      "b'train.tsv''s progress: 83.75%   \n",
      "b'train.tsv''s progress: 86.14%   \n",
      "b'train.tsv''s progress: 88.53%   \n",
      "b'train.tsv''s progress: 90.93%   \n",
      "b'train.tsv''s progress: 93.32%   \n",
      "b'train.tsv''s progress: 95.71%   \n",
      "b'train.tsv''s progress: 98.10%   \n",
      "b'train.tsv''s progress: 100.00%   \n",
      "b'dev.tsv''s progress: 0.00%   \n",
      "b'dev.tsv''s progress: 60.34%   \n",
      "b'dev.tsv''s progress: 100.00%   \n",
      "b'test.tsv''s progress: 0.00%   \n",
      "b'test.tsv''s progress: 58.99%   \n",
      "b'test.tsv''s progress: 100.00%   \n",
      "b'train.tsv''s progress: 0.00%   \n",
      "b'train.tsv''s progress: 2.38%   \n",
      "b'train.tsv''s progress: 4.77%   \n",
      "b'train.tsv''s progress: 7.15%   \n",
      "b'train.tsv''s progress: 9.53%   \n",
      "b'train.tsv''s progress: 11.91%   \n",
      "b'train.tsv''s progress: 14.30%   \n",
      "b'train.tsv''s progress: 16.68%   \n",
      "b'train.tsv''s progress: 19.06%   \n",
      "b'train.tsv''s progress: 21.44%   \n",
      "b'train.tsv''s progress: 23.83%   \n",
      "b'train.tsv''s progress: 26.21%   \n",
      "b'train.tsv''s progress: 28.59%   \n",
      "b'train.tsv''s progress: 30.97%   \n",
      "b'train.tsv''s progress: 33.36%   \n",
      "b'train.tsv''s progress: 35.74%   \n",
      "b'train.tsv''s progress: 38.12%   \n",
      "b'train.tsv''s progress: 40.50%   \n",
      "b'train.tsv''s progress: 42.89%   \n",
      "b'train.tsv''s progress: 45.27%   \n",
      "b'train.tsv''s progress: 47.65%   \n",
      "b'train.tsv''s progress: 50.03%   \n",
      "b'train.tsv''s progress: 52.42%   \n",
      "b'train.tsv''s progress: 54.80%   \n",
      "b'train.tsv''s progress: 57.18%   \n",
      "b'train.tsv''s progress: 59.56%   \n",
      "b'train.tsv''s progress: 61.95%   \n",
      "b'train.tsv''s progress: 64.33%   \n",
      "b'train.tsv''s progress: 66.71%   \n",
      "b'train.tsv''s progress: 69.09%   \n",
      "b'train.tsv''s progress: 71.48%   \n",
      "b'train.tsv''s progress: 73.86%   \n",
      "b'train.tsv''s progress: 76.24%   \n",
      "b'train.tsv''s progress: 78.62%   \n",
      "b'train.tsv''s progress: 81.01%   \n",
      "b'train.tsv''s progress: 83.39%   \n",
      "b'train.tsv''s progress: 85.77%   \n",
      "b'train.tsv''s progress: 88.15%   \n",
      "b'train.tsv''s progress: 90.54%   \n",
      "b'train.tsv''s progress: 92.92%   \n",
      "b'train.tsv''s progress: 95.30%   \n",
      "b'train.tsv''s progress: 97.68%   \n",
      "b'train.tsv''s progress: 100.00%   \n",
      "b'dev.tsv''s progress: 0.00%   \n",
      "b'dev.tsv''s progress: 56.46%   \n",
      "b'dev.tsv''s progress: 100.00%   \n",
      "b'test.tsv''s progress: 0.00%   \n",
      "b'test.tsv''s progress: 58.46%   \n",
      "b'test.tsv''s progress: 100.00%   \n",
      "b'train.tsv''s progress: 0.00%   \n",
      "b'train.tsv''s progress: 2.40%   \n",
      "b'train.tsv''s progress: 4.81%   \n",
      "b'train.tsv''s progress: 7.21%   \n",
      "b'train.tsv''s progress: 9.61%   \n",
      "b'train.tsv''s progress: 12.01%   \n",
      "b'train.tsv''s progress: 14.42%   \n",
      "b'train.tsv''s progress: 16.82%   \n",
      "b'train.tsv''s progress: 19.22%   \n",
      "b'train.tsv''s progress: 21.62%   \n",
      "b'train.tsv''s progress: 24.03%   \n",
      "b'train.tsv''s progress: 26.43%   \n",
      "b'train.tsv''s progress: 28.83%   \n",
      "b'train.tsv''s progress: 31.24%   \n",
      "b'train.tsv''s progress: 33.64%   \n",
      "b'train.tsv''s progress: 36.04%   \n",
      "b'train.tsv''s progress: 38.44%   \n",
      "b'train.tsv''s progress: 40.85%   \n",
      "b'train.tsv''s progress: 43.25%   \n",
      "b'train.tsv''s progress: 45.65%   \n",
      "b'train.tsv''s progress: 48.06%   \n",
      "b'train.tsv''s progress: 50.46%   \n",
      "b'train.tsv''s progress: 52.86%   \n",
      "b'train.tsv''s progress: 55.26%   \n",
      "b'train.tsv''s progress: 57.67%   \n",
      "b'train.tsv''s progress: 60.07%   \n",
      "b'train.tsv''s progress: 62.47%   \n",
      "b'train.tsv''s progress: 64.87%   \n",
      "b'train.tsv''s progress: 67.28%   \n",
      "b'train.tsv''s progress: 69.68%   \n",
      "b'train.tsv''s progress: 72.08%   \n",
      "b'train.tsv''s progress: 74.49%   \n",
      "b'train.tsv''s progress: 76.89%   \n",
      "b'train.tsv''s progress: 79.29%   \n",
      "b'train.tsv''s progress: 81.69%   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'train.tsv''s progress: 84.10%   \r\n",
      "b'train.tsv''s progress: 86.50%   \r\n",
      "b'train.tsv''s progress: 88.90%   \r\n",
      "b'train.tsv''s progress: 91.30%   \r\n",
      "b'train.tsv''s progress: 93.71%   \r\n",
      "b'train.tsv''s progress: 96.11%   \r\n",
      "b'train.tsv''s progress: 98.51%   \r\n",
      "b'train.tsv''s progress: 100.00%   \r\n"
     ]
    }
   ],
   "source": [
    "# for file in glob.glob(local_data_dir+'/high_iaa_train_42*'):\n",
    "#     scp.put(file, recursive=True, remote_path=cluster_data_dir)\n",
    "    \n",
    "for file in glob.glob(os.path.join(local_data_base_dir,local_data_type,'folds/*')):\n",
    "    scp.put(file, recursive=True, remote_path=cluster_data_dir)\n",
    "\n",
    "scp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
