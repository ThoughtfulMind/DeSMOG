,Train data type,Eval set,Cased,Base model,Num epochs,Max seq length,ACCURACY,Micro F1,Macro F1,
Me,Skeppstedt,dev,uncased,bert-base-uncased,3,500,0.59,0.59,0.5,
,Skeppstedt,test,uncased,trained uncased,-,500,0.47,0.47,0.36,
,my annots,dev,uncased,bert-base-uncased,3,500,0.68,0.68,0.6,
,my annots,test,uncased,trained uncased,na,500,0.54,0.54,0.47,
,my annots,dev,uncased,"LM-finetuned-both-vax (Skeppstedt texts, QP2 texts)",3,500,0.66,0.66,0.57,
,my annots,test,uncased,trained LM-finetuned-both-vax,na,500,0.58,0.58,0.49,
,my annots,dev,uncased,"LM-finetuned-all-vax (Skeppstedt texts, QP2 texts, vax blogs)",3,500,0.67,0.67,0.62,
,my annots,test,uncased,trained LM-finetuned-all-vax,na,500,0.59,0.59,0.55,
,both,dev,uncased,bert-base-uncased,3,500,0.62,0.62,0.49,
,both,test,uncased,trained uncased,na,500,0.67,0.67,0.58,
,both,dev,uncased,"LM-finetuned-both-vax (Skeppstedt texts, QP2 texts)",3,500,,,,
,both,test,uncased,trained LM-finetuned-both-vax,na,500,,,,
,both,dev,uncased,"LM-finetuned-all-vax (Skeppstedt texts, QP2 texts, vax blogs)",3,500,0.59,0.59,0.52,
,both,test,uncased,trained LM-finetuned-all-vax,na,500,0.64,0.64,0.57,
,,,,,,,,,,
,,,,,,,,,,
,,,,,,,,,,
,,,,,,,,,,
,,,,,,,,,,
,,,,,,,,,,
,,,,,,,,,,
,,,,,,,,,,
,,,,,,,,,,
,,,,,,,,,,
Skeppstedt et al. baseline,Skeppstedt,,,,,,na,0.48,0.44,https://www.aclweb.org/anthology/W17-5801.pdf