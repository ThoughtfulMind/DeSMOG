{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_pretrained_bert.modeling import BertPreTrainedModel, BertModel, BertSelfAttention\n",
    "import pytorch_pretrained_bert.modeling as modeling\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gelu(x):\n",
    "    \"\"\"Implementation of the gelu activation function.\n",
    "        For information: OpenAI GPT's gelu is slightly different (and gives slightly different results):\n",
    "        0.5 * x * (1 + torch.tanh(math.sqrt(2 / math.pi) * (x + 0.044715 * torch.pow(x, 3))))\n",
    "    \"\"\"\n",
    "    return x * 0.5 * (1.0 + torch.erf(x / math.sqrt(2.0)))\n",
    "\n",
    "def identity(x):\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertForMultitask(BertPreTrainedModel):\n",
    "\n",
    "    def __init__(self, config, cls_num_labels=2, tok_num_labels=2, tok2id=None):\n",
    "        super(BertForMultitask, self).__init__(config)\n",
    "        self.bert = BertModel(config)\n",
    "\n",
    "        self.cls_dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "        self.cls_classifier = nn.Linear(config.hidden_size, cls_num_labels)\n",
    "        \n",
    "        self.tok_dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "        self.tok_classifier = nn.Linear(config.hidden_size, tok_num_labels)\n",
    "        \n",
    "        self.apply(self.init_bert_weights)\n",
    "\n",
    "\n",
    "    def forward(self, input_ids, token_type_ids=None, attention_mask=None, \n",
    "        labels=None, rel_ids=None, pos_ids=None, categories=None, pre_len=None):\n",
    "        global ARGS\n",
    "        sequence_output, pooled_output = self.bert(\n",
    "            input_ids, token_type_ids, attention_mask, output_all_encoded_layers=False)\n",
    "\n",
    "        cls_logits = self.cls_classifier(pooled_output)\n",
    "        cls_logits = self.cls_dropout(cls_logits)\n",
    "\n",
    "        # NOTE -- dropout is after proj, which is non-standard\n",
    "        tok_logits = self.tok_classifier(sequence_output)\n",
    "        tok_logits = self.tok_dropout(tok_logits)\n",
    "\n",
    "        return cls_logits, tok_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class ConcatCombine(nn.Module):\n",
    "    def __init__(self, hidden_size, feature_size, out_size, layers,\n",
    "            dropout_prob, small=False, pre_enrich=False, activation=False,\n",
    "            include_categories=False, category_emb=False,\n",
    "            add_category_emb=False):\n",
    "        super(ConcatCombine, self).__init__()\n",
    "\n",
    "        self.include_categories = include_categories\n",
    "        self.add_category_emb = add_category_emb\n",
    "        if include_categories:\n",
    "            if category_emb and not add_category_emb:\n",
    "                feature_size *= 2\n",
    "            elif not category_emb:\n",
    "                feature_size += 43\n",
    "\n",
    "        if layers == 1:\n",
    "            self.out = nn.Sequential(\n",
    "                nn.Linear(hidden_size + feature_size, out_size),\n",
    "                nn.Dropout(dropout_prob))\n",
    "        elif layers == 2:\n",
    "            waist_size = min(hidden_size, feature_size) if small else max(hidden_size, feature_size)\n",
    "            if activation:\n",
    "                self.out = nn.Sequential(\n",
    "                    nn.Linear(hidden_size + feature_size, waist_size),\n",
    "                    nn.Dropout(dropout_prob),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(waist_size, out_size),\n",
    "                    nn.Dropout(dropout_prob))\n",
    "            else:\n",
    "                self.out = nn.Sequential(\n",
    "                    nn.Linear(hidden_size + feature_size, waist_size),\n",
    "                    nn.Dropout(dropout_prob),\n",
    "                    nn.Linear(waist_size, out_size),\n",
    "                    nn.Dropout(dropout_prob))\n",
    "        if pre_enrich:\n",
    "            if activation:\n",
    "                self.enricher = nn.Sequential(\n",
    "                    nn.Linear(feature_size, feature_size),\n",
    "                    nn.ReLU())\n",
    "            else:\n",
    "                self.enricher = nn.Linear(feature_size, feature_size)\n",
    "        else:\n",
    "            self.enricher = None\n",
    "        # manually set cuda because module doesn't see these combiners for bottom \n",
    "        if CUDA:\n",
    "            self.out = self.out.cuda()\n",
    "            if self.enricher: \n",
    "                self.enricher = self.enricher.cuda()\n",
    "                \n",
    "    def forward(self, hidden, features, categories=None):\n",
    "        if self.include_categories:\n",
    "            categories = categories.unsqueeze(1)\n",
    "            categories = categories.repeat(1, features.shape[1], 1)\n",
    "            if self.add_category_emb:\n",
    "                features = features + categories\n",
    "            else:\n",
    "                features = torch.cat((features, categories), -1)\n",
    "\n",
    "        if self.enricher is not None:\n",
    "            features = self.enricher(features)\n",
    "\n",
    "        return self.out(torch.cat((hidden, features), dim=-1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class AddCombine(nn.Module):\n",
    "    def __init__(self, hidden_dim, feat_dim, layers, dropout_prob, small=False,\n",
    "            out_dim=-1, pre_enrich=False, include_categories=False,\n",
    "            category_emb=False, add_category_emb=False):\n",
    "        super(AddCombine, self).__init__()\n",
    "\n",
    "        self.include_categories = include_categories\n",
    "        if include_categories:\n",
    "            feat_dim += 43\n",
    "\n",
    "        if layers == 1:\n",
    "            self.expand = nn.Sequential(\n",
    "                nn.Linear(feat_dim, hidden_dim),\n",
    "                nn.Dropout(dropout_prob))\n",
    "        else:\n",
    "            waist_size = min(feat_dim, hidden_dim) if small else max(feat_dim, hidden_dim)\n",
    "            self.expand = nn.Sequential(\n",
    "                nn.Linear(feat_dim, waist_size),\n",
    "                nn.Dropout(dropout_prob),\n",
    "                nn.Linear(waist_size, hidden_dim),\n",
    "                nn.Dropout(dropout_prob))\n",
    "        \n",
    "        if out_dim > 0:\n",
    "            self.out = nn.Linear(hidden_dim, out_dim)\n",
    "        else:\n",
    "            self.out = None\n",
    "\n",
    "        if pre_enrich:\n",
    "            self.enricher = nn.Linear(feature_size, feature_size)        \n",
    "        else:\n",
    "            self.enricher = None\n",
    "\n",
    "        # manually set cuda because module doesn't see these combiners for bottom         \n",
    "        if CUDA:\n",
    "            self.expand = self.expand.cuda()\n",
    "            if out_dim > 0:\n",
    "                self.out = self.out.cuda()\n",
    "            if self.enricher is not None:\n",
    "                self.enricher = self.enricher.cuda()\n",
    "\n",
    "    def forward(self, hidden, feat, categories=None):\n",
    "        if self.include_categories:\n",
    "            categories = categories.unsqueeze(1)\n",
    "            categories = categories.repeat(1, features.shape[1], 1)\n",
    "            if self.add_category_emb:\n",
    "                features = features + categories\n",
    "            else:\n",
    "                features = torch.cat((features, categories), -1)\n",
    "\n",
    "        if self.enricher is not None:\n",
    "            feat = self.enricher(feat)\n",
    "    \n",
    "        combined = self.expand(feat) + hidden\n",
    "    \n",
    "        if self.out is not None:\n",
    "            return self.out(combined)\n",
    "\n",
    "        return combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class BertForMultitaskWithFeaturesOnTop(BertPreTrainedModel):\n",
    "    \"\"\" stick the features on top of the model \"\"\"\n",
    "    def __init__(self, config, cls_num_labels=2, tok_num_labels=2, tok2id=None):\n",
    "        super(BertForMultitaskWithFeaturesOnTop, self).__init__(config)\n",
    "        global ARGS\n",
    "        \n",
    "        self.bert = BertModel(config)\n",
    "        \n",
    "        self.featurizer = features.Featurizer(\n",
    "            tok2id, lexicon_feature_bits=ARGS.lexicon_feature_bits) \n",
    "        # TODO -- don't hardcode this...\n",
    "        nfeats = 90 if ARGS.lexicon_feature_bits == 1 else 118\n",
    "\n",
    "        if ARGS.extra_features_method == 'concat':\n",
    "            self.tok_classifier = ConcatCombine(\n",
    "                config.hidden_size, nfeats, tok_num_labels, \n",
    "                ARGS.combiner_layers, config.hidden_dropout_prob,\n",
    "                ARGS.small_waist, pre_enrich=ARGS.pre_enrich,\n",
    "                activation=ARGS.activation_hidden,\n",
    "                include_categories=ARGS.concat_categories,\n",
    "                category_emb=ARGS.category_emb,\n",
    "                add_category_emb=ARGS.add_category_emb)\n",
    "        else:\n",
    "            self.tok_classifier = AddCombine(\n",
    "                config.hidden_size, nfeats, ARGS.combiner_layers,\n",
    "                config.hidden_dropout_prob, ARGS.small_waist,\n",
    "                out_dim=tok_num_labels, pre_enrich=ARGS.pre_enrich,\n",
    "                include_categories=ARGS.concat_categories,\n",
    "                category_emb=ARGS.category_emb,\n",
    "                add_category_emb=ARGS.add_category_emb)\n",
    "\n",
    "        self.cls_dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "        self.cls_classifier = nn.Linear(config.hidden_size, cls_num_labels)\n",
    "\n",
    "        self.category_emb = ARGS.category_emb\n",
    "        if ARGS.category_emb:\n",
    "            self.category_embeddings = nn.Embedding(43, nfeats)\n",
    "\n",
    "        self.apply(self.init_bert_weights)\n",
    "\n",
    "\n",
    "    def forward(self, input_ids, token_type_ids=None, attention_mask=None, \n",
    "        labels=None, rel_ids=None, pos_ids=None, categories=None, pre_len=None):\n",
    "        global ARGS\n",
    "        global CUDA\n",
    "\n",
    "        features = self.featurizer.featurize_batch(\n",
    "            input_ids.detach().cpu().numpy(), \n",
    "            rel_ids.detach().cpu().numpy(), \n",
    "            pos_ids.detach().cpu().numpy(), \n",
    "            padded_len=input_ids.shape[1])\n",
    "        features = torch.tensor(features, dtype=torch.float)\n",
    "        if CUDA:\n",
    "            features = features.cuda()\n",
    "\n",
    "        sequence_output, pooled_output = self.bert(\n",
    "            input_ids, token_type_ids, attention_mask, output_all_encoded_layers=False)\n",
    "\n",
    "        pooled_output = self.cls_dropout(pooled_output)\n",
    "        cls_logits = self.cls_classifier(pooled_output)\n",
    "\n",
    "        if ARGS.category_emb:\n",
    "            categories = self.category_embeddings(\n",
    "                categories.max(-1)[1].type(\n",
    "                    'torch.cuda.LongTensor' if CUDA else 'torch.LongTensor'))\n",
    "\n",
    "        tok_logits = self.tok_classifier(sequence_output, features, categories)\n",
    "\n",
    "        return cls_logits, tok_logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "from transformers import BertForSequenceClassification, BertConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get tokenizer and fine-tuned LM (my-cc, uncased) + trained-vanilla\n",
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../BERT/LM_finetuned/uncased_LM_cc_output\n"
     ]
    }
   ],
   "source": [
    "PRETRAINED_MODELS_DIR = '../BERT/trained_models'\n",
    "DATA_NAME = 'vanilla_new'\n",
    "BASE_MOD = 'uncased_LM'\n",
    "CASING = 'uncased'\n",
    "model_path = os.path.join('../BERT/''LM_finetuned','uncased_LM_cc_output')\n",
    "print(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '../data_creation/scripts/save/mturk_windowed_1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "eval_dev_set = pd.read_csv(os.path.join(DATA_DIR,'dev.tsv'),\n",
    "                          sep='\\t',header=None)\n",
    "eval_dev_set.columns = ['text','label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['[SEP] Their study, published Monday in the journal Nature Climate Change, says that most office buildings set temperatures based on a decades-old formula that uses the metabolic rates of men. [SEP] [CLS] Buildings should â\\x80\\x9creduce gender-discriminating bias in thermal comfortâ\\x80\\x9d because setting temperatures at slightly warmer levels can help combat global warming. [SEP] “In a lot of buildings, you see energy consumption is a lot higher because the standard is calibrated for men’s body heat production,” said Boris Kingma, a co-author of the study and a biophysicist at Maastricht University Medical Center in the Netherlands.',\n",
       "       '[SEP] The proposal does not discuss the issue of greenhouse gases which are reportedly a leading cause in climate change. [SEP] [CLS] It’s only a temporary Band-Aid covering a problem that will persist essentially forever, actually hundreds of thousands of years for fossil fuel CO2 to finally go away naturally. [SEP] ',\n",
       "       ' [SEP] [CLS] The Earth could be heading for a new “ little ice age ” as solar activity drops once again. [SEP] A new paper published in the Chinese Science Bulletin has found a “high correlation between solar activity and the Earth’s averaged surface temperature over centuries,” suggesting that climate change is intimately linked with solar cycles rather than human activity.',\n",
       "       '[SEP] But we don’t know that yet. [SEP] [CLS] Human activity is primarily responsible for the rise in carbon dioxide emissions. [SEP] The Intergovernmental Panel on Climate Change, the top climate-science body at the United Nations, calls carbon dioxide the biggest heat-trapping force and says that it is responsible for about 33 times more added warming than natural causes.',\n",
       "       \"[SEP] Today, scientists believe there are 20,000 to 25,000 polar bears, though this is still about 60 percent below historic levels. [SEP] [CLS] The loss of Arctic sea ice, which bears rely on for hunting and denning, is accelerating to record levels due to global warming. [SEP] As a result, US Geological Survey scientists recently warned that projected changes in sea-ice conditions could lead to the loss of about two-thirds of the world's polar bear population by midcentury.\",\n",
       "       '[SEP] He also said he was disappointed that Mr. Sanders no longer supported a carbon tax, a position he embraced in 2016. [SEP] [CLS] A fee on the burning of fossil fuels is the most efficient way to drive down global warming. [SEP] Still, Mr. Oppenheimer said, Mr. Sanders wins points on vision.',\n",
       "       \" [SEP] [CLS] If they follow that very fossil intensive path, whether gas or coal, it will not be a good thing from a climate perspective. [SEP] The storm's center crossed over Bermuda during Friday night and its winds and heavy surf whipped at the island early Saturday before Gonzalo quickly moved northward over the Atlantic on a track that could take it just off the shore of Newfoundland in Canada.\",\n",
       "       ' [SEP] [CLS] The collapse of sea ice is already forcing entire communities to relocate. [SEP] The report by the Intergovernmental Panel on Climate Change, a United Nations group that periodically summarizes climate science, concluded that ice caps are melting, sea ice in the Arctic is collapsing, water supplies are coming under stress, heat waves and heavy rains are intensifying, coral reefs are dying, and fish and many other creatures are migrating toward the poles or in some cases going extinct.',\n",
       "       '[SEP] Tardiness in submitting the two reports — one is required every two years under the United Nations Framework Convention on Climate Change treaty signed by President George Bush; the other every four years — is not unheard-of. [SEP] [CLS] The missed deadline underscores the disdain with which the Trump administration views the worldwide effort to rein in global warming. [SEP] They also argue it undermines the United States’ push for transparency in countries like China.',\n",
       "       '[SEP] The group led by Dr. Williams concluded that human-caused climate change was responsible for between 8 and 27 percent of the deficit in soil moisture that California experienced from 2012 to 2014. [SEP] [CLS] The low number is derived from a method that did not take account of the way global warming had sped up since the 1970s. [SEP] That led him and his colleagues to conclude that climate change was most likely responsible for about 15 to 20 percent of the moisture deficit.',\n",
       "       '[SEP] “The problem is that rather than allowing agency scientists to use their judgment and weigh the best available evidence, this could put political constraints on how science enters the decision-making process in the first place,” said Ms. Wagner, the University of Texas law professor. [SEP] [CLS] Now we feel like the E.P.A. is being run by the fossil fuel industry. [SEP] says its proposed rule is intended to make the science that underpins potentially costly regulations more transparent.',\n",
       "       '[SEP] The data set covered six years and more than 12,000 individual wells. [SEP] [CLS] Rising fossil fuel emissions, which increase the temperature of the planet, pose grave risks to water supplies. [SEP] Water levels in 21 of the world’s 47 largest known aquifers are trending negative, according to a 2015 study published by a group of NASA scientists in the journal Water Resources Research.',\n",
       "       '[SEP] But while local politicians can take action to shore up their community against the rising tide, they are powerless to stop what scientists say is the heart of the problem: the increasing fossil fuel emissions that continue to warm the planet. [SEP] [CLS] The scale of emission reductions necessary to prevent the most dangerous effects of global warming can only come as a result of national and international policies to cut carbon pollution. [SEP] Some areas of the globe are especially vulnerable to rising sea levels and inhabitants are being forced to make stark changes in their lives.',\n",
       "       '[SEP] “The future must be de-colonised and re-connected to the ancient wisdom of the Earth we once cherished. [SEP] [CLS] Climate change is a man-made problem, which is why women should rule the world. [SEP] “This is not a list to show your sons either,” the Conservative Woman post said.',\n",
       "       '[SEP] The new numbers, reported by a tracking initiative called the Global Carbon Project and published in the journal Nature Geoscience, came on the eve of a United Nations summit meeting meant to harness fresh political ambition in tackling climate change. [SEP] [CLS] Vastly greater efforts would be needed to get long-term global warming within tolerable limits. [SEP] “You can no longer have some countries go first and others come in later, because there is no more time,” said Glen P. Peters, a scientist at the Center for International Climate and Environmental Research in Oslo, who helped compile the new numbers.',\n",
       "       '[SEP] Agence France-Presse (AFP) reported:  UN General Assembly president Maria Espinosa told AFP that mankind was “in danger of disappearing” if climate change was allowed to progress at its current rate. [SEP] [CLS] Right now we’re facing a man-made disaster on a global scale. [SEP] “We require deep transformations of our economies and societies.”  “We need to act urgently, and with audacity,” Espinosa said.',\n",
       "       '[SEP] Find your long johns, break out the thick socks and raid the supermarket. [SEP] [CLS] As the Arctic gets warmer and warmer, the severe weather picks up. [SEP] The phrase has become synonymous with frigid temperatures that make snowstorms more likely.',\n",
       "       '[SEP] We have been through wars on poverty, drugs, cancer and even Christmas. [SEP] [CLS] Global warming is like a world war. [SEP] “It is a world war.” War rhetoric serves a valuable function.',\n",
       "       '[SEP] Tony Abbott told reporters that his government had made \"strong and credible\" achievements in emissions reductions, and that they would be in a good position in Paris. [SEP] [CLS] It is urgent to move away from fossil fuels and towards renewable energy, including large scale wind and household solar. [SEP] ',\n",
       "       \"[SEP] As exhausted as I am angry, I’ve gotten used to seeing the almost C.G.I.-looking photos that appear from around the state, numb to the dystopian desolation and the towering flames that continue to dance along several major freeways, the strewn tires, skeletons of people’s homes, decimated forests and abandoned animals. [SEP] [CLS] It's unquestionable that this year's Kincade fire grew with such disastrous rapidity because of the climate. [SEP] Once sparked, the Kincade fire spread through a football field’s worth of land every three seconds.\",\n",
       "       '[SEP] New data released last month by researchers at Yale and George Mason universities show that a lot of Americans are growing far more concerned about climate change, precisely because they’re drawing the links between freaky weather, a climate kicked off-kilter by a fossil-fuel guzzling civilization, and their own lives. [SEP] [CLS] Global warming is affecting the weather. [SEP] As Yale’s Anthony Laiserowitz told the New York Times, “People are starting to connect the dots.”  Which is what we must do.',\n",
       "       '[SEP] The lawsuits do not specify a compensation amount, but updating San Francisco’s seawall alone to prepare for climate impacts could cost up to $5 billion. [SEP] [CLS] These fossil fuel companies profited handsomely for decades while knowing they are putting the fate of our cities at risk. [SEP] “Instead of owning up to it, they copied a page from the Big Tobacco playbook.',\n",
       "       '[SEP] Democrats began “prodding” the department to “include climate change in its strategic plans” in 2008. [SEP] [CLS] Climate change is a likely threat to national security – though scientists can not yet predict particular climate effects of anticipated global warming with any degree of certainty. [SEP] Former Secretary of Defense Donald Rumsfeld kicked off the effort to cut the military’s reliance on fossil fuels.',\n",
       "       ' [SEP] [CLS] Global warming is going to cause more wars. [SEP] As it is, the fanatics will probably scream that Stavins has become a Nazi-like “climate denier” or tool of Big Oil or something.',\n",
       "       '[SEP] A briefing provided to the failed U.N. Conference of the Parties in Copenhagen in 2009 provided this summary: “The long-term sea level that corresponds to current CO2 concentration is about 23 meters above today’s levels, and the temperatures will be 6 degrees C or more higher. [SEP] [CLS] The long-held, internationally agreed upon target to limit rises in global average temperatures to 2 degrees Celsius is in error and far above the 1C threshold that would need to be maintained in order to avoid the effects of catastrophic climate change. [SEP] And keep in mind that the various major assessments of future global temperatures seldom assume the worst about possible self-reinforcing climate feedback loops like the methane one.',\n",
       "       '[SEP] \"In the real world, climate change is far too challenging a threat to be ended by one person — or even one battle that doesn’t include all of the major powers,\" Romm piously preached. [SEP] [CLS] The climate is about to change for the worse in a way that poses an existential threat for everyone. [SEP] Indeed, Game of Thrones has a strong climate theme.',\n",
       "       '[SEP] It may sound like a storyline straight out of a Godzilla movie, but researchers are warning that toxic waste from a long-abandoned Cold War-era camp could leach into nearby ecosystems as a result of warming temperatures in Greenland. [SEP] [CLS] It is thought that the hazardous waste would stay buried and frozen forever beneath the Greenland Ice Sheet, but climate change is warming the Arctic and causing portions of the ice sheet to melt. [SEP] \"In the past, militaries, industry and even scientists have given little thought to the lasting impact of their activities, including dangerous waste left behind,\" Laurence Smith, a professor in the Department of Geography at the University of California, Los Angeles and author of \"The World in 2050: Four Forces Shaping Civilization\\'s Northern Future\" (Dutton Adult, 2010), told Live Science in an email.',\n",
       "       \"[SEP] The launch of the new group on Sunday comes as diplomats gather in Madrid on Monday for global climate negotiations aimed at strengthening the 2015 Paris Agreement, from which President Trump has vowed to withdraw next year. [SEP] [CLS] The world's richest countries, responsible for emitting more than three-fourths of planet-warming pollution, are not doing enough to keep Earth's temperature from rising to dangerously high levels. [SEP] Net carbon emissions from the two largest polluters, the United States and China, are expanding.\",\n",
       "       \"[SEP] Left unsaid in the report, but explicitly noted by Mr. Bloomberg in a touch of electioneering, was that such national action would require an administration that prioritizes climate change. [SEP] [CLS] Beating climate change won't require a miracle. [SEP] “It will require leadership and common sense.” Under the rules of the Paris Agreement, the United States will remain a party to the accord until Nov. 4, 2020, the day after the presidential election.\",\n",
       "       '[SEP] Nevertheless, many environmentalists disagree, and are disappointed at having to reopen a battle they thought was won long ago. [SEP] [CLS] It is most crucial to combat global warming. [SEP] Environment America, a federation of green groups, stated in a recent report that energy efficiency and renewable sources such as wind, solar, and geothermal can do the job faster and cheaper.',\n",
       "       '[SEP] And what the commission has found is that climate change is already affecting human health in serious ways, with harms “far worse than previously understood.” The report argues that the health professions have a responsibility “to communicate the threats and opportunities” of a phenomenon that is “central to human well-being.” It should be noted that climate change is not the only environmental problem causing widespread health problems. [SEP] [CLS] Human-caused global warming threatens to undermine the past 50 years of gains in public health. [SEP] For instance, the commission found that outdoor labor capacity in rural areas fell, on average, by 5.3 percent over the past 16 years because of heat stress and other conditions making work more difficult.',\n",
       "       '[SEP] Mr. Pompeo, in his remarks on Twitter, said that the United States would still maintain a voice in international discussions on global warming. [SEP] [CLS] We will continue to work with our global partners to enhance resilience to the impacts of climate change and prepare for and respond to natural disasters. [SEP] “Just as we have in the past, the United States will continue to research, innovate, and grow our economy while reducing emissions and extending a helping hand to our friends and partners around the globe,” he said.',\n",
       "       '[SEP] This actually satisfies a psychological need for many people. [SEP] [CLS] Humans make a contribution to global warming. [SEP] Which simply isn’t the case.',\n",
       "       '[SEP] Yang, to his credit, said Democrats must “stop being obsessed over impeachment.” His policy ideas may be a bit wonky, but of all the Democrats on stage, he seems to be the most genuine. [SEP] [CLS] The word climate change, to the best of my knowledge, is not discussed in this new NAFTA agreement at all, which is an outrage. [SEP] But crazy Bernie wasn’t done being crazy.',\n",
       "       '[SEP] Nye told the Daily Beast\\'s Marlow Stern that this \"would be a free-market way to reckon the real cost of a meat diet on the world.\" [SEP] [CLS] A carbon fee would be a fantastic thing for the world. [SEP] Interestingly, Nye shot down the idea of pushing global vegetarianism to prevent climate change.',\n",
       "       '[SEP] But overwhelming scientific consensus says they are actually the result of human-induced climate change and irresponsible construction in flood-prone areas. [SEP] [CLS] Global warming is causing sea levels to rise, while increasing the frequency, intensity, and duration of extreme weather events. [SEP] At the same time, the rapid urbanization of coastal areas is putting more people and property in harm’s way.',\n",
       "       '[SEP] The 375 activists are entitled to their opinion, but the scientific community’s peer-reviewed results overwhelmingly fail to endorse their narrow view that recent warming was predominately manmade. [SEP] [CLS] Global climate change is a very serious problem. [SEP] But so do termites, by emitting more methane than all the world’s farm animals combined.',\n",
       "       '[SEP] The study’s findings may have important implications for the effort to meet Paris Agreement goals. [SEP] [CLS] The fossil fuel industry can be part of the solution–though others say what’s needed is a more rapid transition to a clean energy economy. [SEP] The Paris Agreement goes into force on November 4, after passing the ratification threshold of 55 percent of countries – representing 55 percent of global emissions – on Wednesday.',\n",
       "       '[SEP] And over invasive plant species, such as the bamboo grass that grows thick along the roadsides, obscuring some of the litter tossed from passing vehicles. [SEP] [CLS] Global warming may be contributing to huge fissures on Fuji \\'s slopes, prone to erosion and landslides. [SEP] \"Although Fuji has a power of its own, it is being influenced by global warming and other factors,\" Watanabe says as he looks for trouble spots in some of the most frequented areas.',\n",
       "       '[SEP] But a new study suggests these programs would do well to also preserve forests where deforestation and degradation haven’t begun. [SEP] [CLS] Gradual loss of these largely pristine, intact forests has a much greater climate impact than previously accounted for. [SEP] Globally, forests take more than a quarter of the carbon emissions from human activities out of the atmosphere every year.',\n",
       "       '[SEP] He even gave a straight answer to an elephant trap of a question about what he did personally to save the environment:  “I drive all over the country. [SEP] [CLS] In the years to come, there are going to be hundreds of millions of climate refugees causing national security issues all over the world. [SEP] I am not a leading example.”  That was while being cross-examined on ITV after the main debate in which only Boris and Corbyn took part.',\n",
       "       '[SEP] The damage is part of a massive bleaching event that has been impacting reefs around the world for the past two years. [SEP] [CLS] Bleaching has been triggered by global warming and El Nino, a warming of parts of the Pacific Ocean that changes weather worldwide. [SEP] Hot water puts stress on coral, causing it to turn white and become vulnerable to disease.',\n",
       "       '[SEP] While asserting opinion as fact in a political context can be expected, mischaracterizing the context of the broader debate (in order to inculcate personal political/religious values) is inappropriate, unethical and, in some cases, even unlawful — especially when luring students with the promise of improved science grades. [SEP] [CLS] Humans are exacerbating global climate change. [SEP] Mr. Kay, in the guise of Team Marine “coach,” has made a practice of exploiting his SAMOHI classroom as a campaign headquarter to recruit students into helping him advocate for his pet political (“Whole Earth Wise Generation”-type) projects.',\n",
       "       '[SEP] Cox and Al-Khalili, among others, argue that climate scientists are near-unanimous in agreeing that the world is warming, that humans are causing it, and that it is dangerous. [SEP] [CLS] Somewhere between 90% and 100% of active climate scientists agree that global warming is real and human-caused. [SEP] So having someone who disagrees with this consensus position, the argument goes, isn\\'t providing \"balance\" or being \"impartial\" – it\\'s giving a fringe position undue prominence and suggesting that there is a scientific controversy where none exists.',\n",
       "       '[SEP] But one of the most important and noticeable effects in the Midwest is an increase in rain, especially heavy rain, scientists say. [SEP] [CLS] The impacts of sea level rise are so clear and so targeted. [SEP] “It is much harder to pinpoint one driver of impacts in the Midwest because you’ve got so many things interacting.”  “Too many people see climate change as a coastal issue,” said Julie Cerqueira, executive director of the US Climate Alliance, a governor-led group responding to the climate crisis.',\n",
       "       '[SEP] We’ve seen the rest of the episode already, and won’t spill the beans. [SEP] [CLS] The beans contains some powerful refutations of a number of other global warming denier talking points, as well as some ingenious sequences that explain the planetary-scale significance of climate change. [SEP] It also contains some in situ reporting on the impacts of climate change, straight from the imperiled Arctic.',\n",
       "       '[SEP] “I can’t be the only person that thinks the mural of Greta Thunberg in San Francisco looks like Putin, right?” one person tweeted, according to the paper. [SEP] [CLS] Cobre hopes the image of Thunberg will bring attention to the crisis of climate change. [SEP] He told the magazine that while most people have responded positively to the mural, some have messaged him negative comments on Instagram.',\n",
       "       '[SEP] The victims of climate change are primarily people who have done little to cause the crisis. [SEP] [CLS] Climate change is emerging as potentially the greatest risk to human health in the 21st century. [SEP] Not all the victims of climate change are humans.',\n",
       "       ' [SEP] [CLS] The CO2 emitted by burning fossil fuel is the greenhouse gas that causes global warming. [SEP] Professor Les Woodcock, who has had a long and distinguished academic career, also said there is “no reproducible evidence” that carbon dioxide levels have increased over the past century, and blamed the green movement for inflicting economic damage on ordinary people.',\n",
       "       '[SEP] Paradoxically, heat-trapping greenhouse gases — considered the major cause of global warming — are also helping to rebuild the ozone layer, Newman said. [SEP] [CLS] Rising levels of carbon dioxide and other gases cool the upper stratosphere, and the cooler air increases the amount of ozone. [SEP] And in another worrisome trend, the chemicals that replaced CFCs contribute to global warming and are on the rise, said MIT atmospheric scientist Susan Solomon.',\n",
       "       ' [SEP] [CLS] The Pacific winds are the culprit for slowing global warming. [SEP] Now, scientists say that the “pause” in rising temperatures might last another ten years.',\n",
       "       '[SEP] As the soil gradually melts, these buried organisms will decay and release the greenhouse gases carbon dioxide and methane into the atmosphere, which can, in turn, lead to even more warming. [SEP] [CLS] It would take decades of warming to melt permafrost buried beneath the active layer of soil that freezes and thaws with the seasons. [SEP] \"The conclusions that permafrost-carbon modelers were reaching was that, until you thaw really deep, we\\'re not going to get this large, old carbon signal and that the really deep thaw of carbon on land is not going to happen until beyond 2100,\" study leader Katey Walter Anthony, an ecologist and biogeochemist at the University of Alaska Fairbanks, told Live Science.',\n",
       "       \"[SEP] Alaska's glacial ice loss now comes from thinning, not from icebergs calving at the front of the glacier. [SEP] [CLS] Most of their potential for catastrophic ice mass loss has already run its course. [SEP] Operation IceBridge is in its sixth year of monitoring changes in polar ice.\",\n",
       "       '[SEP] Instead, the site talks about air pollution, dirty energy, and green jobs. [SEP] [CLS] Fighting global warming, the stated purpose of AB32, is a loser with California voters. [SEP] The League of Conservation Voters declares Prop 23 a “threat to California’s landmark air pollution standards.” This is nonsense.',\n",
       "       '[SEP] The melting seen in West Antarctica and the Antarctica Peninsula account for about four-fifths of the ice loss. [SEP] [CLS] Global sea levels have risen approximately 8 inches over the past century, with sea-level rises getting higher in some parts of the globe. [SEP] Coastal areas, such as Florida, Bangladesh and cities like London and Shanghai are at risk.',\n",
       "       '[SEP] The dangerous cold snap caused more than two dozen weather-related deaths in eight states and hundreds of injuries, including frostbite, broken bones, heart attacks and carbon monoxide poisoning. [SEP] [CLS] The temperature dropped to minus 33 in Illinois on Jan 31, breaking the previous record of minus 27 set Jan. 16, 2000. [SEP] The day before, wind chills of negative 54 degrees Fahrenheit were reported in International Falls, Minnesota and Chicago had a wind chill of negative 52 degrees just before sunrise.',\n",
       "       '[SEP] The warmists are using falsified results to push their arguments, as Climategate demonstrated. [SEP] [CLS] The end goal of this scheme is global governance with the creeps who polluted Copenhagen with their presence as our future overlords. [SEP] Not appealing in the least.',\n",
       "       '[SEP] Credit: AFP/Getty Images  1. [SEP] [CLS] Sea levels could rise six meters (20 feet) with the melting of the Antarctic and Greenland ice sheets. [SEP] Now, we know that the South Pole is gaining more ice than it’s losing.',\n",
       "       '[SEP] It estimates that this could be cut by nearly a third through better farming practices. [SEP] [CLS] One of the most effective ways to cut methane is to reduce global populations of ruminant livestock, especially cattle. [SEP] The scientists say not enough attention has been paid to tackling greenhouse gases other than CO2, especially in the ongoing UN climate talks, which last convened in Warsaw in November.',\n",
       "       \"[SEP] “The IPCC graph you refer to is just a draft version which still has a number of problems that will be ironed out,” Potsdam University physics professor Stefan Rahmstorf told FoxNews.com. [SEP] [CLS] The chart does not mean that global warming is a hoax. [SEP] “The IPCC's claim is that they are 90 percent sure that humans have 'contributed to' the observed warming.\",\n",
       "       '[SEP] May you know it!” While sea levels may not have been rising then, as they are now, changes in the water temperature may have been to blame for making life virtually unlivable in parts of the region. [SEP] [CLS] The surface temperatures of the Mediterranean Sea cooled rapidly during this time, severely reducing precipitation over the coasts. [SEP] The study concluded that agriculture would have suffered and that the conditions might have influenced the “population declines, urban abandonments and long-distance migrations associated with the period.” To top it off, catastrophic events, in the form of a series of earthquakes, also rocked many ancient cities in these areas from around 1225 to 1175 B.C.',\n",
       "       '[SEP] Professor Bala at first assumed that this was a uniquely Indian problem, until he read an article in Nature which questioned why there was a shortage of upcoming climate scientists worldwide. [SEP] [CLS] I was surprised to learn that shortage of good climate scientists is a global problem. [SEP] Indeed, Nature was reporting on a group of climate scientists at the Laboratory of Dynamic Meteorology in Paris who had recently published summaries of some of the field’s foremost challenges as a way of driving up interest in the subject.',\n",
       "       '[SEP] While polls in the US show concern for the environment rising by education level, lower income voters or residents sometimes show stronger concern on issues like water or global warming than those with higher incomes. [SEP] [CLS] People in India and Latin America more worried about global warming than those in developed nations. [SEP] Still, the conundrum remains: Can environmentalism coexist with rising prosperity?',\n",
       "       \"[SEP] Until now. [SEP] [CLS] Earth 's forests, it turns out, play a dominant role in absorbing greenhouse gases in the atmosphere, acting like a giant sponge and soaking up on average about 8.8 billion tons of carbon dioxide each year. [SEP] In the end, about 2.4 billion tons of solid carbon were locked away in wood fiber each year over that period – a surprise to scientists.\",\n",
       "       '[SEP] While global investment in renewable energy hit $289 billion in 2018, far exceeding the investment in new fossil fuel power, wind and solar remain a small portion of total energy production. [SEP] [CLS] The real evidence of change would come when investors started exiting carbon-heavy companies, especially those with no transition plan. [SEP] “What is going to cause the change?” she added.',\n",
       "       '[SEP] For example, on Sunday night Steve McIntyre told the fascinating story of how and why Michael Mann and his cohorts “hid the decline,” complete with the relevant e-mails and published charts that irrefutably show how Mann, Jones and the rest of the climategate gang consciously discarded relevant data and then tried to cover their actions up. [SEP] [CLS] While that this revelation this revelation is regrettable, this revelation does nothing to disprove the theory that mankind is responsible for global warming. [SEP] Guess what?',\n",
       "       '[SEP] A new Science Advances study modeled the impact of tsunamis based on sea level increases, and discovered worrying results. [SEP] [CLS] Rising sea levels allowed tsunamis to reach much further inland, significantly increasing the risk of floods. [SEP] ',\n",
       "       '[SEP] For at least a decade, it helped to finance right-leaning ideological organizations that not only fought the treaty, but also mounted attacks on climate science, raising lingering doubts in the public mind about whether the situation was as serious as most scientists believed it to be. [SEP] [CLS] Exxon Mobilâ\\x80\\x99s senior leaders and board decided to go forward with their political activities even though they had been briefed extensively on the risks of global warming by the companyâ\\x80\\x99s own scientists. [SEP] (Exxon merged with Mobil in 1999.)',\n",
       "       '[SEP] Worse, said Wester, the monsoon is also becoming more erratic and prone to extreme downpours. [SEP] [CLS] One-in-100 year floods are starting to happen every 50 years. [SEP] The new report highlights how vulnerable many mountain people are, with one-third living on less than $1.90 a day and far away from help if climate disaster strikes.',\n",
       "       '[SEP] Yes, you read that correctly. [SEP] [CLS] The explanation lies with global warming. [SEP] That is certainly not the popular impression.',\n",
       "       '[SEP] In truth, people of faith have played important roles in environmental causes for generations. [SEP] [CLS] Devout Americans are generally less likely to be concerned about global warming than their nonreligious peers. [SEP] But among Catholics this may be starting to change.',\n",
       "       \"[SEP] While detailed studies and analyses about the role climate change may have played in Harvey's severity will take time to complete, most scientists say they are confident about at least a few factors. [SEP] [CLS] Among the clearest: Sea surface temperatures are higher. [SEP] In addition, warmer subsurface water in the oceans means that storms can last longer than they might otherwise, says Kevin Trenberth, a senior scientist in the Climate Analysis Section at the National Center for Atmospheric Research (NCAR) in Boulder, Colo. Research he and others have done leads him to expect that climate change may actually lead to fewer hurricanes, but ones that are more intense and longer-lasting.\",\n",
       "       \"[SEP] 2014 has also been declared the warmest year on record by the Japan Meteorological Agency, one of the planet's four leading weather-tracking organizations. [SEP] [CLS] The JMA&apos;s global average temperature in 2014 is 1.1 F hotter than its 20th century average. [SEP] The United Kingdom's Hadley Center also tracks global temperatures but has not released its final numbers.\",\n",
       "       '[SEP] Unfortunately, there is no way to know for sure, since early data is sparse in many areas. [SEP] [CLS] Trusel is all but certain that melting in the Antarctic will become more widespread in the coming years. [SEP] \"My research has assessed how surface melting may change in the future under various climate scenarios,\" he adds.',\n",
       "       ' [SEP] [CLS] Natural ice conditions are diminishing across the globe, particularly in Canada. [SEP] There was little to suggest what was inside.',\n",
       "       \" [SEP] [CLS] We will not be imposing a carbon tax and we will not be imposing an emissions trading scheme. [SEP] He's adamant he never said that it was, despite the record clearly showing that he did.\",\n",
       "       '[SEP] “If a model is making bad predictions, which these climate models are, the theory that underlies them must be wrong. [SEP] [CLS] Atmospheric reaction to carbon dioxide, known as climate sensitivity, is probably too high for these models. [SEP] “If you take this climate sensitivity model and tone it down, you get a much closer match to reality.” He contends that the computer models are overcompensating for the addition of CO2’s to the atmosphere.',\n",
       "       \"[SEP] Trudeau, whose campaign was rocked by recent scandals, appeared set to win a second term and his Liberal party won the most seats in the 338-seat Parliament, giving it the best chance to form the next government. [SEP] [CLS] Critics said Thunberg's speech -- which is peppered with cries from pro-oil and gas counter-protesters -- called for action on climate change but failed to propose any plans for possible solutions. [SEP] Canada is well served.\",\n",
       "       ' [SEP] [CLS] City officials city officials decrying global warming out of one side of their mouth while downplaying it in bond disclosures. [SEP] It depends on when you ask them.',\n",
       "       '[SEP] The Navy, Army, and Air Force have all invested increasingly in solar and other renewables in a bid to make the military more efficient, economical, and resilient. [SEP] [CLS] There is a coming transition from fossil fuels to renewables, but are reluctant to speak about it because it’s tied to climate change. [SEP] The national security argument helps pave the way for “a sensible, well-reasoned conversation about advanced energy,” he says.',\n",
       "       '[SEP] In the journal PLOS Biology, researchers examined the consequences of this incident by comparing the more extreme year to the previous two decades. [SEP] [CLS] The Arctic is changing. [SEP] Although the impact of longer-term change is well-documented, researchers know much less about how climate variability and extreme weather events affect the Arctic.',\n",
       "       '[SEP] However, Brugnaro noted, yesterday\\'s intense surge was exceptional, and almost certainly linked to the increasingly powerful storms fueled by global warming. [SEP] [CLS] These are the effects of climate change. [SEP] \"The costs will be high.\"',\n",
       "       ' [SEP] [CLS] Supporters of the demonstration knew firsthand about the effects of climate change. [SEP] A group of about 70 protesters took to the field just before 2 p.m. after the game’s halftime show.',\n",
       "       '[SEP] A White House spokesman said in a statement that the discussion aimed to build on the administration’s efforts to promote fossil fuels at the G20 meeting this year. [SEP] [CLS] Fossil fuels will be used for the foreseeable future. [SEP] As you can imagine, the BBC is very unhappy about this.',\n",
       "       '[SEP] Like a spouse who demands a divorce but then continues to live at home, the relationship between the United States and other parties to the Paris agreement is, at best, awkward. [SEP] [CLS] The Trump administration will abandon the global climate change pact and make no effort to meet its voluntary target to curb planet-warming emissions. [SEP] On Tuesday, President Trump repeated his claim that former President Barack Obama’s diplomats agreed to bad deals.',\n",
       "       '[SEP] [Video: Arctic Sea Ice Continues To Thin]  In the past decade, the Arctic ice-cap extent has bobbed back and forth among top 10 record lows, all the while continuing an overall steady decline that started in the 1970s. [SEP] [CLS] Since 1978, the winter Arctic ice cap has shrunk by 12 percent per decade. [SEP] The lowest winter maximum on record occurred in 2011, when the sea ice extended 5.65 million square miles (14.63 million square km).',\n",
       "       \"[SEP] More recently, precipitation (both snow and rain) has dropped by 3.9 inches and temperatures have risen 1 degree Fahrenheit since 1992. [SEP] [CLS] The researchers suspect that the glacial melting in the Everest region is due to global warming, but they have not yet established a firm connection between the mountains&apos; changes and climate change. [SEP] While Everest isn't the only Himalayan region seeing the effects of climate change, not all of the region's glaciers are melting.\",\n",
       "       '[SEP] He called the wave of fires starting in 2017 “a complete wake-up moment for an industry that thought it knew what was on its books, but actually didn’t.” When insurers try to respond to risks they don’t understand, they tend to set premiums too high, to give themselves a buffer against error, according to Dr. Kousky of the Wharton Risk Center. [SEP] [CLS] When it comes to climate change, insurers may respond by setting premiums so high that insurance in many parts of the country becomes unaffordable. [SEP] By seeking to protect people from higher prices, regulators could make the problem worse by pushing insurers out of dangerous areas altogether, experts say.',\n",
       "       ' [SEP] [CLS] The Arctic sea ice levels are 7 percent below the 1981-2010 average. [SEP] The pup was born on Sunday in the protected basin of the Great Tidal Pool, where the otter mom came for a safe, calm place to deliver her baby.',\n",
       "       '[SEP] A group of U.S. scientists has had to be rescued by helicopter from Antarctica after being trapped by encroaching ice. [SEP] [CLS] A group of American scientists is rescued from an island off Antarcticaâ\\x80\\x99s coast after ice prevented a U.S. Antarctic Program research vessel from reaching them. [SEP] The four U.S. scientists and a support staff member conducting research on Antarctica’s Joinville Island were airlifted by helicopter Sunday from an icebreaker ship dispatched by Argentina, said the National Science Foundation, which funds and manages the Antarctic program.',\n",
       "       '[SEP] This small thickening, sustained over thousands of years and spread over the vast expanse of these sectors of Antarctica, corresponds to a very large gain of ice – enough to outweigh the losses from fast-flowing glaciers in other parts of the continent and reduce global sea level rise. [SEP] [CLS] Antarctica is not currently contributing to sea level rise, but is taking 0.23 millimeters per year away. [SEP] “But this is also bad news.',\n",
       "       '[SEP] Vice Minister Zhao Yingmin told reporters that completed the target of CO2 reduction for 2020 ahead of schedule, while 14.3% of the energy China consumes now comes from non-fossil fuel sources. [SEP] [CLS] These are hard-won results from the efforts of promoting a green and low carbon economy. [SEP] While becoming more efficient, China saw its annual carbon emissions nearly triple between 2000 and 2018 as the economy grew at a rapid pace.',\n",
       "       '[SEP] An artist by training and a producer by profession, Ms. Kodikara, who was born in England to Sri Lankan parents, had been involved with organizations championing immigration reform and helping asylum seekers, but, she said, “I hadn’t really thought about the connections between migration, immigration and climate because the common narratives hadn’t made climate appear relevant to black and brown people at all.” That changed after a conversation with her friend, Thanu Yakupitiyage, associate director of United States communications for 350.org, who had previously worked in immigration reform. [SEP] [CLS] I realized with all that has separated us from each other, climate justice is the great unifier. [SEP] She and the co-hosts “understand the value of supporting these women and listening to the knowledge that they’ve hoarded for generations,” Ms. Kodikara said.',\n",
       "       '[SEP] There are many unexplainable problems with the theory rising carbon-dioxide levels have caused global temperature to increase. [SEP] [CLS] Skeptics reject the claim global temperatures have risen in recent decades. [SEP] Virtually everyone agrees temperatures have increased, the primary issue is the reason or reasons for those increases.',\n",
       "       \"[SEP] “This Year Is Headed for the Hottest on Record, by a Long Shot,” claims Bloomberg Business. [SEP] [CLS] President Barack Obama's Clean Power Plan mandated drastic carbon dioxide emissions cuts from U.S. power plants. [SEP] For nearly 20 years now, the Western world has been battered by these so-called “inconvenient truths” about alleged human effects on global temperature.\",\n",
       "       '[SEP] Last week, a much-discussed new paper in the journal Nature seemed to suggest to some that we needn’t worry too much about the melting of Greenland, the mile-thick mass of ice at the top of the globe. [SEP] [CLS] The Greenland ice sheet seems to have survived a previous warm period in Earth’s history — the Eemian period. [SEP] But Ohio State University glaciologist Jason Box isn’t buying it.',\n",
       "       ' [SEP] [CLS] Temperature readings from the Arctic and Antarctic used to estimate the effects of global warming are nothing more than guesswork. [SEP] Dr Benny Peiser heads up the Global Warming Policy Foundation, which last month announced its intention to launch a wide-ranging review of the data underpinning claims on global warming.',\n",
       "       '[SEP] In this scenario, for Eazy-E read: you and me. [SEP] [CLS] Several leading climate scientists’ve got their facts wrong about global warming. [SEP] For “Business is business” read “the science is settled” – or “just trust us.',\n",
       "       '[SEP] Anyone that has the faintest doubt that this is so should force himself to read the ClimateGate documents which lay it bare. [SEP] [CLS] Lewis recruited over 200 members of APS to oppose the new APS policy that fully supports the global warming fraud. [SEP] Their request for a hearing on the issue was completely ignored.',\n",
       "       '[SEP] They believe, based on computer simulations of hiatus periods and measurements from new floating sensors, they can account for the “missing” heat, much of which they believe is deep in the ocean, more than 700 meters below the water’s surface. [SEP] [CLS] Climate-change skeptics earn mainstream adherents last year, as global temperatures hung perilously close to falling beneath even the lowest model projections. [SEP] “Apocalypse perhaps a little later,” as The Economist put it.',\n",
       "       \"[SEP] “Just like the recent case against Exxon-Mobil in New York that was dismissed, this case by ‘climate concerned children’ was prompted and powered by climate activist interests,” Anthony Watts, senior fellow at the Institute, said in a statement. [SEP] [CLS] The bottom line is that while yes, we've seen some changes in our climate over the past century, with improved crop yields, better health, reduced deaths from weather disasters, and increasingly less impoverishment worldwide, it is hard to argue that an increase of about 1 degree Centigrade has been detrimental to humanity. [SEP] “Ill-informed kids keep being manipulated by radical environmentalists to sue over purported future climate damages,” H. Sterling Burnett, also a fellow at the Institute for the environment and energy policy, said in the joint statement.\",\n",
       "       '[SEP] I challenge Thom Hartmann to name even one. [SEP] [CLS] Despite the threadbare efforts of the usual suspects to pin the blame on “ climate change ”, all the credible evidence suggests that this is about economic migration and about political instability, not about global warming. [SEP] As for those five million climate refugees.',\n",
       "       '[SEP] Earth’s sea levels should be nine meters higher than they are — and dramatic melting in Antarctica may soon plug the gap, scientists warn. [SEP] [CLS] Global temperatures today are the same as they are 115,000 years ago, a time when modern humans were only just beginning to leave Africa. [SEP] Research shows during this time period, known as the Eemian, scorching ocean temperatures caused a catastrophic global ice melt.',\n",
       "       '[SEP] \"It would require the court to substitute its judgment for that of Congress and the Administration on an unprecedented scale.\" [SEP] [CLS] However, it is unfortunate that, in coming to this conclusion, the court summarized the scientific evidence on climate change in such apocalyptic terms. [SEP] \"The Department of Justice should have made clear that its failure to contest this evidence did not mean that the evidence was incontestable.',\n",
       "       '[SEP] If we\\'re searching for \"global warming\" culprits, we might want to look at that 27,000,000 degree ball of gas in the sky. [SEP] [CLS] If human CO2 emissions are a primary driver of global temperatures, it wouldn\\'t make sense for temperatures to drop or stay stagnate while humanity only continues to increase its CO2 output. [SEP] But that\\'s exactly what\\'s happened.',\n",
       "       \"[SEP] Many who denied or disparaged the findings of climate science saw themselves as defenders of liberty and democracy. [SEP] [CLS] Climate change would be used as an excuse to expand `big government' and lead to a loss of personal freedom. [SEP] However, by delaying a reasonable and orderly transition from the fossil fuel economy into one that is not carbon-based, these same deniers were increasing the odds that as climate change turned into a crisis, extreme — even authoritarian — methods would be called upon to address it.\",\n",
       "       ' [SEP] [CLS] One of those pesky realist scientists whose research using awkward facts shows that global warming isn’t nearly the peril it’s cracked up to be and which may ultimately be one of the reasons why Flannery no longer has that $ 180,000 a year (for a three-day week) job. [SEP] By way of introduction, we should note that for nearly two centuries, The Economist has been a stalwart champion of free markets and free trade.',\n",
       "       '[SEP] When a ship carrying scientists and adventure tourists became stuck in ice in the Antarctic late last month, climate change skeptics had a field day. [SEP] [CLS] A group whose journey is meant to highlight the effects of global warming is trapped by a substance that is supposed to be melting. [SEP] “Global warming idiots out of danger,” one noted when the ship’s 52 passengers were finally helicoptered to safety Thursday after more than a week on the ice.',\n",
       "       '[SEP] Sorry, but no. [SEP] [CLS] This says no more about the validity of global warming theory than Einstein’s having shagged Marilyn Monroe says about the validity of his theory of relativity. [SEP] Interesting biographical details and personal tragedy have nothing to do with the scientific method.',\n",
       "       '[SEP] Oxfam also cites a study that suggested the 2011 drought in East Africa and famine in Somalia were made more likely by climate change. [SEP] [CLS] Natural events such as storms, floods, and droughts happen anyway and it is hard to blame particular occurrences on global warming. [SEP] On this, the panel is expected to say on Friday that extreme weather effects are more likely because of climate change, but will stop well short of attributing specific events solely to climate change.',\n",
       "       '[SEP] Event attribution — linking a given weather event to man-made global warming — is exceedingly speculative at best and completely unreliable at worst, even according to true believers. [SEP] [CLS] The alleged â\\x80\\x9c consensus â\\x80\\x9d behind the dangers of anthropogenic global warming is not nearly as settled among climate scientists as people imagine. [SEP] Author Kenneth Richard found that during the course of the year 2017, at least 485 scientific papers were published that in some way questioned the supposed consensus regarding the perils of human CO2 emissions or the efficacy of climate models to predict the future.',\n",
       "       '[SEP] The Coalition’s new white paper, Carbon Dioxide Benefits the World: See for Yourself, reviews the current state of climate science with particular attention to its biological impact. [SEP] [CLS] Global temperature increases have been far, far less than doomsday computer models predicted – about three times smaller. [SEP] Not only has this warming been small, but there is no real reason to think it’s harmful.',\n",
       "       '[SEP] In 2013 far left website Think Progress worried its readers with claims that climate change was “damaging” the lakes and would present “implications for the environment and the economy.”  The Natural Resource Defense Council even contemplated lawsuits to prevent cities on the lakes from tapping into them as a source of water. [SEP] [CLS] The water level is affected by things other than global warming. [SEP] In 2013 USA Today properly noted that some of the water drop was a result of the massive dredging campaigns launched by the U.S. Army Corps of Engineers, a project meant to allow shipping and transportation to more easily ply the waters of the Great Lakes.',\n",
       "       '[SEP] How does it happen that a whole generation of scientific experts is blind to obvious facts?\" [SEP] [CLS] Pollution caused by fossil fuels has been conflated with climate change. [SEP] “Coal is very unpleasant stuff, and there are problems with coal quite apart from climate,” he said.',\n",
       "       '[SEP] Others argue that it might even be a good thing: See: Rep. Joe Read (R-Mont. [SEP] [CLS] Global warming is beneficial to the welfare and business. [SEP] The end times are upon us.',\n",
       "       '[SEP] It’s effective.”  But as the new 2016 Gallup data suggests, influence on climate change belief also works the other way. [SEP] [CLS] Global warming effects will never occur, the lowest rate since 2000. [SEP] ',\n",
       "       '[SEP] Trump has been light on the details of his energy policy, though he recently told supporters in West Virginia that the coal industry would thrive if he were president. [SEP] [CLS] Global warming is a concept \"created by and for the Chinese\" to hurt U.S. business. [SEP] Clinton, meanwhile, has advocated shifting the country to 50 percent clean energy by 2030, promised heavy regulation of fracking, and said her prospective administration would put coal companies \"out of business.\"',\n",
       "       \"[SEP] Of course, it is often hard to know just how much influence any media company has. [SEP] [CLS] I don't think there is much need to address climate change because it is already a focal point across the rest of the media. [SEP] “It’s hard to distract from climate change because it’s spoken about constantly,” he said.\",\n",
       "       '[SEP] Trump has repeatedly called climate change a hoax and scoffs at the overwhelming body of scientific evidence that shows temperatures are rising. [SEP] [CLS] The concept of global warming is created by and for the Chinese in order to make U.S. manufacturing non-competitive. [SEP] The decision to pull out of the climate accord divided Trump’s White House staff.',\n",
       "       '[SEP] The Republican state party chairwoman, Susan Hutchison, said she thought that argument would backfire with voters in a state that already has one of the most environmentally friendly, low-carbon-emission energy profiles in the nation with its reliance on hydropower. [SEP] [CLS] Carrying a climate agenda even further, through measures like a carbon tax on gasoline, natural gas and other products, would hurt ordinary Washingtonians. [SEP] “With Steyer’s very radical environmental agenda, we’ve got the possibility of gas costing a dollar more per gallon,” she said.',\n",
       "       '[SEP] Charles and David Koch, billionaire industrialist brothers, have put millions of dollars into advocacy groups and super PACs like Americans for Prosperity, which have campaigned aggressively against lawmakers who support climate change policy. [SEP] [CLS] The global warming agenda is a loser for them with the American people. [SEP] Mr. Phillips said that none of the four most vulnerable Democratic senators — Mary L. Landrieu of Louisiana, Mark Begich of Alaska, Kay Hagan of North Carolina and Mark Pryor of Arkansas — had embraced climate change policy.',\n",
       "       '[SEP] Citing data from the EM-DAT International Disaster Database, Epstein explained that climate-related deaths have actually declined 98 percent over the last 80 years. [SEP] [CLS] If we look at the big picture, not only are the economic benefits [ of fossil fuels ] overwhelmingly positive, but the environmental benefits are overwhelmingly positive. [SEP] The U.N. has suffered a number of blows in its push for a climate agreement.',\n",
       "       '[SEP] Several economists say that worry is misplaced. [SEP] [CLS] Mr. Wall is exaggerating the impact of carbon taxes on investment decisions. [SEP] For the oil industry, “the carbon price is really a rounding error,” said Andrew Leach, an environmental economist at the University of Alberta in Edmonton.',\n",
       "       '[SEP] In the wake of hurricane Sandy, many have rushed to seize the opportunity as a platform for pushing forward their global warming agendas. [SEP] [CLS] We are instead seeing weather history repeat itself, and this poses an important question to activists pointing to Sandy as “ overwhelming evidence ” of global warming as its cause. [SEP] New York Governor Andrew Cuomo was one of the first to hit the microphone on the issue, when he spoke at a press conference on October 30th.',\n",
       "       '[SEP] Given Kerry’s subsequent description of climate and its underlying physics, it was clear that he was not up to the task. [SEP] [CLS] Lindzenâ\\x80\\x99s scientific case against the man-made global warming scare is essentially this. [SEP] Yet here they are deciding on the basis of no convincing evidence to pin the blame on just one of the many contributory elements to climate – carbon dioxide – and trying to persuade us that this trace gas is somehow the master control knob.',\n",
       "       '[SEP] Her name is Naomi Seibt, she’s 19 years old, but unlike some teenage activists we could mention she is most definitely not welcome at the UN’s COP25 climate conference. [SEP] [CLS] The global warming scare is a massive hoax. [SEP] Worse — and being a German, she should know — Naomi believes that her Chancellor’s green policies are steering her country inexorably towards the kind of totalitarianism it last experienced in the 1930s and the 1940s.',\n",
       "       '[SEP] But if you look at the facts, they tell a completely different story. [SEP] [CLS] Beef cattle produce only 3.3 percent of the total U.S. greenhouse gas emissions. [SEP] By comparison, the transportation and electrical industries generate 56 percent of our nation’s total GHG emissions.',\n",
       "       '[SEP] So, in Nature Communications there is a study claiming that \"climate deniers\" get too much media attention. [SEP] [CLS] 78 percent of the \"climate deniers\" whom the study paints as unscientific actually have articles published in peer-reviewed journals. [SEP] That study also based its assumptions off of the Cook study, which blatantly misrepresented data.',\n",
       "       '[SEP] “It’s a rare event that we’re still trying to understand,” Susan Strahan, an atmospheric scientist with the Universities Space Research Association, said in a statement. [SEP] [CLS] These scientific events are not linked to climate change. [SEP] ',\n",
       "       '[SEP] He’s probably the world’s greatest professor of atmospheric physics. [SEP] [CLS] The whole global warming thing is a scam. [SEP] The flaws in the alarmist position Lindzen exposed in 1992 remain the same today: the global warming scare story depends on hopelessly inadequate computer models which place too much emphasis on man-made CO2 and which therefore produce a “disturbingly arbitrary” picture of the state of climate.'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_dev_set.text.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "archive_file: ../BERT/LM_finetuned/uncased_LM_cc_output/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "config = BertConfig.from_pretrained(model_path, num_labels=3)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path,\n",
    "                                                          config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open (os.path.join(model_path,'vocab.txt'),'r') as f:\n",
    "    vocab = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = [l.strip() for l in vocab]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_dict = dict(zip(range(len(vocab)),vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_predict = eval_dev_set.text.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SEP] Their study, published Monday in the journal Nature Climate Change, says that most office buildings set temperatures based on a decades-old formula that uses the metabolic rates of men. [SEP] [CLS] Buildings should âreduce gender-discriminating bias in thermal comfortâ because setting temperatures at slightly warmer levels can help combat global warming. [SEP] “In a lot of buildings, you see energy consumption is a lot higher because the standard is calibrated for men’s body heat production,” said Boris Kingma, a co-author of the study and a biophysicist at Maastricht University Medical Center in the Netherlands.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'out' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-8012e45bb71f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_dev_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdev_ix\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mencoded_sent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0madd_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded_sent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sentences'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'labels'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'out' is not defined"
     ]
    }
   ],
   "source": [
    "for dev_ix in range(0,2):\n",
    "    sent = to_predict[dev_ix]\n",
    "    print(sent)\n",
    "    label = eval_dev_set.label.values[dev_ix]\n",
    "    encoded_sent = tokenizer.encode(sent,add_special_tokens=True)[1:]\n",
    "    out['input_ids'].append(encoded_sent)\n",
    "    out['sentences'].append(sent)\n",
    "    out['labels'].append(label)\n",
    "    \n",
    "out['input_ids'] = pad_sequences(\n",
    "        out['input_ids'], \n",
    "        maxlen=128, \n",
    "        dtype=\"long\", \n",
    "        value=0, \n",
    "        truncating=\"post\", \n",
    "        padding=\"post\")\n",
    "\n",
    "# get attn masks\n",
    "for sent in out['input_ids']:\n",
    "    tok_type_ids = [0 for tok_id in sent]\n",
    "    mask = [int(tok_id > 0) for tok_id in sent]\n",
    "    out['attention_mask'].append(mask)\n",
    "    out['token_type_ids'].append(tok_type_ids)\n",
    "print(len(out['labels']))\n",
    "print(sum(out['labels']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[SEP] Their study, published Monday in the journal Nature Climate Change, says that most office buildings set temperatures based on a decades-old formula that uses the metabolic rates of men. [SEP] [CLS] Buildings should â\\x80\\x9creduce gender-discriminating bias in thermal comfortâ\\x80\\x9d because setting temperatures at slightly warmer levels can help combat global warming. [SEP] “In a lot of buildings, you see energy consumption is a lot higher because the standard is calibrated for men’s body heat production,” said Boris Kingma, a co-author of the study and a biophysicist at Maastricht University Medical Center in the Netherlands.'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_sent = tokenizer.encode(sent,add_special_tokens=True)[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102 [SEP]\n",
      "2037 their\n",
      "2817 study\n",
      "1010 ,\n",
      "2405 published\n",
      "6928 monday\n",
      "1999 in\n",
      "1996 the\n",
      "3485 journal\n",
      "3267 nature\n",
      "4785 climate\n",
      "2689 change\n",
      "1010 ,\n",
      "2758 says\n",
      "2008 that\n",
      "2087 most\n",
      "2436 office\n",
      "3121 buildings\n",
      "2275 set\n",
      "7715 temperatures\n",
      "2241 based\n",
      "2006 on\n",
      "1037 a\n",
      "5109 decades\n",
      "1011 -\n",
      "2214 old\n",
      "5675 formula\n",
      "2008 that\n",
      "3594 uses\n",
      "1996 the\n",
      "21453 metabolic\n",
      "6165 rates\n",
      "1997 of\n",
      "2273 men\n",
      "1012 .\n",
      "102 [SEP]\n",
      "101 [CLS]\n",
      "3121 buildings\n",
      "2323 should\n",
      "2024 are\n",
      "8566 ##du\n",
      "3401 ##ce\n",
      "5907 gender\n",
      "1011 -\n",
      "5860 disc\n",
      "20026 ##rim\n",
      "19185 ##inating\n",
      "13827 bias\n",
      "1999 in\n",
      "9829 thermal\n",
      "7216 comfort\n",
      "2050 ##a\n",
      "2138 because\n",
      "4292 setting\n",
      "7715 temperatures\n",
      "2012 at\n",
      "3621 slightly\n",
      "16676 warmer\n",
      "3798 levels\n",
      "2064 can\n",
      "2393 help\n",
      "4337 combat\n",
      "3795 global\n",
      "12959 warming\n",
      "1012 .\n",
      "102 [SEP]\n",
      "1523 “\n",
      "1999 in\n",
      "1037 a\n",
      "2843 lot\n",
      "1997 of\n",
      "3121 buildings\n",
      "1010 ,\n",
      "2017 you\n",
      "2156 see\n",
      "2943 energy\n",
      "8381 consumption\n",
      "2003 is\n",
      "1037 a\n",
      "2843 lot\n",
      "3020 higher\n",
      "2138 because\n",
      "1996 the\n",
      "3115 standard\n",
      "2003 is\n",
      "10250 cal\n",
      "12322 ##ib\n",
      "9250 ##rated\n",
      "2005 for\n",
      "2273 men\n",
      "1521 ’\n",
      "1055 s\n",
      "2303 body\n",
      "3684 heat\n",
      "2537 production\n",
      "1010 ,\n",
      "1524 ”\n",
      "2056 said\n",
      "11235 boris\n",
      "2332 king\n",
      "2863 ##ma\n",
      "1010 ,\n",
      "1037 a\n",
      "2522 co\n",
      "1011 -\n",
      "3166 author\n",
      "1997 of\n",
      "1996 the\n",
      "2817 study\n",
      "1998 and\n",
      "1037 a\n",
      "16012 bio\n",
      "21281 ##phy\n",
      "19570 ##sic\n",
      "2923 ##ist\n",
      "2012 at\n",
      "5003 ma\n",
      "14083 ##ast\n",
      "13149 ##rich\n",
      "2102 ##t\n",
      "2118 university\n",
      "2966 medical\n",
      "2415 center\n",
      "1999 in\n",
      "1996 the\n",
      "4549 netherlands\n",
      "1012 .\n",
      "102 [SEP]\n"
     ]
    }
   ],
   "source": [
    "for id_ in encoded_sent:\n",
    "    print(id_,vocab_dict[id_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "objs = [{'input_ids':torch.LongTensor([list(out['input_ids'][ix])]),\n",
    "        'token_type_ids':torch.LongTensor([out['token_type_ids'][ix]]),\n",
    "        'attention_mask':torch.LongTensor([out['attention_mask'][ix]])} \n",
    "        for ix in range(len(out['input_ids']))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feed processed 'out' to model for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "modeled_logits = [model(**objs[ix])[0] for ix in range(len(objs))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeled_results = [torch.softmax(x, dim=1).tolist()[0] \n",
    "                  for x in modeled_logits]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = [get_pred_label(x) for x in modeled_results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0]"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import torch\n",
    "import pandas as pd\n",
    "from transformers import BertTokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from tensorboardX import SummaryWriter\n",
    "import numpy as np\n",
    "import time\n",
    "import datetime\n",
    "import random\n",
    "from collections import defaultdict\n",
    "import argparse\n",
    "import os\n",
    "import scipy\n",
    "import sklearn\n",
    "import math\n",
    "\n",
    "CUDA = (torch.cuda.device_count() > 0)\n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "# # Required parameters\n",
    "# parser.add_argument(\n",
    "#     \"--max_seq_len\",\n",
    "#     default=512,\n",
    "#     type=int,\n",
    "#     help=\"max seq len\"\n",
    "# )\n",
    "# parser.add_argument(\n",
    "#     \"--context_size\",\n",
    "#     default=0,\n",
    "#     type=int,\n",
    "#     help=\"num messages to include in context\"\n",
    "# )\n",
    "# parser.add_argument(\n",
    "#     \"--working_dir\",\n",
    "#     default='working_dir',\n",
    "#     type=str,\n",
    "#     help=\"num messages to include in context\"\n",
    "# )\n",
    "# parser.add_argument(\n",
    "#     \"--epochs\",\n",
    "#     default=70,\n",
    "#     type=int,\n",
    "#     help=\"fine tuning epochs\"\n",
    "# )\n",
    "# parser.add_argument(\n",
    "#     \"--batch_size\",\n",
    "#     default=10,\n",
    "#     type=int,\n",
    "#     help=\"fine tuning epochs\"\n",
    "# )\n",
    "# parser.add_argument(\n",
    "#     \"--learning_rate\",\n",
    "#     default=2e-5,\n",
    "#     type=int,\n",
    "#     help=\"fine tuning epochs\"\n",
    "# )\n",
    "# parser.add_argument(\n",
    "#     \"--seed\",\n",
    "#     default=420,\n",
    "#     type=int,\n",
    "#     help=\"fine tuning epochs\"\n",
    "# )\n",
    "# parser.add_argument(\n",
    "#     \"--length_discard\",\n",
    "#     action='store_true',\n",
    "#     help=\"discard examples that are too long\"\n",
    "# )\n",
    "# parser.add_argument(\n",
    "#     \"--include_metadata\",\n",
    "#     action='store_true',\n",
    "#     help=\"discard examples that are too long\"\n",
    "# )\n",
    "# parser.add_argument(\n",
    "#     \"--downsample\",\n",
    "#     default=0.2,\n",
    "#     type=float,\n",
    "#     help=\"p = prop examples to throw out\"\n",
    "# )\n",
    "# ARGS = parser.parse_args()\n",
    "\n",
    "\n",
    "# random.seed(ARGS.seed)\n",
    "# np.random.seed(ARGS.seed)\n",
    "# torch.manual_seed(ARGS.seed)\n",
    "# torch.cuda.manual_seed_all(ARGS.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSES = ['for','against','neutral']\n",
    "NUM_LABELS = 3\n",
    "\n",
    "def get_pred_label(res_,to_str=False):\n",
    "    if to_str:\n",
    "        return CLASSES[res_.index(max(res_))]\n",
    "    else:\n",
    "        return res_.index(max(res_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data_creation/scripts/save/mturk_windowed_1_downsampled\n",
      "../BERT/LM_finetuned/uncased_LM_cc_output\n"
     ]
    }
   ],
   "source": [
    "PRETRAINED_MODELS_DIR = '../BERT/trained_models'\n",
    "\n",
    "DATA_NAME = 'mturk_windowed_1_downsampled'\n",
    "BASE_MOD = 'uncased_LM'\n",
    "CASING = 'uncased'\n",
    "DATA_DIR = os.path.join('../data_creation/scripts/save',DATA_NAME)\n",
    "print(DATA_DIR)\n",
    "\n",
    "#model_path = os.path.join(PRETRAINED_MODELS_DIR,DATA_NAME,BASE_MOD,\n",
    "#                         CASING)\n",
    "model_path = '../BERT/LM_finetuned/uncased_LM_cc_output'\n",
    "print(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    \n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1234"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_out_data(dat_path,max_seq_length=500):\n",
    "    #eval_set = 'train' # can also be 'test'\n",
    "    data = pd.read_csv(dat_path,\n",
    "                              sep='\\t',header=None)\n",
    "    data.columns = ['text','label']#,'outlet']\n",
    "    \n",
    "    out = defaultdict(list)\n",
    "    \n",
    "    print('Number of examples to predict:',len(data))\n",
    "    to_predict = data.text.values\n",
    "    true = data.label.values\n",
    "    \n",
    "    for dat_ix in range(len(data)):\n",
    "        sent = to_predict[dat_ix]\n",
    "        #print(sent)\n",
    "        label = true[dat_ix]\n",
    "        encoded_sent = tokenizer.encode(sent,add_special_tokens=True)\n",
    "        out['input_ids'].append(encoded_sent)\n",
    "        out['sentences'].append(sent)\n",
    "        out['label'].append(label)\n",
    "\n",
    "    out['input_ids'] = pad_sequences(\n",
    "            out['input_ids'], \n",
    "            maxlen=max_seq_length, \n",
    "            dtype=\"long\", \n",
    "            value=0, \n",
    "            truncating=\"post\", \n",
    "            padding=\"post\")\n",
    "\n",
    "\n",
    "    print('Adding attention masks...')\n",
    "    # get attn masks\n",
    "    for sent in out['input_ids']:\n",
    "        tok_type_ids = [0 for tok_id in sent]\n",
    "        mask = [int(tok_id > 0) for tok_id in sent]\n",
    "        out['attention_mask'].append(mask)\n",
    "        out['token_type_ids'].append(tok_type_ids)\n",
    "    #print(len(out['labels']))\n",
    "    #print(sum(out['labels']))\n",
    "    \n",
    "    print('Preparing input examples for prediction...')\n",
    "    #out['input_ids'] = [torch.LongTensor(x) for x in out['input_ids']]\n",
    "#     objs = [{'input_ids':torch.LongTensor([list(out['input_ids'][ix])]),\n",
    "#         'token_type_ids':torch.LongTensor([out['token_type_ids'][ix]]),\n",
    "#         'attention_mask':torch.LongTensor([out['attention_mask'][ix]]),\n",
    "#             'label':torch.LongTensor([out['label'][ix]])} \n",
    "#         for ix in range(len(out['input_ids']))]\n",
    "\n",
    "#     objs = [{'input_ids':[list(out['input_ids'][ix])],\n",
    "#         'token_type_ids':[out['token_type_ids'][ix]],\n",
    "#         'attention_mask':[out['attention_mask'][ix]],\n",
    "#             'label':[out['label'][ix]]} \n",
    "#         for ix in range(len(out['input_ids']))]\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORKING_DIR = '.'\n",
    "writer = SummaryWriter(WORKING_DIR + '/events')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "archive_file: ../BERT/LM_finetuned/uncased_LM_cc_output/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "# Load model\n",
    "config = BertConfig.from_pretrained(model_path, num_labels=NUM_LABELS)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path,\n",
    "                                                          config=config)\n",
    "with open(os.path.join(model_path,'vocab.txt'),'r') as f:\n",
    "    vocab = f.readlines()\n",
    "vocab = [l.strip() for l in vocab]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of examples to predict: 823\n",
      "Adding attention masks...\n",
      "Preparing input examples for prediction...\n"
     ]
    }
   ],
   "source": [
    "# if os.path.exists(WORKING_DIR + \"/data.cache.pkl\"):\n",
    "#     data = pickle.load(open(WORKING_DIR + \"/data.cache.pkl\", 'rb'))\n",
    "# else:\n",
    "data = get_out_data(os.path.join(DATA_DIR, 'train.tsv'))\n",
    "pickle.dump(data, open(WORKING_DIR + \"/data.cache.pkl\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 472,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_inputs, test_inputs, train_labels, test_labels, train_masks, test_masks, = train_test_split(\n",
    "    data['input_ids'], data['label'], data['attention_mask'],\n",
    "    random_state=SEED, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def build_dataloader(*args, sampler='random'):\n",
    "    #print(args[:2])\n",
    "    data = (torch.tensor(x) for x in args)\n",
    "    #print(data[0])\n",
    "    data = TensorDataset(*data)\n",
    "\n",
    "    #sampler = RandomSampler(data) if sampler == 'random' else SequentialSampler(data)\n",
    "    dataloader = DataLoader(data, batch_size=1)\n",
    "\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_dataloader = build_dataloader(\n",
    "    train_inputs[:100], train_labels[:100], train_masks[:100])\n",
    "test_dataloader = build_dataloader(\n",
    "    test_inputs, test_labels, test_masks,\n",
    "    sampler='order')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARN_RATE=2e-5\n",
    "optimizer = AdamW(model.parameters(), lr=LEARN_RATE, eps=1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS=1\n",
    "total_steps = len(train_dataloader) * NUM_EPOCHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer, num_warmup_steps=0, num_training_steps=total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CUDA:\n",
    "    model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 509,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 510,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Average training loss: 0.60\n",
      "  Training epcoh took: 0:05:23\n",
      "\n",
      "Running Validation...\n",
      "  Loss: 0.60\n",
      "  Accuracy: 0.42\n",
      "  F1: 0.26\n",
      "  Validation took: 0:05:23\n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "for epoch_i in range(0, NUM_EPOCHS):\n",
    "    \n",
    "#     # ========================================\n",
    "#     #               Training\n",
    "#     # ========================================\n",
    "#     print(\"\")\n",
    "#     print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, NUM_EPOCHS))\n",
    "#     print('Training...')\n",
    "\n",
    "#     losses = []\n",
    "#     t0 = time.time()\n",
    "#     model.train()\n",
    "#     for step, batch in enumerate(train_dataloader):\n",
    "#         #print(step,batch)\n",
    "\n",
    "#         if step % 40 == 0 and not step == 0:\n",
    "#             elapsed = format_time(time.time() - t0)\n",
    "#             print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}. Loss: {:.2f}'.format(\n",
    "#                 step, len(train_dataloader), elapsed, float(np.mean(losses))))\n",
    "\n",
    "#         if CUDA:\n",
    "#             batch = (x.cuda() for x in batch)            \n",
    "#         input_ids, labels, masks = batch\n",
    "#         model.zero_grad()        \n",
    "\n",
    "#         outputs = model(\n",
    "#             input_ids,\n",
    "#             attention_mask=masks, \n",
    "#             labels=labels)\n",
    "        \n",
    "#         print(len(outputs))\n",
    "        \n",
    "#         #loss, _, _ = outputs\n",
    "#         loss, _ = outputs\n",
    "#         losses.append(loss.item())\n",
    "\n",
    "#         loss.backward()\n",
    "#         torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "#         optimizer.step()\n",
    "#         scheduler.step()\n",
    "\n",
    "#     avg_loss = np.mean(losses)\n",
    "#     writer.add_scalar('train/loss', np.mean(avg_loss), epoch_i)\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_loss))\n",
    "    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n",
    "        \n",
    "    # ========================================\n",
    "    #               Validation\n",
    "    # ========================================\n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\")\n",
    "\n",
    "#     t0 = time.time()\n",
    "#     model.eval()\n",
    "#     losses = []\n",
    "#     all_preds = []\n",
    "#     all_labels = []\n",
    "#     log = open(WORKING_DIR + '/epoch%d.log' % epoch_i, 'w')\n",
    "#     for step, batch in enumerate(test_dataloader):\n",
    "\n",
    "#         if CUDA:\n",
    "#             batch = (x.cuda() for x in batch)            \n",
    "#         input_ids, labels, masks = batch\n",
    "\n",
    "#         with torch.no_grad():        \n",
    "#             outputs = model(\n",
    "#                 input_ids,\n",
    "#                 attention_mask=masks, \n",
    "#                 labels=labels)\n",
    "#         #loss, logits, attns = outputs\n",
    "#         loss, logits = outputs\n",
    "\n",
    "#         losses.append(loss.item())\n",
    "\n",
    "#         labels = labels.cpu().numpy()\n",
    "#         input_ids = input_ids.cpu().numpy()\n",
    "#         preds = scipy.special.softmax(logits.cpu().numpy(), axis=1)\n",
    "#         input_toks = [\n",
    "#             tokenizer.convert_ids_to_tokens(s) for s in input_ids\n",
    "#         ]\n",
    "\n",
    "#         for seq, label, pred in zip(input_toks, labels, preds):\n",
    "#             sep_char = '+' if np.argmax(pred) == label else '-'\n",
    "#             log.write(sep_char * 40 + '\\n')\n",
    "#             log.write(' '.join(seq) + '\\n')\n",
    "#             log.write('label: ' + str(label) + '\\n')\n",
    "#             log.write('pred: ' + str(np.argmax(pred)) + '\\n')\n",
    "#             log.write('dist: ' + str(pred) + '\\n')\n",
    "#             log.write('\\n\\n')\n",
    "\n",
    "#             all_preds += [pred]\n",
    "#             all_labels += [label]\n",
    "#     log.close()\n",
    "#     all_preds = np.array(all_preds)\n",
    "#     all_labels = np.array(all_labels)\n",
    "\n",
    "    avg_loss = np.mean(losses)\n",
    "    f1 = sklearn.metrics.f1_score(all_labels, np.argmax(all_preds, axis=1),average='macro')\n",
    "    acc = sklearn.metrics.accuracy_score(all_labels, np.argmax(all_preds, axis=1))\n",
    "    #auc = sklearn.metrics.roc_auc_score(all_labels, all_preds[:, 1])\n",
    "\n",
    "    writer.add_scalar('eval/acc', acc, epoch_i)\n",
    "    #writer.add_scalar('eval/auc', auc, epoch_i)\n",
    "    writer.add_scalar('eval/f1', f1, epoch_i)\n",
    "    writer.add_scalar('eval/loss', f1, epoch_i)\n",
    "\n",
    "    print(\"  Loss: {0:.2f}\".format(avg_loss))\n",
    "    print(\"  Accuracy: {0:.2f}\".format(acc))\n",
    "    print(\"  F1: {0:.2f}\".format(f1))\n",
    "    #print(\"  AUC: {0:.2f}\".format(auc))\n",
    "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
    "\n",
    "print(\"\")\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
