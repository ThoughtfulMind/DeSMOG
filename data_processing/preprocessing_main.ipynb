{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/yiweiluo/scientific-debates\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import datetime\n",
    "import pickle\n",
    "import json\n",
    "import time\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import nltk\n",
    "from collections import Counter\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer,PorterStemmer\n",
    "  \n",
    "lemmatizer = WordNetLemmatizer()\n",
    "ps = PorterStemmer()\n",
    "\n",
    "os.chdir('..')\n",
    "print(os.getcwd())\n",
    "from utils import get_fulltext,get_fname,fulltext_exists\n",
    "os.chdir('./data_processing/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "      <th>domain</th>\n",
       "      <th>stance</th>\n",
       "      <th>topic</th>\n",
       "      <th>is_AP</th>\n",
       "      <th>year</th>\n",
       "      <th>pretty_domain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>www.buzzfeednews.com/article/tasneemnashrulla/...</td>\n",
       "      <td>\"eat the babies\" viral video at aoc town hall ...</td>\n",
       "      <td>2019-10-04 00:00:00</td>\n",
       "      <td>buzzfeed</td>\n",
       "      <td>pro</td>\n",
       "      <td>cc</td>\n",
       "      <td>None</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>Buzzfeed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>www.buzzfeednews.com/article/passantino/extrem...</td>\n",
       "      <td>\"extremely likely\" global warming is man-made,...</td>\n",
       "      <td>2013-09-27 00:00:00</td>\n",
       "      <td>buzzfeed</td>\n",
       "      <td>pro</td>\n",
       "      <td>cc</td>\n",
       "      <td>None</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>Buzzfeed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>shotofprevention.com/2010/11/03/history-makes-...</td>\n",
       "      <td>\"history\" makes headlines with launch of new w...</td>\n",
       "      <td>2020-03-13 14:32:02</td>\n",
       "      <td>https://shotofprevention/</td>\n",
       "      <td>pro</td>\n",
       "      <td>vax</td>\n",
       "      <td>False</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>Shot of Prevention</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>www.buzzfeednews.com/article/andrewkaczynski/i...</td>\n",
       "      <td>\"it's global warming, stupid\" - buzzfeed news</td>\n",
       "      <td>2012-11-01 00:00:00</td>\n",
       "      <td>buzzfeed</td>\n",
       "      <td>pro</td>\n",
       "      <td>cc</td>\n",
       "      <td>None</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>Buzzfeed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>www.buzzfeednews.com/article/tasneemnashrulla/...</td>\n",
       "      <td>\"japan dropped an atomic bomb on america durin...</td>\n",
       "      <td>2014-02-24 00:00:00</td>\n",
       "      <td>buzzfeed</td>\n",
       "      <td>pro</td>\n",
       "      <td>cc</td>\n",
       "      <td>None</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>Buzzfeed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>www.buzzfeednews.com/article/llevin/opinion-im...</td>\n",
       "      <td>\"look at my record, child\": joe biden showed m...</td>\n",
       "      <td>2019-10-31 00:00:00</td>\n",
       "      <td>buzzfeed</td>\n",
       "      <td>pro</td>\n",
       "      <td>cc</td>\n",
       "      <td>None</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>Buzzfeed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>www.breitbart.com/politics/2019/06/14/orourke-...</td>\n",
       "      <td>\"president o'rourke will end oil and gas lease...</td>\n",
       "      <td>2019-06-14 00:00:00</td>\n",
       "      <td>breitbart</td>\n",
       "      <td>anti</td>\n",
       "      <td>cc</td>\n",
       "      <td>None</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>Breitbart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>www.buzzfeednews.com/article/andrewkaczynski/s...</td>\n",
       "      <td>smoking doesnt kill and other great old opeds ...</td>\n",
       "      <td>2015-03-31 00:00:00</td>\n",
       "      <td>buzzfeed</td>\n",
       "      <td>pro</td>\n",
       "      <td>cc</td>\n",
       "      <td>None</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>Buzzfeed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>www.foxnews.com/world/100-carbon-tax-by-2030-c...</td>\n",
       "      <td>$100 carbon tax by 2030 could save climate, sa...</td>\n",
       "      <td>2017-05-29 00:00:00</td>\n",
       "      <td>fox</td>\n",
       "      <td>anti</td>\n",
       "      <td>cc</td>\n",
       "      <td>None</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>Fox</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21585</th>\n",
       "      <td>childrenshealthdefense.org/news/4-billion-and-...</td>\n",
       "      <td>$4 billion and growing:  u.s. payouts for vacc...</td>\n",
       "      <td>2018-11-19 00:00:00</td>\n",
       "      <td>chd</td>\n",
       "      <td>anti</td>\n",
       "      <td>vax</td>\n",
       "      <td>None</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>Children's Health Defense</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     url  \\\n",
       "0      www.buzzfeednews.com/article/tasneemnashrulla/...   \n",
       "1      www.buzzfeednews.com/article/passantino/extrem...   \n",
       "2      shotofprevention.com/2010/11/03/history-makes-...   \n",
       "3      www.buzzfeednews.com/article/andrewkaczynski/i...   \n",
       "4      www.buzzfeednews.com/article/tasneemnashrulla/...   \n",
       "5      www.buzzfeednews.com/article/llevin/opinion-im...   \n",
       "6      www.breitbart.com/politics/2019/06/14/orourke-...   \n",
       "7      www.buzzfeednews.com/article/andrewkaczynski/s...   \n",
       "8      www.foxnews.com/world/100-carbon-tax-by-2030-c...   \n",
       "21585  childrenshealthdefense.org/news/4-billion-and-...   \n",
       "\n",
       "                                                   title                 date  \\\n",
       "0      \"eat the babies\" viral video at aoc town hall ...  2019-10-04 00:00:00   \n",
       "1      \"extremely likely\" global warming is man-made,...  2013-09-27 00:00:00   \n",
       "2      \"history\" makes headlines with launch of new w...  2020-03-13 14:32:02   \n",
       "3          \"it's global warming, stupid\" - buzzfeed news  2012-11-01 00:00:00   \n",
       "4      \"japan dropped an atomic bomb on america durin...  2014-02-24 00:00:00   \n",
       "5      \"look at my record, child\": joe biden showed m...  2019-10-31 00:00:00   \n",
       "6      \"president o'rourke will end oil and gas lease...  2019-06-14 00:00:00   \n",
       "7      smoking doesnt kill and other great old opeds ...  2015-03-31 00:00:00   \n",
       "8      $100 carbon tax by 2030 could save climate, sa...  2017-05-29 00:00:00   \n",
       "21585  $4 billion and growing:  u.s. payouts for vacc...  2018-11-19 00:00:00   \n",
       "\n",
       "                          domain stance topic  is_AP    year  \\\n",
       "0                       buzzfeed    pro    cc   None  2019.0   \n",
       "1                       buzzfeed    pro    cc   None  2013.0   \n",
       "2      https://shotofprevention/    pro   vax  False  2020.0   \n",
       "3                       buzzfeed    pro    cc   None  2012.0   \n",
       "4                       buzzfeed    pro    cc   None  2014.0   \n",
       "5                       buzzfeed    pro    cc   None  2019.0   \n",
       "6                      breitbart   anti    cc   None  2019.0   \n",
       "7                       buzzfeed    pro    cc   None  2015.0   \n",
       "8                            fox   anti    cc   None  2017.0   \n",
       "21585                        chd   anti   vax   None  2018.0   \n",
       "\n",
       "                   pretty_domain  \n",
       "0                       Buzzfeed  \n",
       "1                       Buzzfeed  \n",
       "2             Shot of Prevention  \n",
       "3                       Buzzfeed  \n",
       "4                       Buzzfeed  \n",
       "5                       Buzzfeed  \n",
       "6                      Breitbart  \n",
       "7                       Buzzfeed  \n",
       "8                            Fox  \n",
       "21585  Children's Health Defense  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle('../data_scraping/dedup_combined_df.pkl')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contents:\n",
    "* [Define functions](#Define-functions)\n",
    "* [Extract clausal complements with SpaCy](#Extract-embedded-clauses-with-SpaCy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We add a neural coref resolution step to the default SpaCy pipeline: https://github.com/huggingface/neuralcoref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.lang.en.English at 0x133fa2f28>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# First way we can control a parameter\n",
    "#neuralcoref.add_to_pipe(nlp, greedyness=0.75)\n",
    "import neuralcoref\n",
    "neuralcoref.add_to_pipe(nlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper functions for the main ```get_quotes``` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_good_verb_dep(dep):\n",
    "    return dep[:3] == 'aux' or dep[:3] == 'adv' or dep == 'det' or dep == 'rel' or dep == 'prep' or dep[-3:] == 'obj' or dep[-3:] == 'mod' or dep == 'prt' or (dep[-4:] == 'comp' and dep != 'ccomp')\n",
    "\n",
    "def is_good_subj_dep(dep):\n",
    "    return dep != 'ccomp'\n",
    "\n",
    "def is_ROOT(tok):\n",
    "    return tok.dep_ == 'ROOT' or tok.dep_[-2:] == 'cl' or tok.dep_ == 'ccomp' or \\\n",
    "            (tok.dep_ == 'conj' and tok.head.dep_ == 'ROOT')\n",
    "\n",
    "REL_PRONOUNS = set(['who', 'whom', 'whose', 'which', 'that'])\n",
    "def is_rel_pronoun(tok):\n",
    "    tok = tok.lower().strip()\n",
    "    return tok in REL_PRONOUNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def get_quotes(text):\n",
    "    # Do coref resolution\n",
    "    doc = nlp(text)\n",
    "    text = doc._.coref_resolved\n",
    "    \n",
    "    quote_objs = []\n",
    "    \n",
    "    for sent in sent_tokenize(text):#d.sents:\n",
    "        #print(sent)\n",
    "        sent = nlp(sent)\n",
    "        # Go through entire sentence, looking for verbs embedding a complement clause\n",
    "        VERBS = np.unique([token.head for token in sent if token.dep_ == 'ccomp'])\n",
    "        #print(VERBS)\n",
    "       \n",
    "        # Extract everything else for each VERB\n",
    "        for VERB in VERBS:\n",
    "            #print(\"\\nCcomp dependency found! For quoting verb '{}'\".format(VERB))\n",
    "            # Extract the rest of the quoting verb\n",
    "            verb_deps = [x for x in VERB.children if is_good_verb_dep(x.dep_)]\n",
    "            #print(\"\\tFound children:\",verb_deps)\n",
    "            for x in verb_deps:\n",
    "                new_children = [c for c in x.children if is_good_verb_dep(c.dep_)]\n",
    "                #print(\"\\tAdding children of {}:\".format(x.text),new_children)\n",
    "                verb_deps.extend(new_children)\n",
    "                #print(\"\\tUpdated verb deps:\",verb_deps)\n",
    "            \n",
    "            # If verb's head is not itself (i.e., verb is not the ROOT), \n",
    "            # recursively trace back to ROOT, then add all children of ROOT\n",
    "            ROOT = VERB\n",
    "            while not is_ROOT(ROOT):\n",
    "                ROOT = ROOT.head\n",
    "                #print('\\t\\tCurrent root:',ROOT)\n",
    "            if VERB is not ROOT:\n",
    "                verb_deps.append(ROOT) \n",
    "                \n",
    "            #print(\"\\tAdding children of ROOT...\")\n",
    "            root_deps = [x for x in ROOT.children if is_good_verb_dep(x.dep_)]\n",
    "            #print(\"\\tFound ROOT deps:\",root_deps)\n",
    "            for x in root_deps:\n",
    "                new_children = [c for c in x.children if is_good_verb_dep(c.dep_)]\n",
    "                #print(\"\\tAdding children of {}:\".format(x.text),new_children)\n",
    "                root_deps.extend(new_children)\n",
    "                #print(\"\\tUpdated ROOT deps:\",root_deps)\n",
    "\n",
    "            #print(\"\\tAdding ROOT deps to verb deps...\")\n",
    "            verb_deps.extend([x for x in root_deps if x != VERB and x not in verb_deps])\n",
    "            #print(\"\\tUpdated verb deps:\",verb_deps)\n",
    "            \n",
    "            NEG,IS_NEG,neg_children = None,None,None\n",
    "            SUBJECT,subj_children = None,None\n",
    "                \n",
    "            #print(\"\\nLooking for SUBJECT and NEGATION(s)...\")\n",
    "            for child in ROOT.children:\n",
    "                if child.dep_[:5] == 'nsubj' or child.dep_ == 'expl':\n",
    "                    SUBJECT = child\n",
    "                    #print(\"\\tFound SUBJECT:\",SUBJECT)\n",
    "                    if SUBJECT.head.dep_ == 'relcl' and is_rel_pronoun(SUBJECT.text): # we're dealing with the subject of a rel clause\n",
    "                        #print(\"\\tFound quote inside a relative clause. Finding antecedent subject...\")\n",
    "                        SUBJECT = SUBJECT.head.head\n",
    "                        #print(\"\\tTrue subject:\",SUBJECT)\n",
    "                    #print(\"Subject token '{}' is in a coref cluster:\".format(SUBJECT),SUBJECT._.in_coref)\n",
    "                \n",
    "                if child.dep_[:3] == 'neg':\n",
    "                    NEG = child\n",
    "                    verb_deps.append(NEG)\n",
    "                    neg_children = [c for c in NEG.children if c != VERB]\n",
    "                    #print(\"n\\tAdding new NEG children:\",neg_children)\n",
    "                    for x in neg_children:\n",
    "                        new_children = [c for c in x.children]\n",
    "                        #print(\"\\tNew NEG grandchildren:\",new_children)\n",
    "                        neg_children.extend(new_children)\n",
    "                        #print(\"\\tUpdated neg_children:\",neg_children)\n",
    "                    verb_deps.extend(neg_children)\n",
    "                    #print(\"\\tUpdated verb_deps:\",verb_deps)\n",
    "                    IS_NEG = VERB in NEG.head.children or VERB == NEG.head\n",
    "            \n",
    "            if SUBJECT is None and (ROOT.dep_ == 'acl' or ROOT.dep_ == 'advcl'):\n",
    "                main_verb = ROOT.head\n",
    "                #print([(c.text,c.dep_) for c in main_verb.children])\n",
    "                SUBJS = [c for c in main_verb.children if c.dep_[:5] == 'nsubj' or c.dep_ == 'expl']\n",
    "                SUBJECT = SUBJS[0] if len(SUBJS) > 0 else None\n",
    "           \n",
    "            # Get rest of subject tokens\n",
    "            if SUBJECT is not None:\n",
    "                #print(\"\\nFound SUBJECT:\",SUBJECT)\n",
    "                #print(\"\\tAdding children of SUBJECT...\")\n",
    "                subj_children = [c for c in SUBJECT.children if is_good_subj_dep(c.dep_)]\n",
    "                #print(\"\\tFound children:\",subj_children)\n",
    "                for x in subj_children:\n",
    "                    new_children = [c for c in x.children if is_good_subj_dep(c.dep_)]\n",
    "                    #print(\"\\tAdding children of child {}:\".format(x.text),new_children)\n",
    "                    subj_children.extend(new_children)\n",
    "                    #print(\"\\tUpdated subject children:\",subj_children)\n",
    "\n",
    "            sorted_verb_tokens = sorted([(c,c.i) for c in verb_deps+[VERB]],key=lambda x:x[1])\n",
    "            #print(\"\\n\\tSorted verb tokens:\",sorted_verb_tokens)\n",
    "            if SUBJECT is not None:\n",
    "                sorted_subj_tokens = sorted([(c,c.i) for c in subj_children+[SUBJECT]],key=lambda x:x[1])\n",
    "                #print(\"\\tSorted subject tokens:\",sorted_subj_tokens)\n",
    "            else:\n",
    "                sorted_subj_tokens = None\n",
    "            if NEG is not None:\n",
    "                sorted_neg_tokens = sorted([(c,c.i) for c in neg_children+[NEG]],key=lambda x:x[1])\n",
    "            else:\n",
    "                sorted_neg_tokens = None\n",
    "\n",
    "            #print(\"\\nFinding quote introduced by '{}'...\".format(VERB))\n",
    "            emb_main_verbs = [c for c in VERB.children if c.dep_ == 'ccomp']\n",
    "            #print(\"\\tMain verbs of embedded clause:\",emb_main_verbs)\n",
    "            #assert len(emb_main_verbs) <= 2\n",
    "            for emb_main_verb in emb_main_verbs:\n",
    "                #print(\"\\tMain *verb*:\",emb_main_verb)\n",
    "\n",
    "                # Recursively get all children of main verb of embedded clause \n",
    "                #print(\"\\nRecursively getting children of main verb of embedded clause...\\n\")\n",
    "                #print(\"*\"*50)\n",
    "                children_queue = [x for x in emb_main_verb.children]\n",
    "                #print(\"\\tAdding children of main verb:\",children_queue)\n",
    "                for x in children_queue:\n",
    "                    new_children = [c for c in x.children]\n",
    "                    #print(\"\\tAdding children of {}:\".format(x.text),new_children)\n",
    "                    children_queue.extend(new_children)\n",
    "                    #print(\"\\tNew children queue:\",children_queue)\n",
    "\n",
    "                # Sort children and matrix verb to be in correct order\n",
    "                #print(\"\\nSorting tokens in quote...\")\n",
    "                children_and_indices = [(c,c.i) for c in children_queue+[emb_main_verb]]\n",
    "                sorted_ = sorted(children_and_indices,key=lambda x:x[1])\n",
    "                quote_objs.append({'quote':[tup[0].text for tup in sorted_],\n",
    "                        'verb tokens':[tup[0].text for tup in sorted_verb_tokens],\n",
    "                        'main verb':VERB.text,\n",
    "                       'subject tokens':[tup[0].text for tup in sorted_subj_tokens] if sorted_subj_tokens is not None else None,\n",
    "                       'main subject':SUBJECT.text if SUBJECT is not None else None,\n",
    "                       'neg tokens':[tup[0].text for tup in sorted_neg_tokens] if sorted_neg_tokens is not None else None,\n",
    "                       'main neg':NEG.text if NEG is not None else None,\n",
    "                       'is neg':IS_NEG})\n",
    "    \n",
    "    return quote_objs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Extract clausal complements with SpaCy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "(Did this part on the cluster.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "s = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.651726722717285"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time.time()-s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## First 100 URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "www.buzzfeednews.com[SEP]article[SEP]tasneemnashrulla[SEP]eat-babies-aoc-town-hall-pro-trump-troll-larouche\tElapsed time in seconds: 0.05031239986419678\n"
     ]
    }
   ],
   "source": [
    "for url_ix in range(0,1):\n",
    "    start_time = time.time()\n",
    "    curr_url = df.url.values[url_ix]\n",
    "    quotes = get_quotes(get_fulltext(curr_url)[0])\n",
    "    fname = get_fname(curr_url)\n",
    "    with open('./extracted_quotes/{}.jsonlist'.format(fname),'w+') as f:\n",
    "        for res in quotes:\n",
    "            json.dump(res, f)\n",
    "            f.write('\\n')\n",
    "    print('{}\\tElapsed time in seconds:'.format(fname),(time.time()-start_time)/60.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "curr_url_ix = 1\n",
    "curr_url = df.url.values[curr_url_ix]\n",
    "quotes = get_quotes(get_fulltext(curr_url)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "www.buzzfeednews.com[SEP]article[SEP]tasneemnashrulla[SEP]eat-babies-aoc-town-hall-pro-trump-troll-larouche\n"
     ]
    }
   ],
   "source": [
    "fname = get_fname(curr_url)\n",
    "print(fname)\n",
    "with open('./extracted_quotes/{}.jsonlist'.format(fname),'w+') as f:\n",
    "    for res in quotes:\n",
    "        json.dump(res, f)\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n",
      "{'quote': ['climate', 'change', 'is', 'a', 'hoax'], 'verb tokens': ['believes'], 'main verb': 'believes', 'subject tokens': ['the', 'pro', '-', 'Trump', 'LaRouche', 'PAC', ',', 'which', 'believes', ','], 'main subject': 'PAC', 'neg tokens': None, 'main neg': None, 'is neg': None}\n"
     ]
    }
   ],
   "source": [
    "with open('./extracted_quotes/{}.jsonlist'.format(fname),'r') as f:\n",
    "    data = f.readlines()\n",
    "    print(len(data))\n",
    "    \n",
    "read_quotes = [json.loads(q.strip()) for q in data]\n",
    "print(read_quotes[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'quote': ['climate', 'change', 'is', 'a', 'hoax', 'planted', 'the', 'troll'],\n",
       " 'verb tokens': ['believes'],\n",
       " 'main verb': 'believes',\n",
       " 'subject tokens': ['the',\n",
       "  'pro',\n",
       "  '-',\n",
       "  'Trump',\n",
       "  'LaRouche',\n",
       "  'PAC',\n",
       "  ',',\n",
       "  'which',\n",
       "  'believes'],\n",
       " 'main subject': 'PAC',\n",
       " 'neg tokens': None,\n",
       " 'main neg': None,\n",
       " 'is neg': None}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_quotes[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieval of extracted complement clauses from filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR_WITH_NAMES = './extracted_quotes/'\n",
    "DIR_WITH_NOS = './extracted_quotes_2/'\n",
    "N_WITH_NAMES = 7433\n",
    "assert len(os.listdir(DIR_WITH_NAMES)) == N_WITH_NAMES\n",
    "FNAMES_WITH_NAMES = set(os.listdir(DIR_WITH_NAMES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Cool, we've extracted the comp clauses of all the first 7433 URLs. No re-indexing needed.\n",
    "for ix_url in range(0,N_WITH_NAMES):\n",
    "    url = df.url.values[ix_url]\n",
    "    fname = '{}.jsonlist'.format(get_fname(url))\n",
    "    assert fname in FNAMES_WITH_NAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def get_quotes_from_file(url_ix,df,missing):\n",
    "    url = df.url.values[url_ix]\n",
    "    if url_ix < 7433:\n",
    "        fname = get_fname(url)\n",
    "        dir_ = 'extracted_quotes'\n",
    "    else:\n",
    "        fname = 'url_no_'+str(url_ix)\n",
    "        dir_ = 'extracted_quotes_2'\n",
    "    \n",
    "    try:\n",
    "        with open('./{}/{}.jsonlist'.format(dir_,fname),'r') as f:\n",
    "            data = f.readlines()\n",
    "        quotes = []\n",
    "        for x in data:\n",
    "            res = json.loads(x.strip())\n",
    "            res.update({'source':url})                \n",
    "            quotes.append(res)\n",
    "            \n",
    "        return quotes\n",
    "    except FileNotFoundError:\n",
    "        print(fname)\n",
    "        missing.append(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30930, 30930)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(os.listdir(DIR_WITH_NAMES))+len(os.listdir(DIR_WITH_NOS)),len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing = []\n",
    "all_quotes = [get_quotes_from_file(url_ix,df,missing) for url_ix in range(0,len(df))]\n",
    "all_quotes = [item for sublist in all_quotes for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 612995)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(missing),len(all_quotes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(all_quotes,open('all_quotes.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_quotes_with_lemma(lemma,element,quote_list):\n",
    "    return [q for q in quote_list if q[element] is not None and lemmatizer.lemmatize(q[element].lower()) == lemma]\n",
    "\n",
    "def get_quotes_with_stem(stem_set,element,quote_list):\n",
    "    return [q for q in quote_list if q[element] is not None and ps.stem(q[element].lower()) in stem_set]\n",
    "\n",
    "def get_quotes_without_stem(stem_set,element,quote_list):\n",
    "    return [q for q in quote_list if q[element] is not None and ps.stem(q[element].lower()) not in stem_set]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter to true indirect statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove quotes with question verb\n",
    "\n",
    "QUESTION_WORDS = set(['who','what','when','where','why','how','if','whose','whether','which','whom','whence'])\n",
    "QUESTION_VERBS = set(['ask','wonder','figure','guess','inquire','interrogate','question'])\n",
    "\n",
    "def has_indirect_question(quote_obj):\n",
    "    quote = quote_obj['quote']\n",
    "    first_word = quote[0].lower()\n",
    "    return first_word in QUESTION_WORDS\n",
    "\n",
    "def has_question_verb(quote_obj):\n",
    "    verb = ps.stem(quote_obj['main verb'].lower())\n",
    "    return verb in QUESTION_VERBS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "549680"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_quotes = [q for q in all_quotes if not has_question_verb(q)]\n",
    "len(all_quotes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "548113"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set aside quotes with 'be' as main verb\n",
    "\n",
    "BE_STEMS = set(['is','wa','’s','are',\"'s\",'be','’m','am','are','’re',\"'m\",\"'re\",\"been\",'were'])\n",
    "\n",
    "quotes_without_be = get_quotes_without_stem(BE_STEMS,all_quotes)\n",
    "len(quotes_without_be)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#554136"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2585, 4)"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove quotes with 'point','turn' but not 'point_out','turn_out' as main verb\n",
    "\n",
    "point_quotes = get_quotes_with_stem(['point','turn'],quotes_without_be)\n",
    "point_out_quotes = [x for x in point_quotes if 'out' in x['verb tokens']]\n",
    "\n",
    "true_point_out_quotes = []\n",
    "false_point_out_quotes = []\n",
    "for x in point_out_quotes:\n",
    "    indices_out = [i for i,t in enumerate(x['verb tokens']) if t.lower() == 'out']\n",
    "    prev_toks = [ps.stem(x['verb tokens'][i-1].lower()) for i in indices_out]\n",
    "    if 'point' in prev_toks or 'turn' in prev_toks:\n",
    "        true_point_out_quotes.append(x)\n",
    "    else:\n",
    "        false_point_out_quotes.append(x)\n",
    "        \n",
    "len(true_point_out_quotes),len(false_point_out_quotes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(2051, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'quote': ['I',\n",
       "   'am',\n",
       "   'going',\n",
       "   'to',\n",
       "   'ask',\n",
       "   'that',\n",
       "   'you',\n",
       "   'look',\n",
       "   'at',\n",
       "   'him'],\n",
       "  'verb tokens': ['point', 'him', 'out'],\n",
       "  'main verb': 'point',\n",
       "  'subject tokens': None,\n",
       "  'main subject': None,\n",
       "  'neg tokens': None,\n",
       "  'main neg': None,\n",
       "  'is neg': None,\n",
       "  'source': 'rssfeeds.usatoday.com/~/613545646/0/news-opinion~A-he-said-she-said-or-a-violent-rape-What-its-like-to-testify-against-your-rapist/'},\n",
       " {'quote': ['”',\n",
       "   'Kappenberger',\n",
       "   'said',\n",
       "   'of',\n",
       "   'the',\n",
       "   'Environmental',\n",
       "   'Protection',\n",
       "   'Agency',\n",
       "   '’s'],\n",
       "  'verb tokens': ['has', 'pointed', 'this', 'information', 'out', 'to', 'me'],\n",
       "  'main verb': 'pointed',\n",
       "  'subject tokens': ['anyone'],\n",
       "  'main subject': 'anyone',\n",
       "  'neg tokens': None,\n",
       "  'main neg': None,\n",
       "  'is neg': None,\n",
       "  'source': 'dailycaller.com/2015/11/18/undetectable-the-impact-a-un-treaty-will-have-on-global-warming/'},\n",
       " {'quote': ['signature', 'global', 'warming', 'rule'],\n",
       "  'verb tokens': ['has', 'pointed', 'this', 'information', 'out', 'to', 'me'],\n",
       "  'main verb': 'pointed',\n",
       "  'subject tokens': ['anyone'],\n",
       "  'main subject': 'anyone',\n",
       "  'neg tokens': None,\n",
       "  'main neg': None,\n",
       "  'is neg': None,\n",
       "  'source': 'dailycaller.com/2015/11/18/undetectable-the-impact-a-un-treaty-will-have-on-global-warming/'},\n",
       " {'quote': ['that', 'BP', 'hopes', 'will', 'shock', 'this', 'Court'],\n",
       "  'verb tokens': ['had',\n",
       "   'pointed',\n",
       "   'to',\n",
       "   'four',\n",
       "   'examples',\n",
       "   'out',\n",
       "   'of',\n",
       "   'more',\n",
       "   'than',\n",
       "   '40,000',\n",
       "   'filed',\n",
       "   'claims'],\n",
       "  'main verb': 'pointed',\n",
       "  'subject tokens': ['BP'],\n",
       "  'main subject': 'BP',\n",
       "  'neg tokens': None,\n",
       "  'main neg': None,\n",
       "  'is neg': None,\n",
       "  'source': 'www.csmonitor.com/Environment/Latest-News-Wires/2013/0626/BP-oil-spill-Oil-giant-challenges-Gulf-payments'}]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "false_point_out_quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "548109"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_quotes = [q for q in quotes_without_be if q not in false_point_out_quotes]\n",
    "len(all_quotes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#554132"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "442865"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove quotes with a set of non-attributive verbs introducing comp clause\n",
    "OTHER_VERBS = set(['make','made','cause','caus','ensur','like','love',\n",
    "                    'help','mean','meant','get','got','let','allow','want','becam',\n",
    "                    'becom','go','goe','lead','have','had','ha',\n",
    "                  'remain','start','give','work','creat','happen','now',\n",
    "                  'try','tri','matter','set','produc','do','did','need',\n",
    "                  'sure','clear','right','requir','use','hold','watch',\n",
    "                  'take','keep','chang','rule','come','look','put'])\n",
    "\n",
    "non_other_verb_quotes = get_quotes_without_stem(OTHER_VERBS,all_quotes)\n",
    "len(non_other_verb_quotes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#477533"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "440677"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove quotes with 'seem', 'appear' as main verb\n",
    "\n",
    "non_seem_quotes = get_quotes_without_stem(['seem','appear'],non_other_verb_quotes)\n",
    "len(non_seem_quotes)#+len(seem_quotes),len(all_quotes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#475345"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "436611"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove verb with non-alpha main verb\n",
    "\n",
    "non_punc_main_verb_quotes = [q for q in non_seem_quotes if q['main verb'][0].lower().isalpha()]\n",
    "len(non_punc_main_verb_quotes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#471279"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'quote': ['Proof',\n",
       "  'of',\n",
       "  'the',\n",
       "  'experiment',\n",
       "  \"'s\",\n",
       "  'success',\n",
       "  'is',\n",
       "  'that',\n",
       "  'the',\n",
       "  'customer',\n",
       "  'will',\n",
       "  'pay',\n",
       "  'for',\n",
       "  'the',\n",
       "  'technology',\n",
       "  'and',\n",
       "  'start',\n",
       "  'using',\n",
       "  'the',\n",
       "  'technology'],\n",
       " 'verb tokens': ['said'],\n",
       " 'main verb': 'said',\n",
       " 'subject tokens': ['Rossi'],\n",
       " 'main subject': 'Rossi',\n",
       " 'neg tokens': None,\n",
       " 'main neg': None,\n",
       " 'is neg': None,\n",
       " 'source': 'www.foxnews.com/science/cold-fusion-experiment-major-success-or-complex-hoax'}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_punc_main_verb_quotes[32432]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(non_punc_main_verb_quotes,open('filtered_quotes.pkl','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine distribution of indirect statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# most common main verbs, subjects, amount of negation, sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "436611"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quotes = pickle.load(open('filtered_quotes.pkl','rb'))\n",
    "len(quotes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('said', 90224),\n",
       " ('say', 45485),\n",
       " ('think', 18085),\n",
       " ('told', 12025),\n",
       " ('know', 11974),\n",
       " ('believ', 10025),\n",
       " ('show', 9118),\n",
       " ('found', 8970),\n",
       " ('suggest', 8126),\n",
       " ('see', 7116),\n",
       " ('note', 7020),\n",
       " ('argu', 6745),\n",
       " ('report', 5441),\n",
       " ('ad', 5076),\n",
       " ('claim', 4496),\n",
       " ('explain', 4369),\n",
       " ('tell', 4357),\n",
       " ('wrote', 4301),\n",
       " ('find', 3671),\n",
       " ('warn', 3320),\n",
       " ('announc', 3247),\n",
       " ('hope', 3192),\n",
       " ('estim', 3124),\n",
       " ('conclud', 2965),\n",
       " ('understand', 2665),\n",
       " ('expect', 2664),\n",
       " ('thought', 2657),\n",
       " ('consid', 2344),\n",
       " ('agre', 2320),\n",
       " ('point', 2239),\n",
       " ('predict', 2175),\n",
       " ('state', 2088),\n",
       " ('indic', 2020),\n",
       " ('declar', 1983),\n",
       " ('write', 1920),\n",
       " ('assum', 1880),\n",
       " ('acknowledg', 1877),\n",
       " ('realiz', 1823),\n",
       " ('determin', 1790),\n",
       " ('insist', 1751),\n",
       " ('decid', 1554),\n",
       " ('knew', 1547),\n",
       " ('admit', 1445),\n",
       " ('reveal', 1365),\n",
       " ('feel', 1269),\n",
       " ('learn', 1206),\n",
       " ('worri', 1175),\n",
       " ('rememb', 1171),\n",
       " ('add', 1125),\n",
       " ('saw', 1071),\n",
       " ('confirm', 1059),\n",
       " ('imagin', 1055),\n",
       " ('prove', 1030),\n",
       " ('seen', 1022),\n",
       " ('fear', 1022),\n",
       " ('continu', 1010),\n",
       " ('convinc', 1002),\n",
       " ('recogn', 942),\n",
       " ('demonstr', 895),\n",
       " ('shown', 856),\n",
       " ('demand', 845),\n",
       " ('read', 786),\n",
       " ('hear', 785),\n",
       " ('discov', 777),\n",
       " ('turn', 747),\n",
       " ('assert', 712),\n",
       " ('call', 697),\n",
       " ('recal', 664),\n",
       " ('felt', 649),\n",
       " ('recommend', 635),\n",
       " ('calcul', 627),\n",
       " ('suspect', 623),\n",
       " ('heard', 603),\n",
       " ('promis', 596),\n",
       " ('deni', 555),\n",
       " ('mention', 536),\n",
       " ('contend', 533),\n",
       " ('wish', 530),\n",
       " ('emphas', 516),\n",
       " ('remind', 512),\n",
       " ('notic', 510),\n",
       " ('known', 500),\n",
       " ('assur', 497),\n",
       " ('concern', 497),\n",
       " ('complain', 496),\n",
       " ('propos', 485),\n",
       " ('accept', 478),\n",
       " ('project', 475),\n",
       " ('maintain', 472),\n",
       " ('describ', 471),\n",
       " ('observ', 469),\n",
       " ('confid', 445),\n",
       " ('respond', 434),\n",
       " ('caution', 424),\n",
       " ('impli', 400),\n",
       " ('awar', 392),\n",
       " ('includ', 388),\n",
       " ('doubt', 386),\n",
       " ('stress', 383),\n",
       " ('tweet', 382),\n",
       " ('conced', 382),\n",
       " ('alleg', 377),\n",
       " ('signal', 362),\n",
       " ('figur', 361),\n",
       " ('discuss', 356),\n",
       " ('repli', 344),\n",
       " ('suppos', 341),\n",
       " ('provid', 323),\n",
       " ('pretend', 310),\n",
       " ('offer', 294),\n",
       " ('understood', 290),\n",
       " ('forget', 283),\n",
       " ('studi', 281),\n",
       " ('care', 281),\n",
       " ('guarante', 279),\n",
       " ('follow', 278),\n",
       " ('highlight', 265),\n",
       " ('address', 263),\n",
       " ('support', 257),\n",
       " ('releas', 255),\n",
       " ('affect', 253),\n",
       " ('inform', 250),\n",
       " ('surpris', 248),\n",
       " ('stop', 245),\n",
       " ('increas', 243),\n",
       " ('given', 241),\n",
       " ('sign', 240),\n",
       " ('pledg', 239),\n",
       " ('reduc', 236),\n",
       " ('live', 234),\n",
       " ('illustr', 233),\n",
       " ('reflect', 229),\n",
       " ('began', 227),\n",
       " ('left', 222),\n",
       " ('certain', 220),\n",
       " ('doe', 218),\n",
       " ('measur', 218),\n",
       " ('took', 218),\n",
       " ('plan', 218),\n",
       " ('involv', 215),\n",
       " ('bet', 215),\n",
       " ('establish', 214),\n",
       " ('specul', 213),\n",
       " ('testifi', 212),\n",
       " ('charg', 212),\n",
       " ('detail', 212),\n",
       " ('examin', 207),\n",
       " ('end', 206),\n",
       " ('reach', 204),\n",
       " ('render', 201),\n",
       " ('mandat', 195),\n",
       " ('explor', 194),\n",
       " ('leav', 194),\n",
       " ('proclaim', 193),\n",
       " ('mind', 191),\n",
       " ('share', 189),\n",
       " ('rais', 188),\n",
       " ('run', 188),\n",
       " ('depend', 185),\n",
       " ('answer', 184),\n",
       " ('grow', 184),\n",
       " ('clarifi', 184),\n",
       " ('move', 184),\n",
       " ('request', 183),\n",
       " ('went', 183),\n",
       " ('advis', 182),\n",
       " ('face', 181),\n",
       " ('came', 181),\n",
       " ('pay', 176),\n",
       " ('occur', 174),\n",
       " ('investig', 174),\n",
       " ('emerg', 173),\n",
       " ('identifi', 173),\n",
       " ('assess', 171),\n",
       " ('talk', 170),\n",
       " ('done', 169),\n",
       " ('counter', 169),\n",
       " ('die', 168),\n",
       " ('appreci', 167),\n",
       " ('express', 166),\n",
       " ('anticip', 166),\n",
       " ('protect', 164),\n",
       " ('lost', 164),\n",
       " ('forecast', 161),\n",
       " ('receiv', 161),\n",
       " ('debat', 160),\n",
       " ('cut', 158),\n",
       " ('repres', 157),\n",
       " ('begin', 156),\n",
       " ('warm', 156),\n",
       " ('own', 154),\n",
       " ('vote', 154),\n",
       " ('choos', 154),\n",
       " ('persuad', 151),\n",
       " ('boast', 151),\n",
       " ('cost', 149),\n",
       " ('cover', 148),\n",
       " ('remark', 147),\n",
       " ('achiev', 147),\n",
       " ('document', 146),\n",
       " ('joke', 145),\n",
       " ('rise', 145),\n",
       " ('kill', 145),\n",
       " ('dictat', 145),\n",
       " ('glad', 144),\n",
       " ('fail', 144),\n",
       " ('disclos', 144),\n",
       " ('forc', 143),\n",
       " ('develop', 142),\n",
       " ('push', 141),\n",
       " ('realis', 140),\n",
       " ('lose', 139),\n",
       " ('cite', 138),\n",
       " ('order', 138),\n",
       " ('urg', 137),\n",
       " ('oppos', 136),\n",
       " ('expos', 136),\n",
       " ('much', 135),\n",
       " ('test', 135),\n",
       " ('burn', 135),\n",
       " ('bring', 134),\n",
       " ('held', 133),\n",
       " ('afraid', 133),\n",
       " ('exist', 133),\n",
       " ('pass', 131),\n",
       " ('build', 130),\n",
       " ('fall', 127),\n",
       " ('result', 126),\n",
       " ('control', 125),\n",
       " ('hit', 124),\n",
       " ('ignor', 122),\n",
       " ('lament', 122),\n",
       " ('limit', 121),\n",
       " ('check', 121),\n",
       " ('comment', 121),\n",
       " ('encourag', 121),\n",
       " ('vow', 120),\n",
       " ('specifi', 120),\n",
       " ('taken', 120),\n",
       " ('trust', 118),\n",
       " ('prevent', 118),\n",
       " ('present', 118),\n",
       " ('proven', 118),\n",
       " ('spent', 118),\n",
       " ('affirm', 118),\n",
       " ('save', 117),\n",
       " ('reassur', 117),\n",
       " ('underscor', 117),\n",
       " ('publish', 116),\n",
       " ('threaten', 116),\n",
       " ('improv', 116),\n",
       " ('play', 114),\n",
       " ('enabl', 114),\n",
       " ('tend', 113),\n",
       " ('defin', 112),\n",
       " ('drop', 111),\n",
       " ('spend', 111),\n",
       " ('written', 110),\n",
       " ('gener', 110),\n",
       " ('prefer', 110),\n",
       " ('reli', 109),\n",
       " ('reiter', 108),\n",
       " ('review', 107),\n",
       " ('emit', 107),\n",
       " ('destroy', 106),\n",
       " ('optimist', 106),\n",
       " ('built', 106),\n",
       " ('promot', 106),\n",
       " ('challeng', 106),\n",
       " ('posit', 106),\n",
       " ('gave', 105),\n",
       " ('alter', 105),\n",
       " ('captur', 105),\n",
       " ('deliv', 105),\n",
       " ('repeat', 105),\n",
       " ('contain', 104),\n",
       " ('disput', 104),\n",
       " ('outlin', 103),\n",
       " ('drive', 103),\n",
       " ('send', 103),\n",
       " ('analyz', 102),\n",
       " ('melt', 102),\n",
       " ('meet', 102),\n",
       " ('track', 102),\n",
       " ('reject', 101),\n",
       " ('confess', 99),\n",
       " ('harm', 99),\n",
       " ('compar', 99),\n",
       " ('recognis', 99),\n",
       " ('gotten', 98),\n",
       " ('manag', 98),\n",
       " ('view', 98),\n",
       " ('wit', 96),\n",
       " ('vaccin', 96),\n",
       " ('stand', 95),\n",
       " ('aim', 94),\n",
       " ('experienc', 93),\n",
       " ('thank', 93),\n",
       " ('gone', 93),\n",
       " ('taught', 92),\n",
       " ('buy', 92),\n",
       " ('avoid', 92),\n",
       " ('hint', 92),\n",
       " ('post', 91),\n",
       " ('design', 91),\n",
       " ('carri', 91),\n",
       " ('act', 91),\n",
       " ('met', 90),\n",
       " ('suffer', 90),\n",
       " ('fix', 90),\n",
       " ('base', 89),\n",
       " ('expand', 88),\n",
       " ('enough', 88),\n",
       " ('close', 88),\n",
       " ('lie', 88),\n",
       " ('wait', 87),\n",
       " ('unlik', 87),\n",
       " ('advoc', 87),\n",
       " ('serv', 87),\n",
       " ('spread', 87),\n",
       " ('hypothes', 87),\n",
       " ('skeptic', 87),\n",
       " ('declin', 86),\n",
       " ('replac', 86),\n",
       " ('impos', 85),\n",
       " ('spoke', 84),\n",
       " ('place', 84),\n",
       " ('shift', 84),\n",
       " ('won', 84),\n",
       " ('weekday', 84),\n",
       " ('bad', 83),\n",
       " ('refer', 83),\n",
       " ('disagre', 82),\n",
       " ('sent', 81),\n",
       " ('open', 80),\n",
       " ('led', 80),\n",
       " ('regul', 80),\n",
       " ('evalu', 79),\n",
       " ('echo', 79),\n",
       " ('miss', 79),\n",
       " ('pick', 79),\n",
       " ('teach', 79),\n",
       " ('focus', 78),\n",
       " ('eat', 78),\n",
       " ('high', 78),\n",
       " ('undermin', 77),\n",
       " ('account', 77),\n",
       " ('shape', 77),\n",
       " ('seek', 77),\n",
       " ('influenc', 77),\n",
       " ('welcom', 76),\n",
       " ('join', 76),\n",
       " ('disappoint', 76),\n",
       " ('judg', 76),\n",
       " ('presum', 76),\n",
       " ('caught', 76),\n",
       " ('impact', 76),\n",
       " ('happi', 75),\n",
       " ('sens', 75),\n",
       " ('appli', 75),\n",
       " ('fight', 75),\n",
       " ('form', 75),\n",
       " ('prepar', 74),\n",
       " ('quot', 74),\n",
       " ('listen', 74),\n",
       " ('correct', 73),\n",
       " ('back', 73),\n",
       " ('stipul', 73),\n",
       " ('endors', 72),\n",
       " ('prompt', 72),\n",
       " ('pleas', 72),\n",
       " ('monitor', 72),\n",
       " ('deem', 72),\n",
       " ('justifi', 72),\n",
       " ('critic', 72),\n",
       " ('protest', 72),\n",
       " ('contribut', 71),\n",
       " ('lay', 71),\n",
       " ('featur', 71),\n",
       " ('power', 70),\n",
       " ('shut', 70),\n",
       " ('pray', 70),\n",
       " ('introduc', 70),\n",
       " ('sound', 69),\n",
       " ('kept', 69),\n",
       " ('blame', 69),\n",
       " ('refus', 68),\n",
       " ('commit', 68),\n",
       " ('stay', 68),\n",
       " ('conduct', 68),\n",
       " ('arriv', 68),\n",
       " ('shot', 68),\n",
       " ('brought', 67),\n",
       " ('pose', 67),\n",
       " ('pull', 66),\n",
       " ('wast', 66),\n",
       " ('acceler', 66),\n",
       " ('verifi', 66),\n",
       " ('issu', 66),\n",
       " ('slow', 66),\n",
       " ('return', 66),\n",
       " ('treat', 65),\n",
       " ('approv', 65),\n",
       " ('strike', 65),\n",
       " ('so', 65),\n",
       " ('dismiss', 65),\n",
       " ('embrac', 65),\n",
       " ('exceed', 64),\n",
       " ('absorb', 64),\n",
       " ('enjoy', 64),\n",
       " ('grown', 64),\n",
       " ('launch', 63),\n",
       " ('fast', 63),\n",
       " ('accus', 63),\n",
       " ('disappear', 63),\n",
       " ('head', 63),\n",
       " ('win', 63),\n",
       " ('transform', 63),\n",
       " ('unawar', 62),\n",
       " ('feed', 62),\n",
       " ('offset', 62),\n",
       " ('practic', 62),\n",
       " ('rethink', 62),\n",
       " ('risk', 61),\n",
       " ('attack', 61),\n",
       " ('sit', 61),\n",
       " ('fell', 61),\n",
       " ('fund', 61),\n",
       " ('mark', 60),\n",
       " ('revers', 60),\n",
       " ('sell', 60),\n",
       " ('frustrat', 59),\n",
       " ('benefit', 59),\n",
       " ('reckon', 59),\n",
       " ('focu', 59),\n",
       " ('experi', 58),\n",
       " ('hurt', 58),\n",
       " ('solv', 58),\n",
       " ('sever', 58),\n",
       " ('surviv', 58),\n",
       " ('fill', 58),\n",
       " ('small', 57),\n",
       " ('attract', 57),\n",
       " ('count', 57),\n",
       " ('remov', 57),\n",
       " ('celebr', 57),\n",
       " ('laid', 56),\n",
       " ('damag', 56),\n",
       " ('weigh', 56),\n",
       " ('name', 55),\n",
       " ('visit', 55),\n",
       " ('implement', 55),\n",
       " ('grasp', 55),\n",
       " ('list', 54),\n",
       " ('target', 54),\n",
       " ('pressur', 54),\n",
       " ('frack', 54),\n",
       " ('enter', 54),\n",
       " ('break', 54),\n",
       " ('low', 54),\n",
       " ('weaken', 53),\n",
       " ('deserv', 53),\n",
       " ('forgotten', 53),\n",
       " ('underestim', 53),\n",
       " ('invest', 53),\n",
       " ('notifi', 52),\n",
       " ('shout', 52),\n",
       " ('favor', 52),\n",
       " ('engag', 51),\n",
       " ('adopt', 51),\n",
       " ('model', 51),\n",
       " ('import', 51),\n",
       " ('exploit', 51),\n",
       " ('guid', 51),\n",
       " ('elect', 50),\n",
       " ('direct', 50),\n",
       " ('govern', 50),\n",
       " ('elimin', 50),\n",
       " ('upset', 50),\n",
       " ('organ', 50),\n",
       " ('quantifi', 50),\n",
       " ('secur', 49),\n",
       " ('long', 49),\n",
       " ('strengthen', 49),\n",
       " ('record', 49),\n",
       " ('walk', 49),\n",
       " ('speak', 49),\n",
       " ('wo', 49),\n",
       " ('theoriz', 49),\n",
       " ('angri', 49),\n",
       " ('ran', 49),\n",
       " ('deal', 49),\n",
       " ('settl', 48),\n",
       " ('link', 48),\n",
       " ('decreas', 48),\n",
       " ('grate', 48),\n",
       " ('intend', 48),\n",
       " ('bear', 48),\n",
       " ('submit', 48),\n",
       " ('grant', 47),\n",
       " ('ca', 47),\n",
       " ('larg', 47),\n",
       " ('reason', 47),\n",
       " ('cross', 46),\n",
       " ('oper', 46),\n",
       " ('plant', 46),\n",
       " ('detect', 46),\n",
       " ('respect', 46),\n",
       " ('instruct', 46),\n",
       " ('rang', 46),\n",
       " ('concur', 46),\n",
       " ('invit', 46),\n",
       " ('doubl', 46),\n",
       " ('reaffirm', 46),\n",
       " ('collect', 45),\n",
       " ('complet', 45),\n",
       " ('attempt', 45),\n",
       " ('rose', 45),\n",
       " ('motiv', 45),\n",
       " ('will', 45),\n",
       " ('inspir', 44),\n",
       " ('reinforc', 44),\n",
       " ('envis', 44),\n",
       " ('throw', 44),\n",
       " ('approach', 44),\n",
       " ('defend', 44),\n",
       " ('broke', 44),\n",
       " ('leak', 44),\n",
       " ('heat', 44),\n",
       " ('contradict', 44),\n",
       " ('flood', 43),\n",
       " ('extend', 43),\n",
       " ('pollut', 43),\n",
       " ('brag', 43),\n",
       " ('afford', 43),\n",
       " ('begun', 43),\n",
       " ('climat', 43),\n",
       " ('block', 43),\n",
       " ('grew', 43),\n",
       " ('pictur', 42),\n",
       " ('press', 42),\n",
       " ('true', 42),\n",
       " ('paid', 42),\n",
       " ('gather', 42),\n",
       " ('ponder', 41),\n",
       " ('hate', 41),\n",
       " ('research', 41),\n",
       " ('intens', 41),\n",
       " ('struck', 41),\n",
       " ('sought', 41),\n",
       " ('fire', 41),\n",
       " ('match', 40),\n",
       " ('unclear', 40),\n",
       " ('gain', 40),\n",
       " ('rank', 40),\n",
       " ('clean', 40),\n",
       " ('accomplish', 40),\n",
       " ('consum', 40),\n",
       " ('quip', 40),\n",
       " ('earn', 40),\n",
       " ('restrict', 39),\n",
       " ('abandon', 39),\n",
       " ('perform', 39),\n",
       " ('uncertain', 39),\n",
       " ('lack', 39),\n",
       " ('shrink', 39),\n",
       " ('travel', 39),\n",
       " ('employ', 39),\n",
       " ('recount', 39),\n",
       " ('permit', 39),\n",
       " ('lower', 38),\n",
       " ('surg', 38),\n",
       " ('cool', 38),\n",
       " ('perceiv', 38),\n",
       " ('satisfi', 38),\n",
       " ('stood', 38),\n",
       " ('tout', 38),\n",
       " ('roll', 38),\n",
       " ('collaps', 38),\n",
       " ('great', 38),\n",
       " ('renew', 37),\n",
       " ('translat', 37),\n",
       " ('would', 37),\n",
       " ('strong', 37),\n",
       " ('fit', 37),\n",
       " ('delay', 37),\n",
       " ('cancel', 37),\n",
       " ('author', 37),\n",
       " ('insur', 37),\n",
       " ('struggl', 36),\n",
       " ('prais', 36),\n",
       " ('succeed', 36),\n",
       " ('opin', 36),\n",
       " ('accompani', 36),\n",
       " ('hide', 36),\n",
       " ('connect', 36),\n",
       " ('map', 36),\n",
       " ('alert', 36),\n",
       " ('resist', 35),\n",
       " ('draw', 35),\n",
       " ('dare', 35),\n",
       " ('attend', 35),\n",
       " ('confront', 35),\n",
       " ('wake', 35),\n",
       " ('pursu', 35),\n",
       " ('object', 35),\n",
       " ('label', 34),\n",
       " ('postul', 34),\n",
       " ('spark', 34),\n",
       " ('gaug', 34),\n",
       " ('purchas', 34),\n",
       " ('recov', 34),\n",
       " ('success', 34),\n",
       " ('bought', 34),\n",
       " ('such', 34),\n",
       " ('sorri', 34),\n",
       " ('domin', 34),\n",
       " ('stuck', 33),\n",
       " ('cri', 33),\n",
       " ('fret', 33),\n",
       " ('step', 33),\n",
       " ('mitig', 33),\n",
       " ('finish', 33),\n",
       " ('kick', 33),\n",
       " ('regret', 33),\n",
       " ('cold', 33),\n",
       " ('sum', 33),\n",
       " ('dump', 33),\n",
       " ('impress', 32),\n",
       " ('wear', 32),\n",
       " ('pinpoint', 32),\n",
       " ('encount', 32),\n",
       " ('knock', 32),\n",
       " ('certifi', 32),\n",
       " ('rare', 32),\n",
       " ('sink', 32),\n",
       " ('wors', 32),\n",
       " ('lock', 32),\n",
       " ('preserv', 32),\n",
       " ('restor', 32),\n",
       " ('infer', 32),\n",
       " ('fallen', 32),\n",
       " ('wash', 32),\n",
       " ('appeal', 32),\n",
       " ('argument', 32),\n",
       " ('alarm', 32),\n",
       " ('contamin', 32),\n",
       " ('ban', 31),\n",
       " ('vari', 31),\n",
       " ('sustain', 31),\n",
       " ('drink', 31),\n",
       " ('train', 31),\n",
       " ('free', 31),\n",
       " ('apolog', 31),\n",
       " ('bother', 31),\n",
       " ('enact', 31),\n",
       " ('articul', 31),\n",
       " ('file', 31),\n",
       " ('doom', 31),\n",
       " ('obviou', 31),\n",
       " ('thick', 31),\n",
       " ('rest', 31),\n",
       " ('display', 30),\n",
       " ('suck', 30),\n",
       " ('catch', 30),\n",
       " ('updat', 30),\n",
       " ('best', 30),\n",
       " ('pour', 30),\n",
       " ('decre', 30),\n",
       " ('jump', 30),\n",
       " ('chant', 30),\n",
       " ('simul', 30),\n",
       " ('tackl', 30),\n",
       " ('evolv', 29),\n",
       " ('fuel', 29),\n",
       " ('handl', 29),\n",
       " ('sponsor', 29),\n",
       " ('amaz', 29),\n",
       " ('constitut', 29),\n",
       " ('driven', 29),\n",
       " ('instal', 29),\n",
       " ('trigger', 29),\n",
       " ('inject', 29),\n",
       " ('condemn', 29),\n",
       " ('advanc', 29),\n",
       " ('resembl', 29),\n",
       " ('spur', 29),\n",
       " ('crow', 29),\n",
       " ('violat', 28),\n",
       " ('unconvinc', 28),\n",
       " ('okay', 28),\n",
       " ('spot', 28),\n",
       " ('displac', 28),\n",
       " ('far', 28),\n",
       " ('commun', 28),\n",
       " ('sold', 28),\n",
       " ('cheap', 28),\n",
       " ('vast', 28),\n",
       " ('negoti', 28),\n",
       " ('underlin', 28),\n",
       " ('regard', 28),\n",
       " ('flow', 28),\n",
       " ('hot', 28),\n",
       " ('frame', 28),\n",
       " ('resolv', 28),\n",
       " ('hire', 28),\n",
       " ('convey', 27),\n",
       " ('arrest', 27),\n",
       " ('shock', 27),\n",
       " ('reconsid', 27),\n",
       " ('jeopard', 27),\n",
       " ('boost', 27),\n",
       " ('appoint', 27),\n",
       " ('chose', 27),\n",
       " ('can', 27),\n",
       " ('campaign', 27),\n",
       " ('disturb', 27),\n",
       " ('scale', 27),\n",
       " ('ought', 27),\n",
       " ('risen', 27),\n",
       " ('discern', 27),\n",
       " ('disrupt', 27),\n",
       " ('toxin', 27),\n",
       " ('grab', 27),\n",
       " ('exagger', 26),\n",
       " ('suspend', 26),\n",
       " ('lift', 26),\n",
       " ('speed', 26),\n",
       " ('contempl', 26),\n",
       " ('scare', 26),\n",
       " ('overst', 26),\n",
       " ('regist', 26),\n",
       " ('exclaim', 26),\n",
       " ('rebuild', 26),\n",
       " ('fli', 26),\n",
       " ('elabor', 26),\n",
       " ('educ', 26),\n",
       " ('balanc', 26),\n",
       " ('yield', 26),\n",
       " ('reliev', 26),\n",
       " ('contract', 26),\n",
       " ('switch', 26),\n",
       " ('extract', 26),\n",
       " ('trap', 26),\n",
       " ('summar', 25),\n",
       " ('uncov', 25),\n",
       " ('halt', 25),\n",
       " ('convert', 25),\n",
       " ('tie', 25),\n",
       " ('select', 25),\n",
       " ('possibl', 25),\n",
       " ('depict', 25),\n",
       " ('terrifi', 25),\n",
       " ('dire', 25),\n",
       " ('pump', 25),\n",
       " ('expens', 25),\n",
       " ('shake', 25),\n",
       " ('crack', 25),\n",
       " ('born', 25),\n",
       " ('hand', 24),\n",
       " ('endur', 24),\n",
       " ('devot', 24),\n",
       " ('yell', 24),\n",
       " ('good', 24),\n",
       " ('unveil', 24),\n",
       " ('spell', 24),\n",
       " ('ralli', 24),\n",
       " ('devast', 24),\n",
       " ('excit', 24),\n",
       " ('swallow', 24),\n",
       " ('touch', 24),\n",
       " ('diminish', 24),\n",
       " ('last', 24),\n",
       " ('weak', 24),\n",
       " ('mobil', 24),\n",
       " ('mount', 24),\n",
       " ('overwhelm', 24),\n",
       " ('ride', 24),\n",
       " ('dri', 24),\n",
       " ('adapt', 24),\n",
       " ('swear', 23),\n",
       " ('cook', 23),\n",
       " ('green', 23),\n",
       " ('recycl', 23),\n",
       " ('biden', 23),\n",
       " ('quickli', 23),\n",
       " ('soar', 23),\n",
       " ('wrap', 23),\n",
       " ('attribut', 23),\n",
       " ('empow', 23),\n",
       " ('redefin', 23),\n",
       " ('donat', 23),\n",
       " ('cheer', 23),\n",
       " ('erupt', 23),\n",
       " ('big', 23),\n",
       " ('astonish', 23),\n",
       " ('denounc', 23),\n",
       " ('worsen', 23),\n",
       " ('voic', 22),\n",
       " ('should', 22),\n",
       " ('forgot', 22),\n",
       " ('deploy', 22),\n",
       " ('scream', 22),\n",
       " ('beat', 22),\n",
       " ('stick', 22),\n",
       " ('lucki', 22),\n",
       " ('retain', 22),\n",
       " ('differ', 22),\n",
       " ('attest', 22),\n",
       " ('pronounc', 22),\n",
       " ('averag', 22),\n",
       " ('compel', 22),\n",
       " ('sat', 22),\n",
       " ('drove', 22),\n",
       " ('could', 22),\n",
       " ('surround', 22),\n",
       " ('overestim', 22),\n",
       " ('forese', 22),\n",
       " ('email', 22),\n",
       " ('cast', 22),\n",
       " ('extrem', 22),\n",
       " ('new', 22),\n",
       " ('survey', 22),\n",
       " ('aris', 21),\n",
       " ('comprehend', 21),\n",
       " ('wipe', 21),\n",
       " ('embarrass', 21),\n",
       " ('mix', 21),\n",
       " ('amplifi', 21),\n",
       " ('slam', 21),\n",
       " ('overlook', 21),\n",
       " ('exercis', 21),\n",
       " ('relat', 21),\n",
       " ('degre', 21),\n",
       " ('store', 21),\n",
       " ('complic', 21),\n",
       " ('suppli', 21),\n",
       " ('hard', 21),\n",
       " ('escap', 21),\n",
       " ('belong', 21),\n",
       " ('mock', 21),\n",
       " ('rate', 21),\n",
       " ('trade', 21),\n",
       " ('muse', 21),\n",
       " ('valu', 21),\n",
       " ('emphasis', 21),\n",
       " ('plead', 20),\n",
       " ('combin', 20),\n",
       " ('proud', 20),\n",
       " ('embodi', 20),\n",
       " ('seiz', 20),\n",
       " ('gon', 20),\n",
       " ('invent', 20),\n",
       " ('locat', 20),\n",
       " ('decim', 20),\n",
       " ('iron', 20),\n",
       " ('click', 20),\n",
       " ('n’t', 20),\n",
       " ('sort', 20),\n",
       " ('debunk', 20),\n",
       " ('incorpor', 20),\n",
       " ('thrill', 20),\n",
       " ('adjust', 20),\n",
       " ('retort', 20),\n",
       " ('compet', 20),\n",
       " ('subsid', 20),\n",
       " ('compromis', 20),\n",
       " ('huge', 20),\n",
       " ('decri', 20),\n",
       " ('diagnos', 20),\n",
       " ('oblig', 20),\n",
       " ('lobbi', 20),\n",
       " ('shook', 20),\n",
       " ('hang', 20),\n",
       " ('portray', 19),\n",
       " ('avail', 19),\n",
       " ('underst', 19),\n",
       " ('line', 19),\n",
       " ('preach', 19),\n",
       " ('outrag', 19),\n",
       " ('spew', 19),\n",
       " ('distinguish', 19),\n",
       " ('craft', 19),\n",
       " ('acquir', 19),\n",
       " ('troubl', 19),\n",
       " ('complex', 19),\n",
       " ('suffic', 19),\n",
       " ('belief', 19),\n",
       " ('unsurpris', 19),\n",
       " ('circul', 19),\n",
       " ('defeat', 19),\n",
       " ('idea', 19),\n",
       " ('infect', 19),\n",
       " ('chronicl', 19),\n",
       " ('t]he', 19),\n",
       " ('associ', 19),\n",
       " ('plummet', 19),\n",
       " ('discourag', 19),\n",
       " ('grumbl', 19),\n",
       " ('ship', 18),\n",
       " ('command', 18),\n",
       " ('peak', 18),\n",
       " ('separ', 18),\n",
       " ('particip', 18),\n",
       " ('endang', 18),\n",
       " ('tax', 18),\n",
       " ('drew', 18),\n",
       " ('assist', 18),\n",
       " ('laugh', 18),\n",
       " ('applaud', 18),\n",
       " ('nrplu', 18),\n",
       " ('danger', 18),\n",
       " ('unsur', 18),\n",
       " ('hasten', 18),\n",
       " ('minim', 18),\n",
       " ('thrive', 18),\n",
       " ('phase', 18),\n",
       " ('manufactur', 18),\n",
       " ('disregard', 18),\n",
       " ('credit', 18),\n",
       " ('forbid', 18),\n",
       " ('reviv', 18),\n",
       " ('divid', 18),\n",
       " ('intensifi', 17),\n",
       " ('combat', 17),\n",
       " ('progress', 17),\n",
       " ('paint', 17),\n",
       " ('advertis', 17),\n",
       " ('drown', 17),\n",
       " ('swore', 17),\n",
       " ('signifi', 17),\n",
       " ('interview', 17),\n",
       " ('insinu', 17),\n",
       " ('ascertain', 17),\n",
       " ('distribut', 17),\n",
       " ('search', 17),\n",
       " ('volunt', 17),\n",
       " ('appal', 17),\n",
       " ('manipul', 17),\n",
       " ('persist', 17),\n",
       " ('signific', 17),\n",
       " ('age', 17),\n",
       " ('reshap', 17),\n",
       " ('exce', 17),\n",
       " ('dig', 17),\n",
       " ('statement', 17),\n",
       " ('common', 17),\n",
       " ('fulfil', 17),\n",
       " ('deplet', 17),\n",
       " ('surpass', 17),\n",
       " ('surmis', 17),\n",
       " ('eas', 17),\n",
       " ('puzzl', 17),\n",
       " ('dismay', 17),\n",
       " ('host', 16),\n",
       " ('well', 16),\n",
       " ('deep', 16),\n",
       " ('fed', 16),\n",
       " ('reform', 16),\n",
       " ('climb', 16),\n",
       " ('land', 16),\n",
       " ('dramat', 16),\n",
       " ('withdraw', 16),\n",
       " ('blow', 16),\n",
       " ('effect', 16),\n",
       " ('undo', 16),\n",
       " ('wrong', 16),\n",
       " ('heed', 16),\n",
       " ('remot', 16),\n",
       " ('har', 16),\n",
       " ('nomin', 16),\n",
       " ('badli', 16),\n",
       " ('annoy', 16),\n",
       " ('retreat', 16),\n",
       " ('ate', 16),\n",
       " ('accumul', 16),\n",
       " ('breath', 16),\n",
       " ('exit', 16),\n",
       " ('bolster', 16),\n",
       " ('multipli', 16),\n",
       " ('dwarf', 16),\n",
       " ('trace', 16),\n",
       " ('water', 16),\n",
       " ('smartphon', 16),\n",
       " ('corrupt', 16),\n",
       " ('abolish', 16),\n",
       " ('confus', 16),\n",
       " ('valid', 16),\n",
       " ('harvest', 16),\n",
       " ('react', 16),\n",
       " ('honor', 16),\n",
       " ('referenc', 16),\n",
       " ('cap', 16),\n",
       " ('date', 16),\n",
       " ('poor', 16),\n",
       " ('toxic', 16),\n",
       " ('gush', 16),\n",
       " ('stun', 15),\n",
       " ('unit', 15),\n",
       " ('brew', 15),\n",
       " ...]"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_main_verb_stems = [ps.stem(x['main verb']).lower() for x in quotes]\n",
    "counted_main_verb_stems = Counter(all_main_verb_stems)\n",
    "sorted(counted_main_verb_stems.items(),key=lambda x:x[1],reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'wonder' in counted_main_verb_stems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_quotes = get_quotes_with_stem({\n",
    "    'put'\n",
    "},quotes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'quote': ['we', 'heads', 'down'],\n",
       "  'verb tokens': ['are', 'going', 'to', 'put'],\n",
       "  'main verb': 'put',\n",
       "  'subject tokens': ['we'],\n",
       "  'main subject': 'we',\n",
       "  'neg tokens': None,\n",
       "  'main neg': None,\n",
       "  'is neg': None,\n",
       "  'source': 'www.thenation.com/article/archive/trump-climate-whistleblowers/'},\n",
       " {'quote': ['Humans', 'played', 'an', 'important', 'role', ',', 'too'],\n",
       "  'verb tokens': ['put',\n",
       "   'pressure',\n",
       "   'on',\n",
       "   'the',\n",
       "   'animals',\n",
       "   'through',\n",
       "   'hunting',\n",
       "   'scattering',\n",
       "   'the',\n",
       "   'megafauna',\n",
       "   'throughout',\n",
       "   'the',\n",
       "   'region'],\n",
       "  'main verb': 'put',\n",
       "  'subject tokens': ['Humans', 'presence'],\n",
       "  'main subject': 'presence',\n",
       "  'neg tokens': None,\n",
       "  'main neg': None,\n",
       "  'is neg': None,\n",
       "  'source': 'www.nytimes.com/2016/06/18/science/patagonia-extinctions-global-warming.html'},\n",
       " {'quote': ['calls', 'online'],\n",
       "  'verb tokens': ['then', 'puts', 'the', 'recordings', 'of', 'Conference'],\n",
       "  'main verb': 'puts',\n",
       "  'subject tokens': None,\n",
       "  'main subject': None,\n",
       "  'neg tokens': None,\n",
       "  'main neg': None,\n",
       "  'is neg': None,\n",
       "  'source': 'www.voicesforvaccines.org/2015-the-year-of-the-pro-vaxxer/'},\n",
       " {'quote': ['This',\n",
       "   'can',\n",
       "   'make',\n",
       "   'This',\n",
       "   'look',\n",
       "   '—',\n",
       "   'and',\n",
       "   'many',\n",
       "   'candidates',\n",
       "   'want',\n",
       "   'This',\n",
       "   'to',\n",
       "   'look',\n",
       "   '—',\n",
       "   'like',\n",
       "   ',',\n",
       "   'in',\n",
       "   'Pete',\n",
       "   'Buttigieg',\n",
       "   '’s',\n",
       "   'words'],\n",
       "  'verb tokens': ['have',\n",
       "   'put',\n",
       "   'out',\n",
       "   'highly',\n",
       "   'similar',\n",
       "   'visions',\n",
       "   'on',\n",
       "   'climate'],\n",
       "  'main verb': 'put',\n",
       "  'subject tokens': ['we'],\n",
       "  'main subject': 'we',\n",
       "  'neg tokens': None,\n",
       "  'main neg': None,\n",
       "  'is neg': None,\n",
       "  'source': 'www.vox.com/energy-and-environment/2019/8/2/20751255/2019-democratic-debate-joe-biden-jay-inslee-climate-change'},\n",
       " {'quote': ['We',\n",
       "   'can',\n",
       "   'use',\n",
       "   'public',\n",
       "   'transportation',\n",
       "   'to',\n",
       "   'mitigate',\n",
       "   'inequality',\n",
       "   ',',\n",
       "   'to',\n",
       "   'improve',\n",
       "   'the',\n",
       "   'environment',\n",
       "   ',',\n",
       "   'to',\n",
       "   'develop',\n",
       "   'technologically',\n",
       "   'and',\n",
       "   'economically'],\n",
       "  'verb tokens': ['puts',\n",
       "   'more',\n",
       "   'of',\n",
       "   'We',\n",
       "   'on',\n",
       "   'the',\n",
       "   'right',\n",
       "   'side',\n",
       "   'of',\n",
       "   'the',\n",
       "   'tracks'],\n",
       "  'main verb': 'puts',\n",
       "  'subject tokens': ['public', 'transportation'],\n",
       "  'main subject': 'transportation',\n",
       "  'neg tokens': None,\n",
       "  'main neg': None,\n",
       "  'is neg': None,\n",
       "  'source': 'www.thenation.com/article/archive/3-ways-public-transportation-makes-life-better-pretty-much-everyone/'},\n",
       " {'quote': ['that', '’s', 'going', 'to', 'be', 'difficult'],\n",
       "  'verb tokens': ['Put', 'simply'],\n",
       "  'main verb': 'Put',\n",
       "  'subject tokens': None,\n",
       "  'main subject': None,\n",
       "  'neg tokens': None,\n",
       "  'main neg': None,\n",
       "  'is neg': None,\n",
       "  'source': 'grist.org/climate-energy/5-terrifying-facts-from-the-leaked-u-n-climate-report/?utm_source=syndication&utm_medium=rss&utm_campaign=feed'},\n",
       " {'quote': ['One',\n",
       "   'has',\n",
       "   'the',\n",
       "   'ability',\n",
       "   'to',\n",
       "   'turn',\n",
       "   'the',\n",
       "   'carbon',\n",
       "   'dioxide',\n",
       "   'into',\n",
       "   'methane'],\n",
       "  'verb tokens': ['could',\n",
       "   'be',\n",
       "   'put',\n",
       "   'to',\n",
       "   'work',\n",
       "   'converting',\n",
       "   'CO2',\n",
       "   'captured',\n",
       "   'from',\n",
       "   'plants'],\n",
       "  'main verb': 'put',\n",
       "  'subject tokens': ['the', 'carbon', 'dioxide'],\n",
       "  'main subject': 'dioxide',\n",
       "  'neg tokens': None,\n",
       "  'main neg': None,\n",
       "  'is neg': None,\n",
       "  'source': 'www.theguardian.com/environment/2008/jan/05/activists.ethicalliving'},\n",
       " {'quote': ['But',\n",
       "   'whatever',\n",
       "   'InferenceInference',\n",
       "   '’s',\n",
       "   'actual',\n",
       "   'intentions',\n",
       "   ',',\n",
       "   'one',\n",
       "   'thing',\n",
       "   'is',\n",
       "   'clear'],\n",
       "  'verb tokens': ['puts', 'the', 'two', 'on', 'equal', 'footing'],\n",
       "  'main verb': 'puts',\n",
       "  'subject tokens': ['The',\n",
       "   'inclusion',\n",
       "   'of',\n",
       "   'demonstrably',\n",
       "   'pseudoscientific',\n",
       "   'writing',\n",
       "   'alongside',\n",
       "   'the',\n",
       "   'work',\n",
       "   'of',\n",
       "   'highly',\n",
       "   'regarded',\n",
       "   'researchers'],\n",
       "  'main subject': 'inclusion',\n",
       "  'neg tokens': None,\n",
       "  'main neg': None,\n",
       "  'is neg': None,\n",
       "  'source': 'www.motherjones.com/environment/2019/01/a-science-journal-funded-by-peter-thiel-is-running-articles-dismissing-climate-change-and-evolution/'},\n",
       " {'quote': ['You', 'take', 'somebody', 'like', 'Mr.', 'Beal'],\n",
       "  'verb tokens': ['put',\n",
       "   'somebody',\n",
       "   'like',\n",
       "   'Beal',\n",
       "   'in',\n",
       "   'charge',\n",
       "   'of',\n",
       "   'China'],\n",
       "  'main verb': 'put',\n",
       "  'subject tokens': ['you'],\n",
       "  'main subject': 'you',\n",
       "  'neg tokens': None,\n",
       "  'main neg': None,\n",
       "  'is neg': None,\n",
       "  'source': 'www.nytimes.com/2019/03/29/business/energy-environment/andrew-beal-california.html'},\n",
       " {'quote': ['One',\n",
       "   'year',\n",
       "   'after',\n",
       "   'the',\n",
       "   'cyclone',\n",
       "   'hit',\n",
       "   'Beira',\n",
       "   ',',\n",
       "   'reconstruction',\n",
       "   'is',\n",
       "   'taking',\n",
       "   'place',\n",
       "   ',',\n",
       "   'but',\n",
       "   'reconstruction',\n",
       "   '’s',\n",
       "   'growing',\n",
       "   'very',\n",
       "   'slowly',\n",
       "   'and',\n",
       "   'people',\n",
       "   'are',\n",
       "   'rebuilding'],\n",
       "  'verb tokens': ['put', 'a', 'roof', 'on', 'people', 'home'],\n",
       "  'main verb': 'put',\n",
       "  'subject tokens': ['people’ve'],\n",
       "  'main subject': 'people’ve',\n",
       "  'neg tokens': None,\n",
       "  'main neg': None,\n",
       "  'is neg': None,\n",
       "  'source': 'www.washingtonpost.com/world/africa/a-year-after-deadly-cyclone-mozambique-now-braces-for-virus/2020/03/16/a4936118-6764-11ea-b199-3a9799c54512_story.html'}]"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "other_quotes[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A lot of quotes don't have a subject:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44350"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([q for q in quotes if q['main subject'] is None])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most common subject stems--it looks like coref didn't fully do its job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('i', 27014),\n",
       " ('we', 14231),\n",
       " ('you', 10152),\n",
       " ('it', 8506),\n",
       " ('scientist', 6650),\n",
       " ('he', 5808),\n",
       " ('studi', 5787),\n",
       " ('research', 5183),\n",
       " ('report', 4995),\n",
       " ('peopl', 4212),\n",
       " ('trump', 3895),\n",
       " ('offici', 3570),\n",
       " ('’s', 3097),\n",
       " ('she', 2845),\n",
       " ('expert', 2798),\n",
       " ('they', 2221),\n",
       " ('obama', 2030),\n",
       " ('one', 1982),\n",
       " ('author', 1872),\n",
       " ('group', 1818),\n",
       " ('that', 1750),\n",
       " ('percent', 1598),\n",
       " ('agenc', 1481),\n",
       " ('some', 1335),\n",
       " ('compani', 1315),\n",
       " ('sander', 1276),\n",
       " ('thi', 1247),\n",
       " ('administr', 1189),\n",
       " ('govern', 1128),\n",
       " ('“', 956),\n",
       " ('team', 954),\n",
       " ('critic', 952),\n",
       " ('poll', 933),\n",
       " ('democrat', 918),\n",
       " ('presid', 899),\n",
       " ('data', 892),\n",
       " ('pruitt', 869),\n",
       " ('those', 861),\n",
       " ('mani', 855),\n",
       " ('analysi', 844),\n",
       " ('depart', 838),\n",
       " ('leader', 824),\n",
       " ('us', 824),\n",
       " ('biden', 811),\n",
       " ('activist', 781),\n",
       " ('epa', 779),\n",
       " ('state', 774),\n",
       " ('hi', 768),\n",
       " ('brown', 752),\n",
       " ('organ', 747),\n",
       " ('other', 746),\n",
       " ('environmentalist', 741),\n",
       " ('time', 735),\n",
       " ('paper', 730),\n",
       " ('analyst', 725),\n",
       " ('republican', 723),\n",
       " ('panel', 692),\n",
       " ('her', 692),\n",
       " ('countri', 677),\n",
       " ('—', 676),\n",
       " ('model', 675),\n",
       " ('clinton', 669),\n",
       " ('gore', 658),\n",
       " ('smith', 630),\n",
       " ('warren', 617),\n",
       " ('parent', 615),\n",
       " ('offic', 613),\n",
       " ('there', 605),\n",
       " ('american', 602),\n",
       " ('survey', 576),\n",
       " ('evid', 576),\n",
       " ('johnson', 564),\n",
       " ('number', 554),\n",
       " ('chang', 553),\n",
       " ('who', 552),\n",
       " ('cortez', 536),\n",
       " ('member', 529),\n",
       " ('spokesman', 527),\n",
       " ('franci', 525),\n",
       " ('everyon', 522),\n",
       " ('’', 521),\n",
       " ('scienc', 514),\n",
       " ('advoc', 512),\n",
       " ('industri', 511),\n",
       " ('campaign', 501),\n",
       " ('court', 500),\n",
       " ('center', 493),\n",
       " ('all', 484),\n",
       " ('economist', 471),\n",
       " ('china', 460),\n",
       " ('hansen', 459),\n",
       " ('hous', 456),\n",
       " ('bloomberg', 451),\n",
       " ('doctor', 447),\n",
       " ('man', 440),\n",
       " ('mann', 435),\n",
       " ('minist', 434),\n",
       " ('nation', 431),\n",
       " ('’d', 425),\n",
       " ('result', 424),\n",
       " ('institut', 423),\n",
       " ('document', 418),\n",
       " ('anyon', 417),\n",
       " ('investig', 414),\n",
       " ('resid', 411),\n",
       " ('support', 411),\n",
       " ('jone', 397),\n",
       " ('kerri', 396),\n",
       " ('our', 395),\n",
       " ('new', 393),\n",
       " ('mccarthi', 393),\n",
       " ('major', 391),\n",
       " ('statement', 391),\n",
       " ('thunberg', 385),\n",
       " ('articl', 381),\n",
       " ('sourc', 379),\n",
       " ('student', 373),\n",
       " ('jackson', 368),\n",
       " ('plan', 367),\n",
       " ('execut', 367),\n",
       " ('me', 366),\n",
       " ('voter', 364),\n",
       " ('committe', 360),\n",
       " ('candid', 350),\n",
       " ('harri', 346),\n",
       " ('bush', 342),\n",
       " ('post', 341),\n",
       " ('spokesperson', 339),\n",
       " ('polic', 338),\n",
       " ('romney', 338),\n",
       " ('project', 333),\n",
       " ('mckibben', 327),\n",
       " ('woman', 322),\n",
       " ('spokeswoman', 320),\n",
       " ('someon', 318),\n",
       " ('moor', 318),\n",
       " ('ipcc', 315),\n",
       " ('servic', 315),\n",
       " ('politician', 312),\n",
       " ('find', 309),\n",
       " ('which', 309),\n",
       " ('oppon', 309),\n",
       " ('farmer', 307),\n",
       " ('’ve', 306),\n",
       " ('colleagu', 303),\n",
       " ('associ', 301),\n",
       " ('buttigieg', 298),\n",
       " ('observ', 298),\n",
       " ('miller', 298),\n",
       " ('%', 297),\n",
       " ('friend', 293),\n",
       " ('commiss', 288),\n",
       " ('pelosi', 287),\n",
       " ('lot', 280),\n",
       " ('william', 279),\n",
       " ('cdc', 278),\n",
       " ('perri', 274),\n",
       " ('director', 272),\n",
       " ('record', 271),\n",
       " ('davi', 269),\n",
       " ('world', 267),\n",
       " ('nobodi', 265),\n",
       " ('emiss', 265),\n",
       " ('propon', 264),\n",
       " ('wheeler', 260),\n",
       " ('taylor', 259),\n",
       " ('figur', 255),\n",
       " ('estim', 253),\n",
       " ('aid', 253),\n",
       " ('nasa', 253),\n",
       " ('parti', 253),\n",
       " ('commun', 252),\n",
       " ('conserv', 251),\n",
       " ('guardian', 250),\n",
       " ('senat', 250),\n",
       " ('letter', 249),\n",
       " ('lawmak', 248),\n",
       " ('review', 246),\n",
       " ('skeptic', 244),\n",
       " ('gener', 242),\n",
       " ('mcconnel', 236),\n",
       " ('gate', 236),\n",
       " ('bank', 234),\n",
       " ('most', 234),\n",
       " ('advis', 231),\n",
       " ('council', 231),\n",
       " ('n’t', 230),\n",
       " ('assess', 230),\n",
       " ('regul', 230),\n",
       " ('citi', 230),\n",
       " ('worker', 229),\n",
       " ('person', 229),\n",
       " ('journal', 229),\n",
       " ('bill', 228),\n",
       " ('musk', 228),\n",
       " ('children', 228),\n",
       " ('rule', 227),\n",
       " ('lawyer', 227),\n",
       " ('jr.', 226),\n",
       " ('mother', 223),\n",
       " ('’m', 222),\n",
       " ('governor', 222),\n",
       " ('green', 221),\n",
       " ('polici', 220),\n",
       " ('thompson', 220),\n",
       " ('allen', 218),\n",
       " ('anderson', 218),\n",
       " ('stern', 215),\n",
       " ('vaccin', 215),\n",
       " ('stori', 213),\n",
       " ('famili', 213),\n",
       " ('cruz', 212),\n",
       " ('forecast', 211),\n",
       " ('kennedi', 210),\n",
       " ('professor', 210),\n",
       " ('schmidt', 210),\n",
       " ('employe', 209),\n",
       " ('law', 209),\n",
       " ('zink', 208),\n",
       " ('steyer', 207),\n",
       " ('public', 205),\n",
       " ('half', 204),\n",
       " ('press', 204),\n",
       " ('tillerson', 203),\n",
       " ('system', 200),\n",
       " ('fonda', 200),\n",
       " ('univers', 199),\n",
       " ('plant', 198),\n",
       " ('paul', 198),\n",
       " ('mayor', 197),\n",
       " ('repres', 195),\n",
       " ('merkel', 194),\n",
       " ('head', 194),\n",
       " ('experi', 193),\n",
       " ('michael', 192),\n",
       " ('temperatur', 192),\n",
       " ('christi', 190),\n",
       " ('women', 190),\n",
       " ('price', 189),\n",
       " ('king', 189),\n",
       " ('lewi', 188),\n",
       " ('secretari', 188),\n",
       " ('ebel', 187),\n",
       " ('graham', 187),\n",
       " ('bodi', 186),\n",
       " ('guterr', 185),\n",
       " ('websit', 185),\n",
       " ('histori', 185),\n",
       " ('media', 184),\n",
       " ('program', 183),\n",
       " ('morrison', 182),\n",
       " ('exxon', 181),\n",
       " ('hayho', 180),\n",
       " ('robert', 178),\n",
       " ('ocean', 177),\n",
       " ('manag', 177),\n",
       " ('insle', 176),\n",
       " ('blasio', 175),\n",
       " ('judg', 175),\n",
       " ('foundat', 174),\n",
       " ('movement', 173),\n",
       " ('warm', 173),\n",
       " ('fact', 172),\n",
       " ('everybodi', 172),\n",
       " ('inhof', 170),\n",
       " ('level', 170),\n",
       " ('case', 169),\n",
       " ('cohen', 167),\n",
       " ('deal', 167),\n",
       " ('none', 167),\n",
       " ('decis', 166),\n",
       " ('human', 164),\n",
       " ('reuter', 162),\n",
       " ('work', 161),\n",
       " ('congress', 160),\n",
       " ('bp', 159),\n",
       " ('util', 159),\n",
       " ('peter', 159),\n",
       " ('white', 159),\n",
       " ('putin', 159),\n",
       " ('scott', 158),\n",
       " ('third', 156),\n",
       " ('board', 156),\n",
       " ('roger', 156),\n",
       " ('union', 155),\n",
       " ('energi', 155),\n",
       " ('–', 154),\n",
       " ('protest', 154),\n",
       " ('cuomo', 154),\n",
       " ('reader', 154),\n",
       " ('macron', 152),\n",
       " ('california', 152),\n",
       " ('email', 151),\n",
       " ('engin', 151),\n",
       " ('happer', 150),\n",
       " ('water', 148),\n",
       " ('’ll', 148),\n",
       " ('noaa', 148),\n",
       " ('klein', 147),\n",
       " ('father', 147),\n",
       " ('alarmist', 146),\n",
       " ('hay', 146),\n",
       " ('thing', 145),\n",
       " ('guy', 145),\n",
       " ('clark', 144),\n",
       " ('pope', 144),\n",
       " ('yang', 143),\n",
       " ('book', 141),\n",
       " ('test', 141),\n",
       " ('iea', 140),\n",
       " ('greenpeac', 139),\n",
       " ('wilson', 139),\n",
       " ('trenberth', 139),\n",
       " ('lee', 139),\n",
       " ('societi', 138),\n",
       " ('robinson', 138),\n",
       " ('osborn', 137),\n",
       " ('spencer', 136),\n",
       " ('video', 136),\n",
       " ('measur', 135),\n",
       " ('owner', 134),\n",
       " ('negoti', 134),\n",
       " ('kelli', 133),\n",
       " ('power', 133),\n",
       " ('child', 132),\n",
       " ('firm', 131),\n",
       " ('lawsuit', 131),\n",
       " ('rubio', 130),\n",
       " ('curri', 129),\n",
       " ('way', 129),\n",
       " ('watt', 128),\n",
       " ('climat', 128),\n",
       " ('whitehous', 128),\n",
       " ('holdren', 128),\n",
       " ('comment', 127),\n",
       " ('figuer', 127),\n",
       " ('ministri', 127),\n",
       " ('consum', 127),\n",
       " ('abbott', 127),\n",
       " ('young', 127),\n",
       " ('eia', 126),\n",
       " ('question', 125),\n",
       " ('economi', 125),\n",
       " ('men', 125),\n",
       " ('him', 125),\n",
       " ('rate', 124),\n",
       " ('thoma', 124),\n",
       " (\"'s\", 124),\n",
       " ('pompeo', 124),\n",
       " ('action', 123),\n",
       " ('hugh', 123),\n",
       " ('cost', 123),\n",
       " ('klobuchar', 122),\n",
       " ('son', 122),\n",
       " ('martin', 122),\n",
       " ('tree', 121),\n",
       " ('ga', 121),\n",
       " ('hill', 121),\n",
       " ('fund', 120),\n",
       " ('co2', 120),\n",
       " ('act', 119),\n",
       " ('coalit', 119),\n",
       " ('collin', 119),\n",
       " ('cook', 118),\n",
       " ('bureau', 118),\n",
       " ('ad', 117),\n",
       " ('market', 117),\n",
       " ('agreement', 117),\n",
       " ('murray', 117),\n",
       " ('scholar', 117),\n",
       " ('wood', 117),\n",
       " ('propos', 116),\n",
       " ('birol', 116),\n",
       " ('folk', 116),\n",
       " ('editor', 116),\n",
       " ('meyer', 115),\n",
       " ('part', 115),\n",
       " ('wright', 114),\n",
       " ('journalist', 114),\n",
       " ('idea', 114),\n",
       " ('oper', 113),\n",
       " ('trudeau', 113),\n",
       " ('side', 113),\n",
       " ('cnn', 113),\n",
       " ('magazin', 112),\n",
       " ('oppenheim', 112),\n",
       " ('carter', 112),\n",
       " ('hall', 112),\n",
       " ('forc', 111),\n",
       " ('shell', 111),\n",
       " ('schwarzenegg', 111),\n",
       " ('morgan', 110),\n",
       " ('walker', 110),\n",
       " ('god', 110),\n",
       " ('year', 109),\n",
       " ('emanuel', 109),\n",
       " ('murphi', 109),\n",
       " ('donig', 109),\n",
       " ('few', 109),\n",
       " ('outlet', 108),\n",
       " ('daughter', 108),\n",
       " ('amount', 108),\n",
       " ('investor', 108),\n",
       " ('chief', 108),\n",
       " ('effort', 108),\n",
       " ('carlson', 108),\n",
       " ('particip', 107),\n",
       " ('booker', 107),\n",
       " ('what', 107),\n",
       " ('murkowski', 107),\n",
       " ('attorney', 107),\n",
       " ('busi', 106),\n",
       " ('statist', 106),\n",
       " ('singer', 106),\n",
       " ('keith', 106),\n",
       " ('ford', 106),\n",
       " ('prosecutor', 106),\n",
       " ('olson', 106),\n",
       " ('mccain', 105),\n",
       " ('develop', 105),\n",
       " ('diplomat', 105),\n",
       " ('watson', 105),\n",
       " ('brune', 105),\n",
       " ('writer', 104),\n",
       " ('calcul', 104),\n",
       " ('line', 104),\n",
       " ('ryan', 103),\n",
       " ('natur', 103),\n",
       " ('epstein', 103),\n",
       " ('manufactur', 103),\n",
       " ('legisl', 103),\n",
       " ('area', 103),\n",
       " ('well', 103),\n",
       " ('sullivan', 103),\n",
       " ('caldeira', 103),\n",
       " ('dyson', 103),\n",
       " ('jacob', 103),\n",
       " ('draft', 102),\n",
       " ('school', 102),\n",
       " ('plaintiff', 102),\n",
       " ('liber', 101),\n",
       " ('georg', 101),\n",
       " ('nye', 100),\n",
       " ('map', 100),\n",
       " ('biologist', 100),\n",
       " ('imag', 100),\n",
       " ('cox', 100),\n",
       " ('newspap', 100),\n",
       " ('fire', 99),\n",
       " ('thousand', 99),\n",
       " ('issu', 99),\n",
       " ('harvey', 99),\n",
       " ('kid', 99),\n",
       " ('goal', 99),\n",
       " ('anoth', 98),\n",
       " ('peterson', 98),\n",
       " ('corpor', 97),\n",
       " ('product', 97),\n",
       " ('amazon', 97),\n",
       " ('levi', 97),\n",
       " ('milloy', 96),\n",
       " ('field', 96),\n",
       " ('theori', 96),\n",
       " ('keel', 96),\n",
       " ('pachauri', 96),\n",
       " ('myer', 96),\n",
       " ('nelson', 96),\n",
       " ('pilot', 96),\n",
       " ('driver', 95),\n",
       " ('individu', 95),\n",
       " ('bezo', 95),\n",
       " ('u.s.', 95),\n",
       " ('releas', 94),\n",
       " ('levin', 94),\n",
       " ('effect', 94),\n",
       " ('shepherd', 94),\n",
       " ('fda', 94),\n",
       " ('jacobson', 93),\n",
       " ('castro', 93),\n",
       " ('technolog', 93),\n",
       " ('nichol', 93),\n",
       " ('site', 93),\n",
       " ('o’rourk', 92),\n",
       " ('evan', 92),\n",
       " ('club', 92),\n",
       " ('both', 92),\n",
       " ('piec', 92),\n",
       " ('popul', 92),\n",
       " ('wife', 91),\n",
       " ('quarter', 91),\n",
       " ('produc', 91),\n",
       " ('fox', 91),\n",
       " ('staff', 91),\n",
       " ('edward', 91),\n",
       " ('hamilton', 91),\n",
       " ('chairman', 90),\n",
       " ('defend', 90),\n",
       " ('them', 90),\n",
       " ('holland', 90),\n",
       " ('chart', 90),\n",
       " ('facebook', 90),\n",
       " ('automak', 90),\n",
       " ('event', 90),\n",
       " ('conservationist', 90),\n",
       " ('page', 89),\n",
       " ('problem', 89),\n",
       " ('scenario', 89),\n",
       " ('america', 89),\n",
       " ('oil', 89),\n",
       " ('claim', 88),\n",
       " ('carson', 88),\n",
       " ('these', 88),\n",
       " ('elect', 88),\n",
       " ('founder', 87),\n",
       " ('phillip', 87),\n",
       " ('germani', 87),\n",
       " ('teacher', 87),\n",
       " ('russel', 87),\n",
       " ('adam', 86),\n",
       " ('wang', 86),\n",
       " ('much', 86),\n",
       " ('process', 86),\n",
       " ('church', 86),\n",
       " ('gray', 86),\n",
       " ('pyle', 86),\n",
       " ('greta', 85),\n",
       " ('version', 85),\n",
       " ('strauss', 85),\n",
       " ('tax', 84),\n",
       " ('tan', 84),\n",
       " ('wit', 84),\n",
       " ('volkswagen', 84),\n",
       " ('baker', 84),\n",
       " ('cooper', 83),\n",
       " ('un', 83),\n",
       " ('user', 83),\n",
       " ('cameron', 83),\n",
       " ('anybodi', 83),\n",
       " ('tol', 83),\n",
       " ('network', 82),\n",
       " ('maker', 82),\n",
       " ('rest', 82),\n",
       " ('insid', 82),\n",
       " ('bbc', 82),\n",
       " ('progress', 81),\n",
       " ('storm', 81),\n",
       " ('point', 81),\n",
       " ('ceo', 81),\n",
       " ('academi', 81),\n",
       " ('palmer', 81),\n",
       " ('their', 81),\n",
       " ('analys', 80),\n",
       " ('ross', 80),\n",
       " ('climatologist', 80),\n",
       " ('staffer', 80),\n",
       " ('marshal', 80),\n",
       " ('custom', 80),\n",
       " ('citizen', 80),\n",
       " ('sign', 79),\n",
       " ('schneider', 79),\n",
       " ('stewart', 79),\n",
       " ('memo', 78),\n",
       " ('speci', 78),\n",
       " ('sach', 78),\n",
       " ('duke', 78),\n",
       " ('light', 78),\n",
       " ('bolsonaro', 78),\n",
       " ('consensu', 78),\n",
       " ('jame', 78),\n",
       " ('bell', 78),\n",
       " ('frank', 78),\n",
       " ('politico', 77),\n",
       " ('graph', 77),\n",
       " ('trend', 77),\n",
       " ('pielk', 77),\n",
       " ('forest', 77),\n",
       " ('newsom', 77),\n",
       " ('left', 77),\n",
       " ('day', 77),\n",
       " ('bernhardt', 77),\n",
       " ('earth', 76),\n",
       " ('campbel', 76),\n",
       " ('someth', 76),\n",
       " ('ward', 76),\n",
       " ('reed', 76),\n",
       " ('resolut', 76),\n",
       " ('russia', 76),\n",
       " ('lackner', 76),\n",
       " ('moniz', 76),\n",
       " ('diseas', 75),\n",
       " ('patient', 75),\n",
       " ('penc', 75),\n",
       " ('holmstead', 75),\n",
       " ('lindzen', 75),\n",
       " ('offit', 75),\n",
       " ('deleg', 75),\n",
       " ('chamber', 75),\n",
       " ('salazar', 75),\n",
       " ('newman', 75),\n",
       " ('commission', 74),\n",
       " ('girl', 74),\n",
       " ('leiserowitz', 74),\n",
       " ('word', 74),\n",
       " ('titley', 74),\n",
       " ('bishop', 74),\n",
       " ('somebodi', 74),\n",
       " ('turner', 74),\n",
       " ('brook', 74),\n",
       " ('wallac', 74),\n",
       " ('nordhau', 73),\n",
       " ('each', 73),\n",
       " ('kind', 73),\n",
       " ('wolf', 73),\n",
       " ('stein', 73),\n",
       " ('weaver', 73),\n",
       " ('schiff', 73),\n",
       " ('ehrlich', 72),\n",
       " ('messag', 72),\n",
       " ('al', 72),\n",
       " ('adult', 72),\n",
       " ('argument', 72),\n",
       " ('initi', 72),\n",
       " ('denier', 72),\n",
       " ('coleman', 72),\n",
       " ('pollut', 72),\n",
       " ('corp', 72),\n",
       " ('note', 71),\n",
       " ('million', 71),\n",
       " ('friedman', 71),\n",
       " ('planet', 71),\n",
       " ('leadership', 71),\n",
       " ('hundr', 71),\n",
       " ('use', 71),\n",
       " ('moon', 71),\n",
       " ('debat', 71),\n",
       " ('solomon', 71),\n",
       " ('reid', 71),\n",
       " ('mail', 70),\n",
       " ('master', 70),\n",
       " ('rise', 70),\n",
       " ('lomborg', 70),\n",
       " ('monitor', 70),\n",
       " ('exxonmobil', 70),\n",
       " ('foster', 70),\n",
       " ('pg&e', 70),\n",
       " ('ap', 69),\n",
       " ('specialist', 69),\n",
       " ('santorum', 69),\n",
       " ('stephen', 69),\n",
       " ('ice', 69),\n",
       " ('mill', 69),\n",
       " ('mom', 69),\n",
       " ('order', 69),\n",
       " ('tribe', 69),\n",
       " ('hawk', 68),\n",
       " ('…', 68),\n",
       " ('west', 68),\n",
       " ('matthew', 68),\n",
       " ('burk', 68),\n",
       " ('steven', 68),\n",
       " ('romm', 68),\n",
       " ('fauci', 68),\n",
       " ('podesta', 67),\n",
       " ('holm', 67),\n",
       " ('strategist', 67),\n",
       " ('job', 67),\n",
       " ('mobil', 67),\n",
       " ('news', 67),\n",
       " ('impact', 66),\n",
       " ('tyson', 66),\n",
       " ('neighbor', 66),\n",
       " ('tesla', 66),\n",
       " ('boxer', 66),\n",
       " ('goldstein', 66),\n",
       " ('jarraud', 65),\n",
       " ('becker', 65),\n",
       " ('pediatrician', 65),\n",
       " ('respons', 65),\n",
       " ('appl', 65),\n",
       " ('boss', 65),\n",
       " ('burnett', 65),\n",
       " ('bast', 64),\n",
       " ('horner', 64),\n",
       " ('wind', 64),\n",
       " ('hausfath', 64),\n",
       " ('bird', 64),\n",
       " ('india', 64),\n",
       " ('concern', 64),\n",
       " ('inform', 64),\n",
       " ('liu', 64),\n",
       " ('read', 64),\n",
       " ('bate', 64),\n",
       " ('allianc', 64),\n",
       " ('weber', 64),\n",
       " ('challeng', 63),\n",
       " ('look', 63),\n",
       " ('crisi', 63),\n",
       " ('suit', 63),\n",
       " ('haley', 63),\n",
       " ('meteorologist', 63),\n",
       " ('morano', 63),\n",
       " ('fisher', 63),\n",
       " ('rice', 63),\n",
       " ('announc', 62),\n",
       " ('mccabe', 62),\n",
       " ('manchin', 62),\n",
       " ('singh', 62),\n",
       " ('may', 62),\n",
       " ('death', 62),\n",
       " ('star', 62),\n",
       " ('franc', 62),\n",
       " ('meet', 62),\n",
       " ('standard', 62),\n",
       " ('voic', 62),\n",
       " ('snyder', 62),\n",
       " ('justic', 62),\n",
       " ('speaker', 61),\n",
       " ('stone', 61),\n",
       " ('headlin', 61),\n",
       " ('gingrich', 61),\n",
       " ('demand', 61),\n",
       " ('fear', 61),\n",
       " ('chu', 61),\n",
       " ('japan', 61),\n",
       " ('canada', 61),\n",
       " ('howard', 61),\n",
       " ('googl', 61),\n",
       " ('gerrard', 61),\n",
       " ('wagner', 60),\n",
       " ('posit', 60),\n",
       " ('muller', 60),\n",
       " ('karl', 60),\n",
       " ('seri', 60),\n",
       " ('park', 60),\n",
       " ('monckton', 60),\n",
       " ('husband', 60),\n",
       " ('stavin', 60),\n",
       " ('bailey', 60),\n",
       " ('mitchel', 60),\n",
       " ('zuckerberg', 60),\n",
       " ('frieden', 60),\n",
       " ('brother', 59),\n",
       " ('alli', 59),\n",
       " ('patterson', 59),\n",
       " ('approach', 59),\n",
       " ('himself', 59),\n",
       " ('alexand', 59),\n",
       " ('li', 59),\n",
       " ('fink', 59),\n",
       " ('long', 59),\n",
       " ('policymak', 59),\n",
       " ('car', 59),\n",
       " ('hallam', 59),\n",
       " ('kim', 59),\n",
       " ('schumer', 58),\n",
       " ('backer', 58),\n",
       " ('confer', 58),\n",
       " ('anim', 58),\n",
       " ('koch', 58),\n",
       " ('oliv', 58),\n",
       " ('pentagon', 58),\n",
       " ('jenkin', 58),\n",
       " ('complaint', 58),\n",
       " ('bledso', 58),\n",
       " ('ziska', 58),\n",
       " ('morri', 58),\n",
       " ('hunt', 57),\n",
       " ('hawkin', 57),\n",
       " ('xi', 57),\n",
       " ('armstrong', 57),\n",
       " ('nurs', 57),\n",
       " ('markey', 57),\n",
       " ('ban', 57),\n",
       " ('schneiderman', 57),\n",
       " ('mooney', 57),\n",
       " ('steiner', 57),\n",
       " ('rosenberg', 57),\n",
       " ('gordon', 57),\n",
       " ('kelley', 57),\n",
       " ('bolton', 57),\n",
       " ('clement', 56),\n",
       " ('cobb', 56),\n",
       " ('gonzalez', 56),\n",
       " ('fan', 56),\n",
       " ('carney', 55),\n",
       " ('step', 55),\n",
       " ('station', 55),\n",
       " ('increas', 55),\n",
       " ('two', 55),\n",
       " ('lovelock', 55),\n",
       " ('australia', 55),\n",
       " ('idso', 55),\n",
       " ('kaufman', 55),\n",
       " ('mckay', 55),\n",
       " ('burn', 55),\n",
       " ('harper', 55),\n",
       " ('view', 54),\n",
       " ('sever', 54),\n",
       " ('butler', 54),\n",
       " ('eu', 54),\n",
       " ('schellnhub', 54),\n",
       " ('activ', 54),\n",
       " ('palin', 54),\n",
       " ('ingli', 54),\n",
       " ('summari', 54),\n",
       " ('shellenberg', 54),\n",
       " ('reilli', 54),\n",
       " ('shindel', 54),\n",
       " ('wehrum', 54),\n",
       " ('weather', 53),\n",
       " ('mora', 53),\n",
       " ('respond', 53),\n",
       " ('mcintyr', 53),\n",
       " ('johnston', 53),\n",
       " ('prakash', 53),\n",
       " ('defens', 53),\n",
       " ('coupl', 53),\n",
       " ('gabbard', 53),\n",
       " ('patrick', 53),\n",
       " ('fuel', 53),\n",
       " ('move', 53),\n",
       " ('geologist', 53),\n",
       " ('exampl', 53),\n",
       " ('nadler', 53),\n",
       " ('kammen', 52),\n",
       " ('organis', 52),\n",
       " ('parker', 52),\n",
       " ('europ', 52),\n",
       " ('tank', 52),\n",
       " ('coal', 52),\n",
       " ('place', 52),\n",
       " ('goldberg', 52),\n",
       " ('money', 52),\n",
       " ('mnuchin', 52),\n",
       " ('boer', 52),\n",
       " ('cole', 52),\n",
       " ('u.n.', 51),\n",
       " ('region', 51),\n",
       " ('mulvaney', 51),\n",
       " ('merck', 51),\n",
       " ('academ', 51),\n",
       " ('examin', 51),\n",
       " ('victor', 51),\n",
       " ('freeman', 51),\n",
       " ('meier', 51),\n",
       " ('environ', 51),\n",
       " ('howarth', 51),\n",
       " ('oresk', 51),\n",
       " ('keenan', 51),\n",
       " ('scalia', 51),\n",
       " ('hunter', 51),\n",
       " ('richard', 50),\n",
       " ('sheet', 50),\n",
       " ('weiss', 50),\n",
       " ('monbiot', 50),\n",
       " ('sun', 50),\n",
       " ('text', 50),\n",
       " ('grijalva', 50),\n",
       " ('columnist', 50),\n",
       " ('strategi', 50),\n",
       " ('zhang', 50),\n",
       " ('burger', 50),\n",
       " ('netanyahu', 50),\n",
       " ('attack', 49),\n",
       " ('benefit', 49),\n",
       " ('partner', 49),\n",
       " ('factor', 49),\n",
       " ('chines', 49),\n",
       " ('nichola', 49),\n",
       " ('fish', 49),\n",
       " ('shaw', 49),\n",
       " ('goldman', 49),\n",
       " ('success', 49),\n",
       " ('cramer', 49),\n",
       " ('garcia', 49),\n",
       " ('larson', 49),\n",
       " ('ambassador', 49),\n",
       " ('lawrenc', 49),\n",
       " ('berni', 48),\n",
       " ('mabu', 48),\n",
       " ('boehner', 48),\n",
       " ('host', 48),\n",
       " ('show', 48),\n",
       " ('terri', 48),\n",
       " ('local', 48),\n",
       " ('watchdog', 48),\n",
       " ('washington', 48),\n",
       " ('trial', 48),\n",
       " ('cap', 48),\n",
       " ('simpson', 48),\n",
       " ('guard', 48),\n",
       " ('dean', 48),\n",
       " ('dioxid', 48),\n",
       " ('richardson', 48),\n",
       " ('condit', 48),\n",
       " ('bridenstin', 48),\n",
       " ('knight', 48),\n",
       " ('horowitz', 48),\n",
       " ('mae', 48),\n",
       " ('film', 47),\n",
       " ('growth', 47),\n",
       " ('blair', 47),\n",
       " ('hand', 47),\n",
       " ('gregori', 47),\n",
       " ('glacier', 47),\n",
       " ('giant', 47),\n",
       " ('alley', 47),\n",
       " ('vote', 47),\n",
       " ('air', 47),\n",
       " ('juri', 47),\n",
       " ('jewel', 47),\n",
       " ('microsoft', 47),\n",
       " ('ramanathan', 47),\n",
       " ('upton', 47),\n",
       " ('hotez', 47),\n",
       " ('harrison', 47),\n",
       " ('schaffner', 47),\n",
       " ('berri', 47),\n",
       " ('moral', 47),\n",
       " ('kasich', 46),\n",
       " ('leonard', 46),\n",
       " ('player', 46),\n",
       " ('session', 46),\n",
       " ('peiser', 46),\n",
       " ('airlin', 46),\n",
       " ('ali', 46),\n",
       " ('fuller', 46),\n",
       " ('barrasso', 46),\n",
       " ('adler', 46),\n",
       " ('hoerl', 46),\n",
       " ('buckley', 46),\n",
       " ('hospit', 46),\n",
       " ('pipelin', 46),\n",
       " ('historian', 46),\n",
       " ('elit', 46),\n",
       " ('matti', 46),\n",
       " ('powel', 46),\n",
       " ('lin', 46),\n",
       " ('hart', 46),\n",
       " ('homenuk', 46),\n",
       " ('risk', 45),\n",
       " ('york', 45),\n",
       " ('beck', 45),\n",
       " ('island', 45),\n",
       " ('agent', 45),\n",
       " ('rodriguez', 45),\n",
       " ('interest', 45),\n",
       " ('noth', 45),\n",
       " ('threat', 45),\n",
       " ('poland', 45),\n",
       " ('right', 45),\n",
       " ('consult', 45),\n",
       " ('chronicl', 45),\n",
       " ('massi', 45),\n",
       " ('holt', 45),\n",
       " ('veteran', 44),\n",
       " ('gottlieb', 44),\n",
       " ('carbon', 44),\n",
       " ('interview', 44),\n",
       " ('old', 44),\n",
       " ('herzog', 44),\n",
       " ('answer', 44),\n",
       " ('jensen', 44),\n",
       " ('file', 44),\n",
       " ('ball', 44),\n",
       " ('heat', 44),\n",
       " ('griffin', 44),\n",
       " ('zaelk', 44),\n",
       " ('sampl', 44),\n",
       " ('miliband', 44),\n",
       " ('andrew', 44),\n",
       " ('krugman', 44),\n",
       " ('ccc', 44),\n",
       " ('feinstein', 44),\n",
       " ('shah', 44),\n",
       " ('christensen', 44),\n",
       " ('conway', 44),\n",
       " ('diffenbaugh', 44),\n",
       " ('willi', 44),\n",
       " ('hillari', 43),\n",
       " ('actress', 43),\n",
       " ('opinion', 43),\n",
       " ('walsh', 43),\n",
       " ('golden', 43),\n",
       " ('shift', 43),\n",
       " ('hanson', 43),\n",
       " ('outbreak', 43),\n",
       " ('actor', 43),\n",
       " ('overpeck', 43),\n",
       " ('fishermen', 43),\n",
       " ('abram', 43),\n",
       " ('everyth', 43),\n",
       " ('target', 43),\n",
       " ('list', 43),\n",
       " ('edenhof', 43),\n",
       " ('mueller', 43),\n",
       " ('dixon', 43),\n",
       " ('gleick', 43),\n",
       " ('eakin', 43),\n",
       " ('mckenna', 42),\n",
       " ...]"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_main_subj_stems = [ps.stem(x['main subject']).lower() for x in quotes if x['main subject'] is not None]\n",
    "counted_main_subj_stems = Counter(all_main_subj_stems)\n",
    "sorted(counted_main_subj_stems.items(),key=lambda x:x[1],reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5808"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "he_quotes = get_quotes_with_stem({'he'},'main subject',quotes)\n",
    "len(he_quotes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'quote': ['People',\n",
       "  'free',\n",
       "  '-',\n",
       "  'ride',\n",
       "  'when',\n",
       "  'People',\n",
       "  'jump',\n",
       "  'the',\n",
       "  'turnstile',\n",
       "  'on',\n",
       "  'the',\n",
       "  'subway'],\n",
       " 'verb tokens': ['said'],\n",
       " 'main verb': 'said',\n",
       " 'subject tokens': ['he'],\n",
       " 'main subject': 'he',\n",
       " 'neg tokens': None,\n",
       " 'main neg': None,\n",
       " 'is neg': None,\n",
       " 'source': 'www.washingtonpost.com/national/health-science/a-kind-of-dark-realism-why-the-climate-change-problem-is-starting-to-look-too-big-to-solve/2018/12/03/378e49e4-e75d-11e8-a939-9469f1166f9d_story.html'}"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "he_quotes[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Somewhere between 8.3k to 8.8k quotes have a negated main verb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8350"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([q for q in quotes if q['is neg']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8804"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([q for q in quotes if q['main neg'] is not None])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('New York Times', 114096),\n",
       " ('Mother Jones', 43927),\n",
       " ('Fox', 34783),\n",
       " ('Christian Science Monitor', 29316),\n",
       " ('Washington Post', 29108),\n",
       " ('The Nation', 22924),\n",
       " ('Breitbart', 22808),\n",
       " ('Guardian (US)', 22716),\n",
       " ('Vox', 18416),\n",
       " ('Buzzfeed', 9226),\n",
       " ('Daily Caller', 8395),\n",
       " ('Grist', 8242),\n",
       " (\"Children's Health Defense\", 7671),\n",
       " ('Shot of Prevention', 7028),\n",
       " ('Blaze', 5930),\n",
       " ('Alternet', 5925),\n",
       " ('National Review', 5090),\n",
       " ('PJ Media', 4943),\n",
       " ('Drudgereport', 3754),\n",
       " ('USA Today', 3176),\n",
       " ('Reason', 2384),\n",
       " ('Newsweek', 2241),\n",
       " ('Quartz', 2180),\n",
       " ('The Progressive', 1849),\n",
       " ('Voices for Vaccines', 1752),\n",
       " ('The Verge', 1716),\n",
       " ('Democracy Now', 1426),\n",
       " ('American Thinker', 1413),\n",
       " ('NBC', 1342),\n",
       " ('CNS', 1336),\n",
       " ('Sgtreport', 1095),\n",
       " ('New York Magazine', 1083),\n",
       " ('Redstate', 1081),\n",
       " ('Activist Post', 1073),\n",
       " ('Vice', 1064),\n",
       " ('Infowars', 777),\n",
       " ('In These Times', 743),\n",
       " ('News With Views', 616),\n",
       " ('Citizens', 586),\n",
       " ('Hot Air', 505),\n",
       " ('The Week', 472),\n",
       " ('The American Spectator', 408),\n",
       " ('Sons of Liberty Media', 347),\n",
       " ('The American Conservative', 216),\n",
       " ('Independent Sentinel', 169),\n",
       " ('Liberty Unyielding', 149),\n",
       " ('Conservative Daily News', 140),\n",
       " ('Adult Vaccines Now', 134),\n",
       " ('Conservative Firing Line', 132),\n",
       " ('Immunization Evidence', 123),\n",
       " ('Gawker', 99),\n",
       " ('Boston Globe', 79),\n",
       " ('Commdiginews', 79),\n",
       " ('Daily Dot', 59),\n",
       " ('Progressives Today', 58),\n",
       " ('Charisma News', 42),\n",
       " ('Gateway Pundit', 36),\n",
       " ('Rare.us', 32),\n",
       " ('Conservative Treehouse', 27),\n",
       " ('Conservative Review', 20),\n",
       " ('Physicians for Informed Consent', 19),\n",
       " ('CBN', 18),\n",
       " ('Grabien', 17)]"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_quote_domains = [df.loc[df.url==q['source']]['pretty_domain'].values[0] for q in quotes]\n",
    "counted_quote_domains = Counter(all_quote_domains)\n",
    "sorted(counted_quote_domains.items(),key=lambda x:x[1],reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add lemma, stem info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add NER tags?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
