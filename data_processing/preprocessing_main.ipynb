{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/yiweiluo/scientific-debates\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import datetime\n",
    "import pickle\n",
    "import json\n",
    "import time\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import nltk\n",
    "from collections import Counter\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer,PorterStemmer\n",
    "  \n",
    "lemmatizer = WordNetLemmatizer()\n",
    "ps = PorterStemmer()\n",
    "\n",
    "os.chdir('..')\n",
    "print(os.getcwd())\n",
    "from utils import get_fulltext,get_fname,fulltext_exists\n",
    "os.chdir('./data_processing/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "      <th>domain</th>\n",
       "      <th>stance</th>\n",
       "      <th>topic</th>\n",
       "      <th>is_AP</th>\n",
       "      <th>year</th>\n",
       "      <th>pretty_domain</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>www.buzzfeednews.com/article/tasneemnashrulla/...</td>\n",
       "      <td>\"eat the babies\" viral video at aoc town hall ...</td>\n",
       "      <td>2019-10-04 00:00:00</td>\n",
       "      <td>buzzfeed</td>\n",
       "      <td>pro</td>\n",
       "      <td>cc</td>\n",
       "      <td>None</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>Buzzfeed</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>www.buzzfeednews.com/article/passantino/extrem...</td>\n",
       "      <td>\"extremely likely\" global warming is man-made,...</td>\n",
       "      <td>2013-09-27 00:00:00</td>\n",
       "      <td>buzzfeed</td>\n",
       "      <td>pro</td>\n",
       "      <td>cc</td>\n",
       "      <td>None</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>Buzzfeed</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>shotofprevention.com/2010/11/03/history-makes-...</td>\n",
       "      <td>\"history\" makes headlines with launch of new w...</td>\n",
       "      <td>2020-03-13 14:32:02</td>\n",
       "      <td>https://shotofprevention/</td>\n",
       "      <td>pro</td>\n",
       "      <td>vax</td>\n",
       "      <td>False</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>Shot of Prevention</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>www.buzzfeednews.com/article/andrewkaczynski/i...</td>\n",
       "      <td>\"it's global warming, stupid\" - buzzfeed news</td>\n",
       "      <td>2012-11-01 00:00:00</td>\n",
       "      <td>buzzfeed</td>\n",
       "      <td>pro</td>\n",
       "      <td>cc</td>\n",
       "      <td>None</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>Buzzfeed</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>www.buzzfeednews.com/article/tasneemnashrulla/...</td>\n",
       "      <td>\"japan dropped an atomic bomb on america durin...</td>\n",
       "      <td>2014-02-24 00:00:00</td>\n",
       "      <td>buzzfeed</td>\n",
       "      <td>pro</td>\n",
       "      <td>cc</td>\n",
       "      <td>None</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>Buzzfeed</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>www.buzzfeednews.com/article/llevin/opinion-im...</td>\n",
       "      <td>\"look at my record, child\": joe biden showed m...</td>\n",
       "      <td>2019-10-31 00:00:00</td>\n",
       "      <td>buzzfeed</td>\n",
       "      <td>pro</td>\n",
       "      <td>cc</td>\n",
       "      <td>None</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>Buzzfeed</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>www.breitbart.com/politics/2019/06/14/orourke-...</td>\n",
       "      <td>\"president o'rourke will end oil and gas lease...</td>\n",
       "      <td>2019-06-14 00:00:00</td>\n",
       "      <td>breitbart</td>\n",
       "      <td>anti</td>\n",
       "      <td>cc</td>\n",
       "      <td>None</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>Breitbart</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>www.buzzfeednews.com/article/andrewkaczynski/s...</td>\n",
       "      <td>smoking doesnt kill and other great old opeds ...</td>\n",
       "      <td>2015-03-31 00:00:00</td>\n",
       "      <td>buzzfeed</td>\n",
       "      <td>pro</td>\n",
       "      <td>cc</td>\n",
       "      <td>None</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>Buzzfeed</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>www.foxnews.com/world/100-carbon-tax-by-2030-c...</td>\n",
       "      <td>$100 carbon tax by 2030 could save climate, sa...</td>\n",
       "      <td>2017-05-29 00:00:00</td>\n",
       "      <td>fox</td>\n",
       "      <td>anti</td>\n",
       "      <td>cc</td>\n",
       "      <td>None</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>Fox</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>childrenshealthdefense.org/news/4-billion-and-...</td>\n",
       "      <td>$4 billion and growing:  u.s. payouts for vacc...</td>\n",
       "      <td>2018-11-19 00:00:00</td>\n",
       "      <td>chd</td>\n",
       "      <td>anti</td>\n",
       "      <td>vax</td>\n",
       "      <td>None</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>Children's Health Defense</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  \\\n",
       "0  www.buzzfeednews.com/article/tasneemnashrulla/...   \n",
       "1  www.buzzfeednews.com/article/passantino/extrem...   \n",
       "2  shotofprevention.com/2010/11/03/history-makes-...   \n",
       "3  www.buzzfeednews.com/article/andrewkaczynski/i...   \n",
       "4  www.buzzfeednews.com/article/tasneemnashrulla/...   \n",
       "5  www.buzzfeednews.com/article/llevin/opinion-im...   \n",
       "6  www.breitbart.com/politics/2019/06/14/orourke-...   \n",
       "7  www.buzzfeednews.com/article/andrewkaczynski/s...   \n",
       "8  www.foxnews.com/world/100-carbon-tax-by-2030-c...   \n",
       "9  childrenshealthdefense.org/news/4-billion-and-...   \n",
       "\n",
       "                                               title                 date  \\\n",
       "0  \"eat the babies\" viral video at aoc town hall ...  2019-10-04 00:00:00   \n",
       "1  \"extremely likely\" global warming is man-made,...  2013-09-27 00:00:00   \n",
       "2  \"history\" makes headlines with launch of new w...  2020-03-13 14:32:02   \n",
       "3      \"it's global warming, stupid\" - buzzfeed news  2012-11-01 00:00:00   \n",
       "4  \"japan dropped an atomic bomb on america durin...  2014-02-24 00:00:00   \n",
       "5  \"look at my record, child\": joe biden showed m...  2019-10-31 00:00:00   \n",
       "6  \"president o'rourke will end oil and gas lease...  2019-06-14 00:00:00   \n",
       "7  smoking doesnt kill and other great old opeds ...  2015-03-31 00:00:00   \n",
       "8  $100 carbon tax by 2030 could save climate, sa...  2017-05-29 00:00:00   \n",
       "9  $4 billion and growing:  u.s. payouts for vacc...  2018-11-19 00:00:00   \n",
       "\n",
       "                      domain stance topic  is_AP    year  \\\n",
       "0                   buzzfeed    pro    cc   None  2019.0   \n",
       "1                   buzzfeed    pro    cc   None  2013.0   \n",
       "2  https://shotofprevention/    pro   vax  False  2020.0   \n",
       "3                   buzzfeed    pro    cc   None  2012.0   \n",
       "4                   buzzfeed    pro    cc   None  2014.0   \n",
       "5                   buzzfeed    pro    cc   None  2019.0   \n",
       "6                  breitbart   anti    cc   None  2019.0   \n",
       "7                   buzzfeed    pro    cc   None  2015.0   \n",
       "8                        fox   anti    cc   None  2017.0   \n",
       "9                        chd   anti   vax   None  2018.0   \n",
       "\n",
       "               pretty_domain  month  \n",
       "0                   Buzzfeed   10.0  \n",
       "1                   Buzzfeed    9.0  \n",
       "2         Shot of Prevention    3.0  \n",
       "3                   Buzzfeed   11.0  \n",
       "4                   Buzzfeed    2.0  \n",
       "5                   Buzzfeed   10.0  \n",
       "6                  Breitbart    6.0  \n",
       "7                   Buzzfeed    3.0  \n",
       "8                        Fox    5.0  \n",
       "9  Children's Health Defense   11.0  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle('../data_scraping/dedup_combined_df.pkl')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44582, 10)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contents:\n",
    "* [Define functions](#Define-functions)\n",
    "* [Extract clausal complements with SpaCy](#Extract-embedded-clauses-with-SpaCy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We add a neural coref resolution step to the default SpaCy pipeline: https://github.com/huggingface/neuralcoref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.lang.en.English at 0x1331042e8>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "\n",
    "# First way we can control a parameter\n",
    "#neuralcoref.add_to_pipe(nlp, greedyness=0.75)\n",
    "import neuralcoref\n",
    "neuralcoref.add_to_pipe(nlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper functions for the main ```get_quotes``` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_good_verb_dep(dep):\n",
    "    return dep[:3] == 'aux' or dep[:3] == 'adv' or dep == 'det' or dep == 'rel' or dep == 'prep' or dep[-3:] == 'obj' or dep[-3:] == 'mod' or dep == 'prt' or (dep[-4:] == 'comp' and dep != 'ccomp')\n",
    "\n",
    "def is_good_subj_dep(dep):\n",
    "    return dep != 'ccomp'\n",
    "\n",
    "def is_ROOT(tok):\n",
    "    return tok.dep_ == 'ROOT' or tok.dep_[-2:] == 'cl' or tok.dep_ == 'ccomp' or \\\n",
    "            (tok.dep_ == 'conj' and tok.head.dep_ == 'ROOT')\n",
    "\n",
    "REL_PRONOUNS = set(['who', 'whom', 'whose', 'which', 'that'])\n",
    "def is_rel_pronoun(tok):\n",
    "    tok = tok.lower().strip()\n",
    "    return tok in REL_PRONOUNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def get_quotes(text):\n",
    "    # Step 0. Run pipeline.\n",
    "    doc = nlp(text)\n",
    "\n",
    "    # Step 1. Figure out which tokens to tag w/ coreferring token\n",
    "    to_annotate = {}\n",
    "    for clust in doc._.coref_clusters:\n",
    "        non_main_mentions = [x for x in clust.mentions if x != clust.main]\n",
    "        for mention in non_main_mentions:\n",
    "            start = mention.start\n",
    "            to_annotate[start] = True\n",
    "            end = mention.end\n",
    "            if start+1 != end:\n",
    "                for ix in range(start+1,end):\n",
    "                    to_annotate[ix] = False\n",
    "    to_annotate.update({ix: False for ix in range(len(doc)) if ix not in to_annotate})\n",
    "\n",
    "    annotated_tokens = {}\n",
    "    for token in doc:\n",
    "        #print(token.i,token.text,token.head,token.dep_)\n",
    "        if to_annotate[token.i]:\n",
    "            #print('Main span:',token._.coref_clusters[0].main)\n",
    "            # print('Main span start token_ix, end token_ix:',token._.coref_clusters[0].main.start,\n",
    "            #      token._.coref_clusters[0].main.end)\n",
    "            # print('\\n')\n",
    "            annotated_tokens[token.i] = token._.coref_clusters[0].main\n",
    "        else:\n",
    "            annotated_tokens[token.i] = None\n",
    "\n",
    "    # Step 3. Go through each sentence in the doc, extract up to 1 quote from each sentence\n",
    "    quote_objs = []\n",
    "    for sent in doc.sents:\n",
    "        #print(sent)\n",
    "\n",
    "        VERBS = list(np.unique([token.head for token in sent if token.dep_ == 'ccomp']))\n",
    "        #print(VERBS)\n",
    "\n",
    "        # Extract everything else for each VERB\n",
    "        for VERB in VERBS:\n",
    "            #print(\"\\nCcomp dependency found! For quoting verb '{}'\".format(VERB))\n",
    "            # Extract the rest of the quoting verb\n",
    "            verb_deps = [x for x in VERB.children if is_good_verb_dep(x.dep_)]\n",
    "            #print(\"\\tFound children:\",verb_deps)\n",
    "            for x in verb_deps:\n",
    "                new_children = [c for c in x.children if is_good_verb_dep(c.dep_)]\n",
    "                #print(\"\\tAdding children of {}:\".format(x.text),new_children)\n",
    "                verb_deps.extend(new_children)\n",
    "                #print(\"\\tUpdated verb deps:\",verb_deps)\n",
    "\n",
    "            # If verb's head is not itself (i.e., verb is not the ROOT),\n",
    "            # recursively trace back to ROOT, then add all children of ROOT\n",
    "            ROOT = VERB\n",
    "            if is_ROOT(ROOT):\n",
    "                pass\n",
    "                #print(\"\\n\\tVerb '{}' is the ROOT.\".format(ROOT))\n",
    "                #verb_deps.append(ROOT)\n",
    "            else:\n",
    "                #print('\\n\\tFinding ROOT...')\n",
    "                while not is_ROOT(ROOT):\n",
    "                    ROOT = ROOT.head\n",
    "                    #print('\\t\\tCurrent root:',ROOT)\n",
    "                assert is_ROOT(ROOT)\n",
    "                verb_deps.append(ROOT)\n",
    "\n",
    "                #print(\"\\tAdding children of ROOT...\")\n",
    "                root_deps = [x for x in ROOT.children if is_good_verb_dep(x.dep_)]\n",
    "                #print(\"\\tFound ROOT deps:\",root_deps)\n",
    "                for x in root_deps:\n",
    "                    new_children = [c for c in x.children if is_good_verb_dep(c.dep_)]\n",
    "                    #print(\"\\tAdding children of {}:\".format(x.text),new_children)\n",
    "                    root_deps.extend(new_children)\n",
    "                    #print(\"\\tUpdated ROOT deps:\",root_deps)\n",
    "\n",
    "                #print(\"\\tAdding ROOT deps to verb deps...\")\n",
    "                verb_deps.extend([x for x in root_deps if x != VERB and x not in verb_deps])\n",
    "                #print(\"\\tUpdated verb deps:\",verb_deps)\n",
    "\n",
    "            NEG,IS_NEG,neg_children = None,None,None\n",
    "            SUBJECT,subj_children = None,None\n",
    "\n",
    "            #print(\"\\nLooking for SUBJECT and NEGATION(s)...\")\n",
    "            for child in ROOT.children:\n",
    "                if child.dep_[:5] == 'nsubj' or child.dep_ == 'expl':\n",
    "                    SUBJECT = child\n",
    "                    #print(\"\\tFound SUBJECT:\",SUBJECT)\n",
    "                    if SUBJECT.head.dep_ == 'relcl' and is_rel_pronoun(SUBJECT.text): # we're dealing with the subject of a rel clause\n",
    "                        #print(\"\\tFound quote inside a relative clause. Finding antecedent subject...\")\n",
    "                        SUBJECT = SUBJECT.head.head\n",
    "                        #print(\"\\tTrue subject:\",SUBJECT)\n",
    "                    #print(\"Subject token '{}' is in a coref cluster:\".format(SUBJECT),SUBJECT._.in_coref)\n",
    "\n",
    "                if child.dep_[:3] == 'neg':\n",
    "                    NEG = child\n",
    "                    verb_deps.append(NEG)\n",
    "                    neg_children = [c for c in NEG.children if c != VERB]\n",
    "                    #print(\"n\\tAdding new NEG children:\",neg_children)\n",
    "                    for x in neg_children:\n",
    "                        new_children = [c for c in x.children]\n",
    "                        #print(\"\\tNew NEG grandchildren:\",new_children)\n",
    "                        neg_children.extend(new_children)\n",
    "                        #print(\"\\tUpdated neg_children:\",neg_children)\n",
    "                    verb_deps.extend(neg_children)\n",
    "                    #print(\"\\tUpdated verb_deps:\",verb_deps)\n",
    "                    IS_NEG = VERB in NEG.head.children or VERB == NEG.head\n",
    "\n",
    "            if SUBJECT is None and (ROOT.dep_ == 'acl' or ROOT.dep_ == 'advcl'):\n",
    "                main_verb = ROOT.head\n",
    "                #print([(c.text,c.dep_) for c in main_verb.children])\n",
    "                SUBJS = [c for c in main_verb.children if c.dep_[:5] == 'nsubj' or c.dep_ == 'expl']\n",
    "                SUBJECT = SUBJS[0] if len(SUBJS) > 0 else None\n",
    "\n",
    "            # Get rest of subject tokens\n",
    "            if SUBJECT is not None:\n",
    "                #print(\"\\nFound SUBJECT:\",SUBJECT)\n",
    "                #print(\"\\tAdding children of SUBJECT...\")\n",
    "                subj_children = [c for c in SUBJECT.children if is_good_subj_dep(c.dep_)]\n",
    "                #print(\"\\tFound children:\",subj_children)\n",
    "                for x in subj_children:\n",
    "                    new_children = [c for c in x.children if is_good_subj_dep(c.dep_)]\n",
    "                    #print(\"\\tAdding children of child {}:\".format(x.text),new_children)\n",
    "                    subj_children.extend(new_children)\n",
    "                    #print(\"\\tUpdated subject children:\",subj_children)\n",
    "\n",
    "            #print(\"\\nFinding quote introduced by '{}'...\".format(VERB))\n",
    "            emb_main_verbs = [c for c in VERB.children if c.dep_ == 'ccomp']\n",
    "            #print(\"\\tMain verbs of embedded clause:\",emb_main_verbs)\n",
    "            #assert len(emb_main_verbs) <= 2\n",
    "            for emb_main_verb in emb_main_verbs:\n",
    "                #print(\"\\tMain *verb*:\",emb_main_verb)\n",
    "\n",
    "                # Recursively get all children of main verb of embedded clause\n",
    "                #print(\"\\nRecursively getting children of main verb of embedded clause...\\n\")\n",
    "                #print(\"*\"*50)\n",
    "                children_queue = [x for x in emb_main_verb.children]\n",
    "                #print(\"\\tAdding children of main verb:\",children_queue)\n",
    "                for x in children_queue:\n",
    "                    new_children = [c for c in x.children]\n",
    "                    #print(\"\\tAdding children of {}:\".format(x.text),new_children)\n",
    "                    children_queue.extend(new_children)\n",
    "                    #print(\"\\tNew children queue:\",children_queue)\n",
    "\n",
    "                # Sort children and matrix verb to be in correct order\n",
    "                # Replace w/ coreferring text as necessary\n",
    "                children_and_indices_and_coref = [(c,c.i,annotated_tokens[c.i]) for c in children_queue+[emb_main_verb]]\n",
    "                sorted_ = sorted(children_and_indices_and_coref,key=lambda x:x[1])\n",
    "                sorted_verb_tokens = sorted([(c,c.i,annotated_tokens[c.i]) for c in verb_deps+[VERB]],key=lambda x:x[1])\n",
    "                #print(\"\\n\\tSorted verb tokens:\",sorted_verb_tokens)\n",
    "                if SUBJECT is not None:\n",
    "                    sorted_subj_tokens = sorted([(c,c.i,annotated_tokens[c.i]) for c in subj_children+[SUBJECT]],key=lambda x:x[1])\n",
    "                    #print(\"\\tSorted subject tokens:\",sorted_subj_tokens)\n",
    "                else:\n",
    "                    sorted_subj_tokens = None\n",
    "                if NEG is not None:\n",
    "                    sorted_neg_tokens = sorted([(c,c.i,annotated_tokens[c.i]) for c in neg_children+[NEG]],key=lambda x:x[1])\n",
    "                else:\n",
    "                    sorted_neg_tokens = None\n",
    "\n",
    "                dict_ = {'quote tokens':[tup[0] for tup in sorted_],\n",
    "                        'quote tokens coref':[tup[0] if tup[-1] is None else tup[-1] for tup in sorted_],\n",
    "                        'verb tokens':[tup[0] for tup in sorted_verb_tokens],\n",
    "                        'verb tokens coref':[tup[0] if tup[-1] is None else tup[-1] for tup in sorted_verb_tokens],\n",
    "                        'main verb':VERB,\n",
    "                        'main verb coref':annotated_tokens[VERB.i] if annotated_tokens[VERB.i] else VERB,\n",
    "                       'subject tokens':[tup[0] for tup in sorted_subj_tokens] if sorted_subj_tokens is not None else None,\n",
    "                        'subject tokens coref':([tup[0] if tup[-1] is None else tup[-1] for tup in sorted_subj_tokens])\n",
    "                                   if sorted_subj_tokens is not None else None,\n",
    "                       'main subject':SUBJECT if SUBJECT is not None else None,\n",
    "                        'main subject coref':annotated_tokens[SUBJECT.i] if SUBJECT is not None and annotated_tokens[SUBJECT.i] else\n",
    "                                   (SUBJECT if SUBJECT is not None else None),\n",
    "                       'neg tokens':[tup[0] for tup in sorted_neg_tokens] if sorted_neg_tokens is not None else None,\n",
    "                       'main neg':NEG if NEG is not None else None,\n",
    "                       'is neg':IS_NEG}\n",
    "\n",
    "                res_ = {}\n",
    "                res_['quote lemmas'] = [x.lemma_ for x in dict_['quote tokens']]\n",
    "                res_['quote lemmas coref'] = [x.lemma_ for x in dict_['quote tokens coref']]\n",
    "                res_['verb lemmas'] = [x.lemma_ for x in dict_['verb tokens']]\n",
    "                res_['verb lemmas coref'] = [x.lemma_ for x in dict_['verb tokens coref']]\n",
    "                res_['main verb lemma'] = dict_['main verb'].lemma_\n",
    "                res_['main verb lemma coref'] = dict_['main verb coref'].lemma_\n",
    "                res_['subject lemmas'] = [x.lemma_ for x in dict_['subject tokens']] if dict_['subject tokens'] is not None else None\n",
    "                res_['subject lemmas coref'] = [x.lemma_ for x in dict_['subject tokens coref']] if dict_['subject tokens coref'] is not None else None\n",
    "                res_['main subject lemma'] = dict_['main subject'].lemma_ if dict_['main subject'] is not None else None\n",
    "                res_['main subject lemma coref'] = dict_['main subject coref'].lemma_ if dict_['main subject coref'] is not None else None\n",
    "                res_['neg lemmas'] = [x.lemma_ for x in dict_['neg tokens']] if dict_['neg tokens'] is not None else None\n",
    "                res_['main neg lemma'] = dict_['main neg'].norm_ if dict_['main neg'] is not None else None\n",
    "                res_['quote text'] = [x.text for x in dict_['quote tokens']]\n",
    "                res_['verb text'] = [x.text for x in dict_['verb tokens']]\n",
    "                res_['main verb text'] = dict_['main verb'].text\n",
    "                res_['subject text'] = [x.text for x in dict_['subject tokens']] if dict_['subject tokens'] is not None else None\n",
    "                res_['main subject text'] = dict_['main subject'].text if dict_['main subject'] is not None else None\n",
    "                res_['is neg'] = dict_['is neg']\n",
    "\n",
    "                quote_objs.append(res_)\n",
    "\n",
    "    return quote_objs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"A peer-reviewed study has found that humans are causing climate change.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A det study\n",
      "peer npadvmod reviewed\n",
      "- punct reviewed\n",
      "reviewed amod study\n",
      "study nsubj found\n",
      "has aux found\n",
      "found ROOT found\n",
      "that mark causing\n",
      "humans nsubj causing\n",
      "are aux causing\n",
      "causing ccomp found\n",
      "climate compound change\n",
      "change dobj causing\n",
      ". punct found\n"
     ]
    }
   ],
   "source": [
    "for tok in doc:\n",
    "    print(tok.text,tok.dep_,tok.head.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'quote lemmas': ['that', 'human', 'be', 'cause', 'climate', 'change'],\n",
       "  'quote lemmas coref': ['that', 'human', 'be', 'cause', 'climate', 'change'],\n",
       "  'verb lemmas': ['have', 'find'],\n",
       "  'verb lemmas coref': ['have', 'find'],\n",
       "  'main verb lemma': 'find',\n",
       "  'main verb lemma coref': 'find',\n",
       "  'subject lemmas': ['a', 'peer', '-', 'review', 'study'],\n",
       "  'subject lemmas coref': ['a', 'peer', '-', 'review', 'study'],\n",
       "  'main subject lemma': 'study',\n",
       "  'main subject lemma coref': 'study',\n",
       "  'neg lemmas': None,\n",
       "  'main neg lemma': None,\n",
       "  'quote text': ['that', 'humans', 'are', 'causing', 'climate', 'change'],\n",
       "  'verb text': ['has', 'found'],\n",
       "  'main verb text': 'found',\n",
       "  'subject text': ['A', 'peer', '-', 'reviewed', 'study'],\n",
       "  'main subject text': 'study',\n",
       "  'is neg': None}]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_quotes(\"A peer-reviewed study has found that humans are causing climate change.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract clausal complements with SpaCy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Did this part on the cluster.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5713517665863037"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time.time()-s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing URLs that cluster didn't get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_covid_urls = pickle.load(open('missing_urls.pkl','rb'))\n",
    "len(missing_covid_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_df = df.loc[df.topic=='covid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "www.dailymail.co.uk/news/article-7945897/Asylum-seekers-Christmas-Island-kept-away-coronavirus-evacuees.html?ns_mchannel=rss&ns_campaign=1490&ito=1490\n",
      "6400\twww.dailymail.co.uk[SEP]news[SEP]article-7945897[SEP]Asylum-seekers-Christmas-Island-kept-\tElapsed time in seconds: 0.014775717258453369\n",
      "bipartisanreport.com/2020/03/18/biden-publicly-humiliates-trump-with-coronavirus-failure-fact-check/\n",
      "redstate.com/stu-in-sd/2020/03/11/cartoons-and-kids-–-that’s-where-the-social-engineers-start-their-brainwashing/\n",
      "bipartisanreport.com/2020/03/26/china-issues-rebuke-of-pompeos-wuhan-virus-moniker/\n",
      "www.nytimes.com/2020/02/14/pageoneplus/corrections-feb-15-2020.html\n",
      "www.dailymail.co.uk/news/article-8199959/Face-masks-NOT-stop-healthy-people-catching-coronavirus-says.html?ns_mchannel=rss&ns_campaign=1490&ito=1490\n",
      "bipartisanreport.com/2020/03/23/fauci-reveals-he-cant-physically-control-trump-lies/\n",
      "www.dailymail.co.uk/news/article-8172321/FBI-warned-concerns-biosecurity-risk-Chinese-scientists-research-US.html?ns_mchannel=rss&ns_campaign=1490&ito=1490\n",
      "www.dailymail.co.uk/news/article-8034387/Fears-14-day-coronavirus-quarantine-short-pensioner-took-27-days-symptoms.html?ns_mchannel=rss&ns_campaign=1490&ito=1490\n",
      "www.dailymail.co.uk/news/article-8065699/Fears-cancer-patients-hospital-clinician-gets-coronavirus.html?ns_mchannel=rss&ns_campaign=1490&ito=1490\n",
      "www.dailymail.co.uk/news/article-7919985/Fears-Chinese-coronavirus-patients-roaming-streets-Wuhan-freely.html?ns_mchannel=rss&ns_campaign=1490&ito=1490\n",
      "www.dailymail.co.uk/news/article-7944303/Fed-chair-Jerome-Powell-sees-China-virus-risk-world-economy.html?ns_mchannel=rss&ns_campaign=1490&ito=1490\n",
      "bipartisanreport.com/2020/03/02/gop-candidate-caught-tweeting-bonkers-coronavirus-lies/\n",
      "9300\tbipartisanreport.com[SEP]2020[SEP]03[SEP]02[SEP]gop-candidate-caught-tweeting-bonkers-coro\tElapsed time in seconds: 0.9523307323455811\n",
      "bipartisanreport.com/2020/03/18/hillary-checkmates-trump-with-wednesday-coronavirus-rebuttal/\n",
      "www.dailymail.co.uk/news/article-8046977/Korean-Air-flight-attendant-diagnosed-coronavirus-serviced-trips-Seoul-LAX.html?ns_mchannel=rss&ns_campaign=1490&ito=1490\n",
      "www.dailymail.co.uk/news/article-7986727/Kyle-Bass-says-let-coronavirus-rampage-Chinas-Communist-Party.html?ns_mchannel=rss&ns_campaign=1490&ito=1490\n",
      "bipartisanreport.com/2020/03/21/maddow-demands-trump-press-briefings-taken-off-air/\n",
      "www.dailymail.co.uk/news/article-7986067/Japan-says-60-virus-cases-cruise-ship.html?ns_mchannel=rss&ns_campaign=1490&ito=1490\n",
      "bipartisanreport.com/2020/03/31/mcconnell-blames-dems-for-covid-19-relief-fails/\n",
      "bipartisanreport.com/2020/03/19/pelosi-makes-thursday-trump-war-powers-statement/\n",
      "bipartisanreport.com/2020/02/26/pelosi-slams-trump-over-failure-to-respond-to-coronavirus/\n",
      "bipartisanreport.com/2020/03/17/pence-secretly-meets-with-gop-influencers-to-push-virus-propaganda/\n",
      "www.washingtonpost.com/politics/power-up-bernie-sanders-may-have-the-edge-in-tonights-iowas-caucuses-but-its-complicated/2020/02/03/9f37ebfd-88e1-4071-b6ef-f360d37d6539_story.html\n",
      "www.washingtonpost.com/politics/power-up-joe-biden-looms-large-in-senate-impeachment-trial-while-campaigning-to-win-iowa-caucuses/2020/01/23/98c0ef5c-a290-4cd8-b1fa-eaf507bc53e5_story.html\n",
      "www.washingtonpost.com/politics/power-up-maine-sen-angus-king-warns-against-defeating-second-article-of-impeachment-in-trumps-senate-trial/2020/01/27/996c1668-2409-4e26-b192-7811d8b8235f_story.html\n",
      "www.dailymail.co.uk/news/article-7986999/President-Xi-wears-face-mask-temperature-checked.html?ns_mchannel=rss&ns_campaign=1490&ito=1490\n",
      "www.dailymail.co.uk/news/article-8075803/Price-lobsters-fall-coronavirus-crisis-China-closes-borders-Australian-exports.html?ns_mchannel=rss&ns_campaign=1490&ito=1490\n",
      "bipartisanreport.com/2020/03/18/reporter-confronts-trump-over-racist-corona-comment-during-live-broadcast/\n",
      "bipartisanreport.com/2020/03/16/schiff-shows-up-trump-on-twitter-as-don-scares-u-s/\n",
      "bipartisanreport.com/2020/03/19/snapshot-of-trumps-notes-reveal-blatant-racism/\n",
      "www.nytimes.com/2020/01/30/world/Coronavirus-travel-advisory-.html\n",
      "www.washingtonpost.com/politics/the-cybersecurity-202-trump-rails-against-supposed-dangers-of-mail-in-voting-as-coronavirus-spreads/2020/04/08/7d467684-2fe8-49bf-8d00-67ab1027762e_story.html?utm_source=rss&utm_medium=referral&utm_campaign=wp_politics\n",
      "www.washingtonpost.com/politics/the-daily-202-conservative-intellectuals-launch-a-new-group-to-challenge-free-market-fundamentalism-on-the-right/2020/02/18/6309b09a-03d8-47a4-b5c8-4f9f4d1d2047_story.html\n",
      "www.washingtonpost.com/politics/the-finance-202-trump-goes-into-attack-mode-as-coronavirus-panic-hits-stock-market/2020/03/09/d6863f93-49b9-403f-95f6-6562cd40f9d2_story.html?utm_source=rss&utm_medium=referral&utm_campaign=wp_homepage\n",
      "www.washingtonpost.com/politics/the-finance-202-trumps-budget-previews-his-2020-economic-pitch-more-spending-on-tax-cuts-and-the-wall/2020/02/10/b5297f03-2568-44d6-8605-f4890466475e_story.html\n",
      "www.washingtonpost.com/politics/the-finance-202-us-bankers-at-world-economic-forum-in-davos-see-bull-market-extending-its-run/2020/01/23/00199c39-b9f0-4d9f-93ce-182b5b7c9fd3_story.html\n",
      "12000\twww.washingtonpost.com[SEP]politics[SEP]the-finance-202-us-bankers-at-world-economic-forum\tElapsed time in seconds: 2.414493151505788\n",
      "www.washingtonpost.com/politics/the-health-202-democrats-seize-on-sanderss-tensions-with-nevada-union-to-attack-medicare-for-all/2020/02/20/515d7d49-a8bd-4777-9d5c-5bffafa1069f_story.html\n",
      "www.washingtonpost.com/politics/the-health-202-the-supreme-court-may-have-saved-trump-from-himself-on-obamacare/2020/01/22/6776b3cd-eb70-4c95-9b1a-bbef418ab2b5_story.html\n",
      "www.washingtonpost.com/politics/the-technology-202-californias-digital-team-is-racing-to-build-coronavirus-resources/2020/03/13/3ee8de30-a62a-4d36-80bd-13459959c3c3_story.html?utm_source=rss&utm_medium=referral&utm_campaign=wp_business\n",
      "www.washingtonpost.com/politics/the-technology-202-tech-industry-takes-big-stock-hit-from-coronavirus-spread/2020/02/25/3d61aaf9-2513-4f35-b7cf-e68ef70aa481_story.html\n",
      "bipartisanreport.com/2020/03/20/trump-busted-being-racist-once-again/\n",
      "bipartisanreport.com/2020/03/30/trump-delivers-angry-rant-during-am-fox-appearance/\n",
      "bipartisanreport.com/2020/03/22/trump-eliminated-key-cdc-position-before-outbreak/\n",
      "bipartisanreport.com/2020/03/21/trump-freaks-out-over-washington-post-during-rant/\n",
      "bipartisanreport.com/2020/03/18/trump-goes-full-racist-during-wednesday-coronavirus-announcement/\n",
      "bipartisanreport.com/2020/03/17/trump-has-ridiculous-racist-twitter-coronavirus-meltdown/\n",
      "bipartisanreport.com/2020/04/02/trump-ignored-military-warning-of-100k-covid-19-deaths/\n",
      "bipartisanreport.com/2020/03/13/trump-jr-goes-on-rabid-racist-anti-china-virus-rant/\n",
      "bipartisanreport.com/2020/03/20/trump-jr-launches-gross-twitter-rant-as-covid-19-rages/\n",
      "bipartisanreport.com/2020/04/03/trump-outed-for-ending-program-to-track-pandemics/\n",
      "bipartisanreport.com/2020/03/17/trump-says-he-knew-covid-19-was-a-pandemic-before-w-h-o/\n",
      "bipartisanreport.com/2020/03/18/trump-sees-stock-futures-plummet-explodes-into-fit-of-rage/\n",
      "bipartisanreport.com/2020/03/02/trump-shredded-for-false-coronavirus-vaccine-info/\n",
      "bipartisanreport.com/2020/03/21/trump-struggles-through-weekend-covid-19-press-conference/\n",
      "bipartisanreport.com/2020/03/19/trump-threatens-media-during-rambling-press-conference/\n",
      "www.dailymail.co.uk/news/article-8042499/Wall-Street-futures-point-rebound-coronavirus-fears-sent-Dow-plunging-1-000-points.html?ns_mchannel=rss&ns_campaign=1490&ito=1490\n",
      "www.dailymail.co.uk/news/article-8055629/Wall-Street-prepares-hammering-5-TRILLION-wiped-world-economy.html?ns_mchannel=rss&ns_campaign=1490&ito=1490\n",
      "13000\twww.dailymail.co.uk[SEP]news[SEP]article-8055629[SEP]Wall-Street-prepares-hammering-5-TRIL\tElapsed time in seconds: 3.071905016899109\n",
      "bipartisanreport.com/2020/03/17/wh-official-caught-making-racist-coronavirus-remark/\n",
      "bipartisanreport.com/2020/03/19/who-official-speaks-out-against-usage-of-chinese-virus/\n",
      "bipartisanreport.com/2020/04/08/w-h-o-refutes-trumps-whiny-virus-complaints/\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "for url_ix in missing_covid_urls:\n",
    "    curr_url = covid_df.url.values[url_ix]\n",
    "    print(curr_url)\n",
    "    quotes = get_quotes(get_fulltext(curr_url)[0])\n",
    "    fname = get_fname(curr_url)\n",
    "    with open('./extracted_quotes/{}.jl'.format(fname),'w+') as f:\n",
    "        for res in quotes:\n",
    "            json.dump(res, f)\n",
    "            f.write('\\n')\n",
    "    if url_ix % 100 == 0:\n",
    "        print('{}\\t{}\\tElapsed time in seconds:'.format(url_ix,fname),(time.time()-start_time)/60.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieval of extracted complement clauses from filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUOTES_DIR = './extracted_quotes/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44527"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_set = set(os.listdir(QUOTES_DIR))\n",
    "len(extracted_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ix in range(0,len(df)):\n",
    "    url = df.url.values[ix]\n",
    "    fname = url.replace('/','[SEP]')\n",
    "    assert '{}.jl'.format(fname) in extracted_set or \\\n",
    "    '{}.jl'.format(fname[:90]) in extracted_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def get_quotes_from_file(url,df,missing):\n",
    "    fname = url.replace('/','[SEP]')\n",
    "    if fname+'.jl' in extracted_set:\n",
    "        fname = fname+'.jl'\n",
    "    else:\n",
    "        fname = fname[:90]+'.jl'\n",
    "    \n",
    "    try:\n",
    "        with open(os.path.join(QUOTES_DIR,fname),'r') as f:\n",
    "            data = f.readlines()\n",
    "        quotes = []\n",
    "        for x in data:\n",
    "            res = json.loads(x.strip())\n",
    "            res.update({'source':url})                \n",
    "            quotes.append(res)\n",
    "            \n",
    "        return quotes\n",
    "    except FileNotFoundError:\n",
    "        print(fname)\n",
    "        missing.append(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(os.listdir(DIR_WITH_NAMES))+len(os.listdir(DIR_WITH_NOS)),len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing = []\n",
    "# all_quotes = [get_quotes_from_file(url_ix,df,missing) for url_ix in range(0,len(df))]\n",
    "# all_quotes = [item for sublist in all_quotes for item in sublist]\n",
    "covid_quotes = [get_quotes_from_file(url,df,missing) for url in covid_df.url.values]\n",
    "#covid_quotes = [item for sublist in covid_quotes for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "293234"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covid_quotes = [item for sublist in covid_quotes for item in sublist]\n",
    "len(covid_quotes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'quote lemmas': ['-PRON-', 'other', 'than', '-PRON-'],\n",
       " 'quote lemmas coref': ['-PRON-', 'other', 'than', '-PRON-'],\n",
       " 'verb lemmas': ['can', 'see'],\n",
       " 'verb lemmas coref': ['can', 'see'],\n",
       " 'main verb lemma': 'see',\n",
       " 'main verb lemma coref': 'see',\n",
       " 'subject lemmas': ['no', 'one'],\n",
       " 'subject lemmas coref': ['no', 'one'],\n",
       " 'main subject lemma': 'one',\n",
       " 'main subject lemma coref': 'one',\n",
       " 'neg lemmas': None,\n",
       " 'main neg lemma': None,\n",
       " 'quote text': ['him', 'other', 'than', 'me'],\n",
       " 'verb text': ['can', 'see'],\n",
       " 'main verb text': 'see',\n",
       " 'subject text': ['No', 'one'],\n",
       " 'main subject text': 'one',\n",
       " 'is neg': None,\n",
       " 'source': 'www.buzzfeednews.com/article/scaachikoul/animal-crossing-quarantine-distraction'}"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covid_quotes[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 293234)"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(missing),len(covid_quotes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(covid_quotes,open('all_covid_quotes.pkl','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter to true indirect statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_quotes = pickle.load(open('all_covid_quotes.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['quote lemmas', 'quote lemmas coref', 'verb lemmas', 'verb lemmas coref', 'main verb lemma', 'main verb lemma coref', 'subject lemmas', 'subject lemmas coref', 'main subject lemma', 'main subject lemma coref', 'neg lemmas', 'main neg lemma', 'quote text', 'verb text', 'main verb text', 'subject text', 'main subject text', 'is neg', 'source'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_quotes[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('say', 135968),\n",
       " ('be', 47374),\n",
       " ('make', 25420),\n",
       " ('think', 20461),\n",
       " ('tell', 16615),\n",
       " ('know', 13915),\n",
       " ('find', 12468),\n",
       " ('show', 9905),\n",
       " ('believe', 9858),\n",
       " ('see', 8952),\n",
       " ('mean', 8234),\n",
       " ('let', 8160),\n",
       " ('suggest', 8059),\n",
       " ('help', 7236),\n",
       " ('have', 7217),\n",
       " ('note', 7006),\n",
       " ('allow', 6776),\n",
       " ('’s', 6667),\n",
       " ('argue', 6643),\n",
       " ('write', 6425),\n",
       " ('add', 6283),\n",
       " ('report', 5382),\n",
       " ('get', 5196),\n",
       " ('claim', 4505),\n",
       " ('ask', 4355),\n",
       " ('explain', 4337),\n",
       " ('want', 4332),\n",
       " ('—', 3704),\n",
       " ('warn', 3294),\n",
       " ('sure', 3243),\n",
       " ('announce', 3178),\n",
       " ('estimate', 3090),\n",
       " ('cause', 3078),\n",
       " ('conclude', 2959),\n",
       " ('understand', 2834),\n",
       " ('do', 2660),\n",
       " ('ensure', 2604),\n",
       " ('hope', 2601),\n",
       " ('expect', 2592),\n",
       " ('agree', 2275),\n",
       " ('consider', 2241),\n",
       " ('point', 2224),\n",
       " ('predict', 2142),\n",
       " ('state', 2099),\n",
       " ('indicate', 2027),\n",
       " ('’', 2013),\n",
       " ('declare', 1930),\n",
       " ('feel', 1876),\n",
       " ('assume', 1867),\n",
       " ('acknowledge', 1861),\n",
       " ('realize', 1842),\n",
       " ('insist', 1759),\n",
       " ('determine', 1736),\n",
       " ('decide', 1566),\n",
       " ('seem', 1442),\n",
       " ('admit', 1429),\n",
       " ('matter', 1414),\n",
       " ('Get', 1406),\n",
       " ('need', 1386),\n",
       " ('wonder', 1372),\n",
       " ('reveal', 1355),\n",
       " ('hear', 1335),\n",
       " ('go', 1331),\n",
       " ('learn', 1191),\n",
       " ('prove', 1147),\n",
       " ('remember', 1128),\n",
       " ('confirm', 1058),\n",
       " ('imagine', 1031),\n",
       " ('require', 996),\n",
       " ('continue', 992),\n",
       " ('worry', 973),\n",
       " ('fear', 971),\n",
       " ('take', 966),\n",
       " ('recognize', 936),\n",
       " ('figure', 902),\n",
       " ('demonstrate', 866),\n",
       " ('hold', 864),\n",
       " ('demand', 839),\n",
       " ('become', 819),\n",
       " ('convince', 788),\n",
       " ('discover', 784),\n",
       " ('watch', 775),\n",
       " ('read', 764),\n",
       " ('turn', 756),\n",
       " ('use', 736),\n",
       " ('keep', 714),\n",
       " ('assert', 703),\n",
       " ('appear', 681),\n",
       " ('guess', 664),\n",
       " ('recall', 663),\n",
       " ('recommend', 633),\n",
       " ('calculate', 629),\n",
       " ('suspect', 622),\n",
       " ('call', 622),\n",
       " ('give', 589),\n",
       " ('come', 567),\n",
       " ('question', 564),\n",
       " ('promise', 554),\n",
       " ('rule', 539),\n",
       " ('remind', 528),\n",
       " ('contend', 526),\n",
       " ('wish', 522),\n",
       " ('mention', 511),\n",
       " ('assure', 510),\n",
       " ('emphasize', 510),\n",
       " ('deny', 506),\n",
       " ('notice', 503),\n",
       " ('complain', 497),\n",
       " ('change', 488),\n",
       " ('project', 469),\n",
       " ('observe', 461),\n",
       " ('accept', 455),\n",
       " ('confident', 449),\n",
       " ('describe', 436),\n",
       " ('propose', 429),\n",
       " ('likely', 427),\n",
       " ('caution', 422),\n",
       " ('respond', 421),\n",
       " ('look', 412),\n",
       " ('aware', 401),\n",
       " ('maintain', 397),\n",
       " ('concede', 393),\n",
       " ('imply', 393),\n",
       " ('tweet', 391),\n",
       " ('stress', 384),\n",
       " ('signal', 370),\n",
       " ('allege', 364),\n",
       " ('remain', 362),\n",
       " ('now', 360),\n",
       " ('leave', 359),\n",
       " ('include', 355),\n",
       " ('begin', 352),\n",
       " ('forget', 347),\n",
       " ('doubt', 344),\n",
       " ('hop', 340),\n",
       " ('discuss', 339),\n",
       " ('put', 337),\n",
       " ('reply', 331),\n",
       " ('start', 330),\n",
       " ('suppose', 327),\n",
       " ('happen', 325),\n",
       " ('work', 322),\n",
       " ('pretend', 319),\n",
       " ('right', 304),\n",
       " ('create', 295),\n",
       " ('provide', 291),\n",
       " ('produce', 276),\n",
       " ('study', 263),\n",
       " ('offer', 262),\n",
       " ('guarantee', 258),\n",
       " ('try', 257),\n",
       " ('inform', 253),\n",
       " ('concern', 251),\n",
       " ('care', 251),\n",
       " ('lead', 249),\n",
       " ('highlight', 249),\n",
       " ('grow', 249),\n",
       " ('concerned', 247),\n",
       " ('certain', 236),\n",
       " ('like', 235),\n",
       " ('set', 235),\n",
       " ('follow', 233),\n",
       " ('illustrate', 232),\n",
       " ('address', 226),\n",
       " ('sign', 223),\n",
       " ('convinced', 220),\n",
       " ('bet', 219),\n",
       " ('affect', 218),\n",
       " ('speculate', 217),\n",
       " ('increase', 215),\n",
       " ('testify', 213),\n",
       " ('render', 211),\n",
       " ('support', 211),\n",
       " ('worried', 210),\n",
       " ('rise', 208),\n",
       " ('pledge', 208),\n",
       " ('fall', 207),\n",
       " ('establish', 206),\n",
       " ('pay', 205),\n",
       " ('reflect', 205),\n",
       " ('lose', 205),\n",
       " ('stop', 203),\n",
       " ('charge', 200),\n",
       " ('run', 199),\n",
       " ('release', 197),\n",
       " ('proclaim', 196),\n",
       " ('spend', 195),\n",
       " ('build', 192),\n",
       " ('mandate', 190),\n",
       " ('choose', 188),\n",
       " ('end', 187),\n",
       " ('measure', 187),\n",
       " ('hopeful', 183),\n",
       " ('involve', 183),\n",
       " ('reduce', 183),\n",
       " ('examine', 182),\n",
       " ('clarify', 180),\n",
       " ('bring', 176),\n",
       " ('advise', 176),\n",
       " ('investigate', 175),\n",
       " ('teach', 173),\n",
       " ('request', 172),\n",
       " ('talk', 172),\n",
       " ('identify', 172),\n",
       " ('reach', 171),\n",
       " ('move', 168),\n",
       " ('explore', 167),\n",
       " ('appreciate', 166),\n",
       " ('clear', 166),\n",
       " ('detail', 166),\n",
       " ('counter', 166),\n",
       " ('emerge', 165),\n",
       " ('anticipate', 165),\n",
       " ('depend', 163),\n",
       " ('mind', 160),\n",
       " ('send', 158),\n",
       " ('joke', 157),\n",
       " ('occur', 157),\n",
       " ('answer', 157),\n",
       " ('forecast', 154),\n",
       " ('raise', 153),\n",
       " ('persuade', 153),\n",
       " ('glad', 152),\n",
       " ('assess', 152),\n",
       " ('boast', 150),\n",
       " ('die', 148),\n",
       " ('drive', 146),\n",
       " ('will', 144),\n",
       " ('surprised', 143),\n",
       " ('share', 142),\n",
       " ('represent', 142),\n",
       " ('vote', 141),\n",
       " ('face', 141),\n",
       " ('realise', 140),\n",
       " ('debate', 140),\n",
       " ('much', 138),\n",
       " ('plan', 137),\n",
       " ('dictate', 137),\n",
       " ('afraid', 136),\n",
       " ('meet', 136),\n",
       " ('document', 136),\n",
       " ('live', 136),\n",
       " ('disclose', 136),\n",
       " ('receive', 135),\n",
       " ('bad', 131),\n",
       " ('fail', 131),\n",
       " ('stand', 130),\n",
       " ('win', 129),\n",
       " ('express', 127),\n",
       " ('achieve', 127),\n",
       " ('burn', 127),\n",
       " ('push', 126),\n",
       " ('remark', 125),\n",
       " ('experience', 124),\n",
       " ('cut', 123),\n",
       " ('warm', 123),\n",
       " ('cite', 123),\n",
       " ('exist', 123),\n",
       " ('test', 123),\n",
       " ('speak', 122),\n",
       " ('kill', 122),\n",
       " ('cost', 122),\n",
       " ('trust', 121),\n",
       " ('vow', 121),\n",
       " ('urge', 120),\n",
       " ('pass', 119),\n",
       " ('lament', 119),\n",
       " ('result', 119),\n",
       " ('reassure', 118),\n",
       " ('specify', 118),\n",
       " ('cover', 117),\n",
       " ('underscore', 117),\n",
       " ('expose', 117),\n",
       " ('force', 114),\n",
       " ('control', 112),\n",
       " ('develop', 112),\n",
       " ('comment', 111),\n",
       " ('check', 110),\n",
       " ('love', 109),\n",
       " ('protect', 109),\n",
       " ('affirm', 109),\n",
       " ('optimistic', 108),\n",
       " ('order', 108),\n",
       " ('ignore', 106),\n",
       " ('prevent', 106),\n",
       " ('buy', 106),\n",
       " ('break', 106),\n",
       " ('seek', 105),\n",
       " ('tend', 104),\n",
       " ('outline', 104),\n",
       " ('define', 104),\n",
       " ('dispute', 104),\n",
       " ('emit', 103),\n",
       " ('lay', 103),\n",
       " ('threaten', 102),\n",
       " ('oppose', 102),\n",
       " ('prefer', 102),\n",
       " ('hit', 101),\n",
       " ('publish', 100),\n",
       " ('track', 100),\n",
       " ('play', 100),\n",
       " ('save', 99),\n",
       " ('contain', 99),\n",
       " ('recognise', 99),\n",
       " ('confess', 98),\n",
       " ('enable', 98),\n",
       " ('encourage', 98),\n",
       " ('capture', 97),\n",
       " ('catch', 97),\n",
       " ('hint', 97),\n",
       " ('rely', 96),\n",
       " ('drop', 96),\n",
       " ('deliver', 94),\n",
       " ('strike', 93),\n",
       " ('post', 92),\n",
       " ('repeat', 92),\n",
       " ('limit', 91),\n",
       " ('avoid', 91),\n",
       " ('melt', 91),\n",
       " ('focus', 90),\n",
       " ('…', 90),\n",
       " ('analyze', 89),\n",
       " ('lie', 88),\n",
       " ('present', 87),\n",
       " ('hypothesize', 85),\n",
       " ('witness', 84),\n",
       " ('reiterate', 83),\n",
       " ('suffer', 83),\n",
       " ('skeptical', 83),\n",
       " ('happy', 82),\n",
       " ('enough', 82),\n",
       " ('can', 82),\n",
       " ('reject', 81),\n",
       " ('miss', 81),\n",
       " ('challenge', 81),\n",
       " ('review', 80),\n",
       " ('promote', 80),\n",
       " ('compare', 80),\n",
       " ('high', 80),\n",
       " ('eat', 79),\n",
       " ('generate', 78),\n",
       " ('advocate', 78),\n",
       " ('act', 78),\n",
       " ('sit', 77),\n",
       " ('presume', 76),\n",
       " ('exceed', 76),\n",
       " ('serve', 76),\n",
       " ('disagree', 76),\n",
       " ('stipulate', 76),\n",
       " ('decline', 75),\n",
       " ('deem', 75),\n",
       " ('account', 74),\n",
       " ('alter', 74),\n",
       " ('evaluate', 73),\n",
       " ('bear', 73),\n",
       " ('small', 73),\n",
       " ('fight', 73),\n",
       " ('close', 73),\n",
       " ('wait', 72),\n",
       " ('open', 72),\n",
       " ('replace', 72),\n",
       " ('sell', 72),\n",
       " ('protest', 72),\n",
       " ('quote', 71),\n",
       " ('back', 71),\n",
       " ('manage', 71),\n",
       " ('destroy', 71),\n",
       " ('spread', 71),\n",
       " ('sense', 70),\n",
       " ('correct', 70),\n",
       " ('pray', 70),\n",
       " ('judge', 69),\n",
       " ('echo', 69),\n",
       " ('influence', 69),\n",
       " ('feature', 69),\n",
       " ('form', 69),\n",
       " ('shoot', 69),\n",
       " ('fast', 68),\n",
       " ('refer', 68),\n",
       " ('stay', 68),\n",
       " ('place', 67),\n",
       " ('posit', 67),\n",
       " ('carry', 67),\n",
       " ('apply', 66),\n",
       " ('verify', 66),\n",
       " ('low', 66),\n",
       " ('fix', 66),\n",
       " ('join', 66),\n",
       " ('endorse', 65),\n",
       " ('reckon', 65),\n",
       " ('pick', 65),\n",
       " ('prompt', 64),\n",
       " ('welcome', 64),\n",
       " ('aim', 64),\n",
       " ('draw', 63),\n",
       " ('undermine', 63),\n",
       " ('shift', 63),\n",
       " ('arrive', 63),\n",
       " ('regulate', 63),\n",
       " ('unaware', 62),\n",
       " ('shape', 62),\n",
       " ('pose', 62),\n",
       " ('monitor', 61),\n",
       " ('unlikely', 61),\n",
       " ('commit', 61),\n",
       " ('disappear', 61),\n",
       " ('feed', 60),\n",
       " ('surprise', 60),\n",
       " ('dismiss', 60),\n",
       " ('improve', 60),\n",
       " ('impact', 59),\n",
       " ('pleased', 58),\n",
       " ('sound', 58),\n",
       " ('thank', 58),\n",
       " ('impose', 58),\n",
       " ('issue', 58),\n",
       " ('view', 58),\n",
       " ('transform', 58),\n",
       " ('grasp', 58),\n",
       " ('return', 58),\n",
       " ('long', 57),\n",
       " ('shut', 57),\n",
       " ('base', 57),\n",
       " ('introduce', 57),\n",
       " ('contribute', 56),\n",
       " ('hurt', 56),\n",
       " ('absorb', 56),\n",
       " ('attack', 56),\n",
       " ('slow', 56),\n",
       " ('embrace', 56),\n",
       " ('offset', 55),\n",
       " ('risk', 55),\n",
       " ('shout', 55),\n",
       " ('listen', 55),\n",
       " ('expand', 54),\n",
       " ('notify', 54),\n",
       " ('large', 53),\n",
       " ('walk', 52),\n",
       " ('practice', 52),\n",
       " ('reverse', 52),\n",
       " ('weigh', 52),\n",
       " ('criticize', 52),\n",
       " ('treat', 51),\n",
       " ('blame', 51),\n",
       " ('severe', 51),\n",
       " ('enjoy', 51),\n",
       " ('vaccinate', 51),\n",
       " ('fund', 51),\n",
       " ('angry', 51),\n",
       " ('theorize', 51),\n",
       " ('upset', 51),\n",
       " ('count', 51),\n",
       " ('swear', 50),\n",
       " ('approve', 50),\n",
       " ('survive', 50),\n",
       " ('quantify', 50),\n",
       " ('list', 49),\n",
       " ('benefit', 49),\n",
       " ('favor', 49),\n",
       " ('pull', 49),\n",
       " ('grateful', 49),\n",
       " ('rethink', 49),\n",
       " ('launch', 48),\n",
       " ('accelerate', 48),\n",
       " ('underestimate', 48),\n",
       " ('reason', 48),\n",
       " ('enter', 48),\n",
       " ('remove', 48),\n",
       " ('accuse', 47),\n",
       " ('decrease', 47),\n",
       " ('envision', 46),\n",
       " ('brag', 46),\n",
       " ('mark', 46),\n",
       " ('deal', 45),\n",
       " ('link', 45),\n",
       " ('refuse', 45),\n",
       " ('throw', 45),\n",
       " ('name', 45),\n",
       " ('fill', 45),\n",
       " ('attract', 45),\n",
       " ('concur', 45),\n",
       " ('justify', 45),\n",
       " ('design', 45),\n",
       " ('adopt', 44),\n",
       " ('model', 44),\n",
       " ('meaning', 44),\n",
       " ('visit', 44),\n",
       " ('quip', 44),\n",
       " ('solve', 43),\n",
       " ('doubtful', 43),\n",
       " ('settle', 43),\n",
       " ('great', 43),\n",
       " ('ponder', 42),\n",
       " ('strong', 42),\n",
       " ('attempt', 42),\n",
       " ('govern', 42),\n",
       " ('eliminate', 42),\n",
       " ('conduct', 42),\n",
       " ('accomplish', 42),\n",
       " ('operate', 42),\n",
       " ('own', 41),\n",
       " ('grant', 41),\n",
       " ('record', 41),\n",
       " ('deserve', 41),\n",
       " ('head', 41),\n",
       " ('shrink', 41),\n",
       " ('pressure', 41),\n",
       " ('invest', 41),\n",
       " ('perceive', 41),\n",
       " ('thinking', 41),\n",
       " ('label', 40),\n",
       " ('engage', 40),\n",
       " ('waste', 40),\n",
       " ('is', 40),\n",
       " ('succeed', 40),\n",
       " ('direct', 40),\n",
       " ('earn', 40),\n",
       " ('reaffirm', 40),\n",
       " ('fracke', 40),\n",
       " ('flood', 39),\n",
       " ('would', 39),\n",
       " ('prepare', 39),\n",
       " ('double', 39),\n",
       " ('reinforce', 39),\n",
       " ('implement', 39),\n",
       " ('contradict', 39),\n",
       " ('recount', 39),\n",
       " ('target', 39),\n",
       " ('gather', 39),\n",
       " ('motivate', 39),\n",
       " ('cross', 38),\n",
       " ('damage', 38),\n",
       " ('lack', 38),\n",
       " ('collapse', 38),\n",
       " ('organize', 38),\n",
       " ('intend', 38),\n",
       " ('such', 38),\n",
       " ('afford', 38),\n",
       " ('harm', 37),\n",
       " ('disappoint', 37),\n",
       " ('weaken', 37),\n",
       " ('block', 37),\n",
       " ('guide', 37),\n",
       " ('heat', 37),\n",
       " ('match', 36),\n",
       " ('fret', 36),\n",
       " ('plant', 36),\n",
       " ('important', 36),\n",
       " ('sink', 36),\n",
       " ('climate', 36),\n",
       " ('intense', 36),\n",
       " ('employ', 36),\n",
       " ('consume', 36),\n",
       " ('object', 36),\n",
       " ('secure', 35),\n",
       " ('detect', 35),\n",
       " ('invite', 35),\n",
       " ('opine', 35),\n",
       " ('hide', 35),\n",
       " ('insure', 35),\n",
       " ('fly', 35),\n",
       " ('sum', 35),\n",
       " ('thick', 35),\n",
       " ('surge', 34),\n",
       " ('cool', 34),\n",
       " ('postulate', 34),\n",
       " ('struggle', 34),\n",
       " ('uncertain', 34),\n",
       " ('exploit', 34),\n",
       " ('approach', 34),\n",
       " ('gain', 34),\n",
       " ('leak', 34),\n",
       " ('arise', 33),\n",
       " ('inspire', 33),\n",
       " ('understanding', 33),\n",
       " ('good', 33),\n",
       " ('foresee', 33),\n",
       " ('pinpoint', 33),\n",
       " ('extend', 33),\n",
       " ('gauge', 33),\n",
       " ('stick', 33),\n",
       " ('rank', 33),\n",
       " ('map', 33),\n",
       " ('travel', 33),\n",
       " ('contaminate', 33),\n",
       " ('resist', 32),\n",
       " ('dare', 32),\n",
       " ('certify', 32),\n",
       " ('respect', 32),\n",
       " ('research', 32),\n",
       " ('free', 32),\n",
       " ('celebrate', 32),\n",
       " ('submit', 32),\n",
       " ('freeze', 32),\n",
       " ('kick', 32),\n",
       " ('permit', 32),\n",
       " ('cheap', 31),\n",
       " ('abandon', 31),\n",
       " ('ban', 31),\n",
       " ('strengthen', 31),\n",
       " ('wake', 31),\n",
       " ('instruct', 31),\n",
       " ('drink', 31),\n",
       " ('tout', 31),\n",
       " ('regret', 31),\n",
       " ('press', 31),\n",
       " ('alert', 31),\n",
       " ('articulate', 31),\n",
       " ('sorry', 31),\n",
       " ('fire', 31),\n",
       " ('restrict', 30),\n",
       " ('translate', 30),\n",
       " ('picture', 30),\n",
       " ('convey', 30),\n",
       " ('collect', 30),\n",
       " ('fit', 30),\n",
       " ('vary', 30),\n",
       " ('pour', 30),\n",
       " ('decree', 30),\n",
       " ('exclaim', 30),\n",
       " ('successful', 30),\n",
       " ('big', 30),\n",
       " ('roll', 30),\n",
       " ('chant', 30),\n",
       " ('disappointed', 30),\n",
       " ('wear', 30),\n",
       " ('spark', 30),\n",
       " ('frustrated', 29),\n",
       " ('far', 29),\n",
       " ('overstate', 29),\n",
       " ('register', 29),\n",
       " ('blow', 29),\n",
       " ('complete', 29),\n",
       " ('infer', 29),\n",
       " ('delay', 29),\n",
       " ('attend', 29),\n",
       " ('mount', 29),\n",
       " ('tackle', 29),\n",
       " ('range', 29),\n",
       " ('extract', 29),\n",
       " ('hang', 29),\n",
       " ('cold', 29),\n",
       " ('hot', 29),\n",
       " ('cry', 28),\n",
       " ('tie', 28),\n",
       " ('speed', 28),\n",
       " ('clean', 28),\n",
       " ('lock', 28),\n",
       " ('accompany', 28),\n",
       " ('bother', 28),\n",
       " ('denying', 28),\n",
       " ('jump', 28),\n",
       " ('vast', 28),\n",
       " ('spot', 28),\n",
       " ('crow', 28),\n",
       " ('confront', 28),\n",
       " ('powerful', 28),\n",
       " ('violate', 27),\n",
       " ('pursue', 27),\n",
       " ('praise', 27),\n",
       " ('purchase', 27),\n",
       " ('defend', 27),\n",
       " ('cancel', 27),\n",
       " ('underline', 27),\n",
       " ('expensive', 27),\n",
       " ('dig', 27),\n",
       " ('ought', 27),\n",
       " ('uncover', 26),\n",
       " ('display', 26),\n",
       " ('trigger', 26),\n",
       " ('contemplate', 26),\n",
       " ('trap', 26),\n",
       " ('best', 26),\n",
       " ('reconsider', 26),\n",
       " ('recover', 26),\n",
       " ('dire', 26),\n",
       " ('hard', 26),\n",
       " ('sue', 26),\n",
       " ('elaborate', 26),\n",
       " ('preserve', 26),\n",
       " ('spur', 26),\n",
       " ('simulate', 26),\n",
       " ('discern', 26),\n",
       " ('elect', 26),\n",
       " ('appeal', 26),\n",
       " ('evolve', 25),\n",
       " ('handle', 25),\n",
       " ('sponsor', 25),\n",
       " ('rare', 25),\n",
       " ('constitute', 25),\n",
       " ('weak', 25),\n",
       " ('arrest', 25),\n",
       " ('saying', 25),\n",
       " ('lucky', 25),\n",
       " ('select', 25),\n",
       " ('regard', 25),\n",
       " ('exaggerate', 25),\n",
       " ('file', 25),\n",
       " ('yield', 25),\n",
       " ('crack', 25),\n",
       " ('summarize', 24),\n",
       " ('withdraw', 24),\n",
       " ('step', 24),\n",
       " ('found', 24),\n",
       " ('hire', 24),\n",
       " ('spell', 24),\n",
       " ('hate', 24),\n",
       " ('encounter', 24),\n",
       " ('power', 24),\n",
       " ('suck', 24),\n",
       " ('restore', 24),\n",
       " ('fearful', 24),\n",
       " ('overestimate', 24),\n",
       " ('dry', 24),\n",
       " ('quickly', 23),\n",
       " ('perform', 23),\n",
       " ('instal', 23),\n",
       " ('empower', 23),\n",
       " ('redefine', 23),\n",
       " ('advance', 23),\n",
       " ('apologize', 23),\n",
       " ('boost', 23),\n",
       " ('store', 23),\n",
       " ('resemble', 23),\n",
       " ('doom', 23),\n",
       " ('thought', 23),\n",
       " ('dominate', 23),\n",
       " ('educate', 23),\n",
       " ('flow', 23),\n",
       " ('denounce', 23),\n",
       " ('sustain', 23),\n",
       " ('adapt', 23),\n",
       " ('plead', 22),\n",
       " ('comprehend', 22),\n",
       " ('lower', 22),\n",
       " ('scream', 22),\n",
       " ('sort', 22),\n",
       " ('jeopardize', 22),\n",
       " ('attest', 22),\n",
       " ('warning', 22),\n",
       " ('depict', 22),\n",
       " ('attribute', 22),\n",
       " ('displace', 22),\n",
       " ('last', 22),\n",
       " ('balance', 22),\n",
       " ('belong', 22),\n",
       " ('escape', 22),\n",
       " ('connect', 22),\n",
       " ('obvious', 22),\n",
       " ('erupt', 22),\n",
       " ('muse', 22),\n",
       " ('designate', 22),\n",
       " ('resolve', 22),\n",
       " ('well', 21),\n",
       " ('mitigate', 21),\n",
       " ('soar', 21),\n",
       " ('ironic', 21),\n",
       " ('rally', 21),\n",
       " ('condemn', 21),\n",
       " ('debunk', 21),\n",
       " ('train', 21),\n",
       " ('suffice', 21),\n",
       " ('thrill', 21),\n",
       " ('touch', 21),\n",
       " ('cheer', 21),\n",
       " ('retort', 21),\n",
       " ('mobilize', 21),\n",
       " ('campaign', 21),\n",
       " ('convert', 21),\n",
       " ('rest', 21),\n",
       " ('extreme', 21),\n",
       " ('communicate', 21),\n",
       " ('surmise', 21),\n",
       " ('switch', 21),\n",
       " ('grumble', 21),\n",
       " ('cast', 21),\n",
       " ('hand', 20),\n",
       " ('seize', 20),\n",
       " ('fuel', 20),\n",
       " ('pronounce', 20),\n",
       " ('bind', 20),\n",
       " ('locate', 20),\n",
       " ('polluted', 20),\n",
       " ('beat', 20),\n",
       " ('donate', 20),\n",
       " ('overlook', 20),\n",
       " ('volunteer', 20),\n",
       " ('circulate', 20),\n",
       " ('so', 20),\n",
       " ('disturb', 20),\n",
       " ('huge', 20),\n",
       " ('negotiate', 20),\n",
       " ('contract', 20),\n",
       " ('should', 20),\n",
       " ('manufacture', 20),\n",
       " ('forbid', 20),\n",
       " ('decry', 20),\n",
       " ('dump', 20),\n",
       " ('worsen', 20),\n",
       " ('endure', 19),\n",
       " ('recycle', 19),\n",
       " ('combat', 19),\n",
       " ('unveil', 19),\n",
       " ('halt', 19),\n",
       " ('thankful', 19),\n",
       " ('sing', 19),\n",
       " ('endanger', 19),\n",
       " ('inject', 19),\n",
       " ('ascertain', 19),\n",
       " ('slam', 19),\n",
       " ('appoint', 19),\n",
       " ('harness', 19),\n",
       " ('frustrate', 19),\n",
       " ('surround', 19),\n",
       " ('mock', 19),\n",
       " ('infect', 19),\n",
       " ('acquire', 19),\n",
       " ('plummet', 19),\n",
       " ('separate', 19),\n",
       " ('divide', 19),\n",
       " ('emphasise', 19),\n",
       " ('weekday', 19),\n",
       " ('impress', 18),\n",
       " ('deep', 18),\n",
       " ('portray', 18),\n",
       " ('yell', 18),\n",
       " ('paint', 18),\n",
       " ('lift', 18),\n",
       " ('okay', 18),\n",
       " ('react', 18),\n",
       " ('deploy', 18),\n",
       " ('climb', 18),\n",
       " ('undo', 18),\n",
       " ('retain', 18),\n",
       " ('average', 18),\n",
       " ('complex', 18),\n",
       " ('relate', 18),\n",
       " ('significant', 18),\n",
       " ('unsure', 18),\n",
       " ('rebuild', 18),\n",
       " ('compete', 18),\n",
       " ('careful', 18),\n",
       " ('scale', 18),\n",
       " ('pump', 18),\n",
       " ('argument', 18),\n",
       " ('degree', 18),\n",
       " ('swallow', 18),\n",
       " ('email', 18),\n",
       " ('relieve', 18),\n",
       " ('suspend', 18),\n",
       " ('may', 18),\n",
       " ('toxin', 18),\n",
       " ('hammer', 18),\n",
       " ('shake', 18),\n",
       " ('pollute', 18),\n",
       " ('cook', 17),\n",
       " ('proud', 17),\n",
       " ('–', 17),\n",
       " ('supply', 17),\n",
       " ('participate', 17),\n",
       " ('spew', 17),\n",
       " ('distinguish', 17),\n",
       " ('click', 17),\n",
       " ('insinuate', 17),\n",
       " ('mix', 17),\n",
       " ('mimic', 17),\n",
       " ('dangerous', 17),\n",
       " ('factor', 17),\n",
       " ('remote', 17),\n",
       " ('erode', 17),\n",
       " ('accumulate', 17),\n",
       " ('common', 17),\n",
       " ('knock', 17),\n",
       " ('ride', 17),\n",
       " ('tax', 17),\n",
       " ('exercise', 17),\n",
       " ('alarm', 17),\n",
       " ('value', 17),\n",
       " ('disrupt', 17),\n",
       " ('toxic', 17),\n",
       " ('grab', 17),\n",
       " ('gush', 17),\n",
       " ('dismay', 17),\n",
       " ('survey', 17),\n",
       " ('tap', 17),\n",
       " ('wash', 17),\n",
       " ('host', 16),\n",
       " ('green', 16),\n",
       " ('fortunate', 16),\n",
       " ('understate', 16),\n",
       " ('drown', 16),\n",
       " ('access', 16),\n",
       " ('laugh', 16),\n",
       " ('appal', 16),\n",
       " ('author', 16),\n",
       " ('age', 16),\n",
       " ('tease', 16),\n",
       " ('badly', 16),\n",
       " ('illuminate', 16),\n",
       " ('finish', 16),\n",
       " ('amount', 16),\n",
       " ('oversee', 16),\n",
       " ('everywhere', 16),\n",
       " ('scoff', 16),\n",
       " ('manipulate', 16),\n",
       " ('finding', 16),\n",
       " ('associate', 16),\n",
       " ('surpass', 16),\n",
       " ('trade', 16),\n",
       " ('satisfy', 16),\n",
       " ('puzzle', 16),\n",
       " ('combine', 16),\n",
       " ('differ', 16),\n",
       " ('poor', 16),\n",
       " ('smile', 16),\n",
       " ('embody', 15),\n",
       " ('stretch', 15),\n",
       " ('interview', 15),\n",
       " ('update', 15),\n",
       " ('manmade', 15),\n",
       " ('distribute', 15),\n",
       " ('blast', 15),\n",
       " ('applaud', 15),\n",
       " ('export', 15),\n",
       " ('terrify', 15),\n",
       " ('enact', 15),\n",
       " ('bar', 15),\n",
       " ('exit', 15),\n",
       " ('thrive', 15),\n",
       " ('diagnose', 15),\n",
       " ('frame', 15),\n",
       " ('diminish', 15),\n",
       " ('t]he', 15),\n",
       " ('stall', 15),\n",
       " ('dawn', 15),\n",
       " ('Facebook', 15),\n",
       " ('wrap', 15),\n",
       " ('serious', 15),\n",
       " ('often', 15),\n",
       " ('wipe', 14),\n",
       " ('unconvinced', 14),\n",
       " ('sweep', 14),\n",
       " ('abolish', 14),\n",
       " ('preach', 14),\n",
       " ('scared', 14),\n",
       " ('signify', 14),\n",
       " ('flee', 14),\n",
       " ('craft', 14),\n",
       " ('wind', 14),\n",
       " ('profess', 14),\n",
       " ('trouble', 14),\n",
       " ('wrong', 14),\n",
       " ('not', 14),\n",
       " ('devastate', 14),\n",
       " ('massive', 14),\n",
       " ('idea', 14),\n",
       " ('marvel', 14),\n",
       " ('contrast', 14),\n",
       " ('breathe', 14),\n",
       " ('sacrifice', 14),\n",
       " ('satisfied', 14),\n",
       " ('disregard', 14),\n",
       " ('harvest', 14),\n",
       " ('invent', 14),\n",
       " ('reference', 14),\n",
       " ('unconvince', 14),\n",
       " ('await', 14),\n",
       " ('News', 14),\n",
       " ('discourage', 14),\n",
       " ('light', 14),\n",
       " ('subsidize', 14),\n",
       " ('compel', 14),\n",
       " ('line', 14),\n",
       " ('shed', 14),\n",
       " ('wager', 14),\n",
       " ('Have', 14),\n",
       " ('curb', 13),\n",
       " ('more', 13),\n",
       " ('curious', 13),\n",
       " ('retreat', 13),\n",
       " ('shock', 13),\n",
       " ('reconstruct', 13),\n",
       " ('rapidly', 13),\n",
       " ('inquire', 13),\n",
       " ('drill', 13),\n",
       " ('disappointing', 13),\n",
       " ('persist', 13),\n",
       " ('complicate', 13),\n",
       " ('coordinate', 13),\n",
       " ('enormous', 13),\n",
       " ('reshape', 13),\n",
       " ('thunder', 13),\n",
       " ('revise', 13),\n",
       " ('decimate', 13),\n",
       " ('adjust', 13),\n",
       " ('overwhelming', 13),\n",
       " ('deplete', 13),\n",
       " ('positive', 13),\n",
       " ('rate', 13),\n",
       " ('rich', 13),\n",
       " ...]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counted_main_verb_lemmas = sorted(Counter([q['main verb lemma'] for q in all_quotes]).items(),key=lambda x:x[1],\n",
    "                                  reverse=True)\n",
    "counted_main_verb_lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "BLACKLIST_MAIN_VERBS = set(['make','let','help','allow','get','ask','want','cause','ensure','require','go',\n",
    "                           'take','hold','become','watch','use','keep','call','give','come','change',\n",
    "                           'look','remain','now','leave','include','begin','put','start','work','right',\n",
    "                           'create','provide','produce','study','offer','try','lead','grow','like','set',\n",
    "                           'follow','address','sign','affect','increase','render','rise','fall','pay',\n",
    "                           'reflect','lose','stop','run','release','spend','build','choose','end','measure',\n",
    "                           'involve','reduce','examine','bring','investigate','request','talk','identify',\n",
    "                           'reach','move','explore','emerge','depend','send','occur','raise','die',\n",
    "                           'drive','represent','vote','face','much','plan','dictate','meet','live',\n",
    "                           'receive','bad','fail','stand','win','achieve','burn','push','cut','warm',\n",
    "                           'exist','test','kill','cost','pass','result','cover','force','control','develop',\n",
    "                           'check','love','protect','prevent','buy','break','seek','tend','emit','lay',\n",
    "                           'hit','track','play','enable','capture','catch',\n",
    "                            'have','do','decide','direct','need','succeed','hee','carry','dump','mean','ensure'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_quotes_with_lemma(lemma_set,element,quote_list):\n",
    "    return [q for q in quote_list if q[element] is not None and q[element].lower() in lemma_set]\n",
    "\n",
    "def get_quotes_without_lemma(lemma_set,element,quote_list):\n",
    "    return [q for q in quote_list if q[element] is not None and q[element].lower() not in lemma_set]\n",
    "\n",
    "def get_quotes_with_stem(stem_set,element,quote_list):\n",
    "    return [q for q in quote_list if q[element] is not None and ps.stem(q[element].lower()) in stem_set]\n",
    "\n",
    "def get_quotes_without_stem(stem_set,element,quote_list):\n",
    "    return [q for q in quote_list if q[element] is not None and ps.stem(q[element].lower()) not in stem_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove quotes with question verb\n",
    "\n",
    "QUESTION_WORDS = set(['who','what','when','where','why','how','if','whose','whether','which','whom','whence'])\n",
    "QUESTION_VERBS = set(['ask','wonder','figure','guess','inquire','interrogate','question'])\n",
    "\n",
    "def has_indirect_question(quote_obj):\n",
    "    quote = quote_obj['quote']\n",
    "    first_word = quote[0].lower()\n",
    "    return first_word in QUESTION_WORDS\n",
    "\n",
    "def has_question_verb(quote_obj):\n",
    "    verb = quote_obj['main verb lemma'].lower()\n",
    "    return verb in QUESTION_VERBS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "289481"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_quotes = [q for q in all_quotes if not has_question_verb(q)]\n",
    "len(all_quotes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(268236, 21245)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set aside quotes with 'be' as main verb\n",
    "\n",
    "BE_STEMS = set(['is','wa','’s','are',\"'s\",'be','’m','am','are','’re',\"'m\",\"'re\",\"been\",'were'])\n",
    "\n",
    "quotes_without_be = get_quotes_without_lemma(BE_STEMS,'main verb lemma',all_quotes)\n",
    "quotes_with_be = get_quotes_with_lemma(BE_STEMS,'main verb lemma',all_quotes)\n",
    "\n",
    "len(quotes_without_be),len(quotes_with_be)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(735, 0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove quotes with 'point','turn' but not 'point_out','turn_out' as main verb\n",
    "\n",
    "point_quotes = get_quotes_with_lemma(['point','turn'],'main verb lemma',quotes_without_be)\n",
    "point_out_quotes = [x for x in point_quotes if 'out' in x['verb lemmas']]\n",
    "\n",
    "true_point_out_quotes = []\n",
    "false_point_out_quotes = []\n",
    "for x in point_out_quotes:\n",
    "    indices_out = [i for i,t in enumerate(x['verb lemmas']) if t.lower() == 'out']\n",
    "    prev_toks = [ps.stem(x['verb lemmas'][i-1].lower()) for i in indices_out]\n",
    "    if 'point' in prev_toks:\n",
    "        x['main verb lemma'] = 'point_out'\n",
    "        x['main verb lemma coref'] = 'point_out'\n",
    "        true_point_out_quotes.append(x)\n",
    "    elif 'turn' in prev_toks:\n",
    "        x['main verb lemma'] = 'turn_out'\n",
    "        x['main verb lemma coref'] = 'turn_out'\n",
    "        true_point_out_quotes.append(x)\n",
    "    else:\n",
    "        false_point_out_quotes.append(x)\n",
    "        \n",
    "len(true_point_out_quotes),len(false_point_out_quotes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "268236"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_quotes = [q for q in quotes_without_be if q not in false_point_out_quotes]\n",
    "len(all_quotes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "226381"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove quotes with a set of non-attributive verbs introducing comp clause\n",
    "non_other_verb_quotes = get_quotes_without_stem(BLACKLIST_MAIN_VERBS,'main verb lemma',all_quotes)\n",
    "len(non_other_verb_quotes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "225383"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove quotes with 'seem', 'appear' as main verb\n",
    "\n",
    "non_seem_quotes = get_quotes_without_stem(['seem','appear'],'main verb lemma',non_other_verb_quotes)\n",
    "len(non_seem_quotes)#+len(seem_quotes),len(all_quotes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "223227"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove verb with non-alpha main verb\n",
    "\n",
    "non_punc_main_verb_quotes = [q for q in non_seem_quotes if q['main verb lemma'][0].lower().isalpha()]\n",
    "len(non_punc_main_verb_quotes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'quote lemmas': ['-PRON-', 'ignore', 'expert', 'advice', ' '],\n",
       " 'quote lemmas coref': ['President Donald Trump',\n",
       "  'ignore',\n",
       "  'expert',\n",
       "  'advice',\n",
       "  ' '],\n",
       " 'verb lemmas': ['admit'],\n",
       " 'verb lemmas coref': ['admit'],\n",
       " 'main verb lemma': 'admit',\n",
       " 'main verb lemma coref': 'admit',\n",
       " 'subject lemmas': ['trump'],\n",
       " 'subject lemmas coref': ['President Donald Trump'],\n",
       " 'main subject lemma': 'trump',\n",
       " 'main subject lemma coref': 'President Donald Trump',\n",
       " 'neg lemmas': None,\n",
       " 'main neg lemma': None,\n",
       " 'quote text': ['he', 'ignores', 'expert', 'advice', ' '],\n",
       " 'verb text': ['admits'],\n",
       " 'main verb text': 'admits',\n",
       " 'subject text': ['Trump'],\n",
       " 'main subject text': 'Trump',\n",
       " 'is neg': None,\n",
       " 'source': 'www.vox.com/2020/3/24/21191557/trump-coronavirus-economy-reopen-social-distance'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_punc_main_verb_quotes[32432]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "154\n",
      "154\n"
     ]
    }
   ],
   "source": [
    "# Collapse recognize/recognise, realize/realise\n",
    "\n",
    "british_quotes = [q for q in non_punc_main_verb_quotes if q['main verb lemma'].lower() == 'recognise' \n",
    "                      or q['main verb lemma'].lower() == 'realise']\n",
    "print(len(british_quotes))\n",
    "americanized_quotes = []\n",
    "for q in british_quotes:\n",
    "    q['main verb lemma'] = q['main verb lemma'].replace('s','z')\n",
    "    q['main verb lemma coref'] = q['main verb lemma coref'].replace('s','z')\n",
    "    americanized_quotes.append(q)\n",
    "print(len(americanized_quotes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "223227"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spell_standardized_quotes = [q for q in non_punc_main_verb_quotes if q not in british_quotes] + americanized_quotes\n",
    "len(spell_standardized_quotes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"e&e'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "re.sub(\"\\s\\s+\",'','\"   e&e')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "whitespace_cleaned_quotes = []\n",
    "for q in spell_standardized_quotes:\n",
    "    for key in ['main verb lemma','main verb lemma coref','main subject lemma','main subject lemma coref']:\n",
    "        if q[key] is not None:\n",
    "            q[key] = re.sub(\"\\s\\s+\",'',q[key])\n",
    "    whitespace_cleaned_quotes.append(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "223227"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(whitespace_cleaned_quotes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_src_attr(url,attr):\n",
    "    return df.loc[df.url==url][attr].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_quotes = []\n",
    "for q in whitespace_cleaned_quotes:\n",
    "    stance = get_src_attr(q['source'],'stance')\n",
    "    topic = get_src_attr(q['source'],'topic')\n",
    "    q.update({'stance':stance,'topic':topic})\n",
    "    updated_quotes.append(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "223227"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(updated_quotes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(223227, 223227)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hop_collapsed_quotes = []\n",
    "for q in updated_quotes:\n",
    "    if q['main verb lemma'] == 'hop':\n",
    "        q['main verb lemma coref'] = 'hope'\n",
    "        q['main verb lemma'] = 'hope'\n",
    "        q['verb lemmas'] = [v if v != 'hop' else 'hope' for v in q['verb lemmas']]\n",
    "        q['verb lemmas coref'] = [v if v != 'hop' else 'hope' for v in q['verb lemmas coref']]\n",
    "    hop_collapsed_quotes.append(q)\n",
    "len(updated_quotes),len(hop_collapsed_quotes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(hop_collapsed_quotes,open('filtered_covid_quotes.pkl','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine distribution of indirect statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# most common main verbs, subjects, amount of negation, sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "446764"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quotes = pickle.load(open('filtered_quotes.pkl','rb'))\n",
    "len(quotes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('say', 135970),\n",
       " ('think', 20463),\n",
       " ('tell', 16615),\n",
       " ('know', 13916),\n",
       " ('find', 12468),\n",
       " ('show', 9906),\n",
       " ('believe', 9859),\n",
       " ('see', 8952),\n",
       " ('mean', 8234),\n",
       " ('suggest', 8059),\n",
       " ('have', 7231),\n",
       " ('note', 7012),\n",
       " ('argue', 6643),\n",
       " ('write', 6425),\n",
       " ('add', 6283),\n",
       " ('report', 5383),\n",
       " ('claim', 4505),\n",
       " ('explain', 4337),\n",
       " ('warn', 3294),\n",
       " ('sure', 3243),\n",
       " ('announce', 3178),\n",
       " ('estimate', 3090),\n",
       " ('cause', 3078),\n",
       " ('conclude', 2959),\n",
       " ('understand', 2837),\n",
       " ('do', 2670),\n",
       " ('ensure', 2604),\n",
       " ('hope', 2602),\n",
       " ('expect', 2593),\n",
       " ('agree', 2276),\n",
       " ('consider', 2241),\n",
       " ('predict', 2142),\n",
       " ('state', 2099),\n",
       " ('point_out', 2055),\n",
       " ('indicate', 2027),\n",
       " ('realize', 1982),\n",
       " ('declare', 1930),\n",
       " ('feel', 1876),\n",
       " ('assume', 1869),\n",
       " ('acknowledge', 1861),\n",
       " ('insist', 1759),\n",
       " ('determine', 1736),\n",
       " ('decide', 1566),\n",
       " ('admit', 1430),\n",
       " ('matter', 1414),\n",
       " ('need', 1386),\n",
       " ('reveal', 1355),\n",
       " ('hear', 1335),\n",
       " ('learn', 1191),\n",
       " ('prove', 1147),\n",
       " ('remember', 1128),\n",
       " ('confirm', 1058),\n",
       " ('recognize', 1035),\n",
       " ('imagine', 1032),\n",
       " ('require', 996),\n",
       " ('continue', 992),\n",
       " ('worry', 973),\n",
       " ('fear', 971),\n",
       " ('demonstrate', 866),\n",
       " ('demand', 839),\n",
       " ('become', 819),\n",
       " ('convince', 788),\n",
       " ('discover', 784),\n",
       " ('read', 768),\n",
       " ('assert', 703),\n",
       " ('recall', 664),\n",
       " ('recommend', 633),\n",
       " ('calculate', 629),\n",
       " ('suspect', 622),\n",
       " ('turn_out', 574),\n",
       " ('promise', 554),\n",
       " ('rule', 539),\n",
       " ('remind', 528),\n",
       " ('contend', 526),\n",
       " ('wish', 523),\n",
       " ('notice', 511),\n",
       " ('mention', 511),\n",
       " ('assure', 510),\n",
       " ('emphasize', 510),\n",
       " ('deny', 506),\n",
       " ('complain', 497),\n",
       " ('change', 488),\n",
       " ('project', 469),\n",
       " ('observe', 461),\n",
       " ('accept', 455),\n",
       " ('confident', 449),\n",
       " ('describe', 436),\n",
       " ('propose', 429),\n",
       " ('caution', 422),\n",
       " ('respond', 421),\n",
       " ('aware', 401),\n",
       " ('maintain', 397),\n",
       " ('concede', 393),\n",
       " ('imply', 393),\n",
       " ('tweet', 391),\n",
       " ('stress', 384),\n",
       " ('signal', 370),\n",
       " ('allege', 364),\n",
       " ('leave', 359),\n",
       " ('include', 355),\n",
       " ('forget', 347),\n",
       " ('doubt', 344),\n",
       " ('hop', 340),\n",
       " ('discuss', 339),\n",
       " ('reply', 331),\n",
       " ('suppose', 327),\n",
       " ('happen', 325),\n",
       " ('pretend', 320),\n",
       " ('create', 295),\n",
       " ('provide', 291),\n",
       " ('produce', 276),\n",
       " ('study', 264),\n",
       " ('guarantee', 258),\n",
       " ('try', 257),\n",
       " ('inform', 253),\n",
       " ('concern', 251),\n",
       " ('care', 251),\n",
       " ('highlight', 249),\n",
       " ('concerned', 247),\n",
       " ('certain', 236),\n",
       " ('illustrate', 232),\n",
       " ('convinced', 221),\n",
       " ('bet', 219),\n",
       " ('speculate', 217),\n",
       " ('increase', 215),\n",
       " ('testify', 213),\n",
       " ('support', 211),\n",
       " ('worried', 210),\n",
       " ('pledge', 208),\n",
       " ('establish', 206),\n",
       " ('charge', 200),\n",
       " ('release', 197),\n",
       " ('proclaim', 196),\n",
       " ('mandate', 190),\n",
       " ('choose', 188),\n",
       " ('measure', 187),\n",
       " ('hopeful', 183),\n",
       " ('involve', 183),\n",
       " ('reduce', 183),\n",
       " ('examine', 182),\n",
       " ('turn', 181),\n",
       " ('clarify', 180),\n",
       " ('advise', 176),\n",
       " ('investigate', 175),\n",
       " ('teach', 173),\n",
       " ('identify', 172),\n",
       " ('explore', 168),\n",
       " ('appreciate', 166),\n",
       " ('clear', 166),\n",
       " ('point', 166),\n",
       " ('detail', 166),\n",
       " ('counter', 166),\n",
       " ('emerge', 165),\n",
       " ('anticipate', 165),\n",
       " ('mind', 160),\n",
       " ('joke', 157),\n",
       " ('answer', 157),\n",
       " ('forecast', 156),\n",
       " ('glad', 156),\n",
       " ('raise', 153),\n",
       " ('persuade', 153),\n",
       " ('assess', 152),\n",
       " ('boast', 150),\n",
       " ('will', 144),\n",
       " ('surprised', 143),\n",
       " ('share', 142),\n",
       " ('represent', 142),\n",
       " ('debate', 140),\n",
       " ('dictate', 137),\n",
       " ('afraid', 136),\n",
       " ('document', 136),\n",
       " ('disclose', 136),\n",
       " ('receive', 135),\n",
       " ('express', 127),\n",
       " ('achieve', 127),\n",
       " ('remark', 125),\n",
       " ('experience', 124),\n",
       " ('cite', 123),\n",
       " ('speak', 122),\n",
       " ('trust', 121),\n",
       " ('vow', 121),\n",
       " ('urge', 120),\n",
       " ('lament', 119),\n",
       " ('reassure', 118),\n",
       " ('specify', 118),\n",
       " ('underscore', 117),\n",
       " ('expose', 117),\n",
       " ('force', 116),\n",
       " ('comment', 111),\n",
       " ('affirm', 111),\n",
       " ('optimistic', 108),\n",
       " ('order', 108),\n",
       " ('ignore', 106),\n",
       " ('outline', 104),\n",
       " ('define', 104),\n",
       " ('dispute', 104),\n",
       " ('threaten', 102),\n",
       " ('oppose', 102),\n",
       " ('prefer', 102),\n",
       " ('save', 101),\n",
       " ('publish', 100),\n",
       " ('contain', 99),\n",
       " ('confess', 98),\n",
       " ('enable', 98),\n",
       " ('encourage', 98),\n",
       " ('capture', 97),\n",
       " ('hint', 97),\n",
       " ('rely', 96),\n",
       " ('drop', 96),\n",
       " ('deliver', 94),\n",
       " ('strike', 93),\n",
       " ('post', 92),\n",
       " ('repeat', 92),\n",
       " ('limit', 91),\n",
       " ('avoid', 91),\n",
       " ('melt', 91),\n",
       " ('focus', 90),\n",
       " ('analyze', 89),\n",
       " ('lie', 88),\n",
       " ('present', 87),\n",
       " ('hypothesize', 85),\n",
       " ('witness', 84),\n",
       " ('reiterate', 83),\n",
       " ('suffer', 83),\n",
       " ('skeptical', 83),\n",
       " ('happy', 82),\n",
       " ('enough', 82),\n",
       " ('can', 82),\n",
       " ('reject', 81),\n",
       " ('miss', 81),\n",
       " ('challenge', 81),\n",
       " ('review', 80),\n",
       " ('promote', 80),\n",
       " ('compare', 80),\n",
       " ('high', 80),\n",
       " ('eat', 79),\n",
       " ('generate', 78),\n",
       " ('advocate', 78),\n",
       " ('act', 78),\n",
       " ('sit', 77),\n",
       " ('presume', 76),\n",
       " ('exceed', 76),\n",
       " ('serve', 76),\n",
       " ('disagree', 76),\n",
       " ('stipulate', 76),\n",
       " ('decline', 75),\n",
       " ('deem', 75),\n",
       " ('account', 74),\n",
       " ('alter', 74),\n",
       " ('evaluate', 73),\n",
       " ('bear', 73),\n",
       " ('small', 73),\n",
       " ('fight', 73),\n",
       " ('close', 73),\n",
       " ('wait', 72),\n",
       " ('open', 72),\n",
       " ('replace', 72),\n",
       " ('sell', 72),\n",
       " ('protest', 72),\n",
       " ('quote', 71),\n",
       " ('back', 71),\n",
       " ('manage', 71),\n",
       " ('destroy', 71),\n",
       " ('spread', 71),\n",
       " ('sense', 70),\n",
       " ('correct', 70),\n",
       " ('pray', 70),\n",
       " ('judge', 69),\n",
       " ('echo', 69),\n",
       " ('influence', 69),\n",
       " ('feature', 69),\n",
       " ('form', 69),\n",
       " ('shoot', 69),\n",
       " ('fast', 68),\n",
       " ('refer', 68),\n",
       " ('stay', 68),\n",
       " ('place', 67),\n",
       " ('posit', 67),\n",
       " ('carry', 67),\n",
       " ('apply', 66),\n",
       " ('verify', 66),\n",
       " ('low', 66),\n",
       " ('fix', 66),\n",
       " ('join', 66),\n",
       " ('endorse', 65),\n",
       " ('reckon', 65),\n",
       " ('pick', 65),\n",
       " ('prompt', 64),\n",
       " ('welcome', 64),\n",
       " ('aim', 64),\n",
       " ('draw', 63),\n",
       " ('undermine', 63),\n",
       " ('shift', 63),\n",
       " ('arrive', 63),\n",
       " ('regulate', 63),\n",
       " ('unaware', 62),\n",
       " ('shape', 62),\n",
       " ('pose', 62),\n",
       " ('monitor', 61),\n",
       " ('unlikely', 61),\n",
       " ('commit', 61),\n",
       " ('disappear', 61),\n",
       " ('vaccinate', 61),\n",
       " ('feed', 60),\n",
       " ('surprise', 60),\n",
       " ('dismiss', 60),\n",
       " ('improve', 60),\n",
       " ('impact', 59),\n",
       " ('pleased', 58),\n",
       " ('sound', 58),\n",
       " ('thank', 58),\n",
       " ('impose', 58),\n",
       " ('issue', 58),\n",
       " ('view', 58),\n",
       " ('transform', 58),\n",
       " ('grasp', 58),\n",
       " ('return', 58),\n",
       " ('long', 57),\n",
       " ('shut', 57),\n",
       " ('base', 57),\n",
       " ('introduce', 57),\n",
       " ('contribute', 56),\n",
       " ('hurt', 56),\n",
       " ('absorb', 56),\n",
       " ('attack', 56),\n",
       " ('slow', 56),\n",
       " ('embrace', 56),\n",
       " ('offset', 55),\n",
       " ('risk', 55),\n",
       " ('shout', 55),\n",
       " ('listen', 55),\n",
       " ('expand', 54),\n",
       " ('notify', 54),\n",
       " ('large', 53),\n",
       " ('walk', 52),\n",
       " ('practice', 52),\n",
       " ('reverse', 52),\n",
       " ('weigh', 52),\n",
       " ('criticize', 52),\n",
       " ('treat', 51),\n",
       " ('blame', 51),\n",
       " ('severe', 51),\n",
       " ('enjoy', 51),\n",
       " ('fund', 51),\n",
       " ('angry', 51),\n",
       " ('theorize', 51),\n",
       " ('upset', 51),\n",
       " ('count', 51),\n",
       " ('swear', 50),\n",
       " ('approve', 50),\n",
       " ('survive', 50),\n",
       " ('quantify', 50),\n",
       " ('list', 49),\n",
       " ('benefit', 49),\n",
       " ('favor', 49),\n",
       " ('pull', 49),\n",
       " ('grateful', 49),\n",
       " ('rethink', 49),\n",
       " ('launch', 48),\n",
       " ('accelerate', 48),\n",
       " ('underestimate', 48),\n",
       " ('reason', 48),\n",
       " ('enter', 48),\n",
       " ('remove', 48),\n",
       " ('accuse', 47),\n",
       " ('decrease', 47),\n",
       " ('would', 46),\n",
       " ('envision', 46),\n",
       " ('brag', 46),\n",
       " ('mark', 46),\n",
       " ('deal', 45),\n",
       " ('link', 45),\n",
       " ('refuse', 45),\n",
       " ('throw', 45),\n",
       " ('name', 45),\n",
       " ('fill', 45),\n",
       " ('attract', 45),\n",
       " ('concur', 45),\n",
       " ('justify', 45),\n",
       " ('design', 45),\n",
       " ('adopt', 44),\n",
       " ('model', 44),\n",
       " ('meaning', 44),\n",
       " ('visit', 44),\n",
       " ('quip', 44),\n",
       " ('solve', 43),\n",
       " ('doubtful', 43),\n",
       " ('settle', 43),\n",
       " ('great', 43),\n",
       " ('ponder', 42),\n",
       " ('strong', 42),\n",
       " ('attempt', 42),\n",
       " ('govern', 42),\n",
       " ('eliminate', 42),\n",
       " ('conduct', 42),\n",
       " ('accomplish', 42),\n",
       " ('operate', 42),\n",
       " ('own', 41),\n",
       " ('grant', 41),\n",
       " ('record', 41),\n",
       " ('deserve', 41),\n",
       " ('head', 41),\n",
       " ('shrink', 41),\n",
       " ('pressure', 41),\n",
       " ('invest', 41),\n",
       " ('perceive', 41),\n",
       " ('thinking', 41),\n",
       " ('label', 40),\n",
       " ('engage', 40),\n",
       " ('waste', 40),\n",
       " ('succeed', 40),\n",
       " ('direct', 40),\n",
       " ('earn', 40),\n",
       " ('reaffirm', 40),\n",
       " ('fracke', 40),\n",
       " ('flood', 39),\n",
       " ('prepare', 39),\n",
       " ('double', 39),\n",
       " ('reinforce', 39),\n",
       " ('implement', 39),\n",
       " ('contradict', 39),\n",
       " ('recount', 39),\n",
       " ('target', 39),\n",
       " ('gather', 39),\n",
       " ('motivate', 39),\n",
       " ('cross', 38),\n",
       " ('damage', 38),\n",
       " ('lack', 38),\n",
       " ('collapse', 38),\n",
       " ('organize', 38),\n",
       " ('intend', 38),\n",
       " ('such', 38),\n",
       " ('afford', 38),\n",
       " ('harm', 37),\n",
       " ('disappoint', 37),\n",
       " ('weaken', 37),\n",
       " ('block', 37),\n",
       " ('guide', 37),\n",
       " ('heat', 37),\n",
       " ('match', 36),\n",
       " ('fret', 36),\n",
       " ('plant', 36),\n",
       " ('important', 36),\n",
       " ('sink', 36),\n",
       " ('climate', 36),\n",
       " ('intense', 36),\n",
       " ('employ', 36),\n",
       " ('consume', 36),\n",
       " ('object', 36),\n",
       " ('secure', 35),\n",
       " ('detect', 35),\n",
       " ('invite', 35),\n",
       " ('opine', 35),\n",
       " ('hide', 35),\n",
       " ('insure', 35),\n",
       " ('fly', 35),\n",
       " ('sum', 35),\n",
       " ('thick', 35),\n",
       " ('surge', 34),\n",
       " ('cool', 34),\n",
       " ('postulate', 34),\n",
       " ('struggle', 34),\n",
       " ('uncertain', 34),\n",
       " ('exploit', 34),\n",
       " ('approach', 34),\n",
       " ('gain', 34),\n",
       " ('leak', 34),\n",
       " ('arise', 33),\n",
       " ('inspire', 33),\n",
       " ('understanding', 33),\n",
       " ('good', 33),\n",
       " ('foresee', 33),\n",
       " ('pinpoint', 33),\n",
       " ('extend', 33),\n",
       " ('gauge', 33),\n",
       " ('stick', 33),\n",
       " ('rank', 33),\n",
       " ('map', 33),\n",
       " ('travel', 33),\n",
       " ('contaminate', 33),\n",
       " ('resist', 32),\n",
       " ('dare', 32),\n",
       " ('certify', 32),\n",
       " ('respect', 32),\n",
       " ('research', 32),\n",
       " ('free', 32),\n",
       " ('celebrate', 32),\n",
       " ('submit', 32),\n",
       " ('freeze', 32),\n",
       " ('kick', 32),\n",
       " ('permit', 32),\n",
       " ('cheap', 31),\n",
       " ('abandon', 31),\n",
       " ('ban', 31),\n",
       " ('strengthen', 31),\n",
       " ('wake', 31),\n",
       " ('instruct', 31),\n",
       " ('drink', 31),\n",
       " ('tout', 31),\n",
       " ('regret', 31),\n",
       " ('press', 31),\n",
       " ('alert', 31),\n",
       " ('articulate', 31),\n",
       " ('sorry', 31),\n",
       " ('fire', 31),\n",
       " ('restrict', 30),\n",
       " ('translate', 30),\n",
       " ('picture', 30),\n",
       " ('convey', 30),\n",
       " ('collect', 30),\n",
       " ('fit', 30),\n",
       " ('vary', 30),\n",
       " ('pour', 30),\n",
       " ('decree', 30),\n",
       " ('exclaim', 30),\n",
       " ('successful', 30),\n",
       " ('big', 30),\n",
       " ('roll', 30),\n",
       " ('chant', 30),\n",
       " ('disappointed', 30),\n",
       " ('wear', 30),\n",
       " ('spark', 30),\n",
       " ('frustrated', 29),\n",
       " ('far', 29),\n",
       " ('overstate', 29),\n",
       " ('register', 29),\n",
       " ('blow', 29),\n",
       " ('complete', 29),\n",
       " ('infer', 29),\n",
       " ('delay', 29),\n",
       " ('attend', 29),\n",
       " ('mount', 29),\n",
       " ('tackle', 29),\n",
       " ('range', 29),\n",
       " ('extract', 29),\n",
       " ('hang', 29),\n",
       " ('cold', 29),\n",
       " ('hot', 29),\n",
       " ('cry', 28),\n",
       " ('tie', 28),\n",
       " ('speed', 28),\n",
       " ('clean', 28),\n",
       " ('lock', 28),\n",
       " ('accompany', 28),\n",
       " ('bother', 28),\n",
       " ('denying', 28),\n",
       " ('jump', 28),\n",
       " ('vast', 28),\n",
       " ('spot', 28),\n",
       " ('crow', 28),\n",
       " ('confront', 28),\n",
       " ('powerful', 28),\n",
       " ('violate', 27),\n",
       " ('pursue', 27),\n",
       " ('praise', 27),\n",
       " ('purchase', 27),\n",
       " ('defend', 27),\n",
       " ('cancel', 27),\n",
       " ('underline', 27),\n",
       " ('expensive', 27),\n",
       " ('dig', 27),\n",
       " ('ought', 27),\n",
       " ('uncover', 26),\n",
       " ('display', 26),\n",
       " ('trigger', 26),\n",
       " ('contemplate', 26),\n",
       " ('trap', 26),\n",
       " ('best', 26),\n",
       " ('reconsider', 26),\n",
       " ('recover', 26),\n",
       " ('dire', 26),\n",
       " ('hard', 26),\n",
       " ('sue', 26),\n",
       " ('elaborate', 26),\n",
       " ('preserve', 26),\n",
       " ('spur', 26),\n",
       " ('simulate', 26),\n",
       " ('discern', 26),\n",
       " ('elect', 26),\n",
       " ('appeal', 26),\n",
       " ('evolve', 25),\n",
       " ('handle', 25),\n",
       " ('sponsor', 25),\n",
       " ('rare', 25),\n",
       " ('constitute', 25),\n",
       " ('weak', 25),\n",
       " ('arrest', 25),\n",
       " ('saying', 25),\n",
       " ('lucky', 25),\n",
       " ('select', 25),\n",
       " ('regard', 25),\n",
       " ('exaggerate', 25),\n",
       " ('file', 25),\n",
       " ('yield', 25),\n",
       " ('crack', 25),\n",
       " ('summarize', 24),\n",
       " ('withdraw', 24),\n",
       " ('step', 24),\n",
       " ('found', 24),\n",
       " ('hire', 24),\n",
       " ('spell', 24),\n",
       " ('hate', 24),\n",
       " ('encounter', 24),\n",
       " ('power', 24),\n",
       " ('suck', 24),\n",
       " ('restore', 24),\n",
       " ('fearful', 24),\n",
       " ('thought', 24),\n",
       " ('overestimate', 24),\n",
       " ('educate', 24),\n",
       " ('dry', 24),\n",
       " ('quickly', 23),\n",
       " ('perform', 23),\n",
       " ('instal', 23),\n",
       " ('empower', 23),\n",
       " ('redefine', 23),\n",
       " ('advance', 23),\n",
       " ('apologize', 23),\n",
       " ('boost', 23),\n",
       " ('store', 23),\n",
       " ('resemble', 23),\n",
       " ('doom', 23),\n",
       " ('dominate', 23),\n",
       " ('flow', 23),\n",
       " ('denounce', 23),\n",
       " ('switch', 23),\n",
       " ('sustain', 23),\n",
       " ('adapt', 23),\n",
       " ('plead', 22),\n",
       " ('comprehend', 22),\n",
       " ('lower', 22),\n",
       " ('scream', 22),\n",
       " ('sort', 22),\n",
       " ('jeopardize', 22),\n",
       " ('attest', 22),\n",
       " ('warning', 22),\n",
       " ('depict', 22),\n",
       " ('attribute', 22),\n",
       " ('displace', 22),\n",
       " ('last', 22),\n",
       " ('balance', 22),\n",
       " ('belong', 22),\n",
       " ('escape', 22),\n",
       " ('connect', 22),\n",
       " ('obvious', 22),\n",
       " ('erupt', 22),\n",
       " ('muse', 22),\n",
       " ('designate', 22),\n",
       " ('resolve', 22),\n",
       " ('well', 21),\n",
       " ('mitigate', 21),\n",
       " ('soar', 21),\n",
       " ('ironic', 21),\n",
       " ('rally', 21),\n",
       " ('condemn', 21),\n",
       " ('debunk', 21),\n",
       " ('train', 21),\n",
       " ('suffice', 21),\n",
       " ('thrill', 21),\n",
       " ('touch', 21),\n",
       " ('cheer', 21),\n",
       " ('retort', 21),\n",
       " ('mobilize', 21),\n",
       " ('campaign', 21),\n",
       " ('convert', 21),\n",
       " ('should', 21),\n",
       " ('rest', 21),\n",
       " ('extreme', 21),\n",
       " ('communicate', 21),\n",
       " ('surmise', 21),\n",
       " ('grumble', 21),\n",
       " ('cast', 21),\n",
       " ('hand', 20),\n",
       " ('seize', 20),\n",
       " ('fuel', 20),\n",
       " ('pronounce', 20),\n",
       " ('bind', 20),\n",
       " ('news', 20),\n",
       " ('locate', 20),\n",
       " ('polluted', 20),\n",
       " ('beat', 20),\n",
       " ('slam', 20),\n",
       " ('donate', 20),\n",
       " ('overlook', 20),\n",
       " ('volunteer', 20),\n",
       " ('circulate', 20),\n",
       " ('so', 20),\n",
       " ('disturb', 20),\n",
       " ('huge', 20),\n",
       " ('negotiate', 20),\n",
       " ('contract', 20),\n",
       " ('manufacture', 20),\n",
       " ('forbid', 20),\n",
       " ('decry', 20),\n",
       " ('dump', 20),\n",
       " ('worsen', 20),\n",
       " ('endure', 19),\n",
       " ('recycle', 19),\n",
       " ('combat', 19),\n",
       " ('unveil', 19),\n",
       " ('halt', 19),\n",
       " ('thankful', 19),\n",
       " ('sing', 19),\n",
       " ('endanger', 19),\n",
       " ('inject', 19),\n",
       " ('ascertain', 19),\n",
       " ('appoint', 19),\n",
       " ('harness', 19),\n",
       " ('frustrate', 19),\n",
       " ('surround', 19),\n",
       " ('mock', 19),\n",
       " ('email', 19),\n",
       " ('t]he', 19),\n",
       " ('infect', 19),\n",
       " ('acquire', 19),\n",
       " ('plummet', 19),\n",
       " ('separate', 19),\n",
       " ('divide', 19),\n",
       " ('emphasise', 19),\n",
       " ('wash', 19),\n",
       " ('weekday', 19),\n",
       " ('impress', 18),\n",
       " ('deep', 18),\n",
       " ('portray', 18),\n",
       " ('yell', 18),\n",
       " ('paint', 18),\n",
       " ('lift', 18),\n",
       " ('okay', 18),\n",
       " ('react', 18),\n",
       " ('deploy', 18),\n",
       " ('climb', 18),\n",
       " ('undo', 18),\n",
       " ('retain', 18),\n",
       " ('average', 18),\n",
       " ('complex', 18),\n",
       " ('relate', 18),\n",
       " ('significant', 18),\n",
       " ('unsure', 18),\n",
       " ('rebuild', 18),\n",
       " ('compete', 18),\n",
       " ('careful', 18),\n",
       " ('scale', 18),\n",
       " ('pump', 18),\n",
       " ('argument', 18),\n",
       " ('degree', 18),\n",
       " ('swallow', 18),\n",
       " ('relieve', 18),\n",
       " ('suspend', 18),\n",
       " ('may', 18),\n",
       " ('toxin', 18),\n",
       " ('hammer', 18),\n",
       " ('shake', 18),\n",
       " ('grab', 18),\n",
       " ('pollute', 18),\n",
       " ('cook', 17),\n",
       " ('proud', 17),\n",
       " ('supply', 17),\n",
       " ('participate', 17),\n",
       " ('spew', 17),\n",
       " ('distinguish', 17),\n",
       " ('click', 17),\n",
       " ('insinuate', 17),\n",
       " ('mix', 17),\n",
       " ('mimic', 17),\n",
       " ('dangerous', 17),\n",
       " ('factor', 17),\n",
       " ('remote', 17),\n",
       " ('erode', 17),\n",
       " ('accumulate', 17),\n",
       " ('common', 17),\n",
       " ('knock', 17),\n",
       " ('ride', 17),\n",
       " ('tax', 17),\n",
       " ('exercise', 17),\n",
       " ('alarm', 17),\n",
       " ('value', 17),\n",
       " ('disrupt', 17),\n",
       " ('toxic', 17),\n",
       " ('gush', 17),\n",
       " ('dismay', 17),\n",
       " ('survey', 17),\n",
       " ('tap', 17),\n",
       " ('host', 16),\n",
       " ('green', 16),\n",
       " ('fortunate', 16),\n",
       " ('understate', 16),\n",
       " ('drown', 16),\n",
       " ('access', 16),\n",
       " ('laugh', 16),\n",
       " ('appal', 16),\n",
       " ('author', 16),\n",
       " ('age', 16),\n",
       " ('tease', 16),\n",
       " ('badly', 16),\n",
       " ('illuminate', 16),\n",
       " ('finish', 16),\n",
       " ('amount', 16),\n",
       " ('oversee', 16),\n",
       " ('everywhere', 16),\n",
       " ('scoff', 16),\n",
       " ('manipulate', 16),\n",
       " ('finding', 16),\n",
       " ('associate', 16),\n",
       " ('surpass', 16),\n",
       " ('trade', 16),\n",
       " ('satisfy', 16),\n",
       " ('puzzle', 16),\n",
       " ('combine', 16),\n",
       " ('differ', 16),\n",
       " ('poor', 16),\n",
       " ('smile', 16),\n",
       " ('embody', 15),\n",
       " ('stretch', 15),\n",
       " ('interview', 15),\n",
       " ('update', 15),\n",
       " ('manmade', 15),\n",
       " ('wind', 15),\n",
       " ('distribute', 15),\n",
       " ('blast', 15),\n",
       " ('applaud', 15),\n",
       " ('export', 15),\n",
       " ('terrify', 15),\n",
       " ('enact', 15),\n",
       " ('bar', 15),\n",
       " ('exit', 15),\n",
       " ('thrive', 15),\n",
       " ('diagnose', 15),\n",
       " ('frame', 15),\n",
       " ('diminish', 15),\n",
       " ('stall', 15),\n",
       " ('dawn', 15),\n",
       " ('facebook', 15),\n",
       " ('wrap', 15),\n",
       " ('serious', 15),\n",
       " ('often', 15),\n",
       " ('wipe', 14),\n",
       " ('unconvinced', 14),\n",
       " ('sweep', 14),\n",
       " ('abolish', 14),\n",
       " ('preach', 14),\n",
       " ('scared', 14),\n",
       " ('signify', 14),\n",
       " ('flee', 14),\n",
       " ('craft', 14),\n",
       " ('profess', 14),\n",
       " ('trouble', 14),\n",
       " ('wrong', 14),\n",
       " ('not', 14),\n",
       " ('devastate', 14),\n",
       " ('massive', 14),\n",
       " ('idea', 14),\n",
       " ('marvel', 14),\n",
       " ('contrast', 14),\n",
       " ('breathe', 14),\n",
       " ('sacrifice', 14),\n",
       " ('satisfied', 14),\n",
       " ('disregard', 14),\n",
       " ('harvest', 14),\n",
       " ('invent', 14),\n",
       " ('pile', 14),\n",
       " ('reference', 14),\n",
       " ('unconvince', 14),\n",
       " ('await', 14),\n",
       " ('discourage', 14),\n",
       " ('light', 14),\n",
       " ('subsidize', 14),\n",
       " ('compel', 14),\n",
       " ('line', 14),\n",
       " ('shed', 14),\n",
       " ('wager', 14),\n",
       " ('peak', 13),\n",
       " ('curb', 13),\n",
       " ('more', 13),\n",
       " ('curious', 13),\n",
       " ('retreat', 13),\n",
       " ('shock', 13),\n",
       " ('reconstruct', 13),\n",
       " ('rapidly', 13),\n",
       " ('drill', 13),\n",
       " ('disappointing', 13),\n",
       " ('persist', 13),\n",
       " ('complicate', 13),\n",
       " ('coordinate', 13),\n",
       " ('enormous', 13),\n",
       " ('reshape', 13),\n",
       " ('thunder', 13),\n",
       " ('revise', 13),\n",
       " ('decimate', 13),\n",
       " ('adjust', 13),\n",
       " ('overwhelming', 13),\n",
       " ('deplete', 13),\n",
       " ('positive', 13),\n",
       " ('rate', 13),\n",
       " ('rich', 13),\n",
       " ('equal', 13),\n",
       " ('excited', 13),\n",
       " ('vanish', 13),\n",
       " ('lobby', 13),\n",
       " ('lecture', 13),\n",
       " ('proof', 13),\n",
       " ('behoove', 13),\n",
       " ('disprove', 13),\n",
       " ('drain', 13),\n",
       " ('whisper', 13),\n",
       " ('undergo', 13),\n",
       " ('amplify', 13),\n",
       " ('sad', 13),\n",
       " ('avert', 13),\n",
       " ('authorize', 13),\n",
       " ('interpret', 13),\n",
       " ('unleash', 13),\n",
       " ('astonishing', 13),\n",
       " ('trace', 13),\n",
       " ('suggesting', 13),\n",
       " ('occupy', 13),\n",
       " ('convene', 13),\n",
       " ('oblige', 13),\n",
       " ('defeat', 13),\n",
       " ('unite', 12),\n",
       " ('misunderstand', 12),\n",
       " ('hearing', 12),\n",
       " ('intensify', 12),\n",
       " ('assist', 12),\n",
       " ('resign', 12),\n",
       " ('undertake', 12),\n",
       " ('visualize', 12),\n",
       " ('exacerbate', 12),\n",
       " ('surface', 12),\n",
       " ('devise', 12),\n",
       " ('smell', 12),\n",
       " ('insert', 12),\n",
       " ('decarbonize', 12),\n",
       " ('search', 12),\n",
       " ('perpetuate', 12),\n",
       " ('obscure', 12),\n",
       " ('uphold', 12),\n",
       " ('undercut', 12),\n",
       " ('taste', 12),\n",
       " ('assign', 12),\n",
       " ('house', 12),\n",
       " ('replicate', 12),\n",
       " ('harbor', 12),\n",
       " ('showcase', 12),\n",
       " ('compromise', 12),\n",
       " ('bolster', 12),\n",
       " ('phase', 12),\n",
       " ('consist', 12),\n",
       " ('prescribe', 12),\n",
       " ('presuppose', 12),\n",
       " ('discard', 12),\n",
       " ('corrupt', 12),\n",
       " ('prevail', 12),\n",
       " ('fade', 12),\n",
       " ('enhance', 12),\n",
       " ('distort', 12),\n",
       " ('please', 12),\n",
       " ('impressed', 12),\n",
       " ('term', 12),\n",
       " ('enforce', 12),\n",
       " ('parse', 12),\n",
       " ('comprise', 12),\n",
       " ('field', 12),\n",
       " ('considering', 12),\n",
       " ('revive', 12),\n",
       " ('award', 12),\n",
       " ('construct', 12),\n",
       " ('date', 12),\n",
       " ('effective', 12),\n",
       " ('scrap', 12),\n",
       " ('quit', 12),\n",
       " ('schedule', 12),\n",
       " ('admire', 12),\n",
       " ('dream', 12),\n",
       " ('interlude', 12),\n",
       " ('compute', 11),\n",
       " ('chance', 11),\n",
       " ('boil', 11),\n",
       " ('available', 11),\n",
       " ('progress', 11),\n",
       " ('command', 11),\n",
       " ('feeling', 11),\n",
       " ('amazed', 11),\n",
       " ('reap', 11),\n",
       " ('furious', 11),\n",
       " ('downplay', 11),\n",
       " ('embarrassing', 11),\n",
       " ('dramatically', 11),\n",
       " ('swing', 11),\n",
       " ('abundant', 11),\n",
       " ('imperative', 11),\n",
       " ('title', 11),\n",
       " ('slip', 11),\n",
       " ('true', 11),\n",
       " ('excite', 11),\n",
       " ('reward', 11),\n",
       " ('level', 11),\n",
       " ('spotlight', 11),\n",
       " ('institute', 11),\n",
       " ('ramp', 11),\n",
       " ('concentrate', 11),\n",
       " ...]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_main_verb_lemmas = [x['main verb lemma'].lower() for x in quotes]\n",
    "counted_main_verb_lemmas = Counter(all_main_verb_lemmas)\n",
    "sorted(counted_main_verb_lemmas.items(),key=lambda x:x[1],reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'wonder' in counted_main_verb_lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_quotes = get_quotes_with_stem({\n",
    "    'put'\n",
    "},'main verb lemma',quotes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "other_quotes[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A lot of quotes don't have a subject:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41849"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([q for q in quotes if q['main subject lemma coref'] is None])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most common subject stems--it looks like coref didn't fully do its job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['quote lemmas', 'quote lemmas coref', 'verb lemmas', 'verb lemmas coref', 'main verb lemma', 'main verb lemma coref', 'subject lemmas', 'subject lemmas coref', 'main subject lemma', 'main subject lemma coref', 'neg lemmas', 'main neg lemma', 'quote text', 'verb text', 'main verb text', 'subject text', 'main subject text', 'is neg', 'source'])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quotes[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('-pron-', 76401),\n",
       " ('scientist', 6268),\n",
       " ('study', 5692),\n",
       " ('report', 4723),\n",
       " ('people', 3659),\n",
       " ('researcher', 3602),\n",
       " ('that', 3372),\n",
       " ('official', 3312),\n",
       " ('expert', 2712),\n",
       " ('this', 2231),\n",
       " ('trump', 2229),\n",
       " ('one', 1988),\n",
       " ('company', 1727),\n",
       " ('group', 1647),\n",
       " ('percent', 1532),\n",
       " ('research', 1508),\n",
       " ('agency', 1394),\n",
       " ('’s', 1322),\n",
       " ('author', 1311),\n",
       " ('some', 1285),\n",
       " ('government', 1106),\n",
       " ('obama', 1103),\n",
       " ('critic', 934),\n",
       " ('president', 915),\n",
       " ('analysis', 913),\n",
       " ('administration', 896),\n",
       " ('many', 851),\n",
       " ('poll', 826),\n",
       " ('team', 805),\n",
       " ('datum', 776),\n",
       " ('which', 760),\n",
       " ('other', 737),\n",
       " ('those', 731),\n",
       " ('court', 729),\n",
       " ('department', 723),\n",
       " ('analyst', 709),\n",
       " ('there', 701),\n",
       " ('environmentalist', 690),\n",
       " ('paper', 685),\n",
       " ('leader', 680),\n",
       " ('democrats', 670),\n",
       " ('country', 645),\n",
       " ('panel', 642),\n",
       " ('activist', 641),\n",
       " ('—', 639),\n",
       " ('change', 628),\n",
       " ('sanders', 610),\n",
       " ('“', 593),\n",
       " ('who', 572),\n",
       " ('times', 570),\n",
       " ('model', 567),\n",
       " ('evidence', 559),\n",
       " ('survey', 554),\n",
       " ('pruitt', 550),\n",
       " ('president trump', 544),\n",
       " ('parent', 536),\n",
       " ('state', 534),\n",
       " ('everyone', 510),\n",
       " ('organization', 506),\n",
       " ('spokesman', 505),\n",
       " ('epa', 500),\n",
       " ('biden', 496),\n",
       " ('americans', 495),\n",
       " ('smith', 490),\n",
       " ('republicans', 488),\n",
       " ('all', 474),\n",
       " ('science', 471),\n",
       " ('industry', 465),\n",
       " ('advocate', 462),\n",
       " ('brown', 457),\n",
       " ('number', 454),\n",
       " ('not', 453),\n",
       " ('would', 452),\n",
       " ('be', 435),\n",
       " ('economist', 427),\n",
       " ('result', 425),\n",
       " ('member', 408),\n",
       " ('document', 408),\n",
       " ('anyone', 404),\n",
       " ('doctor', 397),\n",
       " ('news', 395),\n",
       " ('minister', 389),\n",
       " ('statement', 389),\n",
       " ('authority', 386),\n",
       " ('office', 382),\n",
       " ('china', 381),\n",
       " ('johnson', 380),\n",
       " ('source', 364),\n",
       " ('house', 360),\n",
       " ('majority', 355),\n",
       " ('man', 353),\n",
       " ('clinton', 350),\n",
       " ('woman', 349),\n",
       " ('warren', 348),\n",
       " ('resident', 342),\n",
       " ('article', 340),\n",
       " ('campaign', 338),\n",
       " ('spokesperson', 335),\n",
       " ('supporter', 333),\n",
       " ('mann', 332),\n",
       " ('ipcc', 328),\n",
       " ('post', 327),\n",
       " ('police', 324),\n",
       " ('hansen', 323),\n",
       " ('cortez', 319),\n",
       " ('president obama', 319),\n",
       " ('executive', 318),\n",
       " ('gore', 314),\n",
       " ('jackson', 310),\n",
       " ('voter', 310),\n",
       " ('someone', 308),\n",
       " ('committee', 302),\n",
       " ('plan', 302),\n",
       " ('finding', 296),\n",
       " ('student', 293),\n",
       " ('spokeswoman', 291),\n",
       " ('jones', 287),\n",
       " ('%', 287),\n",
       " ('opponent', 281),\n",
       " ('donald trump', 276),\n",
       " ('nobody', 274),\n",
       " ('candidate', 274),\n",
       " ('center', 274),\n",
       " ('bloomberg', 273),\n",
       " ('institute', 272),\n",
       " ('lot', 268),\n",
       " ('politician', 264),\n",
       " ('service', 259),\n",
       " ('\"', 256),\n",
       " ('mccarthy', 256),\n",
       " ('francis', 255),\n",
       " ('commission', 250),\n",
       " ('city', 250),\n",
       " ('proponent', 249),\n",
       " ('world', 248),\n",
       " ('record', 245),\n",
       " ('association', 245),\n",
       " ('farmer', 242),\n",
       " ('estimate', 240),\n",
       " ('investigation', 239),\n",
       " ('judge', 239),\n",
       " ('have', 238),\n",
       " ('aide', 238),\n",
       " ('the epa', 236),\n",
       " ('cdc', 235),\n",
       " ('nasa', 231),\n",
       " ('letter', 231),\n",
       " ('moore', 231),\n",
       " ('most', 229),\n",
       " ('fact', 227),\n",
       " ('observer', 227),\n",
       " ('lawmaker', 226),\n",
       " ('skeptic', 225),\n",
       " ('figure', 223),\n",
       " ('miller', 221),\n",
       " ('child', 220),\n",
       " ('senator', 218),\n",
       " ('director', 218),\n",
       " ('emission', 218),\n",
       " ('states', 218),\n",
       " ('friend', 217),\n",
       " ('rule', 216),\n",
       " ('mckibben', 216),\n",
       " ('warming', 215),\n",
       " ('temperature', 215),\n",
       " ('williams', 210),\n",
       " ('lawyer', 210),\n",
       " ('taylor', 210),\n",
       " ('assessment', 209),\n",
       " ('law', 206),\n",
       " ('council', 203),\n",
       " ('kerry', 202),\n",
       " ('’', 202),\n",
       " ('governor', 202),\n",
       " ('policy', 202),\n",
       " ('wheeler', 202),\n",
       " ('review', 200),\n",
       " ('journal', 200),\n",
       " ('thunberg', 198),\n",
       " ('website', 198),\n",
       " ('guardian', 196),\n",
       " ('adviser', 196),\n",
       " ('community', 196),\n",
       " ('bank', 195),\n",
       " ('conservative', 195),\n",
       " ('bernie sanders', 194),\n",
       " ('party', 194),\n",
       " ('anderson', 193),\n",
       " ('nation', 192),\n",
       " ('mayor', 192),\n",
       " ('person', 190),\n",
       " ('president donald trump', 190),\n",
       " ('project', 190),\n",
       " ('bill', 189),\n",
       " ('bush', 188),\n",
       " ('system', 187),\n",
       " ('will', 185),\n",
       " ('press', 183),\n",
       " ('half', 180),\n",
       " ('allen', 180),\n",
       " ('buttigieg', 179),\n",
       " ('plant', 179),\n",
       " ('history', 178),\n",
       " ('romney', 178),\n",
       " ('colleague', 176),\n",
       " ('worker', 175),\n",
       " ('employee', 175),\n",
       " ('story', 173),\n",
       " ('schmidt', 170),\n",
       " ('perry', 169),\n",
       " ('climate', 168),\n",
       " ('pope francis', 168),\n",
       " ('vaccine', 167),\n",
       " ('mcconnell', 167),\n",
       " ('family', 166),\n",
       " ('what', 166),\n",
       " ('none', 166),\n",
       " ('head', 164),\n",
       " ('representative', 163),\n",
       " ('body', 163),\n",
       " ('utility', 163),\n",
       " ('everybody', 163),\n",
       " ('price', 163),\n",
       " ('secretary', 162),\n",
       " ('pelosi', 162),\n",
       " ('congress', 161),\n",
       " ('iea', 161),\n",
       " ('medium', 160),\n",
       " ('hillary clinton', 160),\n",
       " ('university', 158),\n",
       " ('exxon', 158),\n",
       " ('mother', 158),\n",
       " ('mr. trump', 158),\n",
       " ('level', 157),\n",
       " ('regulator', 156),\n",
       " ('kennedy', 156),\n",
       " ('third', 155),\n",
       " ('professor', 155),\n",
       " ('nations', 155),\n",
       " ('tillerson', 155),\n",
       " ('cruz', 153),\n",
       " ('thing', 152),\n",
       " ('board', 152),\n",
       " ('al gore', 152),\n",
       " ('thompson', 152),\n",
       " ('–', 152),\n",
       " ('lewis', 151),\n",
       " ('decision', 151),\n",
       " ('public', 151),\n",
       " ('gas', 151),\n",
       " ('investigator', 150),\n",
       " ('stern', 149),\n",
       " ('the president', 148),\n",
       " ('email', 148),\n",
       " ('ebell', 148),\n",
       " ('king', 147),\n",
       " ('pope', 147),\n",
       " ('general', 146),\n",
       " ('president barack obama', 145),\n",
       " ('case', 145),\n",
       " ('bp', 144),\n",
       " ('reader', 144),\n",
       " ('the researcher', 143),\n",
       " ('few', 143),\n",
       " (\"'\", 142),\n",
       " ('jr.', 142),\n",
       " ('the environmental protection agency', 142),\n",
       " ('paul', 142),\n",
       " ('noaa', 141),\n",
       " ('way', 140),\n",
       " ('cohen', 138),\n",
       " ('work', 138),\n",
       " ('green', 138),\n",
       " ('inhofe', 137),\n",
       " ('officer', 137),\n",
       " ('deal', 135),\n",
       " ('reuters', 135),\n",
       " ('organizer', 133),\n",
       " ('morrison', 133),\n",
       " ('zinke', 133),\n",
       " ('water', 132),\n",
       " ('harris', 132),\n",
       " ('roberts', 132),\n",
       " ('video', 132),\n",
       " ('human', 132),\n",
       " ('blasio', 132),\n",
       " ('union', 131),\n",
       " ('foundation', 131),\n",
       " ('forecaster', 130),\n",
       " ('california', 129),\n",
       " ('cuomo', 129),\n",
       " ('robinson', 129),\n",
       " ('greenpeace', 128),\n",
       " ('owner', 128),\n",
       " ('goal', 128),\n",
       " ('scott', 128),\n",
       " ('movement', 127),\n",
       " ('question', 127),\n",
       " ('manager', 127),\n",
       " ('alarmist', 126),\n",
       " ('co2', 126),\n",
       " ('energy', 126),\n",
       " ('lawsuit', 126),\n",
       " ('act', 125),\n",
       " ('graham', 125),\n",
       " ('book', 123),\n",
       " ('projection', 123),\n",
       " ('part', 123),\n",
       " ('steyer', 122),\n",
       " ('action', 122),\n",
       " ('white', 122),\n",
       " ('program', 121),\n",
       " ('trenberth', 120),\n",
       " ('firm', 119),\n",
       " ('davis', 119),\n",
       " ('eia', 119),\n",
       " ('consumer', 118),\n",
       " ('merkel', 118),\n",
       " ('economy', 118),\n",
       " ('power', 117),\n",
       " ('gates', 117),\n",
       " ('cnn', 117),\n",
       " ('hayhoe', 117),\n",
       " ('mitt romney', 117),\n",
       " ('centers', 116),\n",
       " ('amount', 116),\n",
       " ('e.p.a.', 115),\n",
       " ('peters', 115),\n",
       " ('joe biden', 115),\n",
       " ('society', 114),\n",
       " ('newspaper', 114),\n",
       " ('nature', 113),\n",
       " ('former vice president joe biden', 113),\n",
       " ('ministry', 113),\n",
       " ('campaigner', 113),\n",
       " ('test', 113),\n",
       " ('proposal', 112),\n",
       " ('musk', 112),\n",
       " ('ad', 112),\n",
       " ('rate', 112),\n",
       " ('data', 112),\n",
       " ('negotiator', 112),\n",
       " ('idea', 112),\n",
       " ('editor', 111),\n",
       " ('bureau', 110),\n",
       " ('scholar', 110),\n",
       " ('rogers', 109),\n",
       " ('guterres', 107),\n",
       " ('inslee', 107),\n",
       " ('chief', 106),\n",
       " ('release', 105),\n",
       " ('meyer', 105),\n",
       " ('democrat', 105),\n",
       " ('both', 105),\n",
       " ('outlet', 104),\n",
       " ('protester', 104),\n",
       " ('administrator', 104),\n",
       " ('order', 104),\n",
       " ('experiment', 103),\n",
       " ('oceanic', 103),\n",
       " ('rise', 103),\n",
       " ('statistic', 103),\n",
       " ('attorney', 103),\n",
       " ('regulation', 103),\n",
       " ('holdren', 103),\n",
       " ('doniger', 103),\n",
       " ('journalist', 102),\n",
       " ('engineer', 102),\n",
       " ('brune', 102),\n",
       " ('measurement', 102),\n",
       " ('thomas', 102),\n",
       " ('coalition', 101),\n",
       " ('polling', 101),\n",
       " ('hayes', 101),\n",
       " ('draft', 100),\n",
       " ('agreement', 100),\n",
       " ('klein', 100),\n",
       " ('magazine', 99),\n",
       " ('happer', 99),\n",
       " ('murphy', 99),\n",
       " ('prosecutor', 99),\n",
       " ('michaels', 99),\n",
       " ('kelly', 98),\n",
       " ('side', 98),\n",
       " ('diplomat', 98),\n",
       " ('hughes', 98),\n",
       " ('automaker', 98),\n",
       " ('year', 97),\n",
       " ('theory', 97),\n",
       " ('u.s.', 97),\n",
       " ('birol', 96),\n",
       " ('us', 96),\n",
       " ('murray', 96),\n",
       " ('another', 95),\n",
       " ('wilson', 95),\n",
       " ('martin', 95),\n",
       " ('walker', 94),\n",
       " ('participant', 94),\n",
       " ('plaintiff', 94),\n",
       " ('these', 94),\n",
       " ('experience', 94),\n",
       " ('lee', 94),\n",
       " ('force', 93),\n",
       " ('singer', 93),\n",
       " ('oppenheimer', 93),\n",
       " ('area', 93),\n",
       " ('chart', 93),\n",
       " ('investor', 93),\n",
       " ('god', 93),\n",
       " ('shell', 92),\n",
       " ('scenario', 92),\n",
       " ('manufacturer', 92),\n",
       " ('line', 92),\n",
       " ('republican', 92),\n",
       " ('keith', 92),\n",
       " ('cost', 92),\n",
       " ('standard', 92),\n",
       " ('barack obama', 91),\n",
       " ('folk', 91),\n",
       " ('young', 91),\n",
       " ('event', 91),\n",
       " ('father', 91),\n",
       " ('hill', 91),\n",
       " ('increase', 91),\n",
       " ('osborne', 91),\n",
       " ('sander', 90),\n",
       " ('calculation', 90),\n",
       " ('market', 90),\n",
       " ('macron', 90),\n",
       " ('site', 90),\n",
       " ('morgan', 89),\n",
       " ('milloy', 89),\n",
       " ('effort', 89),\n",
       " ('school', 89),\n",
       " ('fund', 89),\n",
       " ('biologist', 89),\n",
       " ('reporter', 88),\n",
       " ('map', 88),\n",
       " ('hall', 88),\n",
       " ('newsom', 88),\n",
       " ('kid', 87),\n",
       " ('pompeo', 87),\n",
       " ('memo', 86),\n",
       " ('un', 86),\n",
       " ('effect', 86),\n",
       " ('version', 86),\n",
       " ('problem', 85),\n",
       " ('abbott', 85),\n",
       " ('yang', 84),\n",
       " ('storm', 84),\n",
       " ('guy', 84),\n",
       " ('writer', 83),\n",
       " ('figueres', 83),\n",
       " ('sen. bernie sanders ( i - vt )', 83),\n",
       " ('watson', 83),\n",
       " ('business', 83),\n",
       " ('piece', 83),\n",
       " ('individual', 83),\n",
       " ('image', 83),\n",
       " ('scott pruitt', 83),\n",
       " ('fonda', 82),\n",
       " ('club', 82),\n",
       " ('user', 82),\n",
       " ('america', 82),\n",
       " ('something', 82),\n",
       " ('curry', 82),\n",
       " ('liberal', 82),\n",
       " ('sullivan', 82),\n",
       " ('watts', 81),\n",
       " ('fire', 81),\n",
       " ('page', 81),\n",
       " ('thousand', 81),\n",
       " ('conservationist', 81),\n",
       " ('quarter', 81),\n",
       " ('greta', 80),\n",
       " ('point', 80),\n",
       " ('christy', 80),\n",
       " ('use', 80),\n",
       " ('process', 80),\n",
       " ('caldeira', 80),\n",
       " ('olson', 80),\n",
       " ('chairman', 79),\n",
       " ('field', 79),\n",
       " ('cox', 79),\n",
       " ('pachauri', 79),\n",
       " ('producer', 79),\n",
       " ('pyle', 79),\n",
       " ('politico', 78),\n",
       " ('corporation', 78),\n",
       " ('ice', 78),\n",
       " ('murkowski', 78),\n",
       " ('response', 78),\n",
       " ('anybody', 78),\n",
       " ('trend', 77),\n",
       " ('keeling', 77),\n",
       " ('nelson', 77),\n",
       " ('activity', 76),\n",
       " ('facebook', 76),\n",
       " ('the author', 76),\n",
       " ('much', 76),\n",
       " ('ocasio - cortez', 76),\n",
       " ('staff', 76),\n",
       " ('davies', 76),\n",
       " ('climatologist', 75),\n",
       " ('klobuchar', 75),\n",
       " ('wright', 75),\n",
       " ('tree', 75),\n",
       " ('emanuel', 75),\n",
       " ('each', 75),\n",
       " ('holmstead', 75),\n",
       " ('bill mckibben', 75),\n",
       " ('hamilton', 75),\n",
       " ('rest', 74),\n",
       " ('whitehouse', 74),\n",
       " ('amazon', 74),\n",
       " ('cook', 74),\n",
       " ('leadership', 74),\n",
       " ('jacobson', 73),\n",
       " ('sign', 73),\n",
       " ('booker', 73),\n",
       " ('claim', 73),\n",
       " ('technology', 73),\n",
       " ('evans', 72),\n",
       " ('oil', 72),\n",
       " ('fda', 72),\n",
       " ('bbc', 72),\n",
       " ('greta thunberg', 72),\n",
       " ('forecast', 72),\n",
       " ('dyson', 72),\n",
       " ('putin', 72),\n",
       " ('founder', 71),\n",
       " ('operator', 71),\n",
       " ('observation', 71),\n",
       " ('george', 71),\n",
       " ('collins', 71),\n",
       " ('al', 70),\n",
       " ('day', 70),\n",
       " ('duke', 70),\n",
       " ('ford', 70),\n",
       " ('bill gates', 70),\n",
       " ('wood', 70),\n",
       " ('baker', 70),\n",
       " ('graph', 69),\n",
       " ('suit', 69),\n",
       " ('argument', 69),\n",
       " ('word', 69),\n",
       " ('issue', 69),\n",
       " ('fox', 69),\n",
       " ('adams', 69),\n",
       " ('driver', 69),\n",
       " ('million', 68),\n",
       " ('christie', 68),\n",
       " ('staffer', 68),\n",
       " ('clark', 68),\n",
       " ('leiserowitz', 68),\n",
       " ('wang', 68),\n",
       " ('myers', 68),\n",
       " ('patient', 68),\n",
       " ('customer', 68),\n",
       " ('insider', 68),\n",
       " ('trudeau', 68),\n",
       " ('carter', 68),\n",
       " ('kind', 68),\n",
       " ('newman', 68),\n",
       " ('lackner', 68),\n",
       " ('maker', 67),\n",
       " ('denier', 67),\n",
       " ('demand', 67),\n",
       " ('bishop', 67),\n",
       " ('teacher', 67),\n",
       " ('commissioner', 66),\n",
       " ('ross', 66),\n",
       " ('series', 66),\n",
       " ('complaint', 66),\n",
       " ('shepherd', 66),\n",
       " ('elizabeth warren', 66),\n",
       " ('peterson', 66),\n",
       " ('consensus', 66),\n",
       " ('carlson', 66),\n",
       " ('earth', 65),\n",
       " ('pence', 65),\n",
       " ('impact', 65),\n",
       " ('population', 65),\n",
       " ('ward', 65),\n",
       " ('russia', 65),\n",
       " ('sen. elizabeth warren ( d - ma )', 65),\n",
       " ('somebody', 65),\n",
       " ('citizen', 65),\n",
       " ('justice', 65),\n",
       " ('mail', 64),\n",
       " ('adult', 64),\n",
       " ('growth', 64),\n",
       " ('time', 64),\n",
       " ('initiative', 64),\n",
       " ('meteorologist', 64),\n",
       " ('ceo', 64),\n",
       " ('pg&e', 64),\n",
       " ('the scientist', 64),\n",
       " ('russell', 64),\n",
       " ('wind', 63),\n",
       " ('announcement', 63),\n",
       " ('network', 63),\n",
       " ('region', 63),\n",
       " ('schneider', 63),\n",
       " ('information', 63),\n",
       " ('son', 63),\n",
       " ('lack', 63),\n",
       " ('west', 63),\n",
       " ('tans', 63),\n",
       " ('shift', 63),\n",
       " ('moon', 63),\n",
       " ('debate', 63),\n",
       " ('witness', 63),\n",
       " ('election', 63),\n",
       " ('nichols', 63),\n",
       " ('campbell', 62),\n",
       " ('wife', 62),\n",
       " ('specialist', 62),\n",
       " ('look', 62),\n",
       " ('strategist', 62),\n",
       " ('pielke', 62),\n",
       " ('exxonmobil', 62),\n",
       " ('job', 62),\n",
       " ('strauss', 62),\n",
       " ('levin', 62),\n",
       " ('light', 62),\n",
       " ('comment', 61),\n",
       " ('headline', 61),\n",
       " ('phillips', 61),\n",
       " ('harvey', 61),\n",
       " ('coleman', 61),\n",
       " ('titley', 61),\n",
       " ('rubio', 61),\n",
       " ('dioxide', 61),\n",
       " ('mr. obama', 61),\n",
       " ('-pron- all', 60),\n",
       " ('cooper', 60),\n",
       " ('ryan', 60),\n",
       " ('the report', 60),\n",
       " ('weaver', 60),\n",
       " ('chamber', 60),\n",
       " ('challenge', 59),\n",
       " ('factor', 59),\n",
       " ('academy', 59),\n",
       " ('masters', 59),\n",
       " ('palmer', 59),\n",
       " ('resolution', 59),\n",
       " ('volkswagen', 59),\n",
       " ('epstein', 58),\n",
       " ('several', 58),\n",
       " ('condition', 58),\n",
       " ('target', 58),\n",
       " ('spencer', 58),\n",
       " ('disease', 58),\n",
       " ('environment', 58),\n",
       " ('left', 58),\n",
       " ('move', 58),\n",
       " ('former vice president al gore', 57),\n",
       " ('step', 57),\n",
       " ('weather', 57),\n",
       " ('ocean', 57),\n",
       " ('cameron', 57),\n",
       " ('harry', 57),\n",
       " ('marshall', 57),\n",
       " ('lindzen', 57),\n",
       " ('tribe', 57),\n",
       " ('morano', 57),\n",
       " ('reed', 57),\n",
       " ('apple', 57),\n",
       " ('bailey', 57),\n",
       " ('gray', 57),\n",
       " ('generation', 57),\n",
       " ('solomon', 57),\n",
       " ('monitor', 57),\n",
       " ('fauci', 57),\n",
       " ('edwards', 57),\n",
       " ('reid', 57),\n",
       " ('message', 56),\n",
       " ('schumer', 56),\n",
       " ('the cdc', 56),\n",
       " ('becker', 56),\n",
       " ('epa administrator gina mccarthy', 56),\n",
       " ('money', 56),\n",
       " ('tesla', 56),\n",
       " ('example', 56),\n",
       " ('long', 56),\n",
       " ('wells', 56),\n",
       " ('turner', 56),\n",
       " ('bell', 56),\n",
       " ('c.d.c.', 56),\n",
       " ('car', 55),\n",
       " ('policymaker', 55),\n",
       " ('hausfather', 55),\n",
       " ('holmes', 55),\n",
       " ('…', 55),\n",
       " ('nothing', 55),\n",
       " ('washington', 55),\n",
       " ('virus', 55),\n",
       " ('li', 55),\n",
       " ('germany', 55),\n",
       " ('delegate', 55),\n",
       " ('weber', 55),\n",
       " ('jacobs', 55),\n",
       " ('karl', 54),\n",
       " ('friedman', 54),\n",
       " ('mccain', 54),\n",
       " ('approach', 54),\n",
       " ('india', 54),\n",
       " ('couple', 54),\n",
       " ('fuel', 54),\n",
       " ('australia', 54),\n",
       " ('heat', 54),\n",
       " ('schiff', 54),\n",
       " ('rep. alexandria ocasio - cortez ( d - ny )', 53),\n",
       " ('backer', 53),\n",
       " ('speaker', 53),\n",
       " ('eu', 53),\n",
       " ('-pron- have', 53),\n",
       " ('american', 53),\n",
       " ('neighbor', 53),\n",
       " ('crisis', 53),\n",
       " ('development', 53),\n",
       " ('watchdog', 53),\n",
       " ('liu', 53),\n",
       " ('horner', 53),\n",
       " ('rice', 53),\n",
       " ('drought', 53),\n",
       " ('wmo', 52),\n",
       " ('u.n.', 52),\n",
       " ('secretary of state john kerry', 52),\n",
       " ('legislator', 52),\n",
       " ('monckton', 52),\n",
       " ('carson', 52),\n",
       " ('institution', 52),\n",
       " ('giant', 52),\n",
       " ('star', 52),\n",
       " ('bledsoe', 52),\n",
       " ('stevens', 52),\n",
       " ('frank', 52),\n",
       " ('forest', 52),\n",
       " ('morris', 52),\n",
       " ('defender', 52),\n",
       " ('position', 51),\n",
       " ('planet', 51),\n",
       " ('jane fonda', 51),\n",
       " ('girl', 51),\n",
       " ('sachs', 51),\n",
       " ('developer', 51),\n",
       " ('butler', 51),\n",
       " ('lomborg', 51),\n",
       " ('concern', 51),\n",
       " ('alley', 51),\n",
       " ('boss', 51),\n",
       " ('fisher', 51),\n",
       " ('bates', 51),\n",
       " ('stein', 51),\n",
       " ('stewart', 51),\n",
       " ('snyder', 51),\n",
       " ('gerrard', 51),\n",
       " ('markey', 51),\n",
       " ('rosenberg', 51),\n",
       " ('o’rourke', 50),\n",
       " ('note', 50),\n",
       " ('hawkins', 50),\n",
       " ('stavins', 50),\n",
       " ('two', 50),\n",
       " ('goldstein', 50),\n",
       " ('frieden', 50),\n",
       " ('canada', 50),\n",
       " ('wehrum', 50),\n",
       " ('gordon', 50),\n",
       " ('salazar', 50),\n",
       " ('failure', 49),\n",
       " ('mccabe', 49),\n",
       " ('sheet', 49),\n",
       " ('stone', 49),\n",
       " ('xi', 49),\n",
       " ('text', 49),\n",
       " ('ban', 49),\n",
       " ('boxer', 49),\n",
       " ('church', 49),\n",
       " ('steiner', 49),\n",
       " ('pentagon', 49),\n",
       " ('wagner', 48),\n",
       " ('bast', 48),\n",
       " ('nye', 48),\n",
       " ('view', 48),\n",
       " ('schellnhuber', 48),\n",
       " ('prakash', 48),\n",
       " ('voice', 48),\n",
       " ('alexander', 48),\n",
       " ('ap', 48),\n",
       " ('-pron- mother', 48),\n",
       " ('mckay', 48),\n",
       " ('brooks', 48),\n",
       " ('jarraud', 47),\n",
       " ('legislation', 47),\n",
       " ('station', 47),\n",
       " ('gregory', 47),\n",
       " ('summary', 47),\n",
       " ('everything', 47),\n",
       " ('bezos', 47),\n",
       " ('holland', 47),\n",
       " ('strategy', 47),\n",
       " ('geologist', 47),\n",
       " ('shindell', 47),\n",
       " ('commentator', 47),\n",
       " ('burnett', 47),\n",
       " ('japan', 47),\n",
       " ('romm', 47),\n",
       " ('moniz', 47),\n",
       " ('environmental protection agency administrator scott pruitt', 47),\n",
       " ('elon musk', 47),\n",
       " ('w.h.o.', 47),\n",
       " ('clarke', 46),\n",
       " ('boehner', 46),\n",
       " ('the environmental protection agency ( epa )', 46),\n",
       " ('production', 46),\n",
       " ('singh', 46),\n",
       " ('palin', 46),\n",
       " ('place', 46),\n",
       " ('coal', 46),\n",
       " ('france', 46),\n",
       " ('hundred', 46),\n",
       " ('goldberg', 46),\n",
       " ('mitchell', 46),\n",
       " ('alliance', 46),\n",
       " ('goldman', 46),\n",
       " ('idso', 46),\n",
       " ('matthews', 46),\n",
       " ('gingrich', 46),\n",
       " ('film', 45),\n",
       " ('respondent', 45),\n",
       " ('old', 45),\n",
       " ('cobb', 45),\n",
       " ('academic', 45),\n",
       " ('psychologist', 45),\n",
       " ('freeman', 45),\n",
       " ('meier', 45),\n",
       " ('castro', 45),\n",
       " ('ruling', 45),\n",
       " ('mr. sanders', 45),\n",
       " ('air', 45),\n",
       " ('pressure', 45),\n",
       " ('meeting', 45),\n",
       " ('threat', 45),\n",
       " ('google', 45),\n",
       " ('edenhofer', 45),\n",
       " ('james hansen', 45),\n",
       " ('ccc', 45),\n",
       " ('kim', 45),\n",
       " ('hotez', 45),\n",
       " ('lin', 45),\n",
       " ('mr. biden', 44),\n",
       " ('mora', 44),\n",
       " ('situation', 44),\n",
       " ('energy secretary rick perry', 44),\n",
       " ('podesta', 44),\n",
       " ('santorum', 44),\n",
       " ('ally', 44),\n",
       " ('glacier', 44),\n",
       " ('defense', 44),\n",
       " ('gonzalez', 44),\n",
       " ('columnist', 44),\n",
       " ('reilly', 44),\n",
       " ('measure', 44),\n",
       " ('burger', 44),\n",
       " ('loss', 44),\n",
       " ('the united states', 44),\n",
       " ('ziska', 44),\n",
       " ('foster', 44),\n",
       " ('wallace', 44),\n",
       " ('holt', 44),\n",
       " ('risk', 43),\n",
       " ('host', 43),\n",
       " ('husband', 43),\n",
       " ('parker', 43),\n",
       " ('fischer', 43),\n",
       " ('purpose', 43),\n",
       " ('mills', 43),\n",
       " ('victor', 43),\n",
       " ('haley', 43),\n",
       " ('daughter', 43),\n",
       " ('answer', 43),\n",
       " ('simulation', 43),\n",
       " ('shellenberger', 43),\n",
       " ('aoc', 43),\n",
       " ('fan', 43),\n",
       " ('james', 43),\n",
       " ('guard', 43),\n",
       " ('historian', 43),\n",
       " ('larson', 43),\n",
       " ('schaffner', 43),\n",
       " ('bernhardt', 43),\n",
       " ('specie', 42),\n",
       " ('hunt', 42),\n",
       " ('wave', 42),\n",
       " ('mcintyre', 42),\n",
       " ('tyson', 42),\n",
       " ('declaration', 42),\n",
       " ('becerra', 42),\n",
       " ('jenkins', 42),\n",
       " ('fisherman', 42),\n",
       " ('zhang', 42),\n",
       " ('microsoft', 42),\n",
       " ('support', 42),\n",
       " ('wolf', 42),\n",
       " ('corps', 42),\n",
       " ('bridenstine', 42),\n",
       " ('marcus', 42),\n",
       " ('a decorated navy pilot who be shoot down in the pacific in 1944', 42),\n",
       " ('nordhaus', 41),\n",
       " ('ehrlich', 41),\n",
       " ('progressive', 41),\n",
       " ('park', 41),\n",
       " ('decade', 41),\n",
       " ('merck', 41),\n",
       " ('manchin', 41),\n",
       " ('europe', 41),\n",
       " ('conference', 41),\n",
       " ('barrasso', 41),\n",
       " ('show', 41),\n",
       " ('golden', 41),\n",
       " ('trial', 41),\n",
       " ('the obama administration', 41),\n",
       " ('oreskes', 41),\n",
       " ('fink', 41),\n",
       " ('success', 41),\n",
       " ('tol', 41),\n",
       " ('opinion', 41),\n",
       " ('eakin', 41),\n",
       " ('hallam', 41),\n",
       " ('burns', 41),\n",
       " ('mike bloomberg', 41),\n",
       " ('terry', 41),\n",
       " ('actress', 40),\n",
       " ('airline', 40),\n",
       " ('pipeline', 40),\n",
       " ('type', 40),\n",
       " ('chinese', 40),\n",
       " ('branch', 40),\n",
       " ('buckley', 40),\n",
       " ('levi', 40),\n",
       " ('shaw', 40),\n",
       " ('schneiderman', 40),\n",
       " ('powell', 40),\n",
       " ('boer', 40),\n",
       " ('offit', 40),\n",
       " ('sector', 40),\n",
       " ('interest', 40),\n",
       " ('diffenbaugh', 40),\n",
       " ('lawrence', 40),\n",
       " ('mabus', 40),\n",
       " ('salama', 40),\n",
       " ('kammen', 39),\n",
       " ('benefit', 39),\n",
       " ('future', 39),\n",
       " ('life', 39),\n",
       " ('mom', 39),\n",
       " ('arnold schwarzenegger', 39),\n",
       " ('lovelock', 39),\n",
       " ('vote', 39),\n",
       " ('ramanathan', 39),\n",
       " ('the new york times', 39),\n",
       " ('stephens', 39),\n",
       " ('burke', 39),\n",
       " ('cap', 39),\n",
       " ('mr. pruitt', 39),\n",
       " ('winter', 39),\n",
       " ('protest', 39),\n",
       " ('zuckerberg', 39),\n",
       " ('dixon', 39),\n",
       " ('solution', 39),\n",
       " ('richardson', 39),\n",
       " ('jerry brown', 39),\n",
       " ('horowitz', 39),\n",
       " ('hammami', 39),\n",
       " ('humanity', 38),\n",
       " ('discovery', 38),\n",
       " ('player', 38),\n",
       " ('swain', 38),\n",
       " ('monbiot', 38),\n",
       " ('agent', 38),\n",
       " ('modeling', 38),\n",
       " ('term', 38),\n",
       " ('browne', 38),\n",
       " ('bernie', 38),\n",
       " ('chu', 38),\n",
       " ('howard', 38),\n",
       " ('levy', 38),\n",
       " ('decline', 38),\n",
       " ('cole', 38),\n",
       " ('inglis', 38),\n",
       " ('hoffman', 38),\n",
       " ('jeb bush', 38),\n",
       " ('kelley', 38),\n",
       " ('hoeven', 38),\n",
       " ('homenuk', 38),\n",
       " ('leonard', 37),\n",
       " ('reason', 37),\n",
       " ...]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_main_subjs = [x['main subject lemma coref'].lower() for x in quotes if x['main subject lemma coref'] is not None]\n",
    "counted_main_subjs = Counter(all_main_subjs)\n",
    "sorted(counted_main_subjs.items(),key=lambda x:x[1],reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76401"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coref_failed_quotes = [x for x in quotes if x['main subject lemma coref'] is not None and \n",
    "                       x['main subject lemma coref'] == '-PRON-']\n",
    "len(coref_failed_quotes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12130"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_coref_failed_quotes = [x for x in coref_failed_quotes if x['main subject text'].lower() == 'he' \n",
    "                           or x['main subject text'].lower() == 'she' or \n",
    "                           x['main subject text'].lower() == 'they' or \n",
    "                           x['main subject text'].lower() == 'them' or \n",
    "                           x['main subject text'].lower() == 'her' or \n",
    "                           x['main subject text'].lower() == 'him']\n",
    "len(true_coref_failed_quotes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(446764, 434634)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "good_quotes = [q for q in quotes if q not in true_coref_failed_quotes]\n",
    "len(quotes),len(good_quotes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(good_quotes,open('good_coref_quotes.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('i', 27709),\n",
       " ('we', 15663),\n",
       " ('you', 10443),\n",
       " ('it', 9422),\n",
       " ('he', 6631),\n",
       " ('she', 3325),\n",
       " ('they', 2125),\n",
       " ('us', 302),\n",
       " ('me', 278),\n",
       " ('’s', 196),\n",
       " (\"'s\", 129),\n",
       " ('them', 32),\n",
       " ('him', 12),\n",
       " ('myself', 8),\n",
       " ('ourselves', 7),\n",
       " ('china', 7),\n",
       " ('pruitt', 7),\n",
       " ('her', 5),\n",
       " ('gore', 5),\n",
       " ('baker', 4),\n",
       " ('yang', 4),\n",
       " ('bennet', 4),\n",
       " ('johnson', 4),\n",
       " ('yourself', 4),\n",
       " ('fox', 3),\n",
       " ('christy', 3),\n",
       " ('himself', 3),\n",
       " ('jackson', 3),\n",
       " ('fisher', 3),\n",
       " ('nasa', 3),\n",
       " ('kim', 3),\n",
       " ('sanders', 3),\n",
       " ('williams', 3),\n",
       " ('nour', 2),\n",
       " ('themselves', 2),\n",
       " ('inslee', 2),\n",
       " ('ours', 2),\n",
       " ('kirschner', 2),\n",
       " ('carla', 1),\n",
       " ('aep', 1),\n",
       " ('your', 1),\n",
       " ('lujan', 1),\n",
       " ('emily', 1),\n",
       " ('li', 1),\n",
       " ('our', 1),\n",
       " ('cai', 1),\n",
       " ('lau', 1),\n",
       " ('fischer', 1),\n",
       " ('alvarado', 1),\n",
       " ('mueller', 1),\n",
       " ('hvidovre', 1),\n",
       " ('rossiter', 1),\n",
       " ('claire', 1),\n",
       " ('clemente', 1),\n",
       " ('greta', 1),\n",
       " ('romney', 1),\n",
       " ('meyer', 1),\n",
       " ('amador', 1),\n",
       " ('innocent', 1),\n",
       " ('kam', 1),\n",
       " ('jones', 1),\n",
       " ('francis', 1),\n",
       " ('cnn', 1),\n",
       " ('evans', 1),\n",
       " ('tuttle', 1),\n",
       " ('vega', 1),\n",
       " ('edwards', 1),\n",
       " ('watanabe', 1),\n",
       " ('cheney', 1),\n",
       " ('trudeau', 1),\n",
       " ('mina', 1),\n",
       " ('mann', 1),\n",
       " ('my', 1),\n",
       " ('america', 1),\n",
       " ('bahari', 1),\n",
       " ('lewis', 1)]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coref_failed_quote_subjs = [x['main subject text'].lower() for x in coref_failed_quotes]\n",
    "counted_coref_failed_subjs = Counter(coref_failed_quote_subjs)\n",
    "sorted(counted_coref_failed_subjs.items(),key=lambda x:x[1],reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6631"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "he_quotes = [x for x in coref_failed_quotes if x['main subject text'].lower() == 'he']\n",
    "len(he_quotes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'quote lemmas': ['People',\n",
       "  'free',\n",
       "  '-',\n",
       "  'ride',\n",
       "  'when',\n",
       "  '-PRON-',\n",
       "  'jump',\n",
       "  'the',\n",
       "  'turnstile',\n",
       "  'on',\n",
       "  'the',\n",
       "  'subway'],\n",
       " 'quote lemmas coref': ['People',\n",
       "  'free',\n",
       "  '-',\n",
       "  'ride',\n",
       "  'when',\n",
       "  'People',\n",
       "  'jump',\n",
       "  'the',\n",
       "  'turnstile',\n",
       "  'on',\n",
       "  'the',\n",
       "  'subway'],\n",
       " 'verb lemmas': ['say'],\n",
       " 'verb lemmas coref': ['say'],\n",
       " 'main verb lemma': 'say',\n",
       " 'main verb lemma coref': 'say',\n",
       " 'subject lemmas': ['-PRON-'],\n",
       " 'subject lemmas coref': ['-PRON-'],\n",
       " 'main subject lemma': '-PRON-',\n",
       " 'main subject lemma coref': '-PRON-',\n",
       " 'neg lemmas': None,\n",
       " 'main neg lemma': None,\n",
       " 'quote text': ['People',\n",
       "  'free',\n",
       "  '-',\n",
       "  'ride',\n",
       "  'when',\n",
       "  'they',\n",
       "  'jump',\n",
       "  'the',\n",
       "  'turnstile',\n",
       "  'on',\n",
       "  'the',\n",
       "  'subway'],\n",
       " 'verb text': ['said'],\n",
       " 'main verb text': 'said',\n",
       " 'subject text': ['he'],\n",
       " 'main subject text': 'he',\n",
       " 'is neg': None,\n",
       " 'source': 'www.washingtonpost.com/national/health-science/a-kind-of-dark-realism-why-the-climate-change-problem-is-starting-to-look-too-big-to-solve/2018/12/03/378e49e4-e75d-11e8-a939-9469f1166f9d_story.html'}"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "he_quotes[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Somewhere between 9.1k to 9.6k quotes have a negated main verb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9155"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([q for q in good_quotes if q['is neg']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9629"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([q for q in good_quotes if q['main neg lemma'] is not None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "425005"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(good_quotes)-9629"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_quote_domains = [df.loc[df.url==q['source']]['pretty_domain'].values[0] for q in good_quotes]\n",
    "# counted_quote_domains = Counter(all_quote_domains)\n",
    "# sorted(counted_quote_domains.items(),key=lambda x:x[1],reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('New York Times', 111781),\n",
       " ('Mother Jones', 43489),\n",
       " ('Fox', 34778),\n",
       " ('Washington Post', 29123),\n",
       " ('Christian Science Monitor', 29030),\n",
       " ('Breitbart', 22694),\n",
       " ('Guardian (US)', 22631),\n",
       " ('The Nation', 22467),\n",
       " ('Vox', 18943),\n",
       " ('Buzzfeed', 9161),\n",
       " ('Daily Caller', 8802),\n",
       " ('Grist', 8364),\n",
       " (\"Children's Health Defense\", 7836),\n",
       " ('Shot of Prevention', 7310),\n",
       " ('Alternet', 5988),\n",
       " ('Blaze', 5907),\n",
       " ('National Review', 5089),\n",
       " ('PJ Media', 4953),\n",
       " ('Drudgereport', 3752),\n",
       " ('USA Today', 3243),\n",
       " ('Reason', 2417),\n",
       " ('Newsweek', 2278),\n",
       " ('Quartz', 2214),\n",
       " ('The Progressive', 1822),\n",
       " ('Voices for Vaccines', 1775),\n",
       " ('The Verge', 1746),\n",
       " ('American Thinker', 1442),\n",
       " ('Democracy Now', 1398),\n",
       " ('NBC', 1313),\n",
       " ('CNS', 1309),\n",
       " ('Redstate', 1102),\n",
       " ('Sgtreport', 1095),\n",
       " ('Activist Post', 1089),\n",
       " ('Vice', 1059),\n",
       " ('New York Magazine', 1041),\n",
       " ('Infowars', 781),\n",
       " ('In These Times', 752),\n",
       " ('News With Views', 607),\n",
       " ('Citizens', 564),\n",
       " ('Hot Air', 505),\n",
       " ('The Week', 472),\n",
       " ('The American Spectator', 433),\n",
       " ('Sons of Liberty Media', 357),\n",
       " ('The American Conservative', 210),\n",
       " ('Adult Vaccines Now', 160),\n",
       " ('Independent Sentinel', 159),\n",
       " ('Conservative Daily News', 146),\n",
       " ('Liberty Unyielding', 145),\n",
       " ('Immunization Evidence', 142),\n",
       " ('Conservative Firing Line', 127),\n",
       " ('Gawker', 103),\n",
       " ('Boston Globe', 101),\n",
       " ('Commdiginews', 101),\n",
       " ('Progressives Today', 62),\n",
       " ('Daily Dot', 52),\n",
       " ('Charisma News', 46),\n",
       " ('Gateway Pundit', 34),\n",
       " ('Rare.us', 31),\n",
       " ('Conservative Treehouse', 25),\n",
       " ('Physicians for Informed Consent', 21),\n",
       " ('Grabien', 20),\n",
       " ('CBN', 20),\n",
       " ('Conservative Review', 17)]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counted_quote_domains = Counter(all_quote_domains)\n",
    "sorted(counted_quote_domains.items(),key=lambda x:x[1],reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add NER tags?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
